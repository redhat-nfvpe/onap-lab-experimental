2019-06-05 14:03:25,478 p=17240 u=mistral |  ansible-playbook-2 2.7.10
  config file = /var/lib/mistral/lab/ansible.cfg
  configured module search path = [u'/root/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules', u'/usr/share/openstack-tripleo-validations/library']
  ansible python module location = /usr/lib/python2.7/site-packages/ansible
  executable location = /usr/bin/ansible-playbook-2
  python version = 2.7.5 (default, Apr  9 2019, 14:30:50) [GCC 4.8.5 20150623 (Red Hat 4.8.5-36)]
2019-06-05 14:03:25,479 p=17240 u=mistral |  Using /var/lib/mistral/lab/ansible.cfg as config file
2019-06-05 14:03:25,486 p=17240 u=mistral |  /var/lib/mistral/lab/tripleo-ansible-inventory.yaml did not meet host_list requirements, check plugin documentation if this is unexpected
2019-06-05 14:03:25,486 p=17240 u=mistral |  /var/lib/mistral/lab/tripleo-ansible-inventory.yaml did not meet script requirements, check plugin documentation if this is unexpected
2019-06-05 14:03:25,656 p=17240 u=mistral |  statically imported: /var/lib/mistral/lab/Controller/deploy_steps_tasks.yaml
2019-06-05 14:03:25,659 p=17240 u=mistral |  statically imported: /var/lib/mistral/lab/ComputeHCI/deploy_steps_tasks.yaml
2019-06-05 14:03:25,691 p=17240 u=mistral |  statically imported: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml
2019-06-05 14:03:25,745 p=17240 u=mistral |  statically imported: /var/lib/mistral/lab/ComputeHCI/host_prep_tasks.yaml
2019-06-05 14:03:25,785 p=17240 u=mistral |  statically imported: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml
2019-06-05 14:03:25,803 p=17240 u=mistral |  statically imported: /var/lib/mistral/lab/Controller/deploy_steps_tasks.yaml
2019-06-05 14:03:25,806 p=17240 u=mistral |  statically imported: /var/lib/mistral/lab/ComputeHCI/deploy_steps_tasks.yaml
2019-06-05 14:03:25,823 p=17240 u=mistral |  statically imported: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml
2019-06-05 14:03:25,864 p=17240 u=mistral |  statically imported: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml
2019-06-05 14:03:25,881 p=17240 u=mistral |  statically imported: /var/lib/mistral/lab/Controller/deploy_steps_tasks.yaml
2019-06-05 14:03:25,885 p=17240 u=mistral |  statically imported: /var/lib/mistral/lab/ComputeHCI/deploy_steps_tasks.yaml
2019-06-05 14:03:25,897 p=17240 u=mistral |  statically imported: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml
2019-06-05 14:03:25,936 p=17240 u=mistral |  statically imported: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml
2019-06-05 14:03:25,954 p=17240 u=mistral |  statically imported: /var/lib/mistral/lab/Controller/deploy_steps_tasks.yaml
2019-06-05 14:03:25,957 p=17240 u=mistral |  statically imported: /var/lib/mistral/lab/ComputeHCI/deploy_steps_tasks.yaml
2019-06-05 14:03:25,969 p=17240 u=mistral |  statically imported: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml
2019-06-05 14:03:26,008 p=17240 u=mistral |  statically imported: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml
2019-06-05 14:03:26,026 p=17240 u=mistral |  statically imported: /var/lib/mistral/lab/Controller/deploy_steps_tasks.yaml
2019-06-05 14:03:26,029 p=17240 u=mistral |  statically imported: /var/lib/mistral/lab/ComputeHCI/deploy_steps_tasks.yaml
2019-06-05 14:03:26,058 p=17240 u=mistral |  statically imported: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml
2019-06-05 14:03:26,096 p=17240 u=mistral |  statically imported: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml
2019-06-05 14:03:26,114 p=17240 u=mistral |  statically imported: /var/lib/mistral/lab/Controller/deploy_steps_tasks.yaml
2019-06-05 14:03:26,117 p=17240 u=mistral |  statically imported: /var/lib/mistral/lab/ComputeHCI/deploy_steps_tasks.yaml
2019-06-05 14:03:26,130 p=17240 u=mistral |  statically imported: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml
2019-06-05 14:03:26,153 p=17240 u=mistral |  statically imported: /var/lib/mistral/lab/external_post_deploy_steps_tasks.yaml
2019-06-05 14:03:26,245 p=17240 u=mistral |  PLAYBOOK: deploy_steps_playbook.yaml *******************************************
2019-06-05 14:03:26,245 p=17240 u=mistral |  25 plays in /var/lib/mistral/lab/deploy_steps_playbook.yaml
2019-06-05 14:03:26,269 passlib.registry registered 'md5_crypt' handler: <class 'passlib.handlers.md5_crypt.md5_crypt'>
2019-06-05 14:03:26,273 p=17240 u=mistral |  PLAY [Gather facts from undercloud] ********************************************
2019-06-05 14:03:26,279 p=17240 u=mistral |  TASK [Gathering Facts] *********************************************************
2019-06-05 14:03:26,279 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deploy_steps_playbook.yaml:1
2019-06-05 14:03:26,280 p=17240 u=mistral |  Wednesday 05 June 2019  14:03:26 -0500 (0:00:00.049)       0:00:00.049 ******** 
2019-06-05 14:03:29,842 p=17240 u=mistral |  ok: [undercloud]
2019-06-05 14:03:29,845 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:03:29,845 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:03:29,846 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:03:29,850 p=17240 u=mistral |  PLAY [Gather facts from overcloud] *********************************************
2019-06-05 14:03:29,869 p=17240 u=mistral |  TASK [Gathering Facts] *********************************************************
2019-06-05 14:03:29,869 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deploy_steps_playbook.yaml:8
2019-06-05 14:03:29,869 p=17240 u=mistral |  Wednesday 05 June 2019  14:03:29 -0500 (0:00:03.589)       0:00:03.638 ******** 
2019-06-05 14:03:31,353 p=17240 u=mistral |  ok: [lab-controller-0]
2019-06-05 14:03:31,363 p=17240 u=mistral |  ok: [lab-computehci-0]
2019-06-05 14:03:31,365 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:03:31,365 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:03:31,365 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:03:31,369 p=17240 u=mistral |  PLAY [Load global variables] ***************************************************
2019-06-05 14:03:31,370 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:03:31,384 p=17240 u=mistral |  TASK [include_vars] ************************************************************
2019-06-05 14:03:31,384 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deploy_steps_playbook.yaml:18
2019-06-05 14:03:31,384 p=17240 u=mistral |  Wednesday 05 June 2019  14:03:31 -0500 (0:00:01.515)       0:00:05.154 ******** 
2019-06-05 14:03:31,423 p=17240 u=mistral |  ok: [lab-computehci-0] => {"ansible_facts": {"deploy_steps_max": 6, "ssh_known_hosts": {"lab-computehci-0": "[172.16.2.227]*,[lab-computehci-0.localdomain]*,[lab-computehci-0]*,[172.16.1.107]*,[lab-computehci-0.storage.localdomain]*,[lab-computehci-0.storage]*,[172.16.3.54]*,[lab-computehci-0.storagemgmt.localdomain]*,[lab-computehci-0.storagemgmt]*,[172.16.2.227]*,[lab-computehci-0.internalapi.localdomain]*,[lab-computehci-0.internalapi]*,[172.16.0.133]*,[lab-computehci-0.tenant.localdomain]*,[lab-computehci-0.tenant]*,[192.168.24.17]*,[lab-computehci-0.ctlplane.localdomain]*,[lab-computehci-0.ctlplane]*", "lab-controller-0": "[172.16.2.35]*,[lab-controller-0.localdomain]*,[lab-controller-0]*,[172.16.1.240]*,[lab-controller-0.storage.localdomain]*,[lab-controller-0.storage]*,[172.16.3.205]*,[lab-controller-0.storagemgmt.localdomain]*,[lab-controller-0.storagemgmt]*,[172.16.2.35]*,[lab-controller-0.internalapi.localdomain]*,[lab-controller-0.internalapi]*,[172.16.0.171]*,[lab-controller-0.tenant.localdomain]*,[lab-controller-0.tenant]*,[10.0.0.8]*,[lab-controller-0.external.localdomain]*,[lab-controller-0.external]*,[192.168.24.20]*,[lab-controller-0.ctlplane.localdomain]*,[lab-controller-0.ctlplane]*"}}, "ansible_included_var_files": ["/var/lib/mistral/lab/global_vars.yaml"], "changed": false}
2019-06-05 14:03:31,426 p=17240 u=mistral |  ok: [lab-controller-0] => {"ansible_facts": {"deploy_steps_max": 6, "ssh_known_hosts": {"lab-computehci-0": "[172.16.2.227]*,[lab-computehci-0.localdomain]*,[lab-computehci-0]*,[172.16.1.107]*,[lab-computehci-0.storage.localdomain]*,[lab-computehci-0.storage]*,[172.16.3.54]*,[lab-computehci-0.storagemgmt.localdomain]*,[lab-computehci-0.storagemgmt]*,[172.16.2.227]*,[lab-computehci-0.internalapi.localdomain]*,[lab-computehci-0.internalapi]*,[172.16.0.133]*,[lab-computehci-0.tenant.localdomain]*,[lab-computehci-0.tenant]*,[192.168.24.17]*,[lab-computehci-0.ctlplane.localdomain]*,[lab-computehci-0.ctlplane]*", "lab-controller-0": "[172.16.2.35]*,[lab-controller-0.localdomain]*,[lab-controller-0]*,[172.16.1.240]*,[lab-controller-0.storage.localdomain]*,[lab-controller-0.storage]*,[172.16.3.205]*,[lab-controller-0.storagemgmt.localdomain]*,[lab-controller-0.storagemgmt]*,[172.16.2.35]*,[lab-controller-0.internalapi.localdomain]*,[lab-controller-0.internalapi]*,[172.16.0.171]*,[lab-controller-0.tenant.localdomain]*,[lab-controller-0.tenant]*,[10.0.0.8]*,[lab-controller-0.external.localdomain]*,[lab-controller-0.external]*,[192.168.24.20]*,[lab-controller-0.ctlplane.localdomain]*,[lab-controller-0.ctlplane]*"}}, "ansible_included_var_files": ["/var/lib/mistral/lab/global_vars.yaml"], "changed": false}
2019-06-05 14:03:31,443 p=17240 u=mistral |  ok: [undercloud] => {"ansible_facts": {"deploy_steps_max": 6, "ssh_known_hosts": {"lab-computehci-0": "[172.16.2.227]*,[lab-computehci-0.localdomain]*,[lab-computehci-0]*,[172.16.1.107]*,[lab-computehci-0.storage.localdomain]*,[lab-computehci-0.storage]*,[172.16.3.54]*,[lab-computehci-0.storagemgmt.localdomain]*,[lab-computehci-0.storagemgmt]*,[172.16.2.227]*,[lab-computehci-0.internalapi.localdomain]*,[lab-computehci-0.internalapi]*,[172.16.0.133]*,[lab-computehci-0.tenant.localdomain]*,[lab-computehci-0.tenant]*,[192.168.24.17]*,[lab-computehci-0.ctlplane.localdomain]*,[lab-computehci-0.ctlplane]*", "lab-controller-0": "[172.16.2.35]*,[lab-controller-0.localdomain]*,[lab-controller-0]*,[172.16.1.240]*,[lab-controller-0.storage.localdomain]*,[lab-controller-0.storage]*,[172.16.3.205]*,[lab-controller-0.storagemgmt.localdomain]*,[lab-controller-0.storagemgmt]*,[172.16.2.35]*,[lab-controller-0.internalapi.localdomain]*,[lab-controller-0.internalapi]*,[172.16.0.171]*,[lab-controller-0.tenant.localdomain]*,[lab-controller-0.tenant]*,[10.0.0.8]*,[lab-controller-0.external.localdomain]*,[lab-controller-0.external]*,[192.168.24.20]*,[lab-controller-0.ctlplane.localdomain]*,[lab-controller-0.ctlplane]*"}}, "ansible_included_var_files": ["/var/lib/mistral/lab/global_vars.yaml"], "changed": false}
2019-06-05 14:03:31,443 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:03:31,444 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:03:31,447 p=17240 u=mistral |  PLAY [Manage SELinux] **********************************************************
2019-06-05 14:03:31,449 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:03:31,462 p=17240 u=mistral |  TASK [Set selinux state] *******************************************************
2019-06-05 14:03:31,462 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deploy_steps_playbook.yaml:26
2019-06-05 14:03:31,462 p=17240 u=mistral |  Wednesday 05 June 2019  14:03:31 -0500 (0:00:00.078)       0:00:05.232 ******** 
2019-06-05 14:03:31,818 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "configfile": "/etc/selinux/config", "msg": "SELinux state changed from 'permissive' to 'enforcing', Config SELinux state changed from 'permissive' to 'enforcing'", "policy": "targeted", "reboot_required": false, "state": "enforcing"}
2019-06-05 14:03:31,820 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "configfile": "/etc/selinux/config", "msg": "SELinux state changed from 'permissive' to 'enforcing', Config SELinux state changed from 'permissive' to 'enforcing'", "policy": "targeted", "reboot_required": false, "state": "enforcing"}
2019-06-05 14:03:31,828 p=17240 u=mistral |  ok: [undercloud] => {"changed": false, "configfile": "/etc/selinux/config", "msg": "", "policy": "targeted", "reboot_required": false, "state": "enforcing"}
2019-06-05 14:03:31,829 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:03:31,830 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:03:31,833 p=17240 u=mistral |  PLAY [Common roles for TripleO servers] ****************************************
2019-06-05 14:03:31,836 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:03:31,852 p=17240 u=mistral |  TASK [tripleo-bootstrap : Deploy required packages to bootstrap TripleO] *******
2019-06-05 14:03:31,852 p=17240 u=mistral |  task path: /usr/share/ansible/roles/tripleo-bootstrap/tasks/main.yml:3
2019-06-05 14:03:31,852 p=17240 u=mistral |  Wednesday 05 June 2019  14:03:31 -0500 (0:00:00.389)       0:00:05.621 ******** 
2019-06-05 14:03:32,274 p=17240 u=mistral |  ok: [lab-computehci-0] => {"changed": false, "msg": "", "rc": 0, "results": ["openstack-heat-agents-1.8.1-0.20190523203655.1e15344.el7.noarch providing openstack-heat-agents is already installed", "jq-1.5-10.el7.x86_64 providing jq is already installed"]}
2019-06-05 14:03:32,282 p=17240 u=mistral |  ok: [lab-controller-0] => {"changed": false, "msg": "", "rc": 0, "results": ["openstack-heat-agents-1.8.1-0.20190523203655.1e15344.el7.noarch providing openstack-heat-agents is already installed", "jq-1.5-10.el7.x86_64 providing jq is already installed"]}
2019-06-05 14:03:32,299 p=17240 u=mistral |  TASK [tripleo-bootstrap : Check required packages are installed] ***************
2019-06-05 14:03:32,300 p=17240 u=mistral |  task path: /usr/share/ansible/roles/tripleo-bootstrap/tasks/main.yml:9
2019-06-05 14:03:32,300 p=17240 u=mistral |  Wednesday 05 June 2019  14:03:32 -0500 (0:00:00.447)       0:00:06.069 ******** 
2019-06-05 14:03:32,499 p=17240 u=mistral |  changed: [lab-computehci-0] => (item=openstack-heat-agents) => {"changed": true, "cmd": ["rpm", "-q", "openstack-heat-agents"], "delta": "0:00:00.020237", "end": "2019-06-05 19:03:32.487605", "item": "openstack-heat-agents", "rc": 0, "start": "2019-06-05 19:03:32.467368", "stderr": "", "stderr_lines": [], "stdout": "openstack-heat-agents-1.8.1-0.20190523203655.1e15344.el7.noarch", "stdout_lines": ["openstack-heat-agents-1.8.1-0.20190523203655.1e15344.el7.noarch"], "warnings": ["Consider using the yum, dnf or zypper module rather than running 'rpm'.  If you need to use command because yum, dnf or zypper is insufficient you can add 'warn: false' to this command task or set 'command_warnings=False' in ansible.cfg to get rid of this message."]}
2019-06-05 14:03:32,503 p=17240 u=mistral |  changed: [lab-controller-0] => (item=openstack-heat-agents) => {"changed": true, "cmd": ["rpm", "-q", "openstack-heat-agents"], "delta": "0:00:00.020213", "end": "2019-06-05 19:03:32.503215", "item": "openstack-heat-agents", "rc": 0, "start": "2019-06-05 19:03:32.483002", "stderr": "", "stderr_lines": [], "stdout": "openstack-heat-agents-1.8.1-0.20190523203655.1e15344.el7.noarch", "stdout_lines": ["openstack-heat-agents-1.8.1-0.20190523203655.1e15344.el7.noarch"], "warnings": ["Consider using the yum, dnf or zypper module rather than running 'rpm'.  If you need to use command because yum, dnf or zypper is insufficient you can add 'warn: false' to this command task or set 'command_warnings=False' in ansible.cfg to get rid of this message."]}
2019-06-05 14:03:32,603 p=17240 u=mistral |  changed: [lab-computehci-0] => (item=jq) => {"changed": true, "cmd": ["rpm", "-q", "jq"], "delta": "0:00:00.019708", "end": "2019-06-05 19:03:32.594120", "item": "jq", "rc": 0, "start": "2019-06-05 19:03:32.574412", "stderr": "", "stderr_lines": [], "stdout": "jq-1.5-10.el7.x86_64", "stdout_lines": ["jq-1.5-10.el7.x86_64"], "warnings": ["Consider using the yum, dnf or zypper module rather than running 'rpm'.  If you need to use command because yum, dnf or zypper is insufficient you can add 'warn: false' to this command task or set 'command_warnings=False' in ansible.cfg to get rid of this message."]}
2019-06-05 14:03:32,604 p=17240 u=mistral |   [WARNING]: Consider using the yum, dnf or zypper module rather than running
'rpm'.  If you need to use command because yum, dnf or zypper is insufficient
you can add 'warn: false' to this command task or set 'command_warnings=False'
in ansible.cfg to get rid of this message.

2019-06-05 14:03:32,605 p=17240 u=mistral |  changed: [lab-controller-0] => (item=jq) => {"changed": true, "cmd": ["rpm", "-q", "jq"], "delta": "0:00:00.019461", "end": "2019-06-05 19:03:32.607559", "item": "jq", "rc": 0, "start": "2019-06-05 19:03:32.588098", "stderr": "", "stderr_lines": [], "stdout": "jq-1.5-10.el7.x86_64", "stdout_lines": ["jq-1.5-10.el7.x86_64"], "warnings": ["Consider using the yum, dnf or zypper module rather than running 'rpm'.  If you need to use command because yum, dnf or zypper is insufficient you can add 'warn: false' to this command task or set 'command_warnings=False' in ansible.cfg to get rid of this message."]}
2019-06-05 14:03:32,622 p=17240 u=mistral |  TASK [tripleo-bootstrap : Create /var/lib/heat-config/tripleo-config-download directory for deployment data] ***
2019-06-05 14:03:32,622 p=17240 u=mistral |  task path: /usr/share/ansible/roles/tripleo-bootstrap/tasks/main.yml:15
2019-06-05 14:03:32,622 p=17240 u=mistral |  Wednesday 05 June 2019  14:03:32 -0500 (0:00:00.322)       0:00:06.391 ******** 
2019-06-05 14:03:32,801 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "gid": 0, "group": "root", "mode": "0755", "owner": "root", "path": "/var/lib/heat-config/tripleo-config-download", "secontext": "unconfined_u:object_r:var_lib_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:03:32,803 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "gid": 0, "group": "root", "mode": "0755", "owner": "root", "path": "/var/lib/heat-config/tripleo-config-download", "secontext": "unconfined_u:object_r:var_lib_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:03:32,820 p=17240 u=mistral |  TASK [tripleo-bootstrap : Deploy network-scripts required for deprecated network service] ***
2019-06-05 14:03:32,820 p=17240 u=mistral |  task path: /usr/share/ansible/roles/tripleo-bootstrap/tasks/main.yml:33
2019-06-05 14:03:32,820 p=17240 u=mistral |  Wednesday 05 June 2019  14:03:32 -0500 (0:00:00.198)       0:00:06.590 ******** 
2019-06-05 14:03:32,840 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:03:32,847 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:03:32,864 p=17240 u=mistral |  TASK [tripleo-bootstrap : Ensure network service is enabled] *******************
2019-06-05 14:03:32,864 p=17240 u=mistral |  task path: /usr/share/ansible/roles/tripleo-bootstrap/tasks/main.yml:38
2019-06-05 14:03:32,864 p=17240 u=mistral |  Wednesday 05 June 2019  14:03:32 -0500 (0:00:00.043)       0:00:06.634 ******** 
2019-06-05 14:03:32,884 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:03:32,891 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:03:32,908 p=17240 u=mistral |  TASK [tripleo-ssh-known-hosts : Create temporary file for ssh_known_hosts] *****
2019-06-05 14:03:32,908 p=17240 u=mistral |  task path: /usr/share/ansible/roles/tripleo-ssh-known-hosts/tasks/main.yml:9
2019-06-05 14:03:32,908 p=17240 u=mistral |  Wednesday 05 June 2019  14:03:32 -0500 (0:00:00.043)       0:00:06.678 ******** 
2019-06-05 14:03:33,071 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "gid": 0, "group": "root", "mode": "0600", "owner": "root", "path": "/tmp/ansible.jLkz5C", "secontext": "unconfined_u:object_r:user_tmp_t:s0", "size": 0, "state": "file", "uid": 0}
2019-06-05 14:03:33,073 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "gid": 0, "group": "root", "mode": "0600", "owner": "root", "path": "/tmp/ansible._EvTF8", "secontext": "unconfined_u:object_r:user_tmp_t:s0", "size": 0, "state": "file", "uid": 0}
2019-06-05 14:03:33,090 p=17240 u=mistral |  TASK [tripleo-ssh-known-hosts : Create a temporary copy of ssh_known_hosts] ****
2019-06-05 14:03:33,090 p=17240 u=mistral |  task path: /usr/share/ansible/roles/tripleo-ssh-known-hosts/tasks/main.yml:13
2019-06-05 14:03:33,090 p=17240 u=mistral |  Wednesday 05 June 2019  14:03:33 -0500 (0:00:00.181)       0:00:06.859 ******** 
2019-06-05 14:03:33,196 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "cmd": "if [[ -e /etc/ssh/ssh_known_hosts ]]; then\n cat /etc/ssh/ssh_known_hosts > '/tmp/ansible.jLkz5C'\n fi", "delta": "0:00:00.002388", "end": "2019-06-05 19:03:33.199708", "rc": 0, "start": "2019-06-05 19:03:33.197320", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}
2019-06-05 14:03:33,213 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "cmd": "if [[ -e /etc/ssh/ssh_known_hosts ]]; then\n cat /etc/ssh/ssh_known_hosts > '/tmp/ansible._EvTF8'\n fi", "delta": "0:00:00.002394", "end": "2019-06-05 19:03:33.206288", "rc": 0, "start": "2019-06-05 19:03:33.203894", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}
2019-06-05 14:03:33,230 p=17240 u=mistral |  TASK [tripleo-ssh-known-hosts : Add host keys to temporary ssh_known_hosts] ****
2019-06-05 14:03:33,230 p=17240 u=mistral |  task path: /usr/share/ansible/roles/tripleo-ssh-known-hosts/tasks/main.yml:18
2019-06-05 14:03:33,230 p=17240 u=mistral |  Wednesday 05 June 2019  14:03:33 -0500 (0:00:00.140)       0:00:06.999 ******** 
2019-06-05 14:03:33,437 p=17240 u=mistral |  changed: [lab-computehci-0] => (item=lab-controller-0) => {"backup": "", "changed": true, "item": "lab-controller-0", "msg": "line added"}
2019-06-05 14:03:33,439 p=17240 u=mistral |  changed: [lab-controller-0] => (item=lab-controller-0) => {"backup": "", "changed": true, "item": "lab-controller-0", "msg": "line added"}
2019-06-05 14:03:33,548 p=17240 u=mistral |  changed: [lab-controller-0] => (item=lab-computehci-0) => {"backup": "", "changed": true, "item": "lab-computehci-0", "msg": "line added"}
2019-06-05 14:03:33,550 p=17240 u=mistral |  changed: [lab-computehci-0] => (item=lab-computehci-0) => {"backup": "", "changed": true, "item": "lab-computehci-0", "msg": "line added"}
2019-06-05 14:03:33,568 p=17240 u=mistral |  TASK [tripleo-ssh-known-hosts : In-place update of /etc/ssh_known_hosts] *******
2019-06-05 14:03:33,568 p=17240 u=mistral |  task path: /usr/share/ansible/roles/tripleo-ssh-known-hosts/tasks/main.yml:24
2019-06-05 14:03:33,568 p=17240 u=mistral |  Wednesday 05 June 2019  14:03:33 -0500 (0:00:00.338)       0:00:07.337 ******** 
2019-06-05 14:03:33,675 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "cmd": "cat '/tmp/ansible.jLkz5C' > /etc/ssh/ssh_known_hosts\n rm -f '/tmp/ansible.jLkz5C'", "delta": "0:00:00.003833", "end": "2019-06-05 19:03:33.679387", "rc": 0, "start": "2019-06-05 19:03:33.675554", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}
2019-06-05 14:03:33,693 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "cmd": "cat '/tmp/ansible._EvTF8' > /etc/ssh/ssh_known_hosts\n rm -f '/tmp/ansible._EvTF8'", "delta": "0:00:00.003823", "end": "2019-06-05 19:03:33.685356", "rc": 0, "start": "2019-06-05 19:03:33.681533", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}
2019-06-05 14:03:33,694 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:03:33,694 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:03:33,698 p=17240 u=mistral |  PLAY [Overcloud deploy step tasks for step 0] **********************************
2019-06-05 14:03:33,700 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:03:33,716 p=17240 u=mistral |  TASK [Create /var/lib/container-puppet] ****************************************
2019-06-05 14:03:33,716 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deploy_steps_playbook.yaml:58
2019-06-05 14:03:33,716 p=17240 u=mistral |  Wednesday 05 June 2019  14:03:33 -0500 (0:00:00.147)       0:00:07.485 ******** 
2019-06-05 14:03:33,821 p=17240 u=mistral |  changed: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:03:33,839 p=17240 u=mistral |  changed: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:03:33,856 p=17240 u=mistral |  TASK [Write container-puppet.py] ***********************************************
2019-06-05 14:03:33,856 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deploy_steps_playbook.yaml:61
2019-06-05 14:03:33,856 p=17240 u=mistral |  Wednesday 05 June 2019  14:03:33 -0500 (0:00:00.140)       0:00:07.625 ******** 
2019-06-05 14:03:34,278 p=17240 u=mistral |  changed: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:03:34,278 p=17240 u=mistral |  changed: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:03:34,295 p=17240 u=mistral |  TASK [Run puppet on the host to apply IPtables rules] **************************
2019-06-05 14:03:34,295 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/deploy_steps_tasks.yaml:2
2019-06-05 14:03:34,295 p=17240 u=mistral |  Wednesday 05 June 2019  14:03:34 -0500 (0:00:00.438)       0:00:08.064 ******** 
2019-06-05 14:03:34,314 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:03:34,321 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:03:34,338 p=17240 u=mistral |  TASK [configure tmpwatch on the host] ******************************************
2019-06-05 14:03:34,338 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/deploy_steps_tasks.yaml:13
2019-06-05 14:03:34,338 p=17240 u=mistral |  Wednesday 05 June 2019  14:03:34 -0500 (0:00:00.043)       0:00:08.108 ******** 
2019-06-05 14:03:34,357 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:03:34,365 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:03:34,381 p=17240 u=mistral |  TASK [create iptables service] *************************************************
2019-06-05 14:03:34,381 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/deploy_steps_tasks.yaml:27
2019-06-05 14:03:34,382 p=17240 u=mistral |  Wednesday 05 June 2019  14:03:34 -0500 (0:00:00.043)       0:00:08.151 ******** 
2019-06-05 14:03:34,409 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:03:34,665 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "checksum": "378b28e98e5dfdfad3af6fde8c6d67526fadeb7c", "dest": "/etc/systemd/system/tripleo-iptables.service", "gid": 0, "group": "root", "md5sum": "5734923c1378bc14b3b469a26d959c3e", "mode": "0644", "owner": "root", "secontext": "system_u:object_r:systemd_unit_file_t:s0", "size": 300, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559761414.41-171307712196850/source", "state": "file", "uid": 0}
2019-06-05 14:03:34,681 p=17240 u=mistral |  TASK [enable tripleo-iptables service] *****************************************
2019-06-05 14:03:34,681 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/deploy_steps_tasks.yaml:58
2019-06-05 14:03:34,681 p=17240 u=mistral |  Wednesday 05 June 2019  14:03:34 -0500 (0:00:00.299)       0:00:08.450 ******** 
2019-06-05 14:03:34,709 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:03:35,084 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "enabled": true, "name": "tripleo-iptables.service", "status": {"ActiveEnterTimestampMonotonic": "0", "ActiveExitTimestampMonotonic": "0", "ActiveState": "inactive", "After": "system.slice systemd-journald.socket basic.target", "AllowIsolate": "no", "AmbientCapabilities": "0", "AssertResult": "no", "AssertTimestampMonotonic": "0", "Before": "iptables.service shutdown.target", "BlockIOAccounting": "no", "BlockIOWeight": "18446744073709551615", "CPUAccounting": "no", "CPUQuotaPerSecUSec": "infinity", "CPUSchedulingPolicy": "0", "CPUSchedulingPriority": "0", "CPUSchedulingResetOnFork": "no", "CPUShares": "18446744073709551615", "CanIsolate": "no", "CanReload": "no", "CanStart": "yes", "CanStop": "yes", "CapabilityBoundingSet": "18446744073709551615", "ConditionResult": "no", "ConditionTimestampMonotonic": "0", "Conflicts": "shutdown.target", "ControlPID": "0", "DefaultDependencies": "yes", "Delegate": "no", "Description": "Initialize iptables", "DevicePolicy": "auto", "Environment": "BOOTUP=serial CONSOLETYPE=serial", "ExecMainCode": "0", "ExecMainExitTimestampMonotonic": "0", "ExecMainPID": "0", "ExecMainStartTimestampMonotonic": "0", "ExecMainStatus": "0", "ExecStart": "{ path=/usr/sbin/iptables ; argv[]=/usr/sbin/iptables -t raw -nL ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }", "FailureAction": "none", "FileDescriptorStoreMax": "0", "FragmentPath": "/etc/systemd/system/tripleo-iptables.service", "GuessMainPID": "yes", "IOScheduling": "0", "Id": "tripleo-iptables.service", "IgnoreOnIsolate": "no", "IgnoreOnSnapshot": "no", "IgnoreSIGPIPE": "yes", "InactiveEnterTimestampMonotonic": "0", "InactiveExitTimestampMonotonic": "0", "JobTimeoutAction": "none", "JobTimeoutUSec": "0", "KillMode": "control-group", "KillSignal": "15", "LimitAS": "18446744073709551615", "LimitCORE": "18446744073709551615", "LimitCPU": "18446744073709551615", "LimitDATA": "18446744073709551615", "LimitFSIZE": "18446744073709551615", "LimitLOCKS": "18446744073709551615", "LimitMEMLOCK": "65536", "LimitMSGQUEUE": "819200", "LimitNICE": "0", "LimitNOFILE": "4096", "LimitNPROC": "61816", "LimitRSS": "18446744073709551615", "LimitRTPRIO": "0", "LimitRTTIME": "18446744073709551615", "LimitSIGPENDING": "61816", "LimitSTACK": "18446744073709551615", "LoadState": "loaded", "MainPID": "0", "MemoryAccounting": "no", "MemoryCurrent": "18446744073709551615", "MemoryLimit": "18446744073709551615", "MountFlags": "0", "Names": "tripleo-iptables.service", "NeedDaemonReload": "no", "Nice": "0", "NoNewPrivileges": "no", "NonBlocking": "no", "NotifyAccess": "none", "OOMScoreAdjust": "0", "OnFailureJobMode": "replace", "PermissionsStartOnly": "no", "PrivateDevices": "no", "PrivateNetwork": "no", "PrivateTmp": "no", "ProtectHome": "no", "ProtectSystem": "no", "RefuseManualStart": "no", "RefuseManualStop": "no", "RemainAfterExit": "no", "Requires": "basic.target", "Restart": "no", "RestartUSec": "100ms", "Result": "success", "RootDirectoryStartOnly": "no", "RuntimeDirectoryMode": "0755", "SameProcessGroup": "no", "SecureBits": "0", "SendSIGHUP": "no", "SendSIGKILL": "yes", "Slice": "system.slice", "StandardError": "syslog", "StandardInput": "null", "StandardOutput": "syslog", "StartLimitAction": "none", "StartLimitBurst": "5", "StartLimitInterval": "10000000", "StartupBlockIOWeight": "18446744073709551615", "StartupCPUShares": "18446744073709551615", "StatusErrno": "0", "StopWhenUnneeded": "no", "SubState": "dead", "SyslogLevelPrefix": "yes", "SyslogPriority": "30", "SystemCallErrorNumber": "0", "TTYReset": "no", "TTYVHangup": "no", "TTYVTDisallocate": "no", "TasksAccounting": "no", "TasksCurrent": "18446744073709551615", "TasksMax": "18446744073709551615", "TimeoutStartUSec": "0", "TimeoutStopUSec": "1min 30s", "TimerSlackNSec": "50000", "Transient": "no", "Type": "oneshot", "UMask": "0022", "UnitFilePreset": "disabled", "UnitFileState": "disabled", "Wants": "system.slice", "WatchdogTimestampMonotonic": "0", "WatchdogUSec": "0"}}
2019-06-05 14:03:35,101 p=17240 u=mistral |  TASK [create ip6tables service] ************************************************
2019-06-05 14:03:35,101 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/deploy_steps_tasks.yaml:62
2019-06-05 14:03:35,101 p=17240 u=mistral |  Wednesday 05 June 2019  14:03:35 -0500 (0:00:00.420)       0:00:08.870 ******** 
2019-06-05 14:03:35,130 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:03:35,386 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "checksum": "d62ea484eaa71aba3113123f810c045849eb0dac", "dest": "/etc/systemd/system/tripleo-ip6tables.service", "gid": 0, "group": "root", "md5sum": "cd52f0bfc06ffad8610d82534abb7b2f", "mode": "0644", "owner": "root", "secontext": "system_u:object_r:systemd_unit_file_t:s0", "size": 304, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559761415.13-239146774617195/source", "state": "file", "uid": 0}
2019-06-05 14:03:35,403 p=17240 u=mistral |  TASK [enable tripleo-ip6tables service] ****************************************
2019-06-05 14:03:35,403 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/deploy_steps_tasks.yaml:93
2019-06-05 14:03:35,403 p=17240 u=mistral |  Wednesday 05 June 2019  14:03:35 -0500 (0:00:00.302)       0:00:09.173 ******** 
2019-06-05 14:03:35,433 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:03:35,584 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "enabled": true, "name": "tripleo-ip6tables.service", "status": {"ActiveEnterTimestampMonotonic": "0", "ActiveExitTimestampMonotonic": "0", "ActiveState": "inactive", "After": "system.slice systemd-journald.socket basic.target", "AllowIsolate": "no", "AmbientCapabilities": "0", "AssertResult": "no", "AssertTimestampMonotonic": "0", "Before": "ip6tables.service shutdown.target", "BlockIOAccounting": "no", "BlockIOWeight": "18446744073709551615", "CPUAccounting": "no", "CPUQuotaPerSecUSec": "infinity", "CPUSchedulingPolicy": "0", "CPUSchedulingPriority": "0", "CPUSchedulingResetOnFork": "no", "CPUShares": "18446744073709551615", "CanIsolate": "no", "CanReload": "no", "CanStart": "yes", "CanStop": "yes", "CapabilityBoundingSet": "18446744073709551615", "ConditionResult": "no", "ConditionTimestampMonotonic": "0", "Conflicts": "shutdown.target", "ControlPID": "0", "DefaultDependencies": "yes", "Delegate": "no", "Description": "Initialize ip6tables", "DevicePolicy": "auto", "Environment": "BOOTUP=serial CONSOLETYPE=serial", "ExecMainCode": "0", "ExecMainExitTimestampMonotonic": "0", "ExecMainPID": "0", "ExecMainStartTimestampMonotonic": "0", "ExecMainStatus": "0", "ExecStart": "{ path=/usr/sbin/ip6tables ; argv[]=/usr/sbin/ip6tables -t raw -nL ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }", "FailureAction": "none", "FileDescriptorStoreMax": "0", "FragmentPath": "/etc/systemd/system/tripleo-ip6tables.service", "GuessMainPID": "yes", "IOScheduling": "0", "Id": "tripleo-ip6tables.service", "IgnoreOnIsolate": "no", "IgnoreOnSnapshot": "no", "IgnoreSIGPIPE": "yes", "InactiveEnterTimestampMonotonic": "0", "InactiveExitTimestampMonotonic": "0", "JobTimeoutAction": "none", "JobTimeoutUSec": "0", "KillMode": "control-group", "KillSignal": "15", "LimitAS": "18446744073709551615", "LimitCORE": "18446744073709551615", "LimitCPU": "18446744073709551615", "LimitDATA": "18446744073709551615", "LimitFSIZE": "18446744073709551615", "LimitLOCKS": "18446744073709551615", "LimitMEMLOCK": "65536", "LimitMSGQUEUE": "819200", "LimitNICE": "0", "LimitNOFILE": "4096", "LimitNPROC": "61816", "LimitRSS": "18446744073709551615", "LimitRTPRIO": "0", "LimitRTTIME": "18446744073709551615", "LimitSIGPENDING": "61816", "LimitSTACK": "18446744073709551615", "LoadState": "loaded", "MainPID": "0", "MemoryAccounting": "no", "MemoryCurrent": "18446744073709551615", "MemoryLimit": "18446744073709551615", "MountFlags": "0", "Names": "tripleo-ip6tables.service", "NeedDaemonReload": "no", "Nice": "0", "NoNewPrivileges": "no", "NonBlocking": "no", "NotifyAccess": "none", "OOMScoreAdjust": "0", "OnFailureJobMode": "replace", "PermissionsStartOnly": "no", "PrivateDevices": "no", "PrivateNetwork": "no", "PrivateTmp": "no", "ProtectHome": "no", "ProtectSystem": "no", "RefuseManualStart": "no", "RefuseManualStop": "no", "RemainAfterExit": "no", "Requires": "basic.target", "Restart": "no", "RestartUSec": "100ms", "Result": "success", "RootDirectoryStartOnly": "no", "RuntimeDirectoryMode": "0755", "SameProcessGroup": "no", "SecureBits": "0", "SendSIGHUP": "no", "SendSIGKILL": "yes", "Slice": "system.slice", "StandardError": "syslog", "StandardInput": "null", "StandardOutput": "syslog", "StartLimitAction": "none", "StartLimitBurst": "5", "StartLimitInterval": "10000000", "StartupBlockIOWeight": "18446744073709551615", "StartupCPUShares": "18446744073709551615", "StatusErrno": "0", "StopWhenUnneeded": "no", "SubState": "dead", "SyslogLevelPrefix": "yes", "SyslogPriority": "30", "SystemCallErrorNumber": "0", "TTYReset": "no", "TTYVHangup": "no", "TTYVTDisallocate": "no", "TasksAccounting": "no", "TasksCurrent": "18446744073709551615", "TasksMax": "18446744073709551615", "TimeoutStartUSec": "0", "TimeoutStopUSec": "1min 30s", "TimerSlackNSec": "50000", "Transient": "no", "Type": "oneshot", "UMask": "0022", "UnitFilePreset": "disabled", "UnitFileState": "disabled", "Wants": "system.slice", "WatchdogTimestampMonotonic": "0", "WatchdogUSec": "0"}}
2019-06-05 14:03:35,602 p=17240 u=mistral |  TASK [configure tmpwatch on the host] ******************************************
2019-06-05 14:03:35,602 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/deploy_steps_tasks.yaml:2
2019-06-05 14:03:35,602 p=17240 u=mistral |  Wednesday 05 June 2019  14:03:35 -0500 (0:00:00.198)       0:00:09.371 ******** 
2019-06-05 14:03:35,621 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:03:35,631 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:03:35,647 p=17240 u=mistral |  TASK [create iptables service] *************************************************
2019-06-05 14:03:35,647 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/deploy_steps_tasks.yaml:16
2019-06-05 14:03:35,647 p=17240 u=mistral |  Wednesday 05 June 2019  14:03:35 -0500 (0:00:00.045)       0:00:09.417 ******** 
2019-06-05 14:03:35,667 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:03:35,948 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "checksum": "378b28e98e5dfdfad3af6fde8c6d67526fadeb7c", "dest": "/etc/systemd/system/tripleo-iptables.service", "gid": 0, "group": "root", "md5sum": "5734923c1378bc14b3b469a26d959c3e", "mode": "0644", "owner": "root", "secontext": "system_u:object_r:systemd_unit_file_t:s0", "size": 300, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559761415.69-276931691937120/source", "state": "file", "uid": 0}
2019-06-05 14:03:35,965 p=17240 u=mistral |  TASK [enable tripleo-iptables service] *****************************************
2019-06-05 14:03:35,965 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/deploy_steps_tasks.yaml:47
2019-06-05 14:03:35,965 p=17240 u=mistral |  Wednesday 05 June 2019  14:03:35 -0500 (0:00:00.317)       0:00:09.734 ******** 
2019-06-05 14:03:35,985 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:03:36,189 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "enabled": true, "name": "tripleo-iptables.service", "status": {"ActiveEnterTimestampMonotonic": "0", "ActiveExitTimestampMonotonic": "0", "ActiveState": "inactive", "After": "system.slice systemd-journald.socket basic.target", "AllowIsolate": "no", "AmbientCapabilities": "0", "AssertResult": "no", "AssertTimestampMonotonic": "0", "Before": "shutdown.target iptables.service", "BlockIOAccounting": "no", "BlockIOWeight": "18446744073709551615", "CPUAccounting": "no", "CPUQuotaPerSecUSec": "infinity", "CPUSchedulingPolicy": "0", "CPUSchedulingPriority": "0", "CPUSchedulingResetOnFork": "no", "CPUShares": "18446744073709551615", "CanIsolate": "no", "CanReload": "no", "CanStart": "yes", "CanStop": "yes", "CapabilityBoundingSet": "18446744073709551615", "ConditionResult": "no", "ConditionTimestampMonotonic": "0", "Conflicts": "shutdown.target", "ControlPID": "0", "DefaultDependencies": "yes", "Delegate": "no", "Description": "Initialize iptables", "DevicePolicy": "auto", "Environment": "BOOTUP=serial CONSOLETYPE=serial", "ExecMainCode": "0", "ExecMainExitTimestampMonotonic": "0", "ExecMainPID": "0", "ExecMainStartTimestampMonotonic": "0", "ExecMainStatus": "0", "ExecStart": "{ path=/usr/sbin/iptables ; argv[]=/usr/sbin/iptables -t raw -nL ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }", "FailureAction": "none", "FileDescriptorStoreMax": "0", "FragmentPath": "/etc/systemd/system/tripleo-iptables.service", "GuessMainPID": "yes", "IOScheduling": "0", "Id": "tripleo-iptables.service", "IgnoreOnIsolate": "no", "IgnoreOnSnapshot": "no", "IgnoreSIGPIPE": "yes", "InactiveEnterTimestampMonotonic": "0", "InactiveExitTimestampMonotonic": "0", "JobTimeoutAction": "none", "JobTimeoutUSec": "0", "KillMode": "control-group", "KillSignal": "15", "LimitAS": "18446744073709551615", "LimitCORE": "18446744073709551615", "LimitCPU": "18446744073709551615", "LimitDATA": "18446744073709551615", "LimitFSIZE": "18446744073709551615", "LimitLOCKS": "18446744073709551615", "LimitMEMLOCK": "65536", "LimitMSGQUEUE": "819200", "LimitNICE": "0", "LimitNOFILE": "4096", "LimitNPROC": "61816", "LimitRSS": "18446744073709551615", "LimitRTPRIO": "0", "LimitRTTIME": "18446744073709551615", "LimitSIGPENDING": "61816", "LimitSTACK": "18446744073709551615", "LoadState": "loaded", "MainPID": "0", "MemoryAccounting": "no", "MemoryCurrent": "18446744073709551615", "MemoryLimit": "18446744073709551615", "MountFlags": "0", "Names": "tripleo-iptables.service", "NeedDaemonReload": "no", "Nice": "0", "NoNewPrivileges": "no", "NonBlocking": "no", "NotifyAccess": "none", "OOMScoreAdjust": "0", "OnFailureJobMode": "replace", "PermissionsStartOnly": "no", "PrivateDevices": "no", "PrivateNetwork": "no", "PrivateTmp": "no", "ProtectHome": "no", "ProtectSystem": "no", "RefuseManualStart": "no", "RefuseManualStop": "no", "RemainAfterExit": "no", "Requires": "basic.target", "Restart": "no", "RestartUSec": "100ms", "Result": "success", "RootDirectoryStartOnly": "no", "RuntimeDirectoryMode": "0755", "SameProcessGroup": "no", "SecureBits": "0", "SendSIGHUP": "no", "SendSIGKILL": "yes", "Slice": "system.slice", "StandardError": "syslog", "StandardInput": "null", "StandardOutput": "syslog", "StartLimitAction": "none", "StartLimitBurst": "5", "StartLimitInterval": "10000000", "StartupBlockIOWeight": "18446744073709551615", "StartupCPUShares": "18446744073709551615", "StatusErrno": "0", "StopWhenUnneeded": "no", "SubState": "dead", "SyslogLevelPrefix": "yes", "SyslogPriority": "30", "SystemCallErrorNumber": "0", "TTYReset": "no", "TTYVHangup": "no", "TTYVTDisallocate": "no", "TasksAccounting": "no", "TasksCurrent": "18446744073709551615", "TasksMax": "18446744073709551615", "TimeoutStartUSec": "0", "TimeoutStopUSec": "1min 30s", "TimerSlackNSec": "50000", "Transient": "no", "Type": "oneshot", "UMask": "0022", "UnitFilePreset": "disabled", "UnitFileState": "disabled", "Wants": "system.slice", "WatchdogTimestampMonotonic": "0", "WatchdogUSec": "0"}}
2019-06-05 14:03:36,206 p=17240 u=mistral |  TASK [create ip6tables service] ************************************************
2019-06-05 14:03:36,206 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/deploy_steps_tasks.yaml:51
2019-06-05 14:03:36,206 p=17240 u=mistral |  Wednesday 05 June 2019  14:03:36 -0500 (0:00:00.240)       0:00:09.975 ******** 
2019-06-05 14:03:36,226 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:03:36,507 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "checksum": "d62ea484eaa71aba3113123f810c045849eb0dac", "dest": "/etc/systemd/system/tripleo-ip6tables.service", "gid": 0, "group": "root", "md5sum": "cd52f0bfc06ffad8610d82534abb7b2f", "mode": "0644", "owner": "root", "secontext": "system_u:object_r:systemd_unit_file_t:s0", "size": 304, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559761416.25-28649436421057/source", "state": "file", "uid": 0}
2019-06-05 14:03:36,524 p=17240 u=mistral |  TASK [enable tripleo-ip6tables service] ****************************************
2019-06-05 14:03:36,524 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/deploy_steps_tasks.yaml:82
2019-06-05 14:03:36,524 p=17240 u=mistral |  Wednesday 05 June 2019  14:03:36 -0500 (0:00:00.318)       0:00:10.294 ******** 
2019-06-05 14:03:36,543 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:03:36,719 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "enabled": true, "name": "tripleo-ip6tables.service", "status": {"ActiveEnterTimestampMonotonic": "0", "ActiveExitTimestampMonotonic": "0", "ActiveState": "inactive", "After": "system.slice basic.target systemd-journald.socket", "AllowIsolate": "no", "AmbientCapabilities": "0", "AssertResult": "no", "AssertTimestampMonotonic": "0", "Before": "shutdown.target ip6tables.service", "BlockIOAccounting": "no", "BlockIOWeight": "18446744073709551615", "CPUAccounting": "no", "CPUQuotaPerSecUSec": "infinity", "CPUSchedulingPolicy": "0", "CPUSchedulingPriority": "0", "CPUSchedulingResetOnFork": "no", "CPUShares": "18446744073709551615", "CanIsolate": "no", "CanReload": "no", "CanStart": "yes", "CanStop": "yes", "CapabilityBoundingSet": "18446744073709551615", "ConditionResult": "no", "ConditionTimestampMonotonic": "0", "Conflicts": "shutdown.target", "ControlPID": "0", "DefaultDependencies": "yes", "Delegate": "no", "Description": "Initialize ip6tables", "DevicePolicy": "auto", "Environment": "BOOTUP=serial CONSOLETYPE=serial", "ExecMainCode": "0", "ExecMainExitTimestampMonotonic": "0", "ExecMainPID": "0", "ExecMainStartTimestampMonotonic": "0", "ExecMainStatus": "0", "ExecStart": "{ path=/usr/sbin/ip6tables ; argv[]=/usr/sbin/ip6tables -t raw -nL ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }", "FailureAction": "none", "FileDescriptorStoreMax": "0", "FragmentPath": "/etc/systemd/system/tripleo-ip6tables.service", "GuessMainPID": "yes", "IOScheduling": "0", "Id": "tripleo-ip6tables.service", "IgnoreOnIsolate": "no", "IgnoreOnSnapshot": "no", "IgnoreSIGPIPE": "yes", "InactiveEnterTimestampMonotonic": "0", "InactiveExitTimestampMonotonic": "0", "JobTimeoutAction": "none", "JobTimeoutUSec": "0", "KillMode": "control-group", "KillSignal": "15", "LimitAS": "18446744073709551615", "LimitCORE": "18446744073709551615", "LimitCPU": "18446744073709551615", "LimitDATA": "18446744073709551615", "LimitFSIZE": "18446744073709551615", "LimitLOCKS": "18446744073709551615", "LimitMEMLOCK": "65536", "LimitMSGQUEUE": "819200", "LimitNICE": "0", "LimitNOFILE": "4096", "LimitNPROC": "61816", "LimitRSS": "18446744073709551615", "LimitRTPRIO": "0", "LimitRTTIME": "18446744073709551615", "LimitSIGPENDING": "61816", "LimitSTACK": "18446744073709551615", "LoadState": "loaded", "MainPID": "0", "MemoryAccounting": "no", "MemoryCurrent": "18446744073709551615", "MemoryLimit": "18446744073709551615", "MountFlags": "0", "Names": "tripleo-ip6tables.service", "NeedDaemonReload": "no", "Nice": "0", "NoNewPrivileges": "no", "NonBlocking": "no", "NotifyAccess": "none", "OOMScoreAdjust": "0", "OnFailureJobMode": "replace", "PermissionsStartOnly": "no", "PrivateDevices": "no", "PrivateNetwork": "no", "PrivateTmp": "no", "ProtectHome": "no", "ProtectSystem": "no", "RefuseManualStart": "no", "RefuseManualStop": "no", "RemainAfterExit": "no", "Requires": "basic.target", "Restart": "no", "RestartUSec": "100ms", "Result": "success", "RootDirectoryStartOnly": "no", "RuntimeDirectoryMode": "0755", "SameProcessGroup": "no", "SecureBits": "0", "SendSIGHUP": "no", "SendSIGKILL": "yes", "Slice": "system.slice", "StandardError": "syslog", "StandardInput": "null", "StandardOutput": "syslog", "StartLimitAction": "none", "StartLimitBurst": "5", "StartLimitInterval": "10000000", "StartupBlockIOWeight": "18446744073709551615", "StartupCPUShares": "18446744073709551615", "StatusErrno": "0", "StopWhenUnneeded": "no", "SubState": "dead", "SyslogLevelPrefix": "yes", "SyslogPriority": "30", "SystemCallErrorNumber": "0", "TTYReset": "no", "TTYVHangup": "no", "TTYVTDisallocate": "no", "TasksAccounting": "no", "TasksCurrent": "18446744073709551615", "TasksMax": "18446744073709551615", "TimeoutStartUSec": "0", "TimeoutStopUSec": "1min 30s", "TimerSlackNSec": "50000", "Transient": "no", "Type": "oneshot", "UMask": "0022", "UnitFilePreset": "disabled", "UnitFileState": "disabled", "Wants": "system.slice", "WatchdogTimestampMonotonic": "0", "WatchdogUSec": "0"}}
2019-06-05 14:03:36,720 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:03:36,720 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:03:36,723 p=17240 u=mistral |  PLAY [Server deployments] ******************************************************
2019-06-05 14:03:36,725 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:03:36,740 p=17240 u=mistral |  TASK [include_tasks] ***********************************************************
2019-06-05 14:03:36,740 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deploy_steps_playbook.yaml:78
2019-06-05 14:03:36,740 p=17240 u=mistral |  Wednesday 05 June 2019  14:03:36 -0500 (0:00:00.216)       0:00:10.510 ******** 
2019-06-05 14:03:36,826 p=17240 u=mistral |  included: /var/lib/mistral/lab/deployments.yaml for lab-controller-0, lab-computehci-0 => (item=NetworkDeployment)
2019-06-05 14:03:36,843 p=17240 u=mistral |  included: /var/lib/mistral/lab/deployments.yaml for lab-controller-0 => (item=ControllerDeployment)
2019-06-05 14:03:36,861 p=17240 u=mistral |  included: /var/lib/mistral/lab/deployments.yaml for lab-controller-0 => (item=ControllerHostsDeployment)
2019-06-05 14:03:36,879 p=17240 u=mistral |  included: /var/lib/mistral/lab/deployments.yaml for lab-controller-0 => (item=ControllerAllNodesDeployment)
2019-06-05 14:03:36,897 p=17240 u=mistral |  included: /var/lib/mistral/lab/deployments.yaml for lab-controller-0 => (item=ControllerAllNodesValidationDeployment)
2019-06-05 14:03:36,914 p=17240 u=mistral |  included: /var/lib/mistral/lab/deployments.yaml for lab-controller-0 => (item=ControllerArtifactsDeploy)
2019-06-05 14:03:36,932 p=17240 u=mistral |  included: /var/lib/mistral/lab/deployments.yaml for lab-computehci-0 => (item=ComputeHCIDeployment)
2019-06-05 14:03:36,949 p=17240 u=mistral |  included: /var/lib/mistral/lab/deployments.yaml for lab-computehci-0 => (item=ComputeHCIHostsDeployment)
2019-06-05 14:03:36,967 p=17240 u=mistral |  included: /var/lib/mistral/lab/deployments.yaml for lab-computehci-0 => (item=ComputeHCIAllNodesDeployment)
2019-06-05 14:03:36,985 p=17240 u=mistral |  included: /var/lib/mistral/lab/deployments.yaml for lab-computehci-0 => (item=ComputeHCIAllNodesValidationDeployment)
2019-06-05 14:03:37,002 p=17240 u=mistral |  included: /var/lib/mistral/lab/deployments.yaml for lab-computehci-0 => (item=ComputeHCIArtifactsDeploy)
2019-06-05 14:03:37,022 p=17240 u=mistral |  TASK [Lookup deployment UUID] **************************************************
2019-06-05 14:03:37,022 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:1
2019-06-05 14:03:37,022 p=17240 u=mistral |  Wednesday 05 June 2019  14:03:37 -0500 (0:00:00.281)       0:00:10.791 ******** 
2019-06-05 14:03:37,101 p=17240 u=mistral |  ok: [lab-controller-0] => {"ansible_facts": {"deployment_uuid": "bfaf691d-59c5-4a2e-9666-9bfc7cde9654"}, "changed": false}
2019-06-05 14:03:37,119 p=17240 u=mistral |  ok: [lab-computehci-0] => {"ansible_facts": {"deployment_uuid": "0486a9c2-07a4-457f-8586-654b0643bd07"}, "changed": false}
2019-06-05 14:03:37,135 p=17240 u=mistral |  TASK [Lookup deployment group] *************************************************
2019-06-05 14:03:37,135 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:5
2019-06-05 14:03:37,135 p=17240 u=mistral |  Wednesday 05 June 2019  14:03:37 -0500 (0:00:00.113)       0:00:10.904 ******** 
2019-06-05 14:03:37,214 p=17240 u=mistral |  ok: [lab-controller-0] => {"ansible_facts": {"deployment_group": "script"}, "changed": false}
2019-06-05 14:03:37,230 p=17240 u=mistral |  ok: [lab-computehci-0] => {"ansible_facts": {"deployment_group": "script"}, "changed": false}
2019-06-05 14:03:37,248 p=17240 u=mistral |  TASK [Create hiera check-mode directory] ***************************************
2019-06-05 14:03:37,248 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:13
2019-06-05 14:03:37,248 p=17240 u=mistral |  Wednesday 05 June 2019  14:03:37 -0500 (0:00:00.113)       0:00:11.017 ******** 
2019-06-05 14:03:37,268 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:03:37,276 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:03:37,293 p=17240 u=mistral |  TASK [Create deployed check-mode directory] ************************************
2019-06-05 14:03:37,293 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:19
2019-06-05 14:03:37,293 p=17240 u=mistral |  Wednesday 05 June 2019  14:03:37 -0500 (0:00:00.044)       0:00:11.062 ******** 
2019-06-05 14:03:37,313 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:03:37,320 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:03:37,337 p=17240 u=mistral |  TASK [Create tripleo-config-download check-mode directory] *********************
2019-06-05 14:03:37,337 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:25
2019-06-05 14:03:37,337 p=17240 u=mistral |  Wednesday 05 June 2019  14:03:37 -0500 (0:00:00.044)       0:00:11.107 ******** 
2019-06-05 14:03:37,357 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:03:37,364 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:03:37,382 p=17240 u=mistral |  TASK [Render deployment file for NetworkDeployment for check-mode] *************
2019-06-05 14:03:37,382 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:31
2019-06-05 14:03:37,382 p=17240 u=mistral |  Wednesday 05 June 2019  14:03:37 -0500 (0:00:00.044)       0:00:11.151 ******** 
2019-06-05 14:03:37,402 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:03:37,409 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:03:37,425 p=17240 u=mistral |  TASK [Run hiera deployment for check mode] *************************************
2019-06-05 14:03:37,425 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:38
2019-06-05 14:03:37,425 p=17240 u=mistral |  Wednesday 05 June 2019  14:03:37 -0500 (0:00:00.042)       0:00:11.194 ******** 
2019-06-05 14:03:37,445 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:03:37,453 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:03:37,469 p=17240 u=mistral |  TASK [List hieradata files for check mode] *************************************
2019-06-05 14:03:37,469 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:54
2019-06-05 14:03:37,469 p=17240 u=mistral |  Wednesday 05 June 2019  14:03:37 -0500 (0:00:00.043)       0:00:11.238 ******** 
2019-06-05 14:03:37,488 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:03:37,495 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:03:37,512 p=17240 u=mistral |  TASK [diff hieradata changes for check mode] ***********************************
2019-06-05 14:03:37,512 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:60
2019-06-05 14:03:37,512 p=17240 u=mistral |  Wednesday 05 June 2019  14:03:37 -0500 (0:00:00.042)       0:00:11.281 ******** 
2019-06-05 14:03:37,531 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:03:37,540 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:03:37,556 p=17240 u=mistral |  TASK [diff hieradata changes for check mode] ***********************************
2019-06-05 14:03:37,557 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:73
2019-06-05 14:03:37,557 p=17240 u=mistral |  Wednesday 05 June 2019  14:03:37 -0500 (0:00:00.044)       0:00:11.326 ******** 
2019-06-05 14:03:37,576 p=17240 u=mistral |  skipping: [lab-controller-0] => {}
2019-06-05 14:03:37,585 p=17240 u=mistral |  skipping: [lab-computehci-0] => {}
2019-06-05 14:03:37,601 p=17240 u=mistral |  TASK [hiera.yaml changes for check mode] ***************************************
2019-06-05 14:03:37,601 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:82
2019-06-05 14:03:37,601 p=17240 u=mistral |  Wednesday 05 June 2019  14:03:37 -0500 (0:00:00.044)       0:00:11.370 ******** 
2019-06-05 14:03:37,620 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:03:37,627 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:03:37,645 p=17240 u=mistral |  TASK [diff hiera.yaml changes for check mode] **********************************
2019-06-05 14:03:37,645 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:90
2019-06-05 14:03:37,645 p=17240 u=mistral |  Wednesday 05 June 2019  14:03:37 -0500 (0:00:00.044)       0:00:11.414 ******** 
2019-06-05 14:03:37,667 p=17240 u=mistral |  skipping: [lab-controller-0] => {}
2019-06-05 14:03:37,675 p=17240 u=mistral |  skipping: [lab-computehci-0] => {}
2019-06-05 14:03:37,693 p=17240 u=mistral |  TASK [Render deployment file for NetworkDeployment] ****************************
2019-06-05 14:03:37,693 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:102
2019-06-05 14:03:37,694 p=17240 u=mistral |  Wednesday 05 June 2019  14:03:37 -0500 (0:00:00.048)       0:00:11.463 ******** 
2019-06-05 14:03:38,049 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "checksum": "014cc68673ea2b6866b00b06168b65ea9bd7422a", "dest": "/var/lib/heat-config/tripleo-config-download/NetworkDeployment-bfaf691d-59c5-4a2e-9666-9bfc7cde9654", "gid": 0, "group": "root", "md5sum": "5ee8b119751ea22ccea2b4a94822e5fd", "mode": "0644", "owner": "root", "secontext": "system_u:object_r:var_lib_t:s0", "size": 10676, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559761417.78-81148367447008/source", "state": "file", "uid": 0}
2019-06-05 14:03:38,070 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "checksum": "919d7ec97a096038c9bf6173a12811a891df7237", "dest": "/var/lib/heat-config/tripleo-config-download/NetworkDeployment-0486a9c2-07a4-457f-8586-654b0643bd07", "gid": 0, "group": "root", "md5sum": "1a6068de7ced489f9526df6e5871c42b", "mode": "0644", "owner": "root", "secontext": "system_u:object_r:var_lib_t:s0", "size": 10328, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559761417.8-279647562200296/source", "state": "file", "uid": 0}
2019-06-05 14:03:38,088 p=17240 u=mistral |  TASK [Check if deployed file exists for NetworkDeployment] *********************
2019-06-05 14:03:38,088 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:108
2019-06-05 14:03:38,088 p=17240 u=mistral |  Wednesday 05 June 2019  14:03:38 -0500 (0:00:00.394)       0:00:11.857 ******** 
2019-06-05 14:03:38,233 p=17240 u=mistral |  ok: [lab-controller-0] => {"changed": false, "stat": {"exists": false}}
2019-06-05 14:03:38,252 p=17240 u=mistral |  ok: [lab-computehci-0] => {"changed": false, "stat": {"exists": false}}
2019-06-05 14:03:38,269 p=17240 u=mistral |  TASK [Check previous deployment rc for NetworkDeployment] **********************
2019-06-05 14:03:38,269 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:113
2019-06-05 14:03:38,269 p=17240 u=mistral |  Wednesday 05 June 2019  14:03:38 -0500 (0:00:00.181)       0:00:12.039 ******** 
2019-06-05 14:03:38,290 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:03:38,298 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:03:38,315 p=17240 u=mistral |  TASK [Remove deployed file for NetworkDeployment when previous deployment failed] ***
2019-06-05 14:03:38,315 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:121
2019-06-05 14:03:38,315 p=17240 u=mistral |  Wednesday 05 June 2019  14:03:38 -0500 (0:00:00.045)       0:00:12.085 ******** 
2019-06-05 14:03:38,335 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:03:38,343 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:03:38,361 p=17240 u=mistral |  TASK [Force remove deployed file for NetworkDeployment] ************************
2019-06-05 14:03:38,361 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:131
2019-06-05 14:03:38,361 p=17240 u=mistral |  Wednesday 05 June 2019  14:03:38 -0500 (0:00:00.045)       0:00:12.130 ******** 
2019-06-05 14:03:38,380 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:03:38,387 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:03:38,403 p=17240 u=mistral |  TASK [Set fact for async_deployment] *******************************************
2019-06-05 14:03:38,404 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:138
2019-06-05 14:03:38,404 p=17240 u=mistral |  Wednesday 05 June 2019  14:03:38 -0500 (0:00:00.042)       0:00:12.173 ******** 
2019-06-05 14:03:38,472 p=17240 u=mistral |  ok: [lab-controller-0] => {"ansible_facts": {"use_async_deployment": true}, "changed": false}
2019-06-05 14:03:38,487 p=17240 u=mistral |  ok: [lab-computehci-0] => {"ansible_facts": {"use_async_deployment": true}, "changed": false}
2019-06-05 14:03:38,504 p=17240 u=mistral |  TASK [Run deployment NetworkDeployment] ****************************************
2019-06-05 14:03:38,504 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:142
2019-06-05 14:03:38,505 p=17240 u=mistral |  Wednesday 05 June 2019  14:03:38 -0500 (0:00:00.100)       0:00:12.274 ******** 
2019-06-05 14:03:38,524 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:03:38,531 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:03:38,548 p=17240 u=mistral |  TASK [Run async deployment NetworkDeployment] **********************************
2019-06-05 14:03:38,548 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:153
2019-06-05 14:03:38,548 p=17240 u=mistral |  Wednesday 05 June 2019  14:03:38 -0500 (0:00:00.043)       0:00:12.318 ******** 
2019-06-05 14:04:02,780 p=17240 u=mistral |  changed: [lab-computehci-0] => {"ansible_job_id": "91366026800.14067", "changed": true, "cmd": "/usr/libexec/os-refresh-config/configure.d/55-heat-config\n exit $(jq .deploy_status_code /var/lib/heat-config/deployed/0486a9c2-07a4-457f-8586-654b0643bd07.notify.json)", "delta": "0:00:23.649964", "end": "2019-06-05 19:04:02.497955", "finished": 1, "rc": 0, "start": "2019-06-05 19:03:38.847991", "stderr": "[2019-06-05 19:03:38,876] (heat-config) [DEBUG] Running /usr/libexec/heat-config/hooks/script < /var/lib/heat-config/deployed/0486a9c2-07a4-457f-8586-654b0643bd07.json\n[2019-06-05 19:04:02,144] (heat-config) [INFO] |-\n  {\"deploy_stdout\": \"Trying to ping metadata IP 192.168.24.2...SUCCESS\\n\", \"deploy_stderr\": \"+ '[' -n '{\\\"network_config\\\": [{\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"192.168.24.17/24\\\"}], \\\"dns_servers\\\": [\\\"1.0.0.1\\\"], \\\"domain\\\": [], \\\"members\\\": [{\\\"mtu\\\": 1500, \\\"name\\\": \\\"nic1\\\", \\\"primary\\\": true, \\\"type\\\": \\\"interface\\\"}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"172.16.1.107/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 30}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"172.16.3.54/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 40}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"172.16.2.227/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 20}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"172.16.0.133/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 50}], \\\"mtu\\\": 1500, \\\"name\\\": \\\"bridge_name\\\", \\\"routes\\\": [{\\\"destination\\\": \\\"169.254.169.254/32\\\", \\\"nexthop\\\": \\\"192.168.24.3\\\"}, {\\\"ip_netmask\\\": \\\"169.254.169.254/32\\\", \\\"next_hop\\\": \\\"192.168.24.3\\\"}, {\\\"default\\\": true, \\\"next_hop\\\": \\\"192.168.24.1\\\"}], \\\"type\\\": \\\"ovs_bridge\\\", \\\"use_dhcp\\\": false}]}' ']'\\n+ '[' -z '' ']'\\n+ trap configure_safe_defaults EXIT\\n++ date +%Y-%m-%dT%H:%M:%S\\n+ DATETIME=2019-06-05T19:03:38\\n+ '[' -f /etc/os-net-config/config.json ']'\\n+ mkdir -p /etc/os-net-config\\n+ echo '{\\\"network_config\\\": [{\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"192.168.24.17/24\\\"}], \\\"dns_servers\\\": [\\\"1.0.0.1\\\"], \\\"domain\\\": [], \\\"members\\\": [{\\\"mtu\\\": 1500, \\\"name\\\": \\\"nic1\\\", \\\"primary\\\": true, \\\"type\\\": \\\"interface\\\"}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"172.16.1.107/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 30}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"172.16.3.54/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 40}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"172.16.2.227/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 20}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"172.16.0.133/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 50}], \\\"mtu\\\": 1500, \\\"name\\\": \\\"bridge_name\\\", \\\"routes\\\": [{\\\"destination\\\": \\\"169.254.169.254/32\\\", \\\"nexthop\\\": \\\"192.168.24.3\\\"}, {\\\"ip_netmask\\\": \\\"169.254.169.254/32\\\", \\\"next_hop\\\": \\\"192.168.24.3\\\"}, {\\\"default\\\": true, \\\"next_hop\\\": \\\"192.168.24.1\\\"}], \\\"type\\\": \\\"ovs_bridge\\\", \\\"use_dhcp\\\": false}]}'\\n++ type -t network_config_hook\\n+ '[' '' = function ']'\\n+ sed -i s/bridge_name/br-ex/ /etc/os-net-config/config.json\\n+ sed -i s/interface_name/nic1/ /etc/os-net-config/config.json\\n+ set +e\\n+ os-net-config -c /etc/os-net-config/config.json -v --detailed-exit-codes\\n[2019/06/05 07:03:39 PM] [INFO] Using config file at: /etc/os-net-config/config.json\\n[2019/06/05 07:03:39 PM] [INFO] Ifcfg net config provider created.\\n[2019/06/05 07:03:39 PM] [INFO] Not using any mapping file.\\n[2019/06/05 07:03:39 PM] [INFO] Finding active nics\\n[2019/06/05 07:03:39 PM] [INFO] eth0 is an embedded active nic\\n[2019/06/05 07:03:39 PM] [INFO] eth1 is an embedded active nic\\n[2019/06/05 07:03:39 PM] [INFO] lo is not an active nic\\n[2019/06/05 07:03:39 PM] [INFO] No DPDK mapping available in path (/var/lib/os-net-config/dpdk_mapping.yaml)\\n[2019/06/05 07:03:39 PM] [INFO] Active nics are ['eth0', 'eth1']\\n[2019/06/05 07:03:39 PM] [INFO] nic2 mapped to: eth1\\n[2019/06/05 07:03:39 PM] [INFO] nic1 mapped to: eth0\\n[2019/06/05 07:03:39 PM] [INFO] adding bridge: br-ex\\n[2019/06/05 07:03:39 PM] [INFO] adding custom route for interface: br-ex\\n[2019/06/05 07:03:39 PM] [INFO] adding interface: eth0\\n[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan30\\n[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan40\\n[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan20\\n[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan50\\n[2019/06/05 07:03:39 PM] [INFO] applying network configs...\\n[2019/06/05 07:03:39 PM] [INFO] Running ip route add default via 192.168.24.1 dev br-ex\\n[2019/06/05 07:03:39 PM] [WARNING] Error in 'ip route add default via 192.168.24.1 dev br-ex', restarting br-ex:\\nUnexpected error while running command.\\nCommand: /sbin/ip route add default via 192.168.24.1 dev br-ex\\nExit code: 1\\nStdout: u''\\nStderr: u'Cannot find device \\\"br-ex\\\"\\\\n'\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan20\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan30\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan40\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan50\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: eth0\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan20\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan30\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan40\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan50\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: br-ex\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan20\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan30\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan40\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan50\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: eth0\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on bridge: br-ex\\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/route-br-ex\\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan20\\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan40\\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan50\\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-br-ex\\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan30\\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-eth0\\n[2019/06/05 07:03:39 PM] [INFO] running ifup on bridge: br-ex\\n[2019/06/05 07:03:43 PM] [INFO] running ifup on interface: eth0\\n[2019/06/05 07:03:44 PM] [INFO] running ifup on interface: vlan20\\n[2019/06/05 07:03:48 PM] [INFO] running ifup on interface: vlan30\\n[2019/06/05 07:03:52 PM] [INFO] running ifup on interface: vlan40\\n[2019/06/05 07:03:56 PM] [INFO] running ifup on interface: vlan50\\n[2019/06/05 07:04:00 PM] [INFO] running ifup on interface: br-ex\\n[2019/06/05 07:04:00 PM] [INFO] running ifup on interface: vlan20\\n[2019/06/05 07:04:00 PM] [INFO] running ifup on interface: vlan30\\n[2019/06/05 07:04:00 PM] [INFO] running ifup on interface: vlan40\\n[2019/06/05 07:04:00 PM] [INFO] running ifup on interface: vlan50\\n[2019/06/05 07:04:01 PM] [INFO] running ifup on interface: eth0\\n[2019/06/05 07:04:01 PM] [INFO] running ifup on interface: vlan20\\n[2019/06/05 07:04:01 PM] [INFO] running ifup on interface: vlan30\\n[2019/06/05 07:04:01 PM] [INFO] running ifup on interface: vlan40\\n[2019/06/05 07:04:01 PM] [INFO] running ifup on interface: vlan50\\n+ RETVAL=2\\n+ set -e\\n+ [[ 2 == 2 ]]\\n+ ping_metadata_ip\\n++ get_metadata_ip\\n++ local METADATA_IP\\n++ for URL in os-collect-config.cfn.metadata_url os-collect-config.heat.auth_url os-collect-config.request.metadata_url os-collect-config.zaqar.auth_url\\n+++ os-apply-config --key os-collect-config.cfn.metadata_url --key-default '' --type raw\\n+++ sed -e 's|http.*://\\\\[\\\\?\\\\([^]]*\\\\)]\\\\?:.*|\\\\1|'\\n++ METADATA_IP=\\n++ '[' -n '' ']'\\n++ for URL in os-collect-config.cfn.metadata_url os-collect-config.heat.auth_url os-collect-config.request.metadata_url os-collect-config.zaqar.auth_url\\n+++ os-apply-config --key os-collect-config.heat.auth_url --key-default '' --type raw\\n+++ sed -e 's|http.*://\\\\[\\\\?\\\\([^]]*\\\\)]\\\\?:.*|\\\\1|'\\n++ METADATA_IP=\\n++ '[' -n '' ']'\\n++ for URL in os-collect-config.cfn.metadata_url os-collect-config.heat.auth_url os-collect-config.request.metadata_url os-collect-config.zaqar.auth_url\\n+++ os-apply-config --key os-collect-config.request.metadata_url --key-default '' --type raw\\n+++ sed -e 's|http.*://\\\\[\\\\?\\\\([^]]*\\\\)]\\\\?:.*|\\\\1|'\\n++ METADATA_IP=192.168.24.2\\n++ '[' -n 192.168.24.2 ']'\\n++ break\\n++ echo 192.168.24.2\\n+ local METADATA_IP=192.168.24.2\\n+ local METADATA_IP_PING_TIMEOUT=60\\n+ '[' -n 192.168.24.2 ']'\\n+ is_local_ip 192.168.24.2\\n+ local IP_TO_CHECK=192.168.24.2\\n+ ip -o a\\n+ grep 'inet6\\\\? 192.168.24.2/'\\n+ return 1\\n+ echo -n 'Trying to ping metadata IP 192.168.24.2...'\\n++ getent hosts 192.168.24.2\\n++ awk '{ print $1 }'\\n+ _IP=\\n+ _ping=ping\\n+ [[ '' =~ : ]]\\n+ local COUNT=0\\n+ ping -c 1 192.168.24.2\\n+ echo SUCCESS\\n+ '[' -f /etc/udev/rules.d/99-dhcp-all-interfaces.rules ']'\\n+ rm /etc/udev/rules.d/99-dhcp-all-interfaces.rules\\n+ '[' -f /usr/libexec/os-apply-config/templates/etc/os-net-config/config.json ']'\\n+ '[' -f /usr/libexec/os-apply-config/templates/etc/os-net-config/element_config.json ']'\\n+ configure_safe_defaults\\n+ [[ 0 == 0 ]]\\n+ return 0\\n\", \"deploy_status_code\": 0}\n\n[2019-06-05 19:04:02,144] (heat-config) [DEBUG] [2019-06-05 19:03:38,889] (heat-config) [INFO] interface_name=nic1\n[2019-06-05 19:03:38,889] (heat-config) [INFO] bridge_name=br-ex\n[2019-06-05 19:03:38,889] (heat-config) [INFO] deploy_server_id=97f857d8-5e72-44c1-aebf-24385a2d79de\n[2019-06-05 19:03:38,889] (heat-config) [INFO] deploy_action=CREATE\n[2019-06-05 19:03:38,889] (heat-config) [INFO] deploy_stack_id=lab-ComputeHCI-fvdemw2wbikn-0-ytxxbhhyujfh-NetworkDeployment-erjwligksdqs-TripleOSoftwareDeployment-yym5ejhltpmn/611e13e5-b918-4c11-a7a2-20fcc1201285\n[2019-06-05 19:03:38,889] (heat-config) [INFO] deploy_resource_name=TripleOSoftwareDeployment\n[2019-06-05 19:03:38,889] (heat-config) [INFO] deploy_signal_transport=NO_SIGNAL\n[2019-06-05 19:03:38,889] (heat-config) [DEBUG] Running /var/lib/heat-config/heat-config-script/0486a9c2-07a4-457f-8586-654b0643bd07\n[2019-06-05 19:04:02,136] (heat-config) [INFO] Trying to ping metadata IP 192.168.24.2...SUCCESS\n\n[2019-06-05 19:04:02,136] (heat-config) [DEBUG] + '[' -n '{\"network_config\": [{\"addresses\": [{\"ip_netmask\": \"192.168.24.17/24\"}], \"dns_servers\": [\"1.0.0.1\"], \"domain\": [], \"members\": [{\"mtu\": 1500, \"name\": \"nic1\", \"primary\": true, \"type\": \"interface\"}, {\"addresses\": [{\"ip_netmask\": \"172.16.1.107/24\"}], \"mtu\": 1500, \"routes\": [], \"type\": \"vlan\", \"vlan_id\": 30}, {\"addresses\": [{\"ip_netmask\": \"172.16.3.54/24\"}], \"mtu\": 1500, \"routes\": [], \"type\": \"vlan\", \"vlan_id\": 40}, {\"addresses\": [{\"ip_netmask\": \"172.16.2.227/24\"}], \"mtu\": 1500, \"routes\": [], \"type\": \"vlan\", \"vlan_id\": 20}, {\"addresses\": [{\"ip_netmask\": \"172.16.0.133/24\"}], \"mtu\": 1500, \"routes\": [], \"type\": \"vlan\", \"vlan_id\": 50}], \"mtu\": 1500, \"name\": \"bridge_name\", \"routes\": [{\"destination\": \"169.254.169.254/32\", \"nexthop\": \"192.168.24.3\"}, {\"ip_netmask\": \"169.254.169.254/32\", \"next_hop\": \"192.168.24.3\"}, {\"default\": true, \"next_hop\": \"192.168.24.1\"}], \"type\": \"ovs_bridge\", \"use_dhcp\": false}]}' ']'\n+ '[' -z '' ']'\n+ trap configure_safe_defaults EXIT\n++ date +%Y-%m-%dT%H:%M:%S\n+ DATETIME=2019-06-05T19:03:38\n+ '[' -f /etc/os-net-config/config.json ']'\n+ mkdir -p /etc/os-net-config\n+ echo '{\"network_config\": [{\"addresses\": [{\"ip_netmask\": \"192.168.24.17/24\"}], \"dns_servers\": [\"1.0.0.1\"], \"domain\": [], \"members\": [{\"mtu\": 1500, \"name\": \"nic1\", \"primary\": true, \"type\": \"interface\"}, {\"addresses\": [{\"ip_netmask\": \"172.16.1.107/24\"}], \"mtu\": 1500, \"routes\": [], \"type\": \"vlan\", \"vlan_id\": 30}, {\"addresses\": [{\"ip_netmask\": \"172.16.3.54/24\"}], \"mtu\": 1500, \"routes\": [], \"type\": \"vlan\", \"vlan_id\": 40}, {\"addresses\": [{\"ip_netmask\": \"172.16.2.227/24\"}], \"mtu\": 1500, \"routes\": [], \"type\": \"vlan\", \"vlan_id\": 20}, {\"addresses\": [{\"ip_netmask\": \"172.16.0.133/24\"}], \"mtu\": 1500, \"routes\": [], \"type\": \"vlan\", \"vlan_id\": 50}], \"mtu\": 1500, \"name\": \"bridge_name\", \"routes\": [{\"destination\": \"169.254.169.254/32\", \"nexthop\": \"192.168.24.3\"}, {\"ip_netmask\": \"169.254.169.254/32\", \"next_hop\": \"192.168.24.3\"}, {\"default\": true, \"next_hop\": \"192.168.24.1\"}], \"type\": \"ovs_bridge\", \"use_dhcp\": false}]}'\n++ type -t network_config_hook\n+ '[' '' = function ']'\n+ sed -i s/bridge_name/br-ex/ /etc/os-net-config/config.json\n+ sed -i s/interface_name/nic1/ /etc/os-net-config/config.json\n+ set +e\n+ os-net-config -c /etc/os-net-config/config.json -v --detailed-exit-codes\n[2019/06/05 07:03:39 PM] [INFO] Using config file at: /etc/os-net-config/config.json\n[2019/06/05 07:03:39 PM] [INFO] Ifcfg net config provider created.\n[2019/06/05 07:03:39 PM] [INFO] Not using any mapping file.\n[2019/06/05 07:03:39 PM] [INFO] Finding active nics\n[2019/06/05 07:03:39 PM] [INFO] eth0 is an embedded active nic\n[2019/06/05 07:03:39 PM] [INFO] eth1 is an embedded active nic\n[2019/06/05 07:03:39 PM] [INFO] lo is not an active nic\n[2019/06/05 07:03:39 PM] [INFO] No DPDK mapping available in path (/var/lib/os-net-config/dpdk_mapping.yaml)\n[2019/06/05 07:03:39 PM] [INFO] Active nics are ['eth0', 'eth1']\n[2019/06/05 07:03:39 PM] [INFO] nic2 mapped to: eth1\n[2019/06/05 07:03:39 PM] [INFO] nic1 mapped to: eth0\n[2019/06/05 07:03:39 PM] [INFO] adding bridge: br-ex\n[2019/06/05 07:03:39 PM] [INFO] adding custom route for interface: br-ex\n[2019/06/05 07:03:39 PM] [INFO] adding interface: eth0\n[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan30\n[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan40\n[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan20\n[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan50\n[2019/06/05 07:03:39 PM] [INFO] applying network configs...\n[2019/06/05 07:03:39 PM] [INFO] Running ip route add default via 192.168.24.1 dev br-ex\n[2019/06/05 07:03:39 PM] [WARNING] Error in 'ip route add default via 192.168.24.1 dev br-ex', restarting br-ex:\nUnexpected error while running command.\nCommand: /sbin/ip route add default via 192.168.24.1 dev br-ex\nExit code: 1\nStdout: u''\nStderr: u'Cannot find device \"br-ex\"\\n'\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan20\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan30\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan40\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan50\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: eth0\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan20\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan30\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan40\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan50\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: br-ex\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan20\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan30\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan40\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan50\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: eth0\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on bridge: br-ex\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/route-br-ex\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan20\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan40\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan50\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-br-ex\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan30\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-eth0\n[2019/06/05 07:03:39 PM] [INFO] running ifup on bridge: br-ex\n[2019/06/05 07:03:43 PM] [INFO] running ifup on interface: eth0\n[2019/06/05 07:03:44 PM] [INFO] running ifup on interface: vlan20\n[2019/06/05 07:03:48 PM] [INFO] running ifup on interface: vlan30\n[2019/06/05 07:03:52 PM] [INFO] running ifup on interface: vlan40\n[2019/06/05 07:03:56 PM] [INFO] running ifup on interface: vlan50\n[2019/06/05 07:04:00 PM] [INFO] running ifup on interface: br-ex\n[2019/06/05 07:04:00 PM] [INFO] running ifup on interface: vlan20\n[2019/06/05 07:04:00 PM] [INFO] running ifup on interface: vlan30\n[2019/06/05 07:04:00 PM] [INFO] running ifup on interface: vlan40\n[2019/06/05 07:04:00 PM] [INFO] running ifup on interface: vlan50\n[2019/06/05 07:04:01 PM] [INFO] running ifup on interface: eth0\n[2019/06/05 07:04:01 PM] [INFO] running ifup on interface: vlan20\n[2019/06/05 07:04:01 PM] [INFO] running ifup on interface: vlan30\n[2019/06/05 07:04:01 PM] [INFO] running ifup on interface: vlan40\n[2019/06/05 07:04:01 PM] [INFO] running ifup on interface: vlan50\n+ RETVAL=2\n+ set -e\n+ [[ 2 == 2 ]]\n+ ping_metadata_ip\n++ get_metadata_ip\n++ local METADATA_IP\n++ for URL in os-collect-config.cfn.metadata_url os-collect-config.heat.auth_url os-collect-config.request.metadata_url os-collect-config.zaqar.auth_url\n+++ os-apply-config --key os-collect-config.cfn.metadata_url --key-default '' --type raw\n+++ sed -e 's|http.*://\\[\\?\\([^]]*\\)]\\?:.*|\\1|'\n++ METADATA_IP=\n++ '[' -n '' ']'\n++ for URL in os-collect-config.cfn.metadata_url os-collect-config.heat.auth_url os-collect-config.request.metadata_url os-collect-config.zaqar.auth_url\n+++ os-apply-config --key os-collect-config.heat.auth_url --key-default '' --type raw\n+++ sed -e 's|http.*://\\[\\?\\([^]]*\\)]\\?:.*|\\1|'\n++ METADATA_IP=\n++ '[' -n '' ']'\n++ for URL in os-collect-config.cfn.metadata_url os-collect-config.heat.auth_url os-collect-config.request.metadata_url os-collect-config.zaqar.auth_url\n+++ os-apply-config --key os-collect-config.request.metadata_url --key-default '' --type raw\n+++ sed -e 's|http.*://\\[\\?\\([^]]*\\)]\\?:.*|\\1|'\n++ METADATA_IP=192.168.24.2\n++ '[' -n 192.168.24.2 ']'\n++ break\n++ echo 192.168.24.2\n+ local METADATA_IP=192.168.24.2\n+ local METADATA_IP_PING_TIMEOUT=60\n+ '[' -n 192.168.24.2 ']'\n+ is_local_ip 192.168.24.2\n+ local IP_TO_CHECK=192.168.24.2\n+ ip -o a\n+ grep 'inet6\\? 192.168.24.2/'\n+ return 1\n+ echo -n 'Trying to ping metadata IP 192.168.24.2...'\n++ getent hosts 192.168.24.2\n++ awk '{ print $1 }'\n+ _IP=\n+ _ping=ping\n+ [[ '' =~ : ]]\n+ local COUNT=0\n+ ping -c 1 192.168.24.2\n+ echo SUCCESS\n+ '[' -f /etc/udev/rules.d/99-dhcp-all-interfaces.rules ']'\n+ rm /etc/udev/rules.d/99-dhcp-all-interfaces.rules\n+ '[' -f /usr/libexec/os-apply-config/templates/etc/os-net-config/config.json ']'\n+ '[' -f /usr/libexec/os-apply-config/templates/etc/os-net-config/element_config.json ']'\n+ configure_safe_defaults\n+ [[ 0 == 0 ]]\n+ return 0\n\n[2019-06-05 19:04:02,136] (heat-config) [INFO] Completed /var/lib/heat-config/heat-config-script/0486a9c2-07a4-457f-8586-654b0643bd07\n\n[2019-06-05 19:04:02,144] (heat-config) [INFO] Completed /usr/libexec/heat-config/hooks/script\n[2019-06-05 19:04:02,145] (heat-config) [DEBUG] Running heat-config-notify /var/lib/heat-config/deployed/0486a9c2-07a4-457f-8586-654b0643bd07.json < /var/lib/heat-config/deployed/0486a9c2-07a4-457f-8586-654b0643bd07.notify.json\n[2019-06-05 19:04:02,490] (heat-config) [INFO] \n[2019-06-05 19:04:02,490] (heat-config) [DEBUG] ", "stderr_lines": ["[2019-06-05 19:03:38,876] (heat-config) [DEBUG] Running /usr/libexec/heat-config/hooks/script < /var/lib/heat-config/deployed/0486a9c2-07a4-457f-8586-654b0643bd07.json", "[2019-06-05 19:04:02,144] (heat-config) [INFO] |-", "  {\"deploy_stdout\": \"Trying to ping metadata IP 192.168.24.2...SUCCESS\\n\", \"deploy_stderr\": \"+ '[' -n '{\\\"network_config\\\": [{\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"192.168.24.17/24\\\"}], \\\"dns_servers\\\": [\\\"1.0.0.1\\\"], \\\"domain\\\": [], \\\"members\\\": [{\\\"mtu\\\": 1500, \\\"name\\\": \\\"nic1\\\", \\\"primary\\\": true, \\\"type\\\": \\\"interface\\\"}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"172.16.1.107/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 30}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"172.16.3.54/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 40}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"172.16.2.227/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 20}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"172.16.0.133/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 50}], \\\"mtu\\\": 1500, \\\"name\\\": \\\"bridge_name\\\", \\\"routes\\\": [{\\\"destination\\\": \\\"169.254.169.254/32\\\", \\\"nexthop\\\": \\\"192.168.24.3\\\"}, {\\\"ip_netmask\\\": \\\"169.254.169.254/32\\\", \\\"next_hop\\\": \\\"192.168.24.3\\\"}, {\\\"default\\\": true, \\\"next_hop\\\": \\\"192.168.24.1\\\"}], \\\"type\\\": \\\"ovs_bridge\\\", \\\"use_dhcp\\\": false}]}' ']'\\n+ '[' -z '' ']'\\n+ trap configure_safe_defaults EXIT\\n++ date +%Y-%m-%dT%H:%M:%S\\n+ DATETIME=2019-06-05T19:03:38\\n+ '[' -f /etc/os-net-config/config.json ']'\\n+ mkdir -p /etc/os-net-config\\n+ echo '{\\\"network_config\\\": [{\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"192.168.24.17/24\\\"}], \\\"dns_servers\\\": [\\\"1.0.0.1\\\"], \\\"domain\\\": [], \\\"members\\\": [{\\\"mtu\\\": 1500, \\\"name\\\": \\\"nic1\\\", \\\"primary\\\": true, \\\"type\\\": \\\"interface\\\"}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"172.16.1.107/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 30}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"172.16.3.54/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 40}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"172.16.2.227/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 20}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"172.16.0.133/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 50}], \\\"mtu\\\": 1500, \\\"name\\\": \\\"bridge_name\\\", \\\"routes\\\": [{\\\"destination\\\": \\\"169.254.169.254/32\\\", \\\"nexthop\\\": \\\"192.168.24.3\\\"}, {\\\"ip_netmask\\\": \\\"169.254.169.254/32\\\", \\\"next_hop\\\": \\\"192.168.24.3\\\"}, {\\\"default\\\": true, \\\"next_hop\\\": \\\"192.168.24.1\\\"}], \\\"type\\\": \\\"ovs_bridge\\\", \\\"use_dhcp\\\": false}]}'\\n++ type -t network_config_hook\\n+ '[' '' = function ']'\\n+ sed -i s/bridge_name/br-ex/ /etc/os-net-config/config.json\\n+ sed -i s/interface_name/nic1/ /etc/os-net-config/config.json\\n+ set +e\\n+ os-net-config -c /etc/os-net-config/config.json -v --detailed-exit-codes\\n[2019/06/05 07:03:39 PM] [INFO] Using config file at: /etc/os-net-config/config.json\\n[2019/06/05 07:03:39 PM] [INFO] Ifcfg net config provider created.\\n[2019/06/05 07:03:39 PM] [INFO] Not using any mapping file.\\n[2019/06/05 07:03:39 PM] [INFO] Finding active nics\\n[2019/06/05 07:03:39 PM] [INFO] eth0 is an embedded active nic\\n[2019/06/05 07:03:39 PM] [INFO] eth1 is an embedded active nic\\n[2019/06/05 07:03:39 PM] [INFO] lo is not an active nic\\n[2019/06/05 07:03:39 PM] [INFO] No DPDK mapping available in path (/var/lib/os-net-config/dpdk_mapping.yaml)\\n[2019/06/05 07:03:39 PM] [INFO] Active nics are ['eth0', 'eth1']\\n[2019/06/05 07:03:39 PM] [INFO] nic2 mapped to: eth1\\n[2019/06/05 07:03:39 PM] [INFO] nic1 mapped to: eth0\\n[2019/06/05 07:03:39 PM] [INFO] adding bridge: br-ex\\n[2019/06/05 07:03:39 PM] [INFO] adding custom route for interface: br-ex\\n[2019/06/05 07:03:39 PM] [INFO] adding interface: eth0\\n[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan30\\n[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan40\\n[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan20\\n[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan50\\n[2019/06/05 07:03:39 PM] [INFO] applying network configs...\\n[2019/06/05 07:03:39 PM] [INFO] Running ip route add default via 192.168.24.1 dev br-ex\\n[2019/06/05 07:03:39 PM] [WARNING] Error in 'ip route add default via 192.168.24.1 dev br-ex', restarting br-ex:\\nUnexpected error while running command.\\nCommand: /sbin/ip route add default via 192.168.24.1 dev br-ex\\nExit code: 1\\nStdout: u''\\nStderr: u'Cannot find device \\\"br-ex\\\"\\\\n'\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan20\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan30\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan40\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan50\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: eth0\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan20\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan30\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan40\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan50\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: br-ex\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan20\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan30\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan40\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan50\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: eth0\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on bridge: br-ex\\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/route-br-ex\\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan20\\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan40\\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan50\\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-br-ex\\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan30\\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-eth0\\n[2019/06/05 07:03:39 PM] [INFO] running ifup on bridge: br-ex\\n[2019/06/05 07:03:43 PM] [INFO] running ifup on interface: eth0\\n[2019/06/05 07:03:44 PM] [INFO] running ifup on interface: vlan20\\n[2019/06/05 07:03:48 PM] [INFO] running ifup on interface: vlan30\\n[2019/06/05 07:03:52 PM] [INFO] running ifup on interface: vlan40\\n[2019/06/05 07:03:56 PM] [INFO] running ifup on interface: vlan50\\n[2019/06/05 07:04:00 PM] [INFO] running ifup on interface: br-ex\\n[2019/06/05 07:04:00 PM] [INFO] running ifup on interface: vlan20\\n[2019/06/05 07:04:00 PM] [INFO] running ifup on interface: vlan30\\n[2019/06/05 07:04:00 PM] [INFO] running ifup on interface: vlan40\\n[2019/06/05 07:04:00 PM] [INFO] running ifup on interface: vlan50\\n[2019/06/05 07:04:01 PM] [INFO] running ifup on interface: eth0\\n[2019/06/05 07:04:01 PM] [INFO] running ifup on interface: vlan20\\n[2019/06/05 07:04:01 PM] [INFO] running ifup on interface: vlan30\\n[2019/06/05 07:04:01 PM] [INFO] running ifup on interface: vlan40\\n[2019/06/05 07:04:01 PM] [INFO] running ifup on interface: vlan50\\n+ RETVAL=2\\n+ set -e\\n+ [[ 2 == 2 ]]\\n+ ping_metadata_ip\\n++ get_metadata_ip\\n++ local METADATA_IP\\n++ for URL in os-collect-config.cfn.metadata_url os-collect-config.heat.auth_url os-collect-config.request.metadata_url os-collect-config.zaqar.auth_url\\n+++ os-apply-config --key os-collect-config.cfn.metadata_url --key-default '' --type raw\\n+++ sed -e 's|http.*://\\\\[\\\\?\\\\([^]]*\\\\)]\\\\?:.*|\\\\1|'\\n++ METADATA_IP=\\n++ '[' -n '' ']'\\n++ for URL in os-collect-config.cfn.metadata_url os-collect-config.heat.auth_url os-collect-config.request.metadata_url os-collect-config.zaqar.auth_url\\n+++ os-apply-config --key os-collect-config.heat.auth_url --key-default '' --type raw\\n+++ sed -e 's|http.*://\\\\[\\\\?\\\\([^]]*\\\\)]\\\\?:.*|\\\\1|'\\n++ METADATA_IP=\\n++ '[' -n '' ']'\\n++ for URL in os-collect-config.cfn.metadata_url os-collect-config.heat.auth_url os-collect-config.request.metadata_url os-collect-config.zaqar.auth_url\\n+++ os-apply-config --key os-collect-config.request.metadata_url --key-default '' --type raw\\n+++ sed -e 's|http.*://\\\\[\\\\?\\\\([^]]*\\\\)]\\\\?:.*|\\\\1|'\\n++ METADATA_IP=192.168.24.2\\n++ '[' -n 192.168.24.2 ']'\\n++ break\\n++ echo 192.168.24.2\\n+ local METADATA_IP=192.168.24.2\\n+ local METADATA_IP_PING_TIMEOUT=60\\n+ '[' -n 192.168.24.2 ']'\\n+ is_local_ip 192.168.24.2\\n+ local IP_TO_CHECK=192.168.24.2\\n+ ip -o a\\n+ grep 'inet6\\\\? 192.168.24.2/'\\n+ return 1\\n+ echo -n 'Trying to ping metadata IP 192.168.24.2...'\\n++ getent hosts 192.168.24.2\\n++ awk '{ print $1 }'\\n+ _IP=\\n+ _ping=ping\\n+ [[ '' =~ : ]]\\n+ local COUNT=0\\n+ ping -c 1 192.168.24.2\\n+ echo SUCCESS\\n+ '[' -f /etc/udev/rules.d/99-dhcp-all-interfaces.rules ']'\\n+ rm /etc/udev/rules.d/99-dhcp-all-interfaces.rules\\n+ '[' -f /usr/libexec/os-apply-config/templates/etc/os-net-config/config.json ']'\\n+ '[' -f /usr/libexec/os-apply-config/templates/etc/os-net-config/element_config.json ']'\\n+ configure_safe_defaults\\n+ [[ 0 == 0 ]]\\n+ return 0\\n\", \"deploy_status_code\": 0}", "", "[2019-06-05 19:04:02,144] (heat-config) [DEBUG] [2019-06-05 19:03:38,889] (heat-config) [INFO] interface_name=nic1", "[2019-06-05 19:03:38,889] (heat-config) [INFO] bridge_name=br-ex", "[2019-06-05 19:03:38,889] (heat-config) [INFO] deploy_server_id=97f857d8-5e72-44c1-aebf-24385a2d79de", "[2019-06-05 19:03:38,889] (heat-config) [INFO] deploy_action=CREATE", "[2019-06-05 19:03:38,889] (heat-config) [INFO] deploy_stack_id=lab-ComputeHCI-fvdemw2wbikn-0-ytxxbhhyujfh-NetworkDeployment-erjwligksdqs-TripleOSoftwareDeployment-yym5ejhltpmn/611e13e5-b918-4c11-a7a2-20fcc1201285", "[2019-06-05 19:03:38,889] (heat-config) [INFO] deploy_resource_name=TripleOSoftwareDeployment", "[2019-06-05 19:03:38,889] (heat-config) [INFO] deploy_signal_transport=NO_SIGNAL", "[2019-06-05 19:03:38,889] (heat-config) [DEBUG] Running /var/lib/heat-config/heat-config-script/0486a9c2-07a4-457f-8586-654b0643bd07", "[2019-06-05 19:04:02,136] (heat-config) [INFO] Trying to ping metadata IP 192.168.24.2...SUCCESS", "", "[2019-06-05 19:04:02,136] (heat-config) [DEBUG] + '[' -n '{\"network_config\": [{\"addresses\": [{\"ip_netmask\": \"192.168.24.17/24\"}], \"dns_servers\": [\"1.0.0.1\"], \"domain\": [], \"members\": [{\"mtu\": 1500, \"name\": \"nic1\", \"primary\": true, \"type\": \"interface\"}, {\"addresses\": [{\"ip_netmask\": \"172.16.1.107/24\"}], \"mtu\": 1500, \"routes\": [], \"type\": \"vlan\", \"vlan_id\": 30}, {\"addresses\": [{\"ip_netmask\": \"172.16.3.54/24\"}], \"mtu\": 1500, \"routes\": [], \"type\": \"vlan\", \"vlan_id\": 40}, {\"addresses\": [{\"ip_netmask\": \"172.16.2.227/24\"}], \"mtu\": 1500, \"routes\": [], \"type\": \"vlan\", \"vlan_id\": 20}, {\"addresses\": [{\"ip_netmask\": \"172.16.0.133/24\"}], \"mtu\": 1500, \"routes\": [], \"type\": \"vlan\", \"vlan_id\": 50}], \"mtu\": 1500, \"name\": \"bridge_name\", \"routes\": [{\"destination\": \"169.254.169.254/32\", \"nexthop\": \"192.168.24.3\"}, {\"ip_netmask\": \"169.254.169.254/32\", \"next_hop\": \"192.168.24.3\"}, {\"default\": true, \"next_hop\": \"192.168.24.1\"}], \"type\": \"ovs_bridge\", \"use_dhcp\": false}]}' ']'", "+ '[' -z '' ']'", "+ trap configure_safe_defaults EXIT", "++ date +%Y-%m-%dT%H:%M:%S", "+ DATETIME=2019-06-05T19:03:38", "+ '[' -f /etc/os-net-config/config.json ']'", "+ mkdir -p /etc/os-net-config", "+ echo '{\"network_config\": [{\"addresses\": [{\"ip_netmask\": \"192.168.24.17/24\"}], \"dns_servers\": [\"1.0.0.1\"], \"domain\": [], \"members\": [{\"mtu\": 1500, \"name\": \"nic1\", \"primary\": true, \"type\": \"interface\"}, {\"addresses\": [{\"ip_netmask\": \"172.16.1.107/24\"}], \"mtu\": 1500, \"routes\": [], \"type\": \"vlan\", \"vlan_id\": 30}, {\"addresses\": [{\"ip_netmask\": \"172.16.3.54/24\"}], \"mtu\": 1500, \"routes\": [], \"type\": \"vlan\", \"vlan_id\": 40}, {\"addresses\": [{\"ip_netmask\": \"172.16.2.227/24\"}], \"mtu\": 1500, \"routes\": [], \"type\": \"vlan\", \"vlan_id\": 20}, {\"addresses\": [{\"ip_netmask\": \"172.16.0.133/24\"}], \"mtu\": 1500, \"routes\": [], \"type\": \"vlan\", \"vlan_id\": 50}], \"mtu\": 1500, \"name\": \"bridge_name\", \"routes\": [{\"destination\": \"169.254.169.254/32\", \"nexthop\": \"192.168.24.3\"}, {\"ip_netmask\": \"169.254.169.254/32\", \"next_hop\": \"192.168.24.3\"}, {\"default\": true, \"next_hop\": \"192.168.24.1\"}], \"type\": \"ovs_bridge\", \"use_dhcp\": false}]}'", "++ type -t network_config_hook", "+ '[' '' = function ']'", "+ sed -i s/bridge_name/br-ex/ /etc/os-net-config/config.json", "+ sed -i s/interface_name/nic1/ /etc/os-net-config/config.json", "+ set +e", "+ os-net-config -c /etc/os-net-config/config.json -v --detailed-exit-codes", "[2019/06/05 07:03:39 PM] [INFO] Using config file at: /etc/os-net-config/config.json", "[2019/06/05 07:03:39 PM] [INFO] Ifcfg net config provider created.", "[2019/06/05 07:03:39 PM] [INFO] Not using any mapping file.", "[2019/06/05 07:03:39 PM] [INFO] Finding active nics", "[2019/06/05 07:03:39 PM] [INFO] eth0 is an embedded active nic", "[2019/06/05 07:03:39 PM] [INFO] eth1 is an embedded active nic", "[2019/06/05 07:03:39 PM] [INFO] lo is not an active nic", "[2019/06/05 07:03:39 PM] [INFO] No DPDK mapping available in path (/var/lib/os-net-config/dpdk_mapping.yaml)", "[2019/06/05 07:03:39 PM] [INFO] Active nics are ['eth0', 'eth1']", "[2019/06/05 07:03:39 PM] [INFO] nic2 mapped to: eth1", "[2019/06/05 07:03:39 PM] [INFO] nic1 mapped to: eth0", "[2019/06/05 07:03:39 PM] [INFO] adding bridge: br-ex", "[2019/06/05 07:03:39 PM] [INFO] adding custom route for interface: br-ex", "[2019/06/05 07:03:39 PM] [INFO] adding interface: eth0", "[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan30", "[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan40", "[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan20", "[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan50", "[2019/06/05 07:03:39 PM] [INFO] applying network configs...", "[2019/06/05 07:03:39 PM] [INFO] Running ip route add default via 192.168.24.1 dev br-ex", "[2019/06/05 07:03:39 PM] [WARNING] Error in 'ip route add default via 192.168.24.1 dev br-ex', restarting br-ex:", "Unexpected error while running command.", "Command: /sbin/ip route add default via 192.168.24.1 dev br-ex", "Exit code: 1", "Stdout: u''", "Stderr: u'Cannot find device \"br-ex\"\\n'", "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan20", "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan30", "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan40", "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan50", "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: eth0", "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan20", "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan30", "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan40", "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan50", "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: br-ex", "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan20", "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan30", "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan40", "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan50", "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: eth0", "[2019/06/05 07:03:39 PM] [INFO] running ifdown on bridge: br-ex", "[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/route-br-ex", "[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan20", "[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan40", "[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan50", "[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-br-ex", "[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan30", "[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-eth0", "[2019/06/05 07:03:39 PM] [INFO] running ifup on bridge: br-ex", "[2019/06/05 07:03:43 PM] [INFO] running ifup on interface: eth0", "[2019/06/05 07:03:44 PM] [INFO] running ifup on interface: vlan20", "[2019/06/05 07:03:48 PM] [INFO] running ifup on interface: vlan30", "[2019/06/05 07:03:52 PM] [INFO] running ifup on interface: vlan40", "[2019/06/05 07:03:56 PM] [INFO] running ifup on interface: vlan50", "[2019/06/05 07:04:00 PM] [INFO] running ifup on interface: br-ex", "[2019/06/05 07:04:00 PM] [INFO] running ifup on interface: vlan20", "[2019/06/05 07:04:00 PM] [INFO] running ifup on interface: vlan30", "[2019/06/05 07:04:00 PM] [INFO] running ifup on interface: vlan40", "[2019/06/05 07:04:00 PM] [INFO] running ifup on interface: vlan50", "[2019/06/05 07:04:01 PM] [INFO] running ifup on interface: eth0", "[2019/06/05 07:04:01 PM] [INFO] running ifup on interface: vlan20", "[2019/06/05 07:04:01 PM] [INFO] running ifup on interface: vlan30", "[2019/06/05 07:04:01 PM] [INFO] running ifup on interface: vlan40", "[2019/06/05 07:04:01 PM] [INFO] running ifup on interface: vlan50", "+ RETVAL=2", "+ set -e", "+ [[ 2 == 2 ]]", "+ ping_metadata_ip", "++ get_metadata_ip", "++ local METADATA_IP", "++ for URL in os-collect-config.cfn.metadata_url os-collect-config.heat.auth_url os-collect-config.request.metadata_url os-collect-config.zaqar.auth_url", "+++ os-apply-config --key os-collect-config.cfn.metadata_url --key-default '' --type raw", "+++ sed -e 's|http.*://\\[\\?\\([^]]*\\)]\\?:.*|\\1|'", "++ METADATA_IP=", "++ '[' -n '' ']'", "++ for URL in os-collect-config.cfn.metadata_url os-collect-config.heat.auth_url os-collect-config.request.metadata_url os-collect-config.zaqar.auth_url", "+++ os-apply-config --key os-collect-config.heat.auth_url --key-default '' --type raw", "+++ sed -e 's|http.*://\\[\\?\\([^]]*\\)]\\?:.*|\\1|'", "++ METADATA_IP=", "++ '[' -n '' ']'", "++ for URL in os-collect-config.cfn.metadata_url os-collect-config.heat.auth_url os-collect-config.request.metadata_url os-collect-config.zaqar.auth_url", "+++ os-apply-config --key os-collect-config.request.metadata_url --key-default '' --type raw", "+++ sed -e 's|http.*://\\[\\?\\([^]]*\\)]\\?:.*|\\1|'", "++ METADATA_IP=192.168.24.2", "++ '[' -n 192.168.24.2 ']'", "++ break", "++ echo 192.168.24.2", "+ local METADATA_IP=192.168.24.2", "+ local METADATA_IP_PING_TIMEOUT=60", "+ '[' -n 192.168.24.2 ']'", "+ is_local_ip 192.168.24.2", "+ local IP_TO_CHECK=192.168.24.2", "+ ip -o a", "+ grep 'inet6\\? 192.168.24.2/'", "+ return 1", "+ echo -n 'Trying to ping metadata IP 192.168.24.2...'", "++ getent hosts 192.168.24.2", "++ awk '{ print $1 }'", "+ _IP=", "+ _ping=ping", "+ [[ '' =~ : ]]", "+ local COUNT=0", "+ ping -c 1 192.168.24.2", "+ echo SUCCESS", "+ '[' -f /etc/udev/rules.d/99-dhcp-all-interfaces.rules ']'", "+ rm /etc/udev/rules.d/99-dhcp-all-interfaces.rules", "+ '[' -f /usr/libexec/os-apply-config/templates/etc/os-net-config/config.json ']'", "+ '[' -f /usr/libexec/os-apply-config/templates/etc/os-net-config/element_config.json ']'", "+ configure_safe_defaults", "+ [[ 0 == 0 ]]", "+ return 0", "", "[2019-06-05 19:04:02,136] (heat-config) [INFO] Completed /var/lib/heat-config/heat-config-script/0486a9c2-07a4-457f-8586-654b0643bd07", "", "[2019-06-05 19:04:02,144] (heat-config) [INFO] Completed /usr/libexec/heat-config/hooks/script", "[2019-06-05 19:04:02,145] (heat-config) [DEBUG] Running heat-config-notify /var/lib/heat-config/deployed/0486a9c2-07a4-457f-8586-654b0643bd07.json < /var/lib/heat-config/deployed/0486a9c2-07a4-457f-8586-654b0643bd07.notify.json", "[2019-06-05 19:04:02,490] (heat-config) [INFO] ", "[2019-06-05 19:04:02,490] (heat-config) [DEBUG] "], "stdout": "", "stdout_lines": []}
2019-06-05 14:04:08,940 p=17240 u=mistral |  changed: [lab-controller-0] => {"ansible_job_id": "79504109825.14043", "changed": true, "cmd": "/usr/libexec/os-refresh-config/configure.d/55-heat-config\n exit $(jq .deploy_status_code /var/lib/heat-config/deployed/bfaf691d-59c5-4a2e-9666-9bfc7cde9654.notify.json)", "delta": "0:00:28.049203", "end": "2019-06-05 19:04:06.891658", "finished": 1, "rc": 0, "start": "2019-06-05 19:03:38.842455", "stderr": "[2019-06-05 19:03:38,870] (heat-config) [DEBUG] Running /usr/libexec/heat-config/hooks/script < /var/lib/heat-config/deployed/bfaf691d-59c5-4a2e-9666-9bfc7cde9654.json\n[2019-06-05 19:04:06,534] (heat-config) [INFO] |-\n  {\"deploy_stdout\": \"Trying to ping metadata IP 192.168.24.2...SUCCESS\\n\", \"deploy_stderr\": \"+ '[' -n '{\\\"network_config\\\": [{\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"192.168.24.20/24\\\"}], \\\"dns_servers\\\": [\\\"1.0.0.1\\\"], \\\"domain\\\": [], \\\"members\\\": [{\\\"mtu\\\": 1500, \\\"name\\\": \\\"nic1\\\", \\\"primary\\\": true, \\\"type\\\": \\\"interface\\\"}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"172.16.1.240/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 30}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"172.16.3.205/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 40}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"172.16.2.35/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 20}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"172.16.0.171/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 50}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"10.0.0.8/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [{\\\"default\\\": true, \\\"next_hop\\\": \\\"10.0.0.1\\\"}], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 10}], \\\"mtu\\\": 1500, \\\"name\\\": \\\"bridge_name\\\", \\\"routes\\\": [{\\\"destination\\\": \\\"169.254.169.254/32\\\", \\\"nexthop\\\": \\\"192.168.24.3\\\"}, {\\\"ip_netmask\\\": \\\"169.254.169.254/32\\\", \\\"next_hop\\\": \\\"192.168.24.3\\\"}], \\\"type\\\": \\\"ovs_bridge\\\", \\\"use_dhcp\\\": false}]}' ']'\\n+ '[' -z '' ']'\\n+ trap configure_safe_defaults EXIT\\n++ date +%Y-%m-%dT%H:%M:%S\\n+ DATETIME=2019-06-05T19:03:38\\n+ '[' -f /etc/os-net-config/config.json ']'\\n+ mkdir -p /etc/os-net-config\\n+ echo '{\\\"network_config\\\": [{\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"192.168.24.20/24\\\"}], \\\"dns_servers\\\": [\\\"1.0.0.1\\\"], \\\"domain\\\": [], \\\"members\\\": [{\\\"mtu\\\": 1500, \\\"name\\\": \\\"nic1\\\", \\\"primary\\\": true, \\\"type\\\": \\\"interface\\\"}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"172.16.1.240/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 30}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"172.16.3.205/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 40}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"172.16.2.35/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 20}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"172.16.0.171/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 50}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"10.0.0.8/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [{\\\"default\\\": true, \\\"next_hop\\\": \\\"10.0.0.1\\\"}], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 10}], \\\"mtu\\\": 1500, \\\"name\\\": \\\"bridge_name\\\", \\\"routes\\\": [{\\\"destination\\\": \\\"169.254.169.254/32\\\", \\\"nexthop\\\": \\\"192.168.24.3\\\"}, {\\\"ip_netmask\\\": \\\"169.254.169.254/32\\\", \\\"next_hop\\\": \\\"192.168.24.3\\\"}], \\\"type\\\": \\\"ovs_bridge\\\", \\\"use_dhcp\\\": false}]}'\\n++ type -t network_config_hook\\n+ '[' '' = function ']'\\n+ sed -i s/bridge_name/br-ex/ /etc/os-net-config/config.json\\n+ sed -i s/interface_name/nic1/ /etc/os-net-config/config.json\\n+ set +e\\n+ os-net-config -c /etc/os-net-config/config.json -v --detailed-exit-codes\\n[2019/06/05 07:03:39 PM] [INFO] Using config file at: /etc/os-net-config/config.json\\n[2019/06/05 07:03:39 PM] [INFO] Ifcfg net config provider created.\\n[2019/06/05 07:03:39 PM] [INFO] Not using any mapping file.\\n[2019/06/05 07:03:39 PM] [INFO] Finding active nics\\n[2019/06/05 07:03:39 PM] [INFO] eth0 is an embedded active nic\\n[2019/06/05 07:03:39 PM] [INFO] eth1 is an embedded active nic\\n[2019/06/05 07:03:39 PM] [INFO] lo is not an active nic\\n[2019/06/05 07:03:39 PM] [INFO] No DPDK mapping available in path (/var/lib/os-net-config/dpdk_mapping.yaml)\\n[2019/06/05 07:03:39 PM] [INFO] Active nics are ['eth0', 'eth1']\\n[2019/06/05 07:03:39 PM] [INFO] nic2 mapped to: eth1\\n[2019/06/05 07:03:39 PM] [INFO] nic1 mapped to: eth0\\n[2019/06/05 07:03:39 PM] [INFO] adding bridge: br-ex\\n[2019/06/05 07:03:39 PM] [INFO] adding custom route for interface: br-ex\\n[2019/06/05 07:03:39 PM] [INFO] adding interface: eth0\\n[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan30\\n[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan40\\n[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan20\\n[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan50\\n[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan10\\n[2019/06/05 07:03:39 PM] [INFO] adding custom route for interface: vlan10\\n[2019/06/05 07:03:39 PM] [INFO] applying network configs...\\n[2019/06/05 07:03:39 PM] [INFO] Running ip route add 169.254.169.254/32 via 192.168.24.3 dev br-ex\\n[2019/06/05 07:03:39 PM] [WARNING] Error in 'ip route add 169.254.169.254/32 via 192.168.24.3 dev br-ex', restarting br-ex:\\nUnexpected error while running command.\\nCommand: /sbin/ip route add 169.254.169.254/32 via 192.168.24.3 dev br-ex\\nExit code: 1\\nStdout: u''\\nStderr: u'Cannot find device \\\"br-ex\\\"\\\\n'\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan10\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan20\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan30\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan40\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan50\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: eth0\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan10\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan20\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan30\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan40\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan50\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: br-ex\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan10\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan20\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan30\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan40\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan50\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: eth0\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on bridge: br-ex\\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/route-br-ex\\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan20\\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan40\\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan50\\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/route-vlan10\\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan10\\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-br-ex\\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan30\\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-eth0\\n[2019/06/05 07:03:39 PM] [INFO] running ifup on bridge: br-ex\\n[2019/06/05 07:03:44 PM] [INFO] running ifup on interface: eth0\\n[2019/06/05 07:03:44 PM] [INFO] running ifup on interface: vlan10\\n[2019/06/05 07:03:48 PM] [INFO] running ifup on interface: vlan20\\n[2019/06/05 07:03:52 PM] [INFO] running ifup on interface: vlan30\\n[2019/06/05 07:03:56 PM] [INFO] running ifup on interface: vlan40\\n[2019/06/05 07:04:00 PM] [INFO] running ifup on interface: vlan50\\n[2019/06/05 07:04:04 PM] [INFO] running ifup on interface: br-ex\\n[2019/06/05 07:04:04 PM] [INFO] running ifup on interface: vlan10\\n[2019/06/05 07:04:04 PM] [INFO] running ifup on interface: vlan20\\n[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: vlan30\\n[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: vlan40\\n[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: vlan50\\n[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: eth0\\n[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: vlan10\\n[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: vlan20\\n[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: vlan30\\n[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: vlan40\\n[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: vlan50\\n+ RETVAL=2\\n+ set -e\\n+ [[ 2 == 2 ]]\\n+ ping_metadata_ip\\n++ get_metadata_ip\\n++ local METADATA_IP\\n++ for URL in os-collect-config.cfn.metadata_url os-collect-config.heat.auth_url os-collect-config.request.metadata_url os-collect-config.zaqar.auth_url\\n+++ os-apply-config --key os-collect-config.cfn.metadata_url --key-default '' --type raw\\n+++ sed -e 's|http.*://\\\\[\\\\?\\\\([^]]*\\\\)]\\\\?:.*|\\\\1|'\\n++ METADATA_IP=\\n++ '[' -n '' ']'\\n++ for URL in os-collect-config.cfn.metadata_url os-collect-config.heat.auth_url os-collect-config.request.metadata_url os-collect-config.zaqar.auth_url\\n+++ os-apply-config --key os-collect-config.heat.auth_url --key-default '' --type raw\\n+++ sed -e 's|http.*://\\\\[\\\\?\\\\([^]]*\\\\)]\\\\?:.*|\\\\1|'\\n++ METADATA_IP=\\n++ '[' -n '' ']'\\n++ for URL in os-collect-config.cfn.metadata_url os-collect-config.heat.auth_url os-collect-config.request.metadata_url os-collect-config.zaqar.auth_url\\n+++ os-apply-config --key os-collect-config.request.metadata_url --key-default '' --type raw\\n+++ sed -e 's|http.*://\\\\[\\\\?\\\\([^]]*\\\\)]\\\\?:.*|\\\\1|'\\n++ METADATA_IP=192.168.24.2\\n++ '[' -n 192.168.24.2 ']'\\n++ break\\n++ echo 192.168.24.2\\n+ local METADATA_IP=192.168.24.2\\n+ local METADATA_IP_PING_TIMEOUT=60\\n+ '[' -n 192.168.24.2 ']'\\n+ is_local_ip 192.168.24.2\\n+ local IP_TO_CHECK=192.168.24.2\\n+ ip -o a\\n+ grep 'inet6\\\\? 192.168.24.2/'\\n+ return 1\\n+ echo -n 'Trying to ping metadata IP 192.168.24.2...'\\n++ getent hosts 192.168.24.2\\n++ awk '{ print $1 }'\\n+ _IP=\\n+ _ping=ping\\n+ [[ '' =~ : ]]\\n+ local COUNT=0\\n+ ping -c 1 192.168.24.2\\n+ echo SUCCESS\\n+ '[' -f /etc/udev/rules.d/99-dhcp-all-interfaces.rules ']'\\n+ rm /etc/udev/rules.d/99-dhcp-all-interfaces.rules\\n+ '[' -f /usr/libexec/os-apply-config/templates/etc/os-net-config/config.json ']'\\n+ '[' -f /usr/libexec/os-apply-config/templates/etc/os-net-config/element_config.json ']'\\n+ configure_safe_defaults\\n+ [[ 0 == 0 ]]\\n+ return 0\\n\", \"deploy_status_code\": 0}\n\n[2019-06-05 19:04:06,534] (heat-config) [DEBUG] [2019-06-05 19:03:38,883] (heat-config) [INFO] interface_name=nic1\n[2019-06-05 19:03:38,883] (heat-config) [INFO] bridge_name=br-ex\n[2019-06-05 19:03:38,883] (heat-config) [INFO] deploy_server_id=cd2dbcc8-25c9-489f-9138-43515c089a76\n[2019-06-05 19:03:38,883] (heat-config) [INFO] deploy_action=CREATE\n[2019-06-05 19:03:38,883] (heat-config) [INFO] deploy_stack_id=lab-Controller-mmbfn4kct2xh-0-jymrphsrfe7m-NetworkDeployment-4gv4gbacpozu-TripleOSoftwareDeployment-ntf3k2t7b7xi/24c204ab-a8c9-4ac9-95a0-eeeeddccb59d\n[2019-06-05 19:03:38,883] (heat-config) [INFO] deploy_resource_name=TripleOSoftwareDeployment\n[2019-06-05 19:03:38,883] (heat-config) [INFO] deploy_signal_transport=NO_SIGNAL\n[2019-06-05 19:03:38,884] (heat-config) [DEBUG] Running /var/lib/heat-config/heat-config-script/bfaf691d-59c5-4a2e-9666-9bfc7cde9654\n[2019-06-05 19:04:06,526] (heat-config) [INFO] Trying to ping metadata IP 192.168.24.2...SUCCESS\n\n[2019-06-05 19:04:06,526] (heat-config) [DEBUG] + '[' -n '{\"network_config\": [{\"addresses\": [{\"ip_netmask\": \"192.168.24.20/24\"}], \"dns_servers\": [\"1.0.0.1\"], \"domain\": [], \"members\": [{\"mtu\": 1500, \"name\": \"nic1\", \"primary\": true, \"type\": \"interface\"}, {\"addresses\": [{\"ip_netmask\": \"172.16.1.240/24\"}], \"mtu\": 1500, \"routes\": [], \"type\": \"vlan\", \"vlan_id\": 30}, {\"addresses\": [{\"ip_netmask\": \"172.16.3.205/24\"}], \"mtu\": 1500, \"routes\": [], \"type\": \"vlan\", \"vlan_id\": 40}, {\"addresses\": [{\"ip_netmask\": \"172.16.2.35/24\"}], \"mtu\": 1500, \"routes\": [], \"type\": \"vlan\", \"vlan_id\": 20}, {\"addresses\": [{\"ip_netmask\": \"172.16.0.171/24\"}], \"mtu\": 1500, \"routes\": [], \"type\": \"vlan\", \"vlan_id\": 50}, {\"addresses\": [{\"ip_netmask\": \"10.0.0.8/24\"}], \"mtu\": 1500, \"routes\": [{\"default\": true, \"next_hop\": \"10.0.0.1\"}], \"type\": \"vlan\", \"vlan_id\": 10}], \"mtu\": 1500, \"name\": \"bridge_name\", \"routes\": [{\"destination\": \"169.254.169.254/32\", \"nexthop\": \"192.168.24.3\"}, {\"ip_netmask\": \"169.254.169.254/32\", \"next_hop\": \"192.168.24.3\"}], \"type\": \"ovs_bridge\", \"use_dhcp\": false}]}' ']'\n+ '[' -z '' ']'\n+ trap configure_safe_defaults EXIT\n++ date +%Y-%m-%dT%H:%M:%S\n+ DATETIME=2019-06-05T19:03:38\n+ '[' -f /etc/os-net-config/config.json ']'\n+ mkdir -p /etc/os-net-config\n+ echo '{\"network_config\": [{\"addresses\": [{\"ip_netmask\": \"192.168.24.20/24\"}], \"dns_servers\": [\"1.0.0.1\"], \"domain\": [], \"members\": [{\"mtu\": 1500, \"name\": \"nic1\", \"primary\": true, \"type\": \"interface\"}, {\"addresses\": [{\"ip_netmask\": \"172.16.1.240/24\"}], \"mtu\": 1500, \"routes\": [], \"type\": \"vlan\", \"vlan_id\": 30}, {\"addresses\": [{\"ip_netmask\": \"172.16.3.205/24\"}], \"mtu\": 1500, \"routes\": [], \"type\": \"vlan\", \"vlan_id\": 40}, {\"addresses\": [{\"ip_netmask\": \"172.16.2.35/24\"}], \"mtu\": 1500, \"routes\": [], \"type\": \"vlan\", \"vlan_id\": 20}, {\"addresses\": [{\"ip_netmask\": \"172.16.0.171/24\"}], \"mtu\": 1500, \"routes\": [], \"type\": \"vlan\", \"vlan_id\": 50}, {\"addresses\": [{\"ip_netmask\": \"10.0.0.8/24\"}], \"mtu\": 1500, \"routes\": [{\"default\": true, \"next_hop\": \"10.0.0.1\"}], \"type\": \"vlan\", \"vlan_id\": 10}], \"mtu\": 1500, \"name\": \"bridge_name\", \"routes\": [{\"destination\": \"169.254.169.254/32\", \"nexthop\": \"192.168.24.3\"}, {\"ip_netmask\": \"169.254.169.254/32\", \"next_hop\": \"192.168.24.3\"}], \"type\": \"ovs_bridge\", \"use_dhcp\": false}]}'\n++ type -t network_config_hook\n+ '[' '' = function ']'\n+ sed -i s/bridge_name/br-ex/ /etc/os-net-config/config.json\n+ sed -i s/interface_name/nic1/ /etc/os-net-config/config.json\n+ set +e\n+ os-net-config -c /etc/os-net-config/config.json -v --detailed-exit-codes\n[2019/06/05 07:03:39 PM] [INFO] Using config file at: /etc/os-net-config/config.json\n[2019/06/05 07:03:39 PM] [INFO] Ifcfg net config provider created.\n[2019/06/05 07:03:39 PM] [INFO] Not using any mapping file.\n[2019/06/05 07:03:39 PM] [INFO] Finding active nics\n[2019/06/05 07:03:39 PM] [INFO] eth0 is an embedded active nic\n[2019/06/05 07:03:39 PM] [INFO] eth1 is an embedded active nic\n[2019/06/05 07:03:39 PM] [INFO] lo is not an active nic\n[2019/06/05 07:03:39 PM] [INFO] No DPDK mapping available in path (/var/lib/os-net-config/dpdk_mapping.yaml)\n[2019/06/05 07:03:39 PM] [INFO] Active nics are ['eth0', 'eth1']\n[2019/06/05 07:03:39 PM] [INFO] nic2 mapped to: eth1\n[2019/06/05 07:03:39 PM] [INFO] nic1 mapped to: eth0\n[2019/06/05 07:03:39 PM] [INFO] adding bridge: br-ex\n[2019/06/05 07:03:39 PM] [INFO] adding custom route for interface: br-ex\n[2019/06/05 07:03:39 PM] [INFO] adding interface: eth0\n[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan30\n[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan40\n[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan20\n[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan50\n[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan10\n[2019/06/05 07:03:39 PM] [INFO] adding custom route for interface: vlan10\n[2019/06/05 07:03:39 PM] [INFO] applying network configs...\n[2019/06/05 07:03:39 PM] [INFO] Running ip route add 169.254.169.254/32 via 192.168.24.3 dev br-ex\n[2019/06/05 07:03:39 PM] [WARNING] Error in 'ip route add 169.254.169.254/32 via 192.168.24.3 dev br-ex', restarting br-ex:\nUnexpected error while running command.\nCommand: /sbin/ip route add 169.254.169.254/32 via 192.168.24.3 dev br-ex\nExit code: 1\nStdout: u''\nStderr: u'Cannot find device \"br-ex\"\\n'\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan10\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan20\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan30\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan40\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan50\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: eth0\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan10\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan20\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan30\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan40\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan50\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: br-ex\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan10\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan20\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan30\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan40\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan50\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: eth0\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on bridge: br-ex\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/route-br-ex\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan20\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan40\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan50\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/route-vlan10\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan10\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-br-ex\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan30\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-eth0\n[2019/06/05 07:03:39 PM] [INFO] running ifup on bridge: br-ex\n[2019/06/05 07:03:44 PM] [INFO] running ifup on interface: eth0\n[2019/06/05 07:03:44 PM] [INFO] running ifup on interface: vlan10\n[2019/06/05 07:03:48 PM] [INFO] running ifup on interface: vlan20\n[2019/06/05 07:03:52 PM] [INFO] running ifup on interface: vlan30\n[2019/06/05 07:03:56 PM] [INFO] running ifup on interface: vlan40\n[2019/06/05 07:04:00 PM] [INFO] running ifup on interface: vlan50\n[2019/06/05 07:04:04 PM] [INFO] running ifup on interface: br-ex\n[2019/06/05 07:04:04 PM] [INFO] running ifup on interface: vlan10\n[2019/06/05 07:04:04 PM] [INFO] running ifup on interface: vlan20\n[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: vlan30\n[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: vlan40\n[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: vlan50\n[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: eth0\n[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: vlan10\n[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: vlan20\n[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: vlan30\n[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: vlan40\n[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: vlan50\n+ RETVAL=2\n+ set -e\n+ [[ 2 == 2 ]]\n+ ping_metadata_ip\n++ get_metadata_ip\n++ local METADATA_IP\n++ for URL in os-collect-config.cfn.metadata_url os-collect-config.heat.auth_url os-collect-config.request.metadata_url os-collect-config.zaqar.auth_url\n+++ os-apply-config --key os-collect-config.cfn.metadata_url --key-default '' --type raw\n+++ sed -e 's|http.*://\\[\\?\\([^]]*\\)]\\?:.*|\\1|'\n++ METADATA_IP=\n++ '[' -n '' ']'\n++ for URL in os-collect-config.cfn.metadata_url os-collect-config.heat.auth_url os-collect-config.request.metadata_url os-collect-config.zaqar.auth_url\n+++ os-apply-config --key os-collect-config.heat.auth_url --key-default '' --type raw\n+++ sed -e 's|http.*://\\[\\?\\([^]]*\\)]\\?:.*|\\1|'\n++ METADATA_IP=\n++ '[' -n '' ']'\n++ for URL in os-collect-config.cfn.metadata_url os-collect-config.heat.auth_url os-collect-config.request.metadata_url os-collect-config.zaqar.auth_url\n+++ os-apply-config --key os-collect-config.request.metadata_url --key-default '' --type raw\n+++ sed -e 's|http.*://\\[\\?\\([^]]*\\)]\\?:.*|\\1|'\n++ METADATA_IP=192.168.24.2\n++ '[' -n 192.168.24.2 ']'\n++ break\n++ echo 192.168.24.2\n+ local METADATA_IP=192.168.24.2\n+ local METADATA_IP_PING_TIMEOUT=60\n+ '[' -n 192.168.24.2 ']'\n+ is_local_ip 192.168.24.2\n+ local IP_TO_CHECK=192.168.24.2\n+ ip -o a\n+ grep 'inet6\\? 192.168.24.2/'\n+ return 1\n+ echo -n 'Trying to ping metadata IP 192.168.24.2...'\n++ getent hosts 192.168.24.2\n++ awk '{ print $1 }'\n+ _IP=\n+ _ping=ping\n+ [[ '' =~ : ]]\n+ local COUNT=0\n+ ping -c 1 192.168.24.2\n+ echo SUCCESS\n+ '[' -f /etc/udev/rules.d/99-dhcp-all-interfaces.rules ']'\n+ rm /etc/udev/rules.d/99-dhcp-all-interfaces.rules\n+ '[' -f /usr/libexec/os-apply-config/templates/etc/os-net-config/config.json ']'\n+ '[' -f /usr/libexec/os-apply-config/templates/etc/os-net-config/element_config.json ']'\n+ configure_safe_defaults\n+ [[ 0 == 0 ]]\n+ return 0\n\n[2019-06-05 19:04:06,526] (heat-config) [INFO] Completed /var/lib/heat-config/heat-config-script/bfaf691d-59c5-4a2e-9666-9bfc7cde9654\n\n[2019-06-05 19:04:06,534] (heat-config) [INFO] Completed /usr/libexec/heat-config/hooks/script\n[2019-06-05 19:04:06,535] (heat-config) [DEBUG] Running heat-config-notify /var/lib/heat-config/deployed/bfaf691d-59c5-4a2e-9666-9bfc7cde9654.json < /var/lib/heat-config/deployed/bfaf691d-59c5-4a2e-9666-9bfc7cde9654.notify.json\n[2019-06-05 19:04:06,883] (heat-config) [INFO] \n[2019-06-05 19:04:06,883] (heat-config) [DEBUG] ", "stderr_lines": ["[2019-06-05 19:03:38,870] (heat-config) [DEBUG] Running /usr/libexec/heat-config/hooks/script < /var/lib/heat-config/deployed/bfaf691d-59c5-4a2e-9666-9bfc7cde9654.json", "[2019-06-05 19:04:06,534] (heat-config) [INFO] |-", "  {\"deploy_stdout\": \"Trying to ping metadata IP 192.168.24.2...SUCCESS\\n\", \"deploy_stderr\": \"+ '[' -n '{\\\"network_config\\\": [{\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"192.168.24.20/24\\\"}], \\\"dns_servers\\\": [\\\"1.0.0.1\\\"], \\\"domain\\\": [], \\\"members\\\": [{\\\"mtu\\\": 1500, \\\"name\\\": \\\"nic1\\\", \\\"primary\\\": true, \\\"type\\\": \\\"interface\\\"}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"172.16.1.240/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 30}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"172.16.3.205/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 40}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"172.16.2.35/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 20}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"172.16.0.171/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 50}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"10.0.0.8/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [{\\\"default\\\": true, \\\"next_hop\\\": \\\"10.0.0.1\\\"}], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 10}], \\\"mtu\\\": 1500, \\\"name\\\": \\\"bridge_name\\\", \\\"routes\\\": [{\\\"destination\\\": \\\"169.254.169.254/32\\\", \\\"nexthop\\\": \\\"192.168.24.3\\\"}, {\\\"ip_netmask\\\": \\\"169.254.169.254/32\\\", \\\"next_hop\\\": \\\"192.168.24.3\\\"}], \\\"type\\\": \\\"ovs_bridge\\\", \\\"use_dhcp\\\": false}]}' ']'\\n+ '[' -z '' ']'\\n+ trap configure_safe_defaults EXIT\\n++ date +%Y-%m-%dT%H:%M:%S\\n+ DATETIME=2019-06-05T19:03:38\\n+ '[' -f /etc/os-net-config/config.json ']'\\n+ mkdir -p /etc/os-net-config\\n+ echo '{\\\"network_config\\\": [{\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"192.168.24.20/24\\\"}], \\\"dns_servers\\\": [\\\"1.0.0.1\\\"], \\\"domain\\\": [], \\\"members\\\": [{\\\"mtu\\\": 1500, \\\"name\\\": \\\"nic1\\\", \\\"primary\\\": true, \\\"type\\\": \\\"interface\\\"}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"172.16.1.240/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 30}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"172.16.3.205/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 40}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"172.16.2.35/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 20}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"172.16.0.171/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 50}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"10.0.0.8/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [{\\\"default\\\": true, \\\"next_hop\\\": \\\"10.0.0.1\\\"}], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 10}], \\\"mtu\\\": 1500, \\\"name\\\": \\\"bridge_name\\\", \\\"routes\\\": [{\\\"destination\\\": \\\"169.254.169.254/32\\\", \\\"nexthop\\\": \\\"192.168.24.3\\\"}, {\\\"ip_netmask\\\": \\\"169.254.169.254/32\\\", \\\"next_hop\\\": \\\"192.168.24.3\\\"}], \\\"type\\\": \\\"ovs_bridge\\\", \\\"use_dhcp\\\": false}]}'\\n++ type -t network_config_hook\\n+ '[' '' = function ']'\\n+ sed -i s/bridge_name/br-ex/ /etc/os-net-config/config.json\\n+ sed -i s/interface_name/nic1/ /etc/os-net-config/config.json\\n+ set +e\\n+ os-net-config -c /etc/os-net-config/config.json -v --detailed-exit-codes\\n[2019/06/05 07:03:39 PM] [INFO] Using config file at: /etc/os-net-config/config.json\\n[2019/06/05 07:03:39 PM] [INFO] Ifcfg net config provider created.\\n[2019/06/05 07:03:39 PM] [INFO] Not using any mapping file.\\n[2019/06/05 07:03:39 PM] [INFO] Finding active nics\\n[2019/06/05 07:03:39 PM] [INFO] eth0 is an embedded active nic\\n[2019/06/05 07:03:39 PM] [INFO] eth1 is an embedded active nic\\n[2019/06/05 07:03:39 PM] [INFO] lo is not an active nic\\n[2019/06/05 07:03:39 PM] [INFO] No DPDK mapping available in path (/var/lib/os-net-config/dpdk_mapping.yaml)\\n[2019/06/05 07:03:39 PM] [INFO] Active nics are ['eth0', 'eth1']\\n[2019/06/05 07:03:39 PM] [INFO] nic2 mapped to: eth1\\n[2019/06/05 07:03:39 PM] [INFO] nic1 mapped to: eth0\\n[2019/06/05 07:03:39 PM] [INFO] adding bridge: br-ex\\n[2019/06/05 07:03:39 PM] [INFO] adding custom route for interface: br-ex\\n[2019/06/05 07:03:39 PM] [INFO] adding interface: eth0\\n[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan30\\n[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan40\\n[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan20\\n[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan50\\n[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan10\\n[2019/06/05 07:03:39 PM] [INFO] adding custom route for interface: vlan10\\n[2019/06/05 07:03:39 PM] [INFO] applying network configs...\\n[2019/06/05 07:03:39 PM] [INFO] Running ip route add 169.254.169.254/32 via 192.168.24.3 dev br-ex\\n[2019/06/05 07:03:39 PM] [WARNING] Error in 'ip route add 169.254.169.254/32 via 192.168.24.3 dev br-ex', restarting br-ex:\\nUnexpected error while running command.\\nCommand: /sbin/ip route add 169.254.169.254/32 via 192.168.24.3 dev br-ex\\nExit code: 1\\nStdout: u''\\nStderr: u'Cannot find device \\\"br-ex\\\"\\\\n'\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan10\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan20\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan30\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan40\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan50\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: eth0\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan10\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan20\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan30\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan40\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan50\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: br-ex\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan10\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan20\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan30\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan40\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan50\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: eth0\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on bridge: br-ex\\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/route-br-ex\\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan20\\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan40\\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan50\\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/route-vlan10\\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan10\\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-br-ex\\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan30\\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-eth0\\n[2019/06/05 07:03:39 PM] [INFO] running ifup on bridge: br-ex\\n[2019/06/05 07:03:44 PM] [INFO] running ifup on interface: eth0\\n[2019/06/05 07:03:44 PM] [INFO] running ifup on interface: vlan10\\n[2019/06/05 07:03:48 PM] [INFO] running ifup on interface: vlan20\\n[2019/06/05 07:03:52 PM] [INFO] running ifup on interface: vlan30\\n[2019/06/05 07:03:56 PM] [INFO] running ifup on interface: vlan40\\n[2019/06/05 07:04:00 PM] [INFO] running ifup on interface: vlan50\\n[2019/06/05 07:04:04 PM] [INFO] running ifup on interface: br-ex\\n[2019/06/05 07:04:04 PM] [INFO] running ifup on interface: vlan10\\n[2019/06/05 07:04:04 PM] [INFO] running ifup on interface: vlan20\\n[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: vlan30\\n[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: vlan40\\n[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: vlan50\\n[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: eth0\\n[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: vlan10\\n[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: vlan20\\n[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: vlan30\\n[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: vlan40\\n[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: vlan50\\n+ RETVAL=2\\n+ set -e\\n+ [[ 2 == 2 ]]\\n+ ping_metadata_ip\\n++ get_metadata_ip\\n++ local METADATA_IP\\n++ for URL in os-collect-config.cfn.metadata_url os-collect-config.heat.auth_url os-collect-config.request.metadata_url os-collect-config.zaqar.auth_url\\n+++ os-apply-config --key os-collect-config.cfn.metadata_url --key-default '' --type raw\\n+++ sed -e 's|http.*://\\\\[\\\\?\\\\([^]]*\\\\)]\\\\?:.*|\\\\1|'\\n++ METADATA_IP=\\n++ '[' -n '' ']'\\n++ for URL in os-collect-config.cfn.metadata_url os-collect-config.heat.auth_url os-collect-config.request.metadata_url os-collect-config.zaqar.auth_url\\n+++ os-apply-config --key os-collect-config.heat.auth_url --key-default '' --type raw\\n+++ sed -e 's|http.*://\\\\[\\\\?\\\\([^]]*\\\\)]\\\\?:.*|\\\\1|'\\n++ METADATA_IP=\\n++ '[' -n '' ']'\\n++ for URL in os-collect-config.cfn.metadata_url os-collect-config.heat.auth_url os-collect-config.request.metadata_url os-collect-config.zaqar.auth_url\\n+++ os-apply-config --key os-collect-config.request.metadata_url --key-default '' --type raw\\n+++ sed -e 's|http.*://\\\\[\\\\?\\\\([^]]*\\\\)]\\\\?:.*|\\\\1|'\\n++ METADATA_IP=192.168.24.2\\n++ '[' -n 192.168.24.2 ']'\\n++ break\\n++ echo 192.168.24.2\\n+ local METADATA_IP=192.168.24.2\\n+ local METADATA_IP_PING_TIMEOUT=60\\n+ '[' -n 192.168.24.2 ']'\\n+ is_local_ip 192.168.24.2\\n+ local IP_TO_CHECK=192.168.24.2\\n+ ip -o a\\n+ grep 'inet6\\\\? 192.168.24.2/'\\n+ return 1\\n+ echo -n 'Trying to ping metadata IP 192.168.24.2...'\\n++ getent hosts 192.168.24.2\\n++ awk '{ print $1 }'\\n+ _IP=\\n+ _ping=ping\\n+ [[ '' =~ : ]]\\n+ local COUNT=0\\n+ ping -c 1 192.168.24.2\\n+ echo SUCCESS\\n+ '[' -f /etc/udev/rules.d/99-dhcp-all-interfaces.rules ']'\\n+ rm /etc/udev/rules.d/99-dhcp-all-interfaces.rules\\n+ '[' -f /usr/libexec/os-apply-config/templates/etc/os-net-config/config.json ']'\\n+ '[' -f /usr/libexec/os-apply-config/templates/etc/os-net-config/element_config.json ']'\\n+ configure_safe_defaults\\n+ [[ 0 == 0 ]]\\n+ return 0\\n\", \"deploy_status_code\": 0}", "", "[2019-06-05 19:04:06,534] (heat-config) [DEBUG] [2019-06-05 19:03:38,883] (heat-config) [INFO] interface_name=nic1", "[2019-06-05 19:03:38,883] (heat-config) [INFO] bridge_name=br-ex", "[2019-06-05 19:03:38,883] (heat-config) [INFO] deploy_server_id=cd2dbcc8-25c9-489f-9138-43515c089a76", "[2019-06-05 19:03:38,883] (heat-config) [INFO] deploy_action=CREATE", "[2019-06-05 19:03:38,883] (heat-config) [INFO] deploy_stack_id=lab-Controller-mmbfn4kct2xh-0-jymrphsrfe7m-NetworkDeployment-4gv4gbacpozu-TripleOSoftwareDeployment-ntf3k2t7b7xi/24c204ab-a8c9-4ac9-95a0-eeeeddccb59d", "[2019-06-05 19:03:38,883] (heat-config) [INFO] deploy_resource_name=TripleOSoftwareDeployment", "[2019-06-05 19:03:38,883] (heat-config) [INFO] deploy_signal_transport=NO_SIGNAL", "[2019-06-05 19:03:38,884] (heat-config) [DEBUG] Running /var/lib/heat-config/heat-config-script/bfaf691d-59c5-4a2e-9666-9bfc7cde9654", "[2019-06-05 19:04:06,526] (heat-config) [INFO] Trying to ping metadata IP 192.168.24.2...SUCCESS", "", "[2019-06-05 19:04:06,526] (heat-config) [DEBUG] + '[' -n '{\"network_config\": [{\"addresses\": [{\"ip_netmask\": \"192.168.24.20/24\"}], \"dns_servers\": [\"1.0.0.1\"], \"domain\": [], \"members\": [{\"mtu\": 1500, \"name\": \"nic1\", \"primary\": true, \"type\": \"interface\"}, {\"addresses\": [{\"ip_netmask\": \"172.16.1.240/24\"}], \"mtu\": 1500, \"routes\": [], \"type\": \"vlan\", \"vlan_id\": 30}, {\"addresses\": [{\"ip_netmask\": \"172.16.3.205/24\"}], \"mtu\": 1500, \"routes\": [], \"type\": \"vlan\", \"vlan_id\": 40}, {\"addresses\": [{\"ip_netmask\": \"172.16.2.35/24\"}], \"mtu\": 1500, \"routes\": [], \"type\": \"vlan\", \"vlan_id\": 20}, {\"addresses\": [{\"ip_netmask\": \"172.16.0.171/24\"}], \"mtu\": 1500, \"routes\": [], \"type\": \"vlan\", \"vlan_id\": 50}, {\"addresses\": [{\"ip_netmask\": \"10.0.0.8/24\"}], \"mtu\": 1500, \"routes\": [{\"default\": true, \"next_hop\": \"10.0.0.1\"}], \"type\": \"vlan\", \"vlan_id\": 10}], \"mtu\": 1500, \"name\": \"bridge_name\", \"routes\": [{\"destination\": \"169.254.169.254/32\", \"nexthop\": \"192.168.24.3\"}, {\"ip_netmask\": \"169.254.169.254/32\", \"next_hop\": \"192.168.24.3\"}], \"type\": \"ovs_bridge\", \"use_dhcp\": false}]}' ']'", "+ '[' -z '' ']'", "+ trap configure_safe_defaults EXIT", "++ date +%Y-%m-%dT%H:%M:%S", "+ DATETIME=2019-06-05T19:03:38", "+ '[' -f /etc/os-net-config/config.json ']'", "+ mkdir -p /etc/os-net-config", "+ echo '{\"network_config\": [{\"addresses\": [{\"ip_netmask\": \"192.168.24.20/24\"}], \"dns_servers\": [\"1.0.0.1\"], \"domain\": [], \"members\": [{\"mtu\": 1500, \"name\": \"nic1\", \"primary\": true, \"type\": \"interface\"}, {\"addresses\": [{\"ip_netmask\": \"172.16.1.240/24\"}], \"mtu\": 1500, \"routes\": [], \"type\": \"vlan\", \"vlan_id\": 30}, {\"addresses\": [{\"ip_netmask\": \"172.16.3.205/24\"}], \"mtu\": 1500, \"routes\": [], \"type\": \"vlan\", \"vlan_id\": 40}, {\"addresses\": [{\"ip_netmask\": \"172.16.2.35/24\"}], \"mtu\": 1500, \"routes\": [], \"type\": \"vlan\", \"vlan_id\": 20}, {\"addresses\": [{\"ip_netmask\": \"172.16.0.171/24\"}], \"mtu\": 1500, \"routes\": [], \"type\": \"vlan\", \"vlan_id\": 50}, {\"addresses\": [{\"ip_netmask\": \"10.0.0.8/24\"}], \"mtu\": 1500, \"routes\": [{\"default\": true, \"next_hop\": \"10.0.0.1\"}], \"type\": \"vlan\", \"vlan_id\": 10}], \"mtu\": 1500, \"name\": \"bridge_name\", \"routes\": [{\"destination\": \"169.254.169.254/32\", \"nexthop\": \"192.168.24.3\"}, {\"ip_netmask\": \"169.254.169.254/32\", \"next_hop\": \"192.168.24.3\"}], \"type\": \"ovs_bridge\", \"use_dhcp\": false}]}'", "++ type -t network_config_hook", "+ '[' '' = function ']'", "+ sed -i s/bridge_name/br-ex/ /etc/os-net-config/config.json", "+ sed -i s/interface_name/nic1/ /etc/os-net-config/config.json", "+ set +e", "+ os-net-config -c /etc/os-net-config/config.json -v --detailed-exit-codes", "[2019/06/05 07:03:39 PM] [INFO] Using config file at: /etc/os-net-config/config.json", "[2019/06/05 07:03:39 PM] [INFO] Ifcfg net config provider created.", "[2019/06/05 07:03:39 PM] [INFO] Not using any mapping file.", "[2019/06/05 07:03:39 PM] [INFO] Finding active nics", "[2019/06/05 07:03:39 PM] [INFO] eth0 is an embedded active nic", "[2019/06/05 07:03:39 PM] [INFO] eth1 is an embedded active nic", "[2019/06/05 07:03:39 PM] [INFO] lo is not an active nic", "[2019/06/05 07:03:39 PM] [INFO] No DPDK mapping available in path (/var/lib/os-net-config/dpdk_mapping.yaml)", "[2019/06/05 07:03:39 PM] [INFO] Active nics are ['eth0', 'eth1']", "[2019/06/05 07:03:39 PM] [INFO] nic2 mapped to: eth1", "[2019/06/05 07:03:39 PM] [INFO] nic1 mapped to: eth0", "[2019/06/05 07:03:39 PM] [INFO] adding bridge: br-ex", "[2019/06/05 07:03:39 PM] [INFO] adding custom route for interface: br-ex", "[2019/06/05 07:03:39 PM] [INFO] adding interface: eth0", "[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan30", "[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan40", "[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan20", "[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan50", "[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan10", "[2019/06/05 07:03:39 PM] [INFO] adding custom route for interface: vlan10", "[2019/06/05 07:03:39 PM] [INFO] applying network configs...", "[2019/06/05 07:03:39 PM] [INFO] Running ip route add 169.254.169.254/32 via 192.168.24.3 dev br-ex", "[2019/06/05 07:03:39 PM] [WARNING] Error in 'ip route add 169.254.169.254/32 via 192.168.24.3 dev br-ex', restarting br-ex:", "Unexpected error while running command.", "Command: /sbin/ip route add 169.254.169.254/32 via 192.168.24.3 dev br-ex", "Exit code: 1", "Stdout: u''", "Stderr: u'Cannot find device \"br-ex\"\\n'", "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan10", "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan20", "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan30", "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan40", "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan50", "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: eth0", "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan10", "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan20", "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan30", "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan40", "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan50", "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: br-ex", "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan10", "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan20", "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan30", "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan40", "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan50", "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: eth0", "[2019/06/05 07:03:39 PM] [INFO] running ifdown on bridge: br-ex", "[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/route-br-ex", "[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan20", "[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan40", "[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan50", "[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/route-vlan10", "[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan10", "[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-br-ex", "[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan30", "[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-eth0", "[2019/06/05 07:03:39 PM] [INFO] running ifup on bridge: br-ex", "[2019/06/05 07:03:44 PM] [INFO] running ifup on interface: eth0", "[2019/06/05 07:03:44 PM] [INFO] running ifup on interface: vlan10", "[2019/06/05 07:03:48 PM] [INFO] running ifup on interface: vlan20", "[2019/06/05 07:03:52 PM] [INFO] running ifup on interface: vlan30", "[2019/06/05 07:03:56 PM] [INFO] running ifup on interface: vlan40", "[2019/06/05 07:04:00 PM] [INFO] running ifup on interface: vlan50", "[2019/06/05 07:04:04 PM] [INFO] running ifup on interface: br-ex", "[2019/06/05 07:04:04 PM] [INFO] running ifup on interface: vlan10", "[2019/06/05 07:04:04 PM] [INFO] running ifup on interface: vlan20", "[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: vlan30", "[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: vlan40", "[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: vlan50", "[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: eth0", "[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: vlan10", "[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: vlan20", "[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: vlan30", "[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: vlan40", "[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: vlan50", "+ RETVAL=2", "+ set -e", "+ [[ 2 == 2 ]]", "+ ping_metadata_ip", "++ get_metadata_ip", "++ local METADATA_IP", "++ for URL in os-collect-config.cfn.metadata_url os-collect-config.heat.auth_url os-collect-config.request.metadata_url os-collect-config.zaqar.auth_url", "+++ os-apply-config --key os-collect-config.cfn.metadata_url --key-default '' --type raw", "+++ sed -e 's|http.*://\\[\\?\\([^]]*\\)]\\?:.*|\\1|'", "++ METADATA_IP=", "++ '[' -n '' ']'", "++ for URL in os-collect-config.cfn.metadata_url os-collect-config.heat.auth_url os-collect-config.request.metadata_url os-collect-config.zaqar.auth_url", "+++ os-apply-config --key os-collect-config.heat.auth_url --key-default '' --type raw", "+++ sed -e 's|http.*://\\[\\?\\([^]]*\\)]\\?:.*|\\1|'", "++ METADATA_IP=", "++ '[' -n '' ']'", "++ for URL in os-collect-config.cfn.metadata_url os-collect-config.heat.auth_url os-collect-config.request.metadata_url os-collect-config.zaqar.auth_url", "+++ os-apply-config --key os-collect-config.request.metadata_url --key-default '' --type raw", "+++ sed -e 's|http.*://\\[\\?\\([^]]*\\)]\\?:.*|\\1|'", "++ METADATA_IP=192.168.24.2", "++ '[' -n 192.168.24.2 ']'", "++ break", "++ echo 192.168.24.2", "+ local METADATA_IP=192.168.24.2", "+ local METADATA_IP_PING_TIMEOUT=60", "+ '[' -n 192.168.24.2 ']'", "+ is_local_ip 192.168.24.2", "+ local IP_TO_CHECK=192.168.24.2", "+ ip -o a", "+ grep 'inet6\\? 192.168.24.2/'", "+ return 1", "+ echo -n 'Trying to ping metadata IP 192.168.24.2...'", "++ getent hosts 192.168.24.2", "++ awk '{ print $1 }'", "+ _IP=", "+ _ping=ping", "+ [[ '' =~ : ]]", "+ local COUNT=0", "+ ping -c 1 192.168.24.2", "+ echo SUCCESS", "+ '[' -f /etc/udev/rules.d/99-dhcp-all-interfaces.rules ']'", "+ rm /etc/udev/rules.d/99-dhcp-all-interfaces.rules", "+ '[' -f /usr/libexec/os-apply-config/templates/etc/os-net-config/config.json ']'", "+ '[' -f /usr/libexec/os-apply-config/templates/etc/os-net-config/element_config.json ']'", "+ configure_safe_defaults", "+ [[ 0 == 0 ]]", "+ return 0", "", "[2019-06-05 19:04:06,526] (heat-config) [INFO] Completed /var/lib/heat-config/heat-config-script/bfaf691d-59c5-4a2e-9666-9bfc7cde9654", "", "[2019-06-05 19:04:06,534] (heat-config) [INFO] Completed /usr/libexec/heat-config/hooks/script", "[2019-06-05 19:04:06,535] (heat-config) [DEBUG] Running heat-config-notify /var/lib/heat-config/deployed/bfaf691d-59c5-4a2e-9666-9bfc7cde9654.json < /var/lib/heat-config/deployed/bfaf691d-59c5-4a2e-9666-9bfc7cde9654.notify.json", "[2019-06-05 19:04:06,883] (heat-config) [INFO] ", "[2019-06-05 19:04:06,883] (heat-config) [DEBUG] "], "stdout": "", "stdout_lines": []}
2019-06-05 14:04:08,959 p=17240 u=mistral |  TASK [Output for sync deployment NetworkDeployment] ****************************
2019-06-05 14:04:08,959 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:166
2019-06-05 14:04:08,959 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:08 -0500 (0:00:30.410)       0:00:42.728 ******** 
2019-06-05 14:04:08,979 p=17240 u=mistral |  skipping: [lab-controller-0] => {}
2019-06-05 14:04:08,987 p=17240 u=mistral |  skipping: [lab-computehci-0] => {}
2019-06-05 14:04:09,005 p=17240 u=mistral |  TASK [Output for async deployment NetworkDeployment] ***************************
2019-06-05 14:04:09,005 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:176
2019-06-05 14:04:09,005 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:09 -0500 (0:00:00.046)       0:00:42.774 ******** 
2019-06-05 14:04:09,039 p=17240 u=mistral |  ok: [lab-controller-0] => {
    "msg": [
        {
            "stderr": [
                "[2019-06-05 19:03:38,870] (heat-config) [DEBUG] Running /usr/libexec/heat-config/hooks/script < /var/lib/heat-config/deployed/bfaf691d-59c5-4a2e-9666-9bfc7cde9654.json", 
                "[2019-06-05 19:04:06,534] (heat-config) [INFO] |-", 
                "  {\"deploy_stdout\": \"Trying to ping metadata IP 192.168.24.2...SUCCESS\\n\", \"deploy_stderr\": \"+ '[' -n '{\\\"network_config\\\": [{\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"192.168.24.20/24\\\"}], \\\"dns_servers\\\": [\\\"1.0.0.1\\\"], \\\"domain\\\": [], \\\"members\\\": [{\\\"mtu\\\": 1500, \\\"name\\\": \\\"nic1\\\", \\\"primary\\\": true, \\\"type\\\": \\\"interface\\\"}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"172.16.1.240/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 30}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"172.16.3.205/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 40}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"172.16.2.35/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 20}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"172.16.0.171/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 50}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"10.0.0.8/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [{\\\"default\\\": true, \\\"next_hop\\\": \\\"10.0.0.1\\\"}], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 10}], \\\"mtu\\\": 1500, \\\"name\\\": \\\"bridge_name\\\", \\\"routes\\\": [{\\\"destination\\\": \\\"169.254.169.254/32\\\", \\\"nexthop\\\": \\\"192.168.24.3\\\"}, {\\\"ip_netmask\\\": \\\"169.254.169.254/32\\\", \\\"next_hop\\\": \\\"192.168.24.3\\\"}], \\\"type\\\": \\\"ovs_bridge\\\", \\\"use_dhcp\\\": false}]}' ']'\\n+ '[' -z '' ']'\\n+ trap configure_safe_defaults EXIT\\n++ date +%Y-%m-%dT%H:%M:%S\\n+ DATETIME=2019-06-05T19:03:38\\n+ '[' -f /etc/os-net-config/config.json ']'\\n+ mkdir -p /etc/os-net-config\\n+ echo '{\\\"network_config\\\": [{\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"192.168.24.20/24\\\"}], \\\"dns_servers\\\": [\\\"1.0.0.1\\\"], \\\"domain\\\": [], \\\"members\\\": [{\\\"mtu\\\": 1500, \\\"name\\\": \\\"nic1\\\", \\\"primary\\\": true, \\\"type\\\": \\\"interface\\\"}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"172.16.1.240/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 30}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"172.16.3.205/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 40}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"172.16.2.35/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 20}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"172.16.0.171/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 50}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"10.0.0.8/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [{\\\"default\\\": true, \\\"next_hop\\\": \\\"10.0.0.1\\\"}], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 10}], \\\"mtu\\\": 1500, \\\"name\\\": \\\"bridge_name\\\", \\\"routes\\\": [{\\\"destination\\\": \\\"169.254.169.254/32\\\", \\\"nexthop\\\": \\\"192.168.24.3\\\"}, {\\\"ip_netmask\\\": \\\"169.254.169.254/32\\\", \\\"next_hop\\\": \\\"192.168.24.3\\\"}], \\\"type\\\": \\\"ovs_bridge\\\", \\\"use_dhcp\\\": false}]}'\\n++ type -t network_config_hook\\n+ '[' '' = function ']'\\n+ sed -i s/bridge_name/br-ex/ /etc/os-net-config/config.json\\n+ sed -i s/interface_name/nic1/ /etc/os-net-config/config.json\\n+ set +e\\n+ os-net-config -c /etc/os-net-config/config.json -v --detailed-exit-codes\\n[2019/06/05 07:03:39 PM] [INFO] Using config file at: /etc/os-net-config/config.json\\n[2019/06/05 07:03:39 PM] [INFO] Ifcfg net config provider created.\\n[2019/06/05 07:03:39 PM] [INFO] Not using any mapping file.\\n[2019/06/05 07:03:39 PM] [INFO] Finding active nics\\n[2019/06/05 07:03:39 PM] [INFO] eth0 is an embedded active nic\\n[2019/06/05 07:03:39 PM] [INFO] eth1 is an embedded active nic\\n[2019/06/05 07:03:39 PM] [INFO] lo is not an active nic\\n[2019/06/05 07:03:39 PM] [INFO] No DPDK mapping available in path (/var/lib/os-net-config/dpdk_mapping.yaml)\\n[2019/06/05 07:03:39 PM] [INFO] Active nics are ['eth0', 'eth1']\\n[2019/06/05 07:03:39 PM] [INFO] nic2 mapped to: eth1\\n[2019/06/05 07:03:39 PM] [INFO] nic1 mapped to: eth0\\n[2019/06/05 07:03:39 PM] [INFO] adding bridge: br-ex\\n[2019/06/05 07:03:39 PM] [INFO] adding custom route for interface: br-ex\\n[2019/06/05 07:03:39 PM] [INFO] adding interface: eth0\\n[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan30\\n[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan40\\n[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan20\\n[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan50\\n[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan10\\n[2019/06/05 07:03:39 PM] [INFO] adding custom route for interface: vlan10\\n[2019/06/05 07:03:39 PM] [INFO] applying network configs...\\n[2019/06/05 07:03:39 PM] [INFO] Running ip route add 169.254.169.254/32 via 192.168.24.3 dev br-ex\\n[2019/06/05 07:03:39 PM] [WARNING] Error in 'ip route add 169.254.169.254/32 via 192.168.24.3 dev br-ex', restarting br-ex:\\nUnexpected error while running command.\\nCommand: /sbin/ip route add 169.254.169.254/32 via 192.168.24.3 dev br-ex\\nExit code: 1\\nStdout: u''\\nStderr: u'Cannot find device \\\"br-ex\\\"\\\\n'\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan10\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan20\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan30\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan40\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan50\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: eth0\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan10\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan20\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan30\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan40\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan50\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: br-ex\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan10\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan20\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan30\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan40\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan50\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: eth0\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on bridge: br-ex\\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/route-br-ex\\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan20\\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan40\\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan50\\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/route-vlan10\\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan10\\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-br-ex\\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan30\\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-eth0\\n[2019/06/05 07:03:39 PM] [INFO] running ifup on bridge: br-ex\\n[2019/06/05 07:03:44 PM] [INFO] running ifup on interface: eth0\\n[2019/06/05 07:03:44 PM] [INFO] running ifup on interface: vlan10\\n[2019/06/05 07:03:48 PM] [INFO] running ifup on interface: vlan20\\n[2019/06/05 07:03:52 PM] [INFO] running ifup on interface: vlan30\\n[2019/06/05 07:03:56 PM] [INFO] running ifup on interface: vlan40\\n[2019/06/05 07:04:00 PM] [INFO] running ifup on interface: vlan50\\n[2019/06/05 07:04:04 PM] [INFO] running ifup on interface: br-ex\\n[2019/06/05 07:04:04 PM] [INFO] running ifup on interface: vlan10\\n[2019/06/05 07:04:04 PM] [INFO] running ifup on interface: vlan20\\n[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: vlan30\\n[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: vlan40\\n[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: vlan50\\n[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: eth0\\n[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: vlan10\\n[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: vlan20\\n[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: vlan30\\n[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: vlan40\\n[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: vlan50\\n+ RETVAL=2\\n+ set -e\\n+ [[ 2 == 2 ]]\\n+ ping_metadata_ip\\n++ get_metadata_ip\\n++ local METADATA_IP\\n++ for URL in os-collect-config.cfn.metadata_url os-collect-config.heat.auth_url os-collect-config.request.metadata_url os-collect-config.zaqar.auth_url\\n+++ os-apply-config --key os-collect-config.cfn.metadata_url --key-default '' --type raw\\n+++ sed -e 's|http.*://\\\\[\\\\?\\\\([^]]*\\\\)]\\\\?:.*|\\\\1|'\\n++ METADATA_IP=\\n++ '[' -n '' ']'\\n++ for URL in os-collect-config.cfn.metadata_url os-collect-config.heat.auth_url os-collect-config.request.metadata_url os-collect-config.zaqar.auth_url\\n+++ os-apply-config --key os-collect-config.heat.auth_url --key-default '' --type raw\\n+++ sed -e 's|http.*://\\\\[\\\\?\\\\([^]]*\\\\)]\\\\?:.*|\\\\1|'\\n++ METADATA_IP=\\n++ '[' -n '' ']'\\n++ for URL in os-collect-config.cfn.metadata_url os-collect-config.heat.auth_url os-collect-config.request.metadata_url os-collect-config.zaqar.auth_url\\n+++ os-apply-config --key os-collect-config.request.metadata_url --key-default '' --type raw\\n+++ sed -e 's|http.*://\\\\[\\\\?\\\\([^]]*\\\\)]\\\\?:.*|\\\\1|'\\n++ METADATA_IP=192.168.24.2\\n++ '[' -n 192.168.24.2 ']'\\n++ break\\n++ echo 192.168.24.2\\n+ local METADATA_IP=192.168.24.2\\n+ local METADATA_IP_PING_TIMEOUT=60\\n+ '[' -n 192.168.24.2 ']'\\n+ is_local_ip 192.168.24.2\\n+ local IP_TO_CHECK=192.168.24.2\\n+ ip -o a\\n+ grep 'inet6\\\\? 192.168.24.2/'\\n+ return 1\\n+ echo -n 'Trying to ping metadata IP 192.168.24.2...'\\n++ getent hosts 192.168.24.2\\n++ awk '{ print $1 }'\\n+ _IP=\\n+ _ping=ping\\n+ [[ '' =~ : ]]\\n+ local COUNT=0\\n+ ping -c 1 192.168.24.2\\n+ echo SUCCESS\\n+ '[' -f /etc/udev/rules.d/99-dhcp-all-interfaces.rules ']'\\n+ rm /etc/udev/rules.d/99-dhcp-all-interfaces.rules\\n+ '[' -f /usr/libexec/os-apply-config/templates/etc/os-net-config/config.json ']'\\n+ '[' -f /usr/libexec/os-apply-config/templates/etc/os-net-config/element_config.json ']'\\n+ configure_safe_defaults\\n+ [[ 0 == 0 ]]\\n+ return 0\\n\", \"deploy_status_code\": 0}", 
                "", 
                "[2019-06-05 19:04:06,534] (heat-config) [DEBUG] [2019-06-05 19:03:38,883] (heat-config) [INFO] interface_name=nic1", 
                "[2019-06-05 19:03:38,883] (heat-config) [INFO] bridge_name=br-ex", 
                "[2019-06-05 19:03:38,883] (heat-config) [INFO] deploy_server_id=cd2dbcc8-25c9-489f-9138-43515c089a76", 
                "[2019-06-05 19:03:38,883] (heat-config) [INFO] deploy_action=CREATE", 
                "[2019-06-05 19:03:38,883] (heat-config) [INFO] deploy_stack_id=lab-Controller-mmbfn4kct2xh-0-jymrphsrfe7m-NetworkDeployment-4gv4gbacpozu-TripleOSoftwareDeployment-ntf3k2t7b7xi/24c204ab-a8c9-4ac9-95a0-eeeeddccb59d", 
                "[2019-06-05 19:03:38,883] (heat-config) [INFO] deploy_resource_name=TripleOSoftwareDeployment", 
                "[2019-06-05 19:03:38,883] (heat-config) [INFO] deploy_signal_transport=NO_SIGNAL", 
                "[2019-06-05 19:03:38,884] (heat-config) [DEBUG] Running /var/lib/heat-config/heat-config-script/bfaf691d-59c5-4a2e-9666-9bfc7cde9654", 
                "[2019-06-05 19:04:06,526] (heat-config) [INFO] Trying to ping metadata IP 192.168.24.2...SUCCESS", 
                "", 
                "[2019-06-05 19:04:06,526] (heat-config) [DEBUG] + '[' -n '{\"network_config\": [{\"addresses\": [{\"ip_netmask\": \"192.168.24.20/24\"}], \"dns_servers\": [\"1.0.0.1\"], \"domain\": [], \"members\": [{\"mtu\": 1500, \"name\": \"nic1\", \"primary\": true, \"type\": \"interface\"}, {\"addresses\": [{\"ip_netmask\": \"172.16.1.240/24\"}], \"mtu\": 1500, \"routes\": [], \"type\": \"vlan\", \"vlan_id\": 30}, {\"addresses\": [{\"ip_netmask\": \"172.16.3.205/24\"}], \"mtu\": 1500, \"routes\": [], \"type\": \"vlan\", \"vlan_id\": 40}, {\"addresses\": [{\"ip_netmask\": \"172.16.2.35/24\"}], \"mtu\": 1500, \"routes\": [], \"type\": \"vlan\", \"vlan_id\": 20}, {\"addresses\": [{\"ip_netmask\": \"172.16.0.171/24\"}], \"mtu\": 1500, \"routes\": [], \"type\": \"vlan\", \"vlan_id\": 50}, {\"addresses\": [{\"ip_netmask\": \"10.0.0.8/24\"}], \"mtu\": 1500, \"routes\": [{\"default\": true, \"next_hop\": \"10.0.0.1\"}], \"type\": \"vlan\", \"vlan_id\": 10}], \"mtu\": 1500, \"name\": \"bridge_name\", \"routes\": [{\"destination\": \"169.254.169.254/32\", \"nexthop\": \"192.168.24.3\"}, {\"ip_netmask\": \"169.254.169.254/32\", \"next_hop\": \"192.168.24.3\"}], \"type\": \"ovs_bridge\", \"use_dhcp\": false}]}' ']'", 
                "+ '[' -z '' ']'", 
                "+ trap configure_safe_defaults EXIT", 
                "++ date +%Y-%m-%dT%H:%M:%S", 
                "+ DATETIME=2019-06-05T19:03:38", 
                "+ '[' -f /etc/os-net-config/config.json ']'", 
                "+ mkdir -p /etc/os-net-config", 
                "+ echo '{\"network_config\": [{\"addresses\": [{\"ip_netmask\": \"192.168.24.20/24\"}], \"dns_servers\": [\"1.0.0.1\"], \"domain\": [], \"members\": [{\"mtu\": 1500, \"name\": \"nic1\", \"primary\": true, \"type\": \"interface\"}, {\"addresses\": [{\"ip_netmask\": \"172.16.1.240/24\"}], \"mtu\": 1500, \"routes\": [], \"type\": \"vlan\", \"vlan_id\": 30}, {\"addresses\": [{\"ip_netmask\": \"172.16.3.205/24\"}], \"mtu\": 1500, \"routes\": [], \"type\": \"vlan\", \"vlan_id\": 40}, {\"addresses\": [{\"ip_netmask\": \"172.16.2.35/24\"}], \"mtu\": 1500, \"routes\": [], \"type\": \"vlan\", \"vlan_id\": 20}, {\"addresses\": [{\"ip_netmask\": \"172.16.0.171/24\"}], \"mtu\": 1500, \"routes\": [], \"type\": \"vlan\", \"vlan_id\": 50}, {\"addresses\": [{\"ip_netmask\": \"10.0.0.8/24\"}], \"mtu\": 1500, \"routes\": [{\"default\": true, \"next_hop\": \"10.0.0.1\"}], \"type\": \"vlan\", \"vlan_id\": 10}], \"mtu\": 1500, \"name\": \"bridge_name\", \"routes\": [{\"destination\": \"169.254.169.254/32\", \"nexthop\": \"192.168.24.3\"}, {\"ip_netmask\": \"169.254.169.254/32\", \"next_hop\": \"192.168.24.3\"}], \"type\": \"ovs_bridge\", \"use_dhcp\": false}]}'", 
                "++ type -t network_config_hook", 
                "+ '[' '' = function ']'", 
                "+ sed -i s/bridge_name/br-ex/ /etc/os-net-config/config.json", 
                "+ sed -i s/interface_name/nic1/ /etc/os-net-config/config.json", 
                "+ set +e", 
                "+ os-net-config -c /etc/os-net-config/config.json -v --detailed-exit-codes", 
                "[2019/06/05 07:03:39 PM] [INFO] Using config file at: /etc/os-net-config/config.json", 
                "[2019/06/05 07:03:39 PM] [INFO] Ifcfg net config provider created.", 
                "[2019/06/05 07:03:39 PM] [INFO] Not using any mapping file.", 
                "[2019/06/05 07:03:39 PM] [INFO] Finding active nics", 
                "[2019/06/05 07:03:39 PM] [INFO] eth0 is an embedded active nic", 
                "[2019/06/05 07:03:39 PM] [INFO] eth1 is an embedded active nic", 
                "[2019/06/05 07:03:39 PM] [INFO] lo is not an active nic", 
                "[2019/06/05 07:03:39 PM] [INFO] No DPDK mapping available in path (/var/lib/os-net-config/dpdk_mapping.yaml)", 
                "[2019/06/05 07:03:39 PM] [INFO] Active nics are ['eth0', 'eth1']", 
                "[2019/06/05 07:03:39 PM] [INFO] nic2 mapped to: eth1", 
                "[2019/06/05 07:03:39 PM] [INFO] nic1 mapped to: eth0", 
                "[2019/06/05 07:03:39 PM] [INFO] adding bridge: br-ex", 
                "[2019/06/05 07:03:39 PM] [INFO] adding custom route for interface: br-ex", 
                "[2019/06/05 07:03:39 PM] [INFO] adding interface: eth0", 
                "[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan30", 
                "[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan40", 
                "[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan20", 
                "[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan50", 
                "[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan10", 
                "[2019/06/05 07:03:39 PM] [INFO] adding custom route for interface: vlan10", 
                "[2019/06/05 07:03:39 PM] [INFO] applying network configs...", 
                "[2019/06/05 07:03:39 PM] [INFO] Running ip route add 169.254.169.254/32 via 192.168.24.3 dev br-ex", 
                "[2019/06/05 07:03:39 PM] [WARNING] Error in 'ip route add 169.254.169.254/32 via 192.168.24.3 dev br-ex', restarting br-ex:", 
                "Unexpected error while running command.", 
                "Command: /sbin/ip route add 169.254.169.254/32 via 192.168.24.3 dev br-ex", 
                "Exit code: 1", 
                "Stdout: u''", 
                "Stderr: u'Cannot find device \"br-ex\"\\n'", 
                "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan10", 
                "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan20", 
                "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan30", 
                "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan40", 
                "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan50", 
                "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: eth0", 
                "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan10", 
                "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan20", 
                "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan30", 
                "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan40", 
                "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan50", 
                "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: br-ex", 
                "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan10", 
                "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan20", 
                "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan30", 
                "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan40", 
                "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan50", 
                "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: eth0", 
                "[2019/06/05 07:03:39 PM] [INFO] running ifdown on bridge: br-ex", 
                "[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/route-br-ex", 
                "[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan20", 
                "[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan40", 
                "[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan50", 
                "[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/route-vlan10", 
                "[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan10", 
                "[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-br-ex", 
                "[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan30", 
                "[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-eth0", 
                "[2019/06/05 07:03:39 PM] [INFO] running ifup on bridge: br-ex", 
                "[2019/06/05 07:03:44 PM] [INFO] running ifup on interface: eth0", 
                "[2019/06/05 07:03:44 PM] [INFO] running ifup on interface: vlan10", 
                "[2019/06/05 07:03:48 PM] [INFO] running ifup on interface: vlan20", 
                "[2019/06/05 07:03:52 PM] [INFO] running ifup on interface: vlan30", 
                "[2019/06/05 07:03:56 PM] [INFO] running ifup on interface: vlan40", 
                "[2019/06/05 07:04:00 PM] [INFO] running ifup on interface: vlan50", 
                "[2019/06/05 07:04:04 PM] [INFO] running ifup on interface: br-ex", 
                "[2019/06/05 07:04:04 PM] [INFO] running ifup on interface: vlan10", 
                "[2019/06/05 07:04:04 PM] [INFO] running ifup on interface: vlan20", 
                "[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: vlan30", 
                "[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: vlan40", 
                "[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: vlan50", 
                "[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: eth0", 
                "[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: vlan10", 
                "[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: vlan20", 
                "[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: vlan30", 
                "[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: vlan40", 
                "[2019/06/05 07:04:05 PM] [INFO] running ifup on interface: vlan50", 
                "+ RETVAL=2", 
                "+ set -e", 
                "+ [[ 2 == 2 ]]", 
                "+ ping_metadata_ip", 
                "++ get_metadata_ip", 
                "++ local METADATA_IP", 
                "++ for URL in os-collect-config.cfn.metadata_url os-collect-config.heat.auth_url os-collect-config.request.metadata_url os-collect-config.zaqar.auth_url", 
                "+++ os-apply-config --key os-collect-config.cfn.metadata_url --key-default '' --type raw", 
                "+++ sed -e 's|http.*://\\[\\?\\([^]]*\\)]\\?:.*|\\1|'", 
                "++ METADATA_IP=", 
                "++ '[' -n '' ']'", 
                "++ for URL in os-collect-config.cfn.metadata_url os-collect-config.heat.auth_url os-collect-config.request.metadata_url os-collect-config.zaqar.auth_url", 
                "+++ os-apply-config --key os-collect-config.heat.auth_url --key-default '' --type raw", 
                "+++ sed -e 's|http.*://\\[\\?\\([^]]*\\)]\\?:.*|\\1|'", 
                "++ METADATA_IP=", 
                "++ '[' -n '' ']'", 
                "++ for URL in os-collect-config.cfn.metadata_url os-collect-config.heat.auth_url os-collect-config.request.metadata_url os-collect-config.zaqar.auth_url", 
                "+++ os-apply-config --key os-collect-config.request.metadata_url --key-default '' --type raw", 
                "+++ sed -e 's|http.*://\\[\\?\\([^]]*\\)]\\?:.*|\\1|'", 
                "++ METADATA_IP=192.168.24.2", 
                "++ '[' -n 192.168.24.2 ']'", 
                "++ break", 
                "++ echo 192.168.24.2", 
                "+ local METADATA_IP=192.168.24.2", 
                "+ local METADATA_IP_PING_TIMEOUT=60", 
                "+ '[' -n 192.168.24.2 ']'", 
                "+ is_local_ip 192.168.24.2", 
                "+ local IP_TO_CHECK=192.168.24.2", 
                "+ ip -o a", 
                "+ grep 'inet6\\? 192.168.24.2/'", 
                "+ return 1", 
                "+ echo -n 'Trying to ping metadata IP 192.168.24.2...'", 
                "++ getent hosts 192.168.24.2", 
                "++ awk '{ print $1 }'", 
                "+ _IP=", 
                "+ _ping=ping", 
                "+ [[ '' =~ : ]]", 
                "+ local COUNT=0", 
                "+ ping -c 1 192.168.24.2", 
                "+ echo SUCCESS", 
                "+ '[' -f /etc/udev/rules.d/99-dhcp-all-interfaces.rules ']'", 
                "+ rm /etc/udev/rules.d/99-dhcp-all-interfaces.rules", 
                "+ '[' -f /usr/libexec/os-apply-config/templates/etc/os-net-config/config.json ']'", 
                "+ '[' -f /usr/libexec/os-apply-config/templates/etc/os-net-config/element_config.json ']'", 
                "+ configure_safe_defaults", 
                "+ [[ 0 == 0 ]]", 
                "+ return 0", 
                "", 
                "[2019-06-05 19:04:06,526] (heat-config) [INFO] Completed /var/lib/heat-config/heat-config-script/bfaf691d-59c5-4a2e-9666-9bfc7cde9654", 
                "", 
                "[2019-06-05 19:04:06,534] (heat-config) [INFO] Completed /usr/libexec/heat-config/hooks/script", 
                "[2019-06-05 19:04:06,535] (heat-config) [DEBUG] Running heat-config-notify /var/lib/heat-config/deployed/bfaf691d-59c5-4a2e-9666-9bfc7cde9654.json < /var/lib/heat-config/deployed/bfaf691d-59c5-4a2e-9666-9bfc7cde9654.notify.json", 
                "[2019-06-05 19:04:06,883] (heat-config) [INFO] ", 
                "[2019-06-05 19:04:06,883] (heat-config) [DEBUG] "
            ]
        }, 
        {
            "status_code": "0"
        }
    ]
}
2019-06-05 14:04:09,059 p=17240 u=mistral |  ok: [lab-computehci-0] => {
    "msg": [
        {
            "stderr": [
                "[2019-06-05 19:03:38,876] (heat-config) [DEBUG] Running /usr/libexec/heat-config/hooks/script < /var/lib/heat-config/deployed/0486a9c2-07a4-457f-8586-654b0643bd07.json", 
                "[2019-06-05 19:04:02,144] (heat-config) [INFO] |-", 
                "  {\"deploy_stdout\": \"Trying to ping metadata IP 192.168.24.2...SUCCESS\\n\", \"deploy_stderr\": \"+ '[' -n '{\\\"network_config\\\": [{\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"192.168.24.17/24\\\"}], \\\"dns_servers\\\": [\\\"1.0.0.1\\\"], \\\"domain\\\": [], \\\"members\\\": [{\\\"mtu\\\": 1500, \\\"name\\\": \\\"nic1\\\", \\\"primary\\\": true, \\\"type\\\": \\\"interface\\\"}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"172.16.1.107/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 30}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"172.16.3.54/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 40}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"172.16.2.227/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 20}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"172.16.0.133/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 50}], \\\"mtu\\\": 1500, \\\"name\\\": \\\"bridge_name\\\", \\\"routes\\\": [{\\\"destination\\\": \\\"169.254.169.254/32\\\", \\\"nexthop\\\": \\\"192.168.24.3\\\"}, {\\\"ip_netmask\\\": \\\"169.254.169.254/32\\\", \\\"next_hop\\\": \\\"192.168.24.3\\\"}, {\\\"default\\\": true, \\\"next_hop\\\": \\\"192.168.24.1\\\"}], \\\"type\\\": \\\"ovs_bridge\\\", \\\"use_dhcp\\\": false}]}' ']'\\n+ '[' -z '' ']'\\n+ trap configure_safe_defaults EXIT\\n++ date +%Y-%m-%dT%H:%M:%S\\n+ DATETIME=2019-06-05T19:03:38\\n+ '[' -f /etc/os-net-config/config.json ']'\\n+ mkdir -p /etc/os-net-config\\n+ echo '{\\\"network_config\\\": [{\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"192.168.24.17/24\\\"}], \\\"dns_servers\\\": [\\\"1.0.0.1\\\"], \\\"domain\\\": [], \\\"members\\\": [{\\\"mtu\\\": 1500, \\\"name\\\": \\\"nic1\\\", \\\"primary\\\": true, \\\"type\\\": \\\"interface\\\"}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"172.16.1.107/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 30}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"172.16.3.54/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 40}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"172.16.2.227/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 20}, {\\\"addresses\\\": [{\\\"ip_netmask\\\": \\\"172.16.0.133/24\\\"}], \\\"mtu\\\": 1500, \\\"routes\\\": [], \\\"type\\\": \\\"vlan\\\", \\\"vlan_id\\\": 50}], \\\"mtu\\\": 1500, \\\"name\\\": \\\"bridge_name\\\", \\\"routes\\\": [{\\\"destination\\\": \\\"169.254.169.254/32\\\", \\\"nexthop\\\": \\\"192.168.24.3\\\"}, {\\\"ip_netmask\\\": \\\"169.254.169.254/32\\\", \\\"next_hop\\\": \\\"192.168.24.3\\\"}, {\\\"default\\\": true, \\\"next_hop\\\": \\\"192.168.24.1\\\"}], \\\"type\\\": \\\"ovs_bridge\\\", \\\"use_dhcp\\\": false}]}'\\n++ type -t network_config_hook\\n+ '[' '' = function ']'\\n+ sed -i s/bridge_name/br-ex/ /etc/os-net-config/config.json\\n+ sed -i s/interface_name/nic1/ /etc/os-net-config/config.json\\n+ set +e\\n+ os-net-config -c /etc/os-net-config/config.json -v --detailed-exit-codes\\n[2019/06/05 07:03:39 PM] [INFO] Using config file at: /etc/os-net-config/config.json\\n[2019/06/05 07:03:39 PM] [INFO] Ifcfg net config provider created.\\n[2019/06/05 07:03:39 PM] [INFO] Not using any mapping file.\\n[2019/06/05 07:03:39 PM] [INFO] Finding active nics\\n[2019/06/05 07:03:39 PM] [INFO] eth0 is an embedded active nic\\n[2019/06/05 07:03:39 PM] [INFO] eth1 is an embedded active nic\\n[2019/06/05 07:03:39 PM] [INFO] lo is not an active nic\\n[2019/06/05 07:03:39 PM] [INFO] No DPDK mapping available in path (/var/lib/os-net-config/dpdk_mapping.yaml)\\n[2019/06/05 07:03:39 PM] [INFO] Active nics are ['eth0', 'eth1']\\n[2019/06/05 07:03:39 PM] [INFO] nic2 mapped to: eth1\\n[2019/06/05 07:03:39 PM] [INFO] nic1 mapped to: eth0\\n[2019/06/05 07:03:39 PM] [INFO] adding bridge: br-ex\\n[2019/06/05 07:03:39 PM] [INFO] adding custom route for interface: br-ex\\n[2019/06/05 07:03:39 PM] [INFO] adding interface: eth0\\n[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan30\\n[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan40\\n[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan20\\n[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan50\\n[2019/06/05 07:03:39 PM] [INFO] applying network configs...\\n[2019/06/05 07:03:39 PM] [INFO] Running ip route add default via 192.168.24.1 dev br-ex\\n[2019/06/05 07:03:39 PM] [WARNING] Error in 'ip route add default via 192.168.24.1 dev br-ex', restarting br-ex:\\nUnexpected error while running command.\\nCommand: /sbin/ip route add default via 192.168.24.1 dev br-ex\\nExit code: 1\\nStdout: u''\\nStderr: u'Cannot find device \\\"br-ex\\\"\\\\n'\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan20\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan30\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan40\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan50\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: eth0\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan20\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan30\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan40\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan50\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: br-ex\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan20\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan30\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan40\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan50\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: eth0\\n[2019/06/05 07:03:39 PM] [INFO] running ifdown on bridge: br-ex\\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/route-br-ex\\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan20\\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan40\\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan50\\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-br-ex\\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan30\\n[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-eth0\\n[2019/06/05 07:03:39 PM] [INFO] running ifup on bridge: br-ex\\n[2019/06/05 07:03:43 PM] [INFO] running ifup on interface: eth0\\n[2019/06/05 07:03:44 PM] [INFO] running ifup on interface: vlan20\\n[2019/06/05 07:03:48 PM] [INFO] running ifup on interface: vlan30\\n[2019/06/05 07:03:52 PM] [INFO] running ifup on interface: vlan40\\n[2019/06/05 07:03:56 PM] [INFO] running ifup on interface: vlan50\\n[2019/06/05 07:04:00 PM] [INFO] running ifup on interface: br-ex\\n[2019/06/05 07:04:00 PM] [INFO] running ifup on interface: vlan20\\n[2019/06/05 07:04:00 PM] [INFO] running ifup on interface: vlan30\\n[2019/06/05 07:04:00 PM] [INFO] running ifup on interface: vlan40\\n[2019/06/05 07:04:00 PM] [INFO] running ifup on interface: vlan50\\n[2019/06/05 07:04:01 PM] [INFO] running ifup on interface: eth0\\n[2019/06/05 07:04:01 PM] [INFO] running ifup on interface: vlan20\\n[2019/06/05 07:04:01 PM] [INFO] running ifup on interface: vlan30\\n[2019/06/05 07:04:01 PM] [INFO] running ifup on interface: vlan40\\n[2019/06/05 07:04:01 PM] [INFO] running ifup on interface: vlan50\\n+ RETVAL=2\\n+ set -e\\n+ [[ 2 == 2 ]]\\n+ ping_metadata_ip\\n++ get_metadata_ip\\n++ local METADATA_IP\\n++ for URL in os-collect-config.cfn.metadata_url os-collect-config.heat.auth_url os-collect-config.request.metadata_url os-collect-config.zaqar.auth_url\\n+++ os-apply-config --key os-collect-config.cfn.metadata_url --key-default '' --type raw\\n+++ sed -e 's|http.*://\\\\[\\\\?\\\\([^]]*\\\\)]\\\\?:.*|\\\\1|'\\n++ METADATA_IP=\\n++ '[' -n '' ']'\\n++ for URL in os-collect-config.cfn.metadata_url os-collect-config.heat.auth_url os-collect-config.request.metadata_url os-collect-config.zaqar.auth_url\\n+++ os-apply-config --key os-collect-config.heat.auth_url --key-default '' --type raw\\n+++ sed -e 's|http.*://\\\\[\\\\?\\\\([^]]*\\\\)]\\\\?:.*|\\\\1|'\\n++ METADATA_IP=\\n++ '[' -n '' ']'\\n++ for URL in os-collect-config.cfn.metadata_url os-collect-config.heat.auth_url os-collect-config.request.metadata_url os-collect-config.zaqar.auth_url\\n+++ os-apply-config --key os-collect-config.request.metadata_url --key-default '' --type raw\\n+++ sed -e 's|http.*://\\\\[\\\\?\\\\([^]]*\\\\)]\\\\?:.*|\\\\1|'\\n++ METADATA_IP=192.168.24.2\\n++ '[' -n 192.168.24.2 ']'\\n++ break\\n++ echo 192.168.24.2\\n+ local METADATA_IP=192.168.24.2\\n+ local METADATA_IP_PING_TIMEOUT=60\\n+ '[' -n 192.168.24.2 ']'\\n+ is_local_ip 192.168.24.2\\n+ local IP_TO_CHECK=192.168.24.2\\n+ ip -o a\\n+ grep 'inet6\\\\? 192.168.24.2/'\\n+ return 1\\n+ echo -n 'Trying to ping metadata IP 192.168.24.2...'\\n++ getent hosts 192.168.24.2\\n++ awk '{ print $1 }'\\n+ _IP=\\n+ _ping=ping\\n+ [[ '' =~ : ]]\\n+ local COUNT=0\\n+ ping -c 1 192.168.24.2\\n+ echo SUCCESS\\n+ '[' -f /etc/udev/rules.d/99-dhcp-all-interfaces.rules ']'\\n+ rm /etc/udev/rules.d/99-dhcp-all-interfaces.rules\\n+ '[' -f /usr/libexec/os-apply-config/templates/etc/os-net-config/config.json ']'\\n+ '[' -f /usr/libexec/os-apply-config/templates/etc/os-net-config/element_config.json ']'\\n+ configure_safe_defaults\\n+ [[ 0 == 0 ]]\\n+ return 0\\n\", \"deploy_status_code\": 0}", 
                "", 
                "[2019-06-05 19:04:02,144] (heat-config) [DEBUG] [2019-06-05 19:03:38,889] (heat-config) [INFO] interface_name=nic1", 
                "[2019-06-05 19:03:38,889] (heat-config) [INFO] bridge_name=br-ex", 
                "[2019-06-05 19:03:38,889] (heat-config) [INFO] deploy_server_id=97f857d8-5e72-44c1-aebf-24385a2d79de", 
                "[2019-06-05 19:03:38,889] (heat-config) [INFO] deploy_action=CREATE", 
                "[2019-06-05 19:03:38,889] (heat-config) [INFO] deploy_stack_id=lab-ComputeHCI-fvdemw2wbikn-0-ytxxbhhyujfh-NetworkDeployment-erjwligksdqs-TripleOSoftwareDeployment-yym5ejhltpmn/611e13e5-b918-4c11-a7a2-20fcc1201285", 
                "[2019-06-05 19:03:38,889] (heat-config) [INFO] deploy_resource_name=TripleOSoftwareDeployment", 
                "[2019-06-05 19:03:38,889] (heat-config) [INFO] deploy_signal_transport=NO_SIGNAL", 
                "[2019-06-05 19:03:38,889] (heat-config) [DEBUG] Running /var/lib/heat-config/heat-config-script/0486a9c2-07a4-457f-8586-654b0643bd07", 
                "[2019-06-05 19:04:02,136] (heat-config) [INFO] Trying to ping metadata IP 192.168.24.2...SUCCESS", 
                "", 
                "[2019-06-05 19:04:02,136] (heat-config) [DEBUG] + '[' -n '{\"network_config\": [{\"addresses\": [{\"ip_netmask\": \"192.168.24.17/24\"}], \"dns_servers\": [\"1.0.0.1\"], \"domain\": [], \"members\": [{\"mtu\": 1500, \"name\": \"nic1\", \"primary\": true, \"type\": \"interface\"}, {\"addresses\": [{\"ip_netmask\": \"172.16.1.107/24\"}], \"mtu\": 1500, \"routes\": [], \"type\": \"vlan\", \"vlan_id\": 30}, {\"addresses\": [{\"ip_netmask\": \"172.16.3.54/24\"}], \"mtu\": 1500, \"routes\": [], \"type\": \"vlan\", \"vlan_id\": 40}, {\"addresses\": [{\"ip_netmask\": \"172.16.2.227/24\"}], \"mtu\": 1500, \"routes\": [], \"type\": \"vlan\", \"vlan_id\": 20}, {\"addresses\": [{\"ip_netmask\": \"172.16.0.133/24\"}], \"mtu\": 1500, \"routes\": [], \"type\": \"vlan\", \"vlan_id\": 50}], \"mtu\": 1500, \"name\": \"bridge_name\", \"routes\": [{\"destination\": \"169.254.169.254/32\", \"nexthop\": \"192.168.24.3\"}, {\"ip_netmask\": \"169.254.169.254/32\", \"next_hop\": \"192.168.24.3\"}, {\"default\": true, \"next_hop\": \"192.168.24.1\"}], \"type\": \"ovs_bridge\", \"use_dhcp\": false}]}' ']'", 
                "+ '[' -z '' ']'", 
                "+ trap configure_safe_defaults EXIT", 
                "++ date +%Y-%m-%dT%H:%M:%S", 
                "+ DATETIME=2019-06-05T19:03:38", 
                "+ '[' -f /etc/os-net-config/config.json ']'", 
                "+ mkdir -p /etc/os-net-config", 
                "+ echo '{\"network_config\": [{\"addresses\": [{\"ip_netmask\": \"192.168.24.17/24\"}], \"dns_servers\": [\"1.0.0.1\"], \"domain\": [], \"members\": [{\"mtu\": 1500, \"name\": \"nic1\", \"primary\": true, \"type\": \"interface\"}, {\"addresses\": [{\"ip_netmask\": \"172.16.1.107/24\"}], \"mtu\": 1500, \"routes\": [], \"type\": \"vlan\", \"vlan_id\": 30}, {\"addresses\": [{\"ip_netmask\": \"172.16.3.54/24\"}], \"mtu\": 1500, \"routes\": [], \"type\": \"vlan\", \"vlan_id\": 40}, {\"addresses\": [{\"ip_netmask\": \"172.16.2.227/24\"}], \"mtu\": 1500, \"routes\": [], \"type\": \"vlan\", \"vlan_id\": 20}, {\"addresses\": [{\"ip_netmask\": \"172.16.0.133/24\"}], \"mtu\": 1500, \"routes\": [], \"type\": \"vlan\", \"vlan_id\": 50}], \"mtu\": 1500, \"name\": \"bridge_name\", \"routes\": [{\"destination\": \"169.254.169.254/32\", \"nexthop\": \"192.168.24.3\"}, {\"ip_netmask\": \"169.254.169.254/32\", \"next_hop\": \"192.168.24.3\"}, {\"default\": true, \"next_hop\": \"192.168.24.1\"}], \"type\": \"ovs_bridge\", \"use_dhcp\": false}]}'", 
                "++ type -t network_config_hook", 
                "+ '[' '' = function ']'", 
                "+ sed -i s/bridge_name/br-ex/ /etc/os-net-config/config.json", 
                "+ sed -i s/interface_name/nic1/ /etc/os-net-config/config.json", 
                "+ set +e", 
                "+ os-net-config -c /etc/os-net-config/config.json -v --detailed-exit-codes", 
                "[2019/06/05 07:03:39 PM] [INFO] Using config file at: /etc/os-net-config/config.json", 
                "[2019/06/05 07:03:39 PM] [INFO] Ifcfg net config provider created.", 
                "[2019/06/05 07:03:39 PM] [INFO] Not using any mapping file.", 
                "[2019/06/05 07:03:39 PM] [INFO] Finding active nics", 
                "[2019/06/05 07:03:39 PM] [INFO] eth0 is an embedded active nic", 
                "[2019/06/05 07:03:39 PM] [INFO] eth1 is an embedded active nic", 
                "[2019/06/05 07:03:39 PM] [INFO] lo is not an active nic", 
                "[2019/06/05 07:03:39 PM] [INFO] No DPDK mapping available in path (/var/lib/os-net-config/dpdk_mapping.yaml)", 
                "[2019/06/05 07:03:39 PM] [INFO] Active nics are ['eth0', 'eth1']", 
                "[2019/06/05 07:03:39 PM] [INFO] nic2 mapped to: eth1", 
                "[2019/06/05 07:03:39 PM] [INFO] nic1 mapped to: eth0", 
                "[2019/06/05 07:03:39 PM] [INFO] adding bridge: br-ex", 
                "[2019/06/05 07:03:39 PM] [INFO] adding custom route for interface: br-ex", 
                "[2019/06/05 07:03:39 PM] [INFO] adding interface: eth0", 
                "[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan30", 
                "[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan40", 
                "[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan20", 
                "[2019/06/05 07:03:39 PM] [INFO] adding vlan: vlan50", 
                "[2019/06/05 07:03:39 PM] [INFO] applying network configs...", 
                "[2019/06/05 07:03:39 PM] [INFO] Running ip route add default via 192.168.24.1 dev br-ex", 
                "[2019/06/05 07:03:39 PM] [WARNING] Error in 'ip route add default via 192.168.24.1 dev br-ex', restarting br-ex:", 
                "Unexpected error while running command.", 
                "Command: /sbin/ip route add default via 192.168.24.1 dev br-ex", 
                "Exit code: 1", 
                "Stdout: u''", 
                "Stderr: u'Cannot find device \"br-ex\"\\n'", 
                "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan20", 
                "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan30", 
                "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan40", 
                "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan50", 
                "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: eth0", 
                "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan20", 
                "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan30", 
                "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan40", 
                "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan50", 
                "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: br-ex", 
                "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan20", 
                "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan30", 
                "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan40", 
                "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: vlan50", 
                "[2019/06/05 07:03:39 PM] [INFO] running ifdown on interface: eth0", 
                "[2019/06/05 07:03:39 PM] [INFO] running ifdown on bridge: br-ex", 
                "[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/route-br-ex", 
                "[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan20", 
                "[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan40", 
                "[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan50", 
                "[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-br-ex", 
                "[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-vlan30", 
                "[2019/06/05 07:03:39 PM] [INFO] Writing config /etc/sysconfig/network-scripts/ifcfg-eth0", 
                "[2019/06/05 07:03:39 PM] [INFO] running ifup on bridge: br-ex", 
                "[2019/06/05 07:03:43 PM] [INFO] running ifup on interface: eth0", 
                "[2019/06/05 07:03:44 PM] [INFO] running ifup on interface: vlan20", 
                "[2019/06/05 07:03:48 PM] [INFO] running ifup on interface: vlan30", 
                "[2019/06/05 07:03:52 PM] [INFO] running ifup on interface: vlan40", 
                "[2019/06/05 07:03:56 PM] [INFO] running ifup on interface: vlan50", 
                "[2019/06/05 07:04:00 PM] [INFO] running ifup on interface: br-ex", 
                "[2019/06/05 07:04:00 PM] [INFO] running ifup on interface: vlan20", 
                "[2019/06/05 07:04:00 PM] [INFO] running ifup on interface: vlan30", 
                "[2019/06/05 07:04:00 PM] [INFO] running ifup on interface: vlan40", 
                "[2019/06/05 07:04:00 PM] [INFO] running ifup on interface: vlan50", 
                "[2019/06/05 07:04:01 PM] [INFO] running ifup on interface: eth0", 
                "[2019/06/05 07:04:01 PM] [INFO] running ifup on interface: vlan20", 
                "[2019/06/05 07:04:01 PM] [INFO] running ifup on interface: vlan30", 
                "[2019/06/05 07:04:01 PM] [INFO] running ifup on interface: vlan40", 
                "[2019/06/05 07:04:01 PM] [INFO] running ifup on interface: vlan50", 
                "+ RETVAL=2", 
                "+ set -e", 
                "+ [[ 2 == 2 ]]", 
                "+ ping_metadata_ip", 
                "++ get_metadata_ip", 
                "++ local METADATA_IP", 
                "++ for URL in os-collect-config.cfn.metadata_url os-collect-config.heat.auth_url os-collect-config.request.metadata_url os-collect-config.zaqar.auth_url", 
                "+++ os-apply-config --key os-collect-config.cfn.metadata_url --key-default '' --type raw", 
                "+++ sed -e 's|http.*://\\[\\?\\([^]]*\\)]\\?:.*|\\1|'", 
                "++ METADATA_IP=", 
                "++ '[' -n '' ']'", 
                "++ for URL in os-collect-config.cfn.metadata_url os-collect-config.heat.auth_url os-collect-config.request.metadata_url os-collect-config.zaqar.auth_url", 
                "+++ os-apply-config --key os-collect-config.heat.auth_url --key-default '' --type raw", 
                "+++ sed -e 's|http.*://\\[\\?\\([^]]*\\)]\\?:.*|\\1|'", 
                "++ METADATA_IP=", 
                "++ '[' -n '' ']'", 
                "++ for URL in os-collect-config.cfn.metadata_url os-collect-config.heat.auth_url os-collect-config.request.metadata_url os-collect-config.zaqar.auth_url", 
                "+++ os-apply-config --key os-collect-config.request.metadata_url --key-default '' --type raw", 
                "+++ sed -e 's|http.*://\\[\\?\\([^]]*\\)]\\?:.*|\\1|'", 
                "++ METADATA_IP=192.168.24.2", 
                "++ '[' -n 192.168.24.2 ']'", 
                "++ break", 
                "++ echo 192.168.24.2", 
                "+ local METADATA_IP=192.168.24.2", 
                "+ local METADATA_IP_PING_TIMEOUT=60", 
                "+ '[' -n 192.168.24.2 ']'", 
                "+ is_local_ip 192.168.24.2", 
                "+ local IP_TO_CHECK=192.168.24.2", 
                "+ ip -o a", 
                "+ grep 'inet6\\? 192.168.24.2/'", 
                "+ return 1", 
                "+ echo -n 'Trying to ping metadata IP 192.168.24.2...'", 
                "++ getent hosts 192.168.24.2", 
                "++ awk '{ print $1 }'", 
                "+ _IP=", 
                "+ _ping=ping", 
                "+ [[ '' =~ : ]]", 
                "+ local COUNT=0", 
                "+ ping -c 1 192.168.24.2", 
                "+ echo SUCCESS", 
                "+ '[' -f /etc/udev/rules.d/99-dhcp-all-interfaces.rules ']'", 
                "+ rm /etc/udev/rules.d/99-dhcp-all-interfaces.rules", 
                "+ '[' -f /usr/libexec/os-apply-config/templates/etc/os-net-config/config.json ']'", 
                "+ '[' -f /usr/libexec/os-apply-config/templates/etc/os-net-config/element_config.json ']'", 
                "+ configure_safe_defaults", 
                "+ [[ 0 == 0 ]]", 
                "+ return 0", 
                "", 
                "[2019-06-05 19:04:02,136] (heat-config) [INFO] Completed /var/lib/heat-config/heat-config-script/0486a9c2-07a4-457f-8586-654b0643bd07", 
                "", 
                "[2019-06-05 19:04:02,144] (heat-config) [INFO] Completed /usr/libexec/heat-config/hooks/script", 
                "[2019-06-05 19:04:02,145] (heat-config) [DEBUG] Running heat-config-notify /var/lib/heat-config/deployed/0486a9c2-07a4-457f-8586-654b0643bd07.json < /var/lib/heat-config/deployed/0486a9c2-07a4-457f-8586-654b0643bd07.notify.json", 
                "[2019-06-05 19:04:02,490] (heat-config) [INFO] ", 
                "[2019-06-05 19:04:02,490] (heat-config) [DEBUG] "
            ]
        }, 
        {
            "status_code": "0"
        }
    ]
}
2019-06-05 14:04:09,076 p=17240 u=mistral |  TASK [Check-mode for Run deployment NetworkDeployment (changed status indicates deployment would run)] ***
2019-06-05 14:04:09,076 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:186
2019-06-05 14:04:09,076 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:09 -0500 (0:00:00.071)       0:00:42.846 ******** 
2019-06-05 14:04:09,096 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:09,102 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:09,119 p=17240 u=mistral |  TASK [Lookup deployment UUID] **************************************************
2019-06-05 14:04:09,119 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:1
2019-06-05 14:04:09,119 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:09 -0500 (0:00:00.042)       0:00:42.888 ******** 
2019-06-05 14:04:09,121 p=17240 u=mistral |  META: noop
2019-06-05 14:04:09,296 p=17240 u=mistral |  ok: [lab-controller-0] => {"ansible_facts": {"deployment_uuid": "07bd55ba-19cc-48f6-ab2e-01cdf94e05fd"}, "changed": false}
2019-06-05 14:04:09,312 p=17240 u=mistral |  TASK [Lookup deployment group] *************************************************
2019-06-05 14:04:09,312 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:5
2019-06-05 14:04:09,312 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:09 -0500 (0:00:00.192)       0:00:43.081 ******** 
2019-06-05 14:04:09,314 p=17240 u=mistral |  META: noop
2019-06-05 14:04:09,489 p=17240 u=mistral |  ok: [lab-controller-0] => {"ansible_facts": {"deployment_group": "hiera"}, "changed": false}
2019-06-05 14:04:09,505 p=17240 u=mistral |  TASK [Create hiera check-mode directory] ***************************************
2019-06-05 14:04:09,505 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:13
2019-06-05 14:04:09,505 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:09 -0500 (0:00:00.193)       0:00:43.275 ******** 
2019-06-05 14:04:09,507 p=17240 u=mistral |  META: noop
2019-06-05 14:04:09,518 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:09,534 p=17240 u=mistral |  TASK [Create deployed check-mode directory] ************************************
2019-06-05 14:04:09,534 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:19
2019-06-05 14:04:09,535 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:09 -0500 (0:00:00.029)       0:00:43.304 ******** 
2019-06-05 14:04:09,536 p=17240 u=mistral |  META: noop
2019-06-05 14:04:09,548 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:09,566 p=17240 u=mistral |  TASK [Create tripleo-config-download check-mode directory] *********************
2019-06-05 14:04:09,566 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:25
2019-06-05 14:04:09,566 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:09 -0500 (0:00:00.031)       0:00:43.336 ******** 
2019-06-05 14:04:09,568 p=17240 u=mistral |  META: noop
2019-06-05 14:04:09,577 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:09,595 p=17240 u=mistral |  TASK [Render deployment file for ControllerDeployment for check-mode] **********
2019-06-05 14:04:09,595 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:31
2019-06-05 14:04:09,595 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:09 -0500 (0:00:00.028)       0:00:43.364 ******** 
2019-06-05 14:04:09,597 p=17240 u=mistral |  META: noop
2019-06-05 14:04:09,607 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:09,623 p=17240 u=mistral |  TASK [Run hiera deployment for check mode] *************************************
2019-06-05 14:04:09,623 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:38
2019-06-05 14:04:09,623 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:09 -0500 (0:00:00.027)       0:00:43.392 ******** 
2019-06-05 14:04:09,625 p=17240 u=mistral |  META: noop
2019-06-05 14:04:09,634 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:09,650 p=17240 u=mistral |  TASK [List hieradata files for check mode] *************************************
2019-06-05 14:04:09,650 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:54
2019-06-05 14:04:09,650 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:09 -0500 (0:00:00.027)       0:00:43.420 ******** 
2019-06-05 14:04:09,652 p=17240 u=mistral |  META: noop
2019-06-05 14:04:09,662 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:09,679 p=17240 u=mistral |  TASK [diff hieradata changes for check mode] ***********************************
2019-06-05 14:04:09,679 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:60
2019-06-05 14:04:09,679 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:09 -0500 (0:00:00.028)       0:00:43.448 ******** 
2019-06-05 14:04:09,681 p=17240 u=mistral |  META: noop
2019-06-05 14:04:09,691 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:09,707 p=17240 u=mistral |  TASK [diff hieradata changes for check mode] ***********************************
2019-06-05 14:04:09,707 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:73
2019-06-05 14:04:09,707 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:09 -0500 (0:00:00.028)       0:00:43.477 ******** 
2019-06-05 14:04:09,709 p=17240 u=mistral |  META: noop
2019-06-05 14:04:09,719 p=17240 u=mistral |  skipping: [lab-controller-0] => {}
2019-06-05 14:04:09,735 p=17240 u=mistral |  TASK [hiera.yaml changes for check mode] ***************************************
2019-06-05 14:04:09,735 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:82
2019-06-05 14:04:09,735 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:09 -0500 (0:00:00.028)       0:00:43.505 ******** 
2019-06-05 14:04:09,737 p=17240 u=mistral |  META: noop
2019-06-05 14:04:09,747 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:09,764 p=17240 u=mistral |  TASK [diff hiera.yaml changes for check mode] **********************************
2019-06-05 14:04:09,764 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:90
2019-06-05 14:04:09,764 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:09 -0500 (0:00:00.028)       0:00:43.533 ******** 
2019-06-05 14:04:09,766 p=17240 u=mistral |  META: noop
2019-06-05 14:04:09,774 p=17240 u=mistral |  skipping: [lab-controller-0] => {}
2019-06-05 14:04:09,792 p=17240 u=mistral |  TASK [Render deployment file for ControllerDeployment] *************************
2019-06-05 14:04:09,792 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:102
2019-06-05 14:04:09,792 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:09 -0500 (0:00:00.028)       0:00:43.561 ******** 
2019-06-05 14:04:09,794 p=17240 u=mistral |  META: noop
2019-06-05 14:04:10,260 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "checksum": "6b7c68ba74515ba4855d9a6e6a3b530e25403ca0", "dest": "/var/lib/heat-config/tripleo-config-download/ControllerDeployment-07bd55ba-19cc-48f6-ab2e-01cdf94e05fd", "gid": 0, "group": "root", "md5sum": "6106f2eeec0eb5dd2ddc8e12e48b1c6a", "mode": "0644", "owner": "root", "secontext": "system_u:object_r:var_lib_t:s0", "size": 60711, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559761449.99-149718930648784/source", "state": "file", "uid": 0}
2019-06-05 14:04:10,277 p=17240 u=mistral |  TASK [Check if deployed file exists for ControllerDeployment] ******************
2019-06-05 14:04:10,277 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:108
2019-06-05 14:04:10,277 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:10 -0500 (0:00:00.485)       0:00:44.047 ******** 
2019-06-05 14:04:10,279 p=17240 u=mistral |  META: noop
2019-06-05 14:04:10,379 p=17240 u=mistral |  ok: [lab-controller-0] => {"changed": false, "stat": {"exists": false}}
2019-06-05 14:04:10,397 p=17240 u=mistral |  TASK [Check previous deployment rc for ControllerDeployment] *******************
2019-06-05 14:04:10,397 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:113
2019-06-05 14:04:10,397 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:10 -0500 (0:00:00.119)       0:00:44.166 ******** 
2019-06-05 14:04:10,399 p=17240 u=mistral |  META: noop
2019-06-05 14:04:10,408 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:10,425 p=17240 u=mistral |  TASK [Remove deployed file for ControllerDeployment when previous deployment failed] ***
2019-06-05 14:04:10,426 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:121
2019-06-05 14:04:10,426 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:10 -0500 (0:00:00.028)       0:00:44.195 ******** 
2019-06-05 14:04:10,427 p=17240 u=mistral |  META: noop
2019-06-05 14:04:10,437 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:10,454 p=17240 u=mistral |  TASK [Force remove deployed file for ControllerDeployment] *********************
2019-06-05 14:04:10,455 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:131
2019-06-05 14:04:10,455 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:10 -0500 (0:00:00.029)       0:00:44.224 ******** 
2019-06-05 14:04:10,457 p=17240 u=mistral |  META: noop
2019-06-05 14:04:10,465 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:10,482 p=17240 u=mistral |  TASK [Set fact for async_deployment] *******************************************
2019-06-05 14:04:10,482 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:138
2019-06-05 14:04:10,482 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:10 -0500 (0:00:00.027)       0:00:44.251 ******** 
2019-06-05 14:04:10,485 p=17240 u=mistral |  META: noop
2019-06-05 14:04:10,508 p=17240 u=mistral |  ok: [lab-controller-0] => {"ansible_facts": {"use_async_deployment": false}, "changed": false}
2019-06-05 14:04:10,525 p=17240 u=mistral |  TASK [Run deployment ControllerDeployment] *************************************
2019-06-05 14:04:10,525 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:142
2019-06-05 14:04:10,525 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:10 -0500 (0:00:00.043)       0:00:44.294 ******** 
2019-06-05 14:04:10,527 p=17240 u=mistral |  META: noop
2019-06-05 14:04:11,126 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "cmd": "/usr/libexec/os-refresh-config/configure.d/55-heat-config\n exit $(jq .deploy_status_code /var/lib/heat-config/deployed/07bd55ba-19cc-48f6-ab2e-01cdf94e05fd.notify.json)", "delta": "0:00:00.495142", "end": "2019-06-05 19:04:11.116434", "rc": 0, "start": "2019-06-05 19:04:10.621292", "stderr": "[2019-06-05 19:04:10,650] (heat-config) [DEBUG] Running /usr/libexec/heat-config/hooks/hiera < /var/lib/heat-config/deployed/07bd55ba-19cc-48f6-ab2e-01cdf94e05fd.json\n[2019-06-05 19:04:10,817] (heat-config) [INFO] |-\n  {\"deploy_stdout\": \"\", \"deploy_stderr\": \"\", \"deploy_status_code\": 0}\n\n[2019-06-05 19:04:10,818] (heat-config) [DEBUG] \n[2019-06-05 19:04:10,818] (heat-config) [INFO] Completed /usr/libexec/heat-config/hooks/hiera\n[2019-06-05 19:04:10,818] (heat-config) [DEBUG] Running heat-config-notify /var/lib/heat-config/deployed/07bd55ba-19cc-48f6-ab2e-01cdf94e05fd.json < /var/lib/heat-config/deployed/07bd55ba-19cc-48f6-ab2e-01cdf94e05fd.notify.json\n[2019-06-05 19:04:11,110] (heat-config) [INFO] \n[2019-06-05 19:04:11,110] (heat-config) [DEBUG] ", "stderr_lines": ["[2019-06-05 19:04:10,650] (heat-config) [DEBUG] Running /usr/libexec/heat-config/hooks/hiera < /var/lib/heat-config/deployed/07bd55ba-19cc-48f6-ab2e-01cdf94e05fd.json", "[2019-06-05 19:04:10,817] (heat-config) [INFO] |-", "  {\"deploy_stdout\": \"\", \"deploy_stderr\": \"\", \"deploy_status_code\": 0}", "", "[2019-06-05 19:04:10,818] (heat-config) [DEBUG] ", "[2019-06-05 19:04:10,818] (heat-config) [INFO] Completed /usr/libexec/heat-config/hooks/hiera", "[2019-06-05 19:04:10,818] (heat-config) [DEBUG] Running heat-config-notify /var/lib/heat-config/deployed/07bd55ba-19cc-48f6-ab2e-01cdf94e05fd.json < /var/lib/heat-config/deployed/07bd55ba-19cc-48f6-ab2e-01cdf94e05fd.notify.json", "[2019-06-05 19:04:11,110] (heat-config) [INFO] ", "[2019-06-05 19:04:11,110] (heat-config) [DEBUG] "], "stdout": "", "stdout_lines": []}
2019-06-05 14:04:11,143 p=17240 u=mistral |  TASK [Run async deployment ControllerDeployment] *******************************
2019-06-05 14:04:11,143 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:153
2019-06-05 14:04:11,143 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:11 -0500 (0:00:00.618)       0:00:44.913 ******** 
2019-06-05 14:04:11,145 p=17240 u=mistral |  META: noop
2019-06-05 14:04:11,153 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:11,170 p=17240 u=mistral |  TASK [Output for sync deployment ControllerDeployment] *************************
2019-06-05 14:04:11,170 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:166
2019-06-05 14:04:11,170 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:11 -0500 (0:00:00.026)       0:00:44.939 ******** 
2019-06-05 14:04:11,172 p=17240 u=mistral |  META: noop
2019-06-05 14:04:11,202 p=17240 u=mistral |  ok: [lab-controller-0] => {
    "msg": [
        {
            "stderr": [
                "[2019-06-05 19:04:10,650] (heat-config) [DEBUG] Running /usr/libexec/heat-config/hooks/hiera < /var/lib/heat-config/deployed/07bd55ba-19cc-48f6-ab2e-01cdf94e05fd.json", 
                "[2019-06-05 19:04:10,817] (heat-config) [INFO] |-", 
                "  {\"deploy_stdout\": \"\", \"deploy_stderr\": \"\", \"deploy_status_code\": 0}", 
                "", 
                "[2019-06-05 19:04:10,818] (heat-config) [DEBUG] ", 
                "[2019-06-05 19:04:10,818] (heat-config) [INFO] Completed /usr/libexec/heat-config/hooks/hiera", 
                "[2019-06-05 19:04:10,818] (heat-config) [DEBUG] Running heat-config-notify /var/lib/heat-config/deployed/07bd55ba-19cc-48f6-ab2e-01cdf94e05fd.json < /var/lib/heat-config/deployed/07bd55ba-19cc-48f6-ab2e-01cdf94e05fd.notify.json", 
                "[2019-06-05 19:04:11,110] (heat-config) [INFO] ", 
                "[2019-06-05 19:04:11,110] (heat-config) [DEBUG] "
            ]
        }, 
        {
            "status_code": "0"
        }
    ]
}
2019-06-05 14:04:11,219 p=17240 u=mistral |  TASK [Output for async deployment ControllerDeployment] ************************
2019-06-05 14:04:11,219 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:176
2019-06-05 14:04:11,219 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:11 -0500 (0:00:00.049)       0:00:44.989 ******** 
2019-06-05 14:04:11,221 p=17240 u=mistral |  META: noop
2019-06-05 14:04:11,230 p=17240 u=mistral |  skipping: [lab-controller-0] => {}
2019-06-05 14:04:11,247 p=17240 u=mistral |  TASK [Check-mode for Run deployment ControllerDeployment (changed status indicates deployment would run)] ***
2019-06-05 14:04:11,247 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:186
2019-06-05 14:04:11,247 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:11 -0500 (0:00:00.027)       0:00:45.017 ******** 
2019-06-05 14:04:11,249 p=17240 u=mistral |  META: noop
2019-06-05 14:04:11,256 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:11,272 p=17240 u=mistral |  TASK [Lookup deployment UUID] **************************************************
2019-06-05 14:04:11,272 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:1
2019-06-05 14:04:11,272 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:11 -0500 (0:00:00.024)       0:00:45.041 ******** 
2019-06-05 14:04:11,274 p=17240 u=mistral |  META: noop
2019-06-05 14:04:11,307 p=17240 u=mistral |  ok: [lab-controller-0] => {"ansible_facts": {"deployment_uuid": "68f83282-7d94-4bce-8450-22aadd93df5a"}, "changed": false}
2019-06-05 14:04:11,325 p=17240 u=mistral |  TASK [Lookup deployment group] *************************************************
2019-06-05 14:04:11,325 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:5
2019-06-05 14:04:11,325 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:11 -0500 (0:00:00.052)       0:00:45.094 ******** 
2019-06-05 14:04:11,327 p=17240 u=mistral |  META: noop
2019-06-05 14:04:11,358 p=17240 u=mistral |  ok: [lab-controller-0] => {"ansible_facts": {"deployment_group": "script"}, "changed": false}
2019-06-05 14:04:11,374 p=17240 u=mistral |  TASK [Create hiera check-mode directory] ***************************************
2019-06-05 14:04:11,374 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:13
2019-06-05 14:04:11,374 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:11 -0500 (0:00:00.049)       0:00:45.144 ******** 
2019-06-05 14:04:11,376 p=17240 u=mistral |  META: noop
2019-06-05 14:04:11,385 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:11,401 p=17240 u=mistral |  TASK [Create deployed check-mode directory] ************************************
2019-06-05 14:04:11,401 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:19
2019-06-05 14:04:11,401 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:11 -0500 (0:00:00.026)       0:00:45.170 ******** 
2019-06-05 14:04:11,403 p=17240 u=mistral |  META: noop
2019-06-05 14:04:11,411 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:11,428 p=17240 u=mistral |  TASK [Create tripleo-config-download check-mode directory] *********************
2019-06-05 14:04:11,428 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:25
2019-06-05 14:04:11,428 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:11 -0500 (0:00:00.026)       0:00:45.197 ******** 
2019-06-05 14:04:11,430 p=17240 u=mistral |  META: noop
2019-06-05 14:04:11,438 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:11,455 p=17240 u=mistral |  TASK [Render deployment file for ControllerHostsDeployment for check-mode] *****
2019-06-05 14:04:11,455 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:31
2019-06-05 14:04:11,455 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:11 -0500 (0:00:00.027)       0:00:45.225 ******** 
2019-06-05 14:04:11,457 p=17240 u=mistral |  META: noop
2019-06-05 14:04:11,466 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:11,482 p=17240 u=mistral |  TASK [Run hiera deployment for check mode] *************************************
2019-06-05 14:04:11,482 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:38
2019-06-05 14:04:11,482 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:11 -0500 (0:00:00.026)       0:00:45.252 ******** 
2019-06-05 14:04:11,484 p=17240 u=mistral |  META: noop
2019-06-05 14:04:11,493 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:11,510 p=17240 u=mistral |  TASK [List hieradata files for check mode] *************************************
2019-06-05 14:04:11,510 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:54
2019-06-05 14:04:11,510 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:11 -0500 (0:00:00.027)       0:00:45.280 ******** 
2019-06-05 14:04:11,512 p=17240 u=mistral |  META: noop
2019-06-05 14:04:11,521 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:11,538 p=17240 u=mistral |  TASK [diff hieradata changes for check mode] ***********************************
2019-06-05 14:04:11,538 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:60
2019-06-05 14:04:11,538 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:11 -0500 (0:00:00.027)       0:00:45.307 ******** 
2019-06-05 14:04:11,540 p=17240 u=mistral |  META: noop
2019-06-05 14:04:11,549 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:11,566 p=17240 u=mistral |  TASK [diff hieradata changes for check mode] ***********************************
2019-06-05 14:04:11,566 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:73
2019-06-05 14:04:11,566 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:11 -0500 (0:00:00.028)       0:00:45.335 ******** 
2019-06-05 14:04:11,568 p=17240 u=mistral |  META: noop
2019-06-05 14:04:11,578 p=17240 u=mistral |  skipping: [lab-controller-0] => {}
2019-06-05 14:04:11,594 p=17240 u=mistral |  TASK [hiera.yaml changes for check mode] ***************************************
2019-06-05 14:04:11,594 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:82
2019-06-05 14:04:11,594 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:11 -0500 (0:00:00.028)       0:00:45.364 ******** 
2019-06-05 14:04:11,596 p=17240 u=mistral |  META: noop
2019-06-05 14:04:11,605 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:11,622 p=17240 u=mistral |  TASK [diff hiera.yaml changes for check mode] **********************************
2019-06-05 14:04:11,622 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:90
2019-06-05 14:04:11,622 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:11 -0500 (0:00:00.027)       0:00:45.391 ******** 
2019-06-05 14:04:11,624 p=17240 u=mistral |  META: noop
2019-06-05 14:04:11,632 p=17240 u=mistral |  skipping: [lab-controller-0] => {}
2019-06-05 14:04:11,651 p=17240 u=mistral |  TASK [Render deployment file for ControllerHostsDeployment] ********************
2019-06-05 14:04:11,651 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:102
2019-06-05 14:04:11,651 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:11 -0500 (0:00:00.028)       0:00:45.420 ******** 
2019-06-05 14:04:11,653 p=17240 u=mistral |  META: noop
2019-06-05 14:04:11,945 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "checksum": "b7f39de7f65c57d3e217b62742498fe06227c4ef", "dest": "/var/lib/heat-config/tripleo-config-download/ControllerHostsDeployment-68f83282-7d94-4bce-8450-22aadd93df5a", "gid": 0, "group": "root", "md5sum": "94cd81ee3b442ac7cb23ae5b95397769", "mode": "0644", "owner": "root", "secontext": "system_u:object_r:var_lib_t:s0", "size": 3845, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559761451.69-274948934134156/source", "state": "file", "uid": 0}
2019-06-05 14:04:11,962 p=17240 u=mistral |  TASK [Check if deployed file exists for ControllerHostsDeployment] *************
2019-06-05 14:04:11,962 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:108
2019-06-05 14:04:11,963 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:11 -0500 (0:00:00.311)       0:00:45.732 ******** 
2019-06-05 14:04:11,965 p=17240 u=mistral |  META: noop
2019-06-05 14:04:12,065 p=17240 u=mistral |  ok: [lab-controller-0] => {"changed": false, "stat": {"exists": false}}
2019-06-05 14:04:12,082 p=17240 u=mistral |  TASK [Check previous deployment rc for ControllerHostsDeployment] **************
2019-06-05 14:04:12,082 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:113
2019-06-05 14:04:12,082 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:12 -0500 (0:00:00.119)       0:00:45.851 ******** 
2019-06-05 14:04:12,084 p=17240 u=mistral |  META: noop
2019-06-05 14:04:12,093 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:12,110 p=17240 u=mistral |  TASK [Remove deployed file for ControllerHostsDeployment when previous deployment failed] ***
2019-06-05 14:04:12,110 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:121
2019-06-05 14:04:12,110 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:12 -0500 (0:00:00.027)       0:00:45.879 ******** 
2019-06-05 14:04:12,112 p=17240 u=mistral |  META: noop
2019-06-05 14:04:12,125 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:12,144 p=17240 u=mistral |  TASK [Force remove deployed file for ControllerHostsDeployment] ****************
2019-06-05 14:04:12,144 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:131
2019-06-05 14:04:12,144 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:12 -0500 (0:00:00.034)       0:00:45.914 ******** 
2019-06-05 14:04:12,146 p=17240 u=mistral |  META: noop
2019-06-05 14:04:12,155 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:12,171 p=17240 u=mistral |  TASK [Set fact for async_deployment] *******************************************
2019-06-05 14:04:12,172 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:138
2019-06-05 14:04:12,172 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:12 -0500 (0:00:00.027)       0:00:45.941 ******** 
2019-06-05 14:04:12,173 p=17240 u=mistral |  META: noop
2019-06-05 14:04:12,199 p=17240 u=mistral |  ok: [lab-controller-0] => {"ansible_facts": {"use_async_deployment": false}, "changed": false}
2019-06-05 14:04:12,217 p=17240 u=mistral |  TASK [Run deployment ControllerHostsDeployment] ********************************
2019-06-05 14:04:12,217 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:142
2019-06-05 14:04:12,217 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:12 -0500 (0:00:00.045)       0:00:45.986 ******** 
2019-06-05 14:04:12,219 p=17240 u=mistral |  META: noop
2019-06-05 14:04:12,744 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "cmd": "/usr/libexec/os-refresh-config/configure.d/55-heat-config\n exit $(jq .deploy_status_code /var/lib/heat-config/deployed/68f83282-7d94-4bce-8450-22aadd93df5a.notify.json)", "delta": "0:00:00.369255", "end": "2019-06-05 19:04:12.682991", "rc": 0, "start": "2019-06-05 19:04:12.313736", "stderr": "[2019-06-05 19:04:12,340] (heat-config) [DEBUG] Running /usr/libexec/heat-config/hooks/script < /var/lib/heat-config/deployed/68f83282-7d94-4bce-8450-22aadd93df5a.json\n[2019-06-05 19:04:12,385] (heat-config) [INFO] |-\n  {\"deploy_stdout\": \"\", \"deploy_stderr\": \"+ set -o pipefail\\n+ hosts='192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ '[' '!' -z '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n' ']'\\n+ for tmpl in '/etc/cloud/templates/hosts.*.tmpl'\\n+ write_entries /etc/cloud/templates/hosts.debian.tmpl '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ local file=/etc/cloud/templates/hosts.debian.tmpl\\n+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ '[' '!' -f /etc/cloud/templates/hosts.debian.tmpl ']'\\n+ grep -q '^# HEAT_HOSTS_START' /etc/cloud/templates/hosts.debian.tmpl\\n++ hostname -s\\n+ sed -i /lab-controller-0/d /etc/cloud/templates/hosts.debian.tmpl\\n+ echo -ne '\\\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\\\n'\\n+ echo '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ echo -ne '# HEAT_HOSTS_END\\\\n\\\\n'\\n+ for tmpl in '/etc/cloud/templates/hosts.*.tmpl'\\n+ write_entries /etc/cloud/templates/hosts.freebsd.tmpl '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ local file=/etc/cloud/templates/hosts.freebsd.tmpl\\n+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ '[' '!' -f /etc/cloud/templates/hosts.freebsd.tmpl ']'\\n+ grep -q '^# HEAT_HOSTS_START' /etc/cloud/templates/hosts.freebsd.tmpl\\n++ hostname -s\\n+ sed -i /lab-controller-0/d /etc/cloud/templates/hosts.freebsd.tmpl\\n+ echo -ne '\\\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\\\n'\\n+ echo '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ echo -ne '# HEAT_HOSTS_END\\\\n\\\\n'\\n+ for tmpl in '/etc/cloud/templates/hosts.*.tmpl'\\n+ write_entries /etc/cloud/templates/hosts.redhat.tmpl '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ local file=/etc/cloud/templates/hosts.redhat.tmpl\\n+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ '[' '!' -f /etc/cloud/templates/hosts.redhat.tmpl ']'\\n+ grep -q '^# HEAT_HOSTS_START' /etc/cloud/templates/hosts.redhat.tmpl\\n++ hostname -s\\n+ sed -i /lab-controller-0/d /etc/cloud/templates/hosts.redhat.tmpl\\n+ echo -ne '\\\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\\\n'\\n+ echo '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ echo -ne '# HEAT_HOSTS_END\\\\n\\\\n'\\n+ for tmpl in '/etc/cloud/templates/hosts.*.tmpl'\\n+ write_entries /etc/cloud/templates/hosts.suse.tmpl '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ local file=/etc/cloud/templates/hosts.suse.tmpl\\n+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ '[' '!' -f /etc/cloud/templates/hosts.suse.tmpl ']'\\n+ grep -q '^# HEAT_HOSTS_START' /etc/cloud/templates/hosts.suse.tmpl\\n++ hostname -s\\n+ sed -i /lab-controller-0/d /etc/cloud/templates/hosts.suse.tmpl\\n+ echo -ne '\\\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\\\n'\\n+ echo '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ echo -ne '# HEAT_HOSTS_END\\\\n\\\\n'\\n+ write_entries /etc/hosts '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ local file=/etc/hosts\\n+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ '[' '!' -f /etc/hosts ']'\\n+ grep -q '^# HEAT_HOSTS_START' /etc/hosts\\n++ hostname -s\\n+ sed -i /lab-controller-0/d /etc/hosts\\n+ echo -ne '\\\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\\\n'\\n+ echo '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ echo -ne '# HEAT_HOSTS_END\\\\n\\\\n'\\n\", \"deploy_status_code\": 0}\n\n[2019-06-05 19:04:12,385] (heat-config) [DEBUG] [2019-06-05 19:04:12,352] (heat-config) [INFO] deploy_server_id=cd2dbcc8-25c9-489f-9138-43515c089a76\n[2019-06-05 19:04:12,352] (heat-config) [INFO] deploy_action=CREATE\n[2019-06-05 19:04:12,352] (heat-config) [INFO] deploy_stack_id=lab-ControllerHostsDeployment-ciyh3koaad3j-0-3onhyxq7m47m/2dd022f3-7e2d-48e4-8285-9b9eab47d5d6\n[2019-06-05 19:04:12,352] (heat-config) [INFO] deploy_resource_name=TripleOSoftwareDeployment\n[2019-06-05 19:04:12,352] (heat-config) [INFO] deploy_signal_transport=NO_SIGNAL\n[2019-06-05 19:04:12,352] (heat-config) [DEBUG] Running /var/lib/heat-config/heat-config-script/68f83282-7d94-4bce-8450-22aadd93df5a\n[2019-06-05 19:04:12,369] (heat-config) [INFO] \n[2019-06-05 19:04:12,369] (heat-config) [DEBUG] + set -o pipefail\n+ hosts='192.168.24.19  overcloud.ctlplane.localdomain\n172.16.1.114  overcloud.storage.localdomain\n172.16.3.106  overcloud.storagemgmt.localdomain\n172.16.2.110  overcloud.internalapi.localdomain\n10.0.0.248  overcloud.localdomain\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\n\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\n'\n+ '[' '!' -z '192.168.24.19  overcloud.ctlplane.localdomain\n172.16.1.114  overcloud.storage.localdomain\n172.16.3.106  overcloud.storagemgmt.localdomain\n172.16.2.110  overcloud.internalapi.localdomain\n10.0.0.248  overcloud.localdomain\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\n\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\n' ']'\n+ for tmpl in '/etc/cloud/templates/hosts.*.tmpl'\n+ write_entries /etc/cloud/templates/hosts.debian.tmpl '192.168.24.19  overcloud.ctlplane.localdomain\n172.16.1.114  overcloud.storage.localdomain\n172.16.3.106  overcloud.storagemgmt.localdomain\n172.16.2.110  overcloud.internalapi.localdomain\n10.0.0.248  overcloud.localdomain\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\n\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\n'\n+ local file=/etc/cloud/templates/hosts.debian.tmpl\n+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain\n172.16.1.114  overcloud.storage.localdomain\n172.16.3.106  overcloud.storagemgmt.localdomain\n172.16.2.110  overcloud.internalapi.localdomain\n10.0.0.248  overcloud.localdomain\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\n\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\n'\n+ '[' '!' -f /etc/cloud/templates/hosts.debian.tmpl ']'\n+ grep -q '^# HEAT_HOSTS_START' /etc/cloud/templates/hosts.debian.tmpl\n++ hostname -s\n+ sed -i /lab-controller-0/d /etc/cloud/templates/hosts.debian.tmpl\n+ echo -ne '\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\n'\n+ echo '192.168.24.19  overcloud.ctlplane.localdomain\n172.16.1.114  overcloud.storage.localdomain\n172.16.3.106  overcloud.storagemgmt.localdomain\n172.16.2.110  overcloud.internalapi.localdomain\n10.0.0.248  overcloud.localdomain\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\n\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\n'\n+ echo -ne '# HEAT_HOSTS_END\\n\\n'\n+ for tmpl in '/etc/cloud/templates/hosts.*.tmpl'\n+ write_entries /etc/cloud/templates/hosts.freebsd.tmpl '192.168.24.19  overcloud.ctlplane.localdomain\n172.16.1.114  overcloud.storage.localdomain\n172.16.3.106  overcloud.storagemgmt.localdomain\n172.16.2.110  overcloud.internalapi.localdomain\n10.0.0.248  overcloud.localdomain\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\n\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\n'\n+ local file=/etc/cloud/templates/hosts.freebsd.tmpl\n+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain\n172.16.1.114  overcloud.storage.localdomain\n172.16.3.106  overcloud.storagemgmt.localdomain\n172.16.2.110  overcloud.internalapi.localdomain\n10.0.0.248  overcloud.localdomain\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\n\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\n'\n+ '[' '!' -f /etc/cloud/templates/hosts.freebsd.tmpl ']'\n+ grep -q '^# HEAT_HOSTS_START' /etc/cloud/templates/hosts.freebsd.tmpl\n++ hostname -s\n+ sed -i /lab-controller-0/d /etc/cloud/templates/hosts.freebsd.tmpl\n+ echo -ne '\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\n'\n+ echo '192.168.24.19  overcloud.ctlplane.localdomain\n172.16.1.114  overcloud.storage.localdomain\n172.16.3.106  overcloud.storagemgmt.localdomain\n172.16.2.110  overcloud.internalapi.localdomain\n10.0.0.248  overcloud.localdomain\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\n\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\n'\n+ echo -ne '# HEAT_HOSTS_END\\n\\n'\n+ for tmpl in '/etc/cloud/templates/hosts.*.tmpl'\n+ write_entries /etc/cloud/templates/hosts.redhat.tmpl '192.168.24.19  overcloud.ctlplane.localdomain\n172.16.1.114  overcloud.storage.localdomain\n172.16.3.106  overcloud.storagemgmt.localdomain\n172.16.2.110  overcloud.internalapi.localdomain\n10.0.0.248  overcloud.localdomain\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\n\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\n'\n+ local file=/etc/cloud/templates/hosts.redhat.tmpl\n+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain\n172.16.1.114  overcloud.storage.localdomain\n172.16.3.106  overcloud.storagemgmt.localdomain\n172.16.2.110  overcloud.internalapi.localdomain\n10.0.0.248  overcloud.localdomain\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\n\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\n'\n+ '[' '!' -f /etc/cloud/templates/hosts.redhat.tmpl ']'\n+ grep -q '^# HEAT_HOSTS_START' /etc/cloud/templates/hosts.redhat.tmpl\n++ hostname -s\n+ sed -i /lab-controller-0/d /etc/cloud/templates/hosts.redhat.tmpl\n+ echo -ne '\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\n'\n+ echo '192.168.24.19  overcloud.ctlplane.localdomain\n172.16.1.114  overcloud.storage.localdomain\n172.16.3.106  overcloud.storagemgmt.localdomain\n172.16.2.110  overcloud.internalapi.localdomain\n10.0.0.248  overcloud.localdomain\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\n\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\n'\n+ echo -ne '# HEAT_HOSTS_END\\n\\n'\n+ for tmpl in '/etc/cloud/templates/hosts.*.tmpl'\n+ write_entries /etc/cloud/templates/hosts.suse.tmpl '192.168.24.19  overcloud.ctlplane.localdomain\n172.16.1.114  overcloud.storage.localdomain\n172.16.3.106  overcloud.storagemgmt.localdomain\n172.16.2.110  overcloud.internalapi.localdomain\n10.0.0.248  overcloud.localdomain\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\n\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\n'\n+ local file=/etc/cloud/templates/hosts.suse.tmpl\n+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain\n172.16.1.114  overcloud.storage.localdomain\n172.16.3.106  overcloud.storagemgmt.localdomain\n172.16.2.110  overcloud.internalapi.localdomain\n10.0.0.248  overcloud.localdomain\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\n\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\n'\n+ '[' '!' -f /etc/cloud/templates/hosts.suse.tmpl ']'\n+ grep -q '^# HEAT_HOSTS_START' /etc/cloud/templates/hosts.suse.tmpl\n++ hostname -s\n+ sed -i /lab-controller-0/d /etc/cloud/templates/hosts.suse.tmpl\n+ echo -ne '\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\n'\n+ echo '192.168.24.19  overcloud.ctlplane.localdomain\n172.16.1.114  overcloud.storage.localdomain\n172.16.3.106  overcloud.storagemgmt.localdomain\n172.16.2.110  overcloud.internalapi.localdomain\n10.0.0.248  overcloud.localdomain\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\n\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\n'\n+ echo -ne '# HEAT_HOSTS_END\\n\\n'\n+ write_entries /etc/hosts '192.168.24.19  overcloud.ctlplane.localdomain\n172.16.1.114  overcloud.storage.localdomain\n172.16.3.106  overcloud.storagemgmt.localdomain\n172.16.2.110  overcloud.internalapi.localdomain\n10.0.0.248  overcloud.localdomain\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\n\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\n'\n+ local file=/etc/hosts\n+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain\n172.16.1.114  overcloud.storage.localdomain\n172.16.3.106  overcloud.storagemgmt.localdomain\n172.16.2.110  overcloud.internalapi.localdomain\n10.0.0.248  overcloud.localdomain\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\n\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\n'\n+ '[' '!' -f /etc/hosts ']'\n+ grep -q '^# HEAT_HOSTS_START' /etc/hosts\n++ hostname -s\n+ sed -i /lab-controller-0/d /etc/hosts\n+ echo -ne '\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\n'\n+ echo '192.168.24.19  overcloud.ctlplane.localdomain\n172.16.1.114  overcloud.storage.localdomain\n172.16.3.106  overcloud.storagemgmt.localdomain\n172.16.2.110  overcloud.internalapi.localdomain\n10.0.0.248  overcloud.localdomain\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\n\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\n'\n+ echo -ne '# HEAT_HOSTS_END\\n\\n'\n\n[2019-06-05 19:04:12,369] (heat-config) [INFO] Completed /var/lib/heat-config/heat-config-script/68f83282-7d94-4bce-8450-22aadd93df5a\n\n[2019-06-05 19:04:12,385] (heat-config) [INFO] Completed /usr/libexec/heat-config/hooks/script\n[2019-06-05 19:04:12,385] (heat-config) [DEBUG] Running heat-config-notify /var/lib/heat-config/deployed/68f83282-7d94-4bce-8450-22aadd93df5a.json < /var/lib/heat-config/deployed/68f83282-7d94-4bce-8450-22aadd93df5a.notify.json\n[2019-06-05 19:04:12,676] (heat-config) [INFO] \n[2019-06-05 19:04:12,676] (heat-config) [DEBUG] ", "stderr_lines": ["[2019-06-05 19:04:12,340] (heat-config) [DEBUG] Running /usr/libexec/heat-config/hooks/script < /var/lib/heat-config/deployed/68f83282-7d94-4bce-8450-22aadd93df5a.json", "[2019-06-05 19:04:12,385] (heat-config) [INFO] |-", "  {\"deploy_stdout\": \"\", \"deploy_stderr\": \"+ set -o pipefail\\n+ hosts='192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ '[' '!' -z '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n' ']'\\n+ for tmpl in '/etc/cloud/templates/hosts.*.tmpl'\\n+ write_entries /etc/cloud/templates/hosts.debian.tmpl '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ local file=/etc/cloud/templates/hosts.debian.tmpl\\n+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ '[' '!' -f /etc/cloud/templates/hosts.debian.tmpl ']'\\n+ grep -q '^# HEAT_HOSTS_START' /etc/cloud/templates/hosts.debian.tmpl\\n++ hostname -s\\n+ sed -i /lab-controller-0/d /etc/cloud/templates/hosts.debian.tmpl\\n+ echo -ne '\\\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\\\n'\\n+ echo '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ echo -ne '# HEAT_HOSTS_END\\\\n\\\\n'\\n+ for tmpl in '/etc/cloud/templates/hosts.*.tmpl'\\n+ write_entries /etc/cloud/templates/hosts.freebsd.tmpl '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ local file=/etc/cloud/templates/hosts.freebsd.tmpl\\n+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ '[' '!' -f /etc/cloud/templates/hosts.freebsd.tmpl ']'\\n+ grep -q '^# HEAT_HOSTS_START' /etc/cloud/templates/hosts.freebsd.tmpl\\n++ hostname -s\\n+ sed -i /lab-controller-0/d /etc/cloud/templates/hosts.freebsd.tmpl\\n+ echo -ne '\\\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\\\n'\\n+ echo '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ echo -ne '# HEAT_HOSTS_END\\\\n\\\\n'\\n+ for tmpl in '/etc/cloud/templates/hosts.*.tmpl'\\n+ write_entries /etc/cloud/templates/hosts.redhat.tmpl '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ local file=/etc/cloud/templates/hosts.redhat.tmpl\\n+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ '[' '!' -f /etc/cloud/templates/hosts.redhat.tmpl ']'\\n+ grep -q '^# HEAT_HOSTS_START' /etc/cloud/templates/hosts.redhat.tmpl\\n++ hostname -s\\n+ sed -i /lab-controller-0/d /etc/cloud/templates/hosts.redhat.tmpl\\n+ echo -ne '\\\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\\\n'\\n+ echo '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ echo -ne '# HEAT_HOSTS_END\\\\n\\\\n'\\n+ for tmpl in '/etc/cloud/templates/hosts.*.tmpl'\\n+ write_entries /etc/cloud/templates/hosts.suse.tmpl '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ local file=/etc/cloud/templates/hosts.suse.tmpl\\n+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ '[' '!' -f /etc/cloud/templates/hosts.suse.tmpl ']'\\n+ grep -q '^# HEAT_HOSTS_START' /etc/cloud/templates/hosts.suse.tmpl\\n++ hostname -s\\n+ sed -i /lab-controller-0/d /etc/cloud/templates/hosts.suse.tmpl\\n+ echo -ne '\\\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\\\n'\\n+ echo '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ echo -ne '# HEAT_HOSTS_END\\\\n\\\\n'\\n+ write_entries /etc/hosts '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ local file=/etc/hosts\\n+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ '[' '!' -f /etc/hosts ']'\\n+ grep -q '^# HEAT_HOSTS_START' /etc/hosts\\n++ hostname -s\\n+ sed -i /lab-controller-0/d /etc/hosts\\n+ echo -ne '\\\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\\\n'\\n+ echo '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ echo -ne '# HEAT_HOSTS_END\\\\n\\\\n'\\n\", \"deploy_status_code\": 0}", "", "[2019-06-05 19:04:12,385] (heat-config) [DEBUG] [2019-06-05 19:04:12,352] (heat-config) [INFO] deploy_server_id=cd2dbcc8-25c9-489f-9138-43515c089a76", "[2019-06-05 19:04:12,352] (heat-config) [INFO] deploy_action=CREATE", "[2019-06-05 19:04:12,352] (heat-config) [INFO] deploy_stack_id=lab-ControllerHostsDeployment-ciyh3koaad3j-0-3onhyxq7m47m/2dd022f3-7e2d-48e4-8285-9b9eab47d5d6", "[2019-06-05 19:04:12,352] (heat-config) [INFO] deploy_resource_name=TripleOSoftwareDeployment", "[2019-06-05 19:04:12,352] (heat-config) [INFO] deploy_signal_transport=NO_SIGNAL", "[2019-06-05 19:04:12,352] (heat-config) [DEBUG] Running /var/lib/heat-config/heat-config-script/68f83282-7d94-4bce-8450-22aadd93df5a", "[2019-06-05 19:04:12,369] (heat-config) [INFO] ", "[2019-06-05 19:04:12,369] (heat-config) [DEBUG] + set -o pipefail", "+ hosts='192.168.24.19  overcloud.ctlplane.localdomain", "172.16.1.114  overcloud.storage.localdomain", "172.16.3.106  overcloud.storagemgmt.localdomain", "172.16.2.110  overcloud.internalapi.localdomain", "10.0.0.248  overcloud.localdomain", "172.16.2.35 lab-controller-0.localdomain lab-controller-0", "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", "", "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", "'", "+ '[' '!' -z '192.168.24.19  overcloud.ctlplane.localdomain", "172.16.1.114  overcloud.storage.localdomain", "172.16.3.106  overcloud.storagemgmt.localdomain", "172.16.2.110  overcloud.internalapi.localdomain", "10.0.0.248  overcloud.localdomain", "172.16.2.35 lab-controller-0.localdomain lab-controller-0", "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", "", "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", "' ']'", "+ for tmpl in '/etc/cloud/templates/hosts.*.tmpl'", "+ write_entries /etc/cloud/templates/hosts.debian.tmpl '192.168.24.19  overcloud.ctlplane.localdomain", "172.16.1.114  overcloud.storage.localdomain", "172.16.3.106  overcloud.storagemgmt.localdomain", "172.16.2.110  overcloud.internalapi.localdomain", "10.0.0.248  overcloud.localdomain", "172.16.2.35 lab-controller-0.localdomain lab-controller-0", "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", "", "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", "'", "+ local file=/etc/cloud/templates/hosts.debian.tmpl", "+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain", "172.16.1.114  overcloud.storage.localdomain", "172.16.3.106  overcloud.storagemgmt.localdomain", "172.16.2.110  overcloud.internalapi.localdomain", "10.0.0.248  overcloud.localdomain", "172.16.2.35 lab-controller-0.localdomain lab-controller-0", "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", "", "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", "'", "+ '[' '!' -f /etc/cloud/templates/hosts.debian.tmpl ']'", "+ grep -q '^# HEAT_HOSTS_START' /etc/cloud/templates/hosts.debian.tmpl", "++ hostname -s", "+ sed -i /lab-controller-0/d /etc/cloud/templates/hosts.debian.tmpl", "+ echo -ne '\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\n'", "+ echo '192.168.24.19  overcloud.ctlplane.localdomain", "172.16.1.114  overcloud.storage.localdomain", "172.16.3.106  overcloud.storagemgmt.localdomain", "172.16.2.110  overcloud.internalapi.localdomain", "10.0.0.248  overcloud.localdomain", "172.16.2.35 lab-controller-0.localdomain lab-controller-0", "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", "", "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", "'", "+ echo -ne '# HEAT_HOSTS_END\\n\\n'", "+ for tmpl in '/etc/cloud/templates/hosts.*.tmpl'", "+ write_entries /etc/cloud/templates/hosts.freebsd.tmpl '192.168.24.19  overcloud.ctlplane.localdomain", "172.16.1.114  overcloud.storage.localdomain", "172.16.3.106  overcloud.storagemgmt.localdomain", "172.16.2.110  overcloud.internalapi.localdomain", "10.0.0.248  overcloud.localdomain", "172.16.2.35 lab-controller-0.localdomain lab-controller-0", "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", "", "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", "'", "+ local file=/etc/cloud/templates/hosts.freebsd.tmpl", "+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain", "172.16.1.114  overcloud.storage.localdomain", "172.16.3.106  overcloud.storagemgmt.localdomain", "172.16.2.110  overcloud.internalapi.localdomain", "10.0.0.248  overcloud.localdomain", "172.16.2.35 lab-controller-0.localdomain lab-controller-0", "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", "", "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", "'", "+ '[' '!' -f /etc/cloud/templates/hosts.freebsd.tmpl ']'", "+ grep -q '^# HEAT_HOSTS_START' /etc/cloud/templates/hosts.freebsd.tmpl", "++ hostname -s", "+ sed -i /lab-controller-0/d /etc/cloud/templates/hosts.freebsd.tmpl", "+ echo -ne '\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\n'", "+ echo '192.168.24.19  overcloud.ctlplane.localdomain", "172.16.1.114  overcloud.storage.localdomain", "172.16.3.106  overcloud.storagemgmt.localdomain", "172.16.2.110  overcloud.internalapi.localdomain", "10.0.0.248  overcloud.localdomain", "172.16.2.35 lab-controller-0.localdomain lab-controller-0", "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", "", "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", "'", "+ echo -ne '# HEAT_HOSTS_END\\n\\n'", "+ for tmpl in '/etc/cloud/templates/hosts.*.tmpl'", "+ write_entries /etc/cloud/templates/hosts.redhat.tmpl '192.168.24.19  overcloud.ctlplane.localdomain", "172.16.1.114  overcloud.storage.localdomain", "172.16.3.106  overcloud.storagemgmt.localdomain", "172.16.2.110  overcloud.internalapi.localdomain", "10.0.0.248  overcloud.localdomain", "172.16.2.35 lab-controller-0.localdomain lab-controller-0", "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", "", "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", "'", "+ local file=/etc/cloud/templates/hosts.redhat.tmpl", "+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain", "172.16.1.114  overcloud.storage.localdomain", "172.16.3.106  overcloud.storagemgmt.localdomain", "172.16.2.110  overcloud.internalapi.localdomain", "10.0.0.248  overcloud.localdomain", "172.16.2.35 lab-controller-0.localdomain lab-controller-0", "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", "", "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", "'", "+ '[' '!' -f /etc/cloud/templates/hosts.redhat.tmpl ']'", "+ grep -q '^# HEAT_HOSTS_START' /etc/cloud/templates/hosts.redhat.tmpl", "++ hostname -s", "+ sed -i /lab-controller-0/d /etc/cloud/templates/hosts.redhat.tmpl", "+ echo -ne '\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\n'", "+ echo '192.168.24.19  overcloud.ctlplane.localdomain", "172.16.1.114  overcloud.storage.localdomain", "172.16.3.106  overcloud.storagemgmt.localdomain", "172.16.2.110  overcloud.internalapi.localdomain", "10.0.0.248  overcloud.localdomain", "172.16.2.35 lab-controller-0.localdomain lab-controller-0", "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", "", "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", "'", "+ echo -ne '# HEAT_HOSTS_END\\n\\n'", "+ for tmpl in '/etc/cloud/templates/hosts.*.tmpl'", "+ write_entries /etc/cloud/templates/hosts.suse.tmpl '192.168.24.19  overcloud.ctlplane.localdomain", "172.16.1.114  overcloud.storage.localdomain", "172.16.3.106  overcloud.storagemgmt.localdomain", "172.16.2.110  overcloud.internalapi.localdomain", "10.0.0.248  overcloud.localdomain", "172.16.2.35 lab-controller-0.localdomain lab-controller-0", "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", "", "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", "'", "+ local file=/etc/cloud/templates/hosts.suse.tmpl", "+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain", "172.16.1.114  overcloud.storage.localdomain", "172.16.3.106  overcloud.storagemgmt.localdomain", "172.16.2.110  overcloud.internalapi.localdomain", "10.0.0.248  overcloud.localdomain", "172.16.2.35 lab-controller-0.localdomain lab-controller-0", "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", "", "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", "'", "+ '[' '!' -f /etc/cloud/templates/hosts.suse.tmpl ']'", "+ grep -q '^# HEAT_HOSTS_START' /etc/cloud/templates/hosts.suse.tmpl", "++ hostname -s", "+ sed -i /lab-controller-0/d /etc/cloud/templates/hosts.suse.tmpl", "+ echo -ne '\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\n'", "+ echo '192.168.24.19  overcloud.ctlplane.localdomain", "172.16.1.114  overcloud.storage.localdomain", "172.16.3.106  overcloud.storagemgmt.localdomain", "172.16.2.110  overcloud.internalapi.localdomain", "10.0.0.248  overcloud.localdomain", "172.16.2.35 lab-controller-0.localdomain lab-controller-0", "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", "", "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", "'", "+ echo -ne '# HEAT_HOSTS_END\\n\\n'", "+ write_entries /etc/hosts '192.168.24.19  overcloud.ctlplane.localdomain", "172.16.1.114  overcloud.storage.localdomain", "172.16.3.106  overcloud.storagemgmt.localdomain", "172.16.2.110  overcloud.internalapi.localdomain", "10.0.0.248  overcloud.localdomain", "172.16.2.35 lab-controller-0.localdomain lab-controller-0", "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", "", "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", "'", "+ local file=/etc/hosts", "+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain", "172.16.1.114  overcloud.storage.localdomain", "172.16.3.106  overcloud.storagemgmt.localdomain", "172.16.2.110  overcloud.internalapi.localdomain", "10.0.0.248  overcloud.localdomain", "172.16.2.35 lab-controller-0.localdomain lab-controller-0", "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", "", "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", "'", "+ '[' '!' -f /etc/hosts ']'", "+ grep -q '^# HEAT_HOSTS_START' /etc/hosts", "++ hostname -s", "+ sed -i /lab-controller-0/d /etc/hosts", "+ echo -ne '\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\n'", "+ echo '192.168.24.19  overcloud.ctlplane.localdomain", "172.16.1.114  overcloud.storage.localdomain", "172.16.3.106  overcloud.storagemgmt.localdomain", "172.16.2.110  overcloud.internalapi.localdomain", "10.0.0.248  overcloud.localdomain", "172.16.2.35 lab-controller-0.localdomain lab-controller-0", "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", "", "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", "'", "+ echo -ne '# HEAT_HOSTS_END\\n\\n'", "", "[2019-06-05 19:04:12,369] (heat-config) [INFO] Completed /var/lib/heat-config/heat-config-script/68f83282-7d94-4bce-8450-22aadd93df5a", "", "[2019-06-05 19:04:12,385] (heat-config) [INFO] Completed /usr/libexec/heat-config/hooks/script", "[2019-06-05 19:04:12,385] (heat-config) [DEBUG] Running heat-config-notify /var/lib/heat-config/deployed/68f83282-7d94-4bce-8450-22aadd93df5a.json < /var/lib/heat-config/deployed/68f83282-7d94-4bce-8450-22aadd93df5a.notify.json", "[2019-06-05 19:04:12,676] (heat-config) [INFO] ", "[2019-06-05 19:04:12,676] (heat-config) [DEBUG] "], "stdout": "", "stdout_lines": []}
2019-06-05 14:04:12,761 p=17240 u=mistral |  TASK [Run async deployment ControllerHostsDeployment] **************************
2019-06-05 14:04:12,761 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:153
2019-06-05 14:04:12,761 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:12 -0500 (0:00:00.544)       0:00:46.531 ******** 
2019-06-05 14:04:12,763 p=17240 u=mistral |  META: noop
2019-06-05 14:04:12,771 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:12,788 p=17240 u=mistral |  TASK [Output for sync deployment ControllerHostsDeployment] ********************
2019-06-05 14:04:12,788 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:166
2019-06-05 14:04:12,789 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:12 -0500 (0:00:00.027)       0:00:46.558 ******** 
2019-06-05 14:04:12,790 p=17240 u=mistral |  META: noop
2019-06-05 14:04:12,828 p=17240 u=mistral |  ok: [lab-controller-0] => {
    "msg": [
        {
            "stderr": [
                "[2019-06-05 19:04:12,340] (heat-config) [DEBUG] Running /usr/libexec/heat-config/hooks/script < /var/lib/heat-config/deployed/68f83282-7d94-4bce-8450-22aadd93df5a.json", 
                "[2019-06-05 19:04:12,385] (heat-config) [INFO] |-", 
                "  {\"deploy_stdout\": \"\", \"deploy_stderr\": \"+ set -o pipefail\\n+ hosts='192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ '[' '!' -z '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n' ']'\\n+ for tmpl in '/etc/cloud/templates/hosts.*.tmpl'\\n+ write_entries /etc/cloud/templates/hosts.debian.tmpl '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ local file=/etc/cloud/templates/hosts.debian.tmpl\\n+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ '[' '!' -f /etc/cloud/templates/hosts.debian.tmpl ']'\\n+ grep -q '^# HEAT_HOSTS_START' /etc/cloud/templates/hosts.debian.tmpl\\n++ hostname -s\\n+ sed -i /lab-controller-0/d /etc/cloud/templates/hosts.debian.tmpl\\n+ echo -ne '\\\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\\\n'\\n+ echo '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ echo -ne '# HEAT_HOSTS_END\\\\n\\\\n'\\n+ for tmpl in '/etc/cloud/templates/hosts.*.tmpl'\\n+ write_entries /etc/cloud/templates/hosts.freebsd.tmpl '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ local file=/etc/cloud/templates/hosts.freebsd.tmpl\\n+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ '[' '!' -f /etc/cloud/templates/hosts.freebsd.tmpl ']'\\n+ grep -q '^# HEAT_HOSTS_START' /etc/cloud/templates/hosts.freebsd.tmpl\\n++ hostname -s\\n+ sed -i /lab-controller-0/d /etc/cloud/templates/hosts.freebsd.tmpl\\n+ echo -ne '\\\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\\\n'\\n+ echo '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ echo -ne '# HEAT_HOSTS_END\\\\n\\\\n'\\n+ for tmpl in '/etc/cloud/templates/hosts.*.tmpl'\\n+ write_entries /etc/cloud/templates/hosts.redhat.tmpl '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ local file=/etc/cloud/templates/hosts.redhat.tmpl\\n+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ '[' '!' -f /etc/cloud/templates/hosts.redhat.tmpl ']'\\n+ grep -q '^# HEAT_HOSTS_START' /etc/cloud/templates/hosts.redhat.tmpl\\n++ hostname -s\\n+ sed -i /lab-controller-0/d /etc/cloud/templates/hosts.redhat.tmpl\\n+ echo -ne '\\\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\\\n'\\n+ echo '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ echo -ne '# HEAT_HOSTS_END\\\\n\\\\n'\\n+ for tmpl in '/etc/cloud/templates/hosts.*.tmpl'\\n+ write_entries /etc/cloud/templates/hosts.suse.tmpl '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ local file=/etc/cloud/templates/hosts.suse.tmpl\\n+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ '[' '!' -f /etc/cloud/templates/hosts.suse.tmpl ']'\\n+ grep -q '^# HEAT_HOSTS_START' /etc/cloud/templates/hosts.suse.tmpl\\n++ hostname -s\\n+ sed -i /lab-controller-0/d /etc/cloud/templates/hosts.suse.tmpl\\n+ echo -ne '\\\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\\\n'\\n+ echo '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ echo -ne '# HEAT_HOSTS_END\\\\n\\\\n'\\n+ write_entries /etc/hosts '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ local file=/etc/hosts\\n+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ '[' '!' -f /etc/hosts ']'\\n+ grep -q '^# HEAT_HOSTS_START' /etc/hosts\\n++ hostname -s\\n+ sed -i /lab-controller-0/d /etc/hosts\\n+ echo -ne '\\\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\\\n'\\n+ echo '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ echo -ne '# HEAT_HOSTS_END\\\\n\\\\n'\\n\", \"deploy_status_code\": 0}", 
                "", 
                "[2019-06-05 19:04:12,385] (heat-config) [DEBUG] [2019-06-05 19:04:12,352] (heat-config) [INFO] deploy_server_id=cd2dbcc8-25c9-489f-9138-43515c089a76", 
                "[2019-06-05 19:04:12,352] (heat-config) [INFO] deploy_action=CREATE", 
                "[2019-06-05 19:04:12,352] (heat-config) [INFO] deploy_stack_id=lab-ControllerHostsDeployment-ciyh3koaad3j-0-3onhyxq7m47m/2dd022f3-7e2d-48e4-8285-9b9eab47d5d6", 
                "[2019-06-05 19:04:12,352] (heat-config) [INFO] deploy_resource_name=TripleOSoftwareDeployment", 
                "[2019-06-05 19:04:12,352] (heat-config) [INFO] deploy_signal_transport=NO_SIGNAL", 
                "[2019-06-05 19:04:12,352] (heat-config) [DEBUG] Running /var/lib/heat-config/heat-config-script/68f83282-7d94-4bce-8450-22aadd93df5a", 
                "[2019-06-05 19:04:12,369] (heat-config) [INFO] ", 
                "[2019-06-05 19:04:12,369] (heat-config) [DEBUG] + set -o pipefail", 
                "+ hosts='192.168.24.19  overcloud.ctlplane.localdomain", 
                "172.16.1.114  overcloud.storage.localdomain", 
                "172.16.3.106  overcloud.storagemgmt.localdomain", 
                "172.16.2.110  overcloud.internalapi.localdomain", 
                "10.0.0.248  overcloud.localdomain", 
                "172.16.2.35 lab-controller-0.localdomain lab-controller-0", 
                "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", 
                "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", 
                "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", 
                "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", 
                "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", 
                "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", 
                "", 
                "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", 
                "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", 
                "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", 
                "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", 
                "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", 
                "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", 
                "'", 
                "+ '[' '!' -z '192.168.24.19  overcloud.ctlplane.localdomain", 
                "172.16.1.114  overcloud.storage.localdomain", 
                "172.16.3.106  overcloud.storagemgmt.localdomain", 
                "172.16.2.110  overcloud.internalapi.localdomain", 
                "10.0.0.248  overcloud.localdomain", 
                "172.16.2.35 lab-controller-0.localdomain lab-controller-0", 
                "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", 
                "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", 
                "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", 
                "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", 
                "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", 
                "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", 
                "", 
                "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", 
                "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", 
                "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", 
                "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", 
                "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", 
                "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", 
                "' ']'", 
                "+ for tmpl in '/etc/cloud/templates/hosts.*.tmpl'", 
                "+ write_entries /etc/cloud/templates/hosts.debian.tmpl '192.168.24.19  overcloud.ctlplane.localdomain", 
                "172.16.1.114  overcloud.storage.localdomain", 
                "172.16.3.106  overcloud.storagemgmt.localdomain", 
                "172.16.2.110  overcloud.internalapi.localdomain", 
                "10.0.0.248  overcloud.localdomain", 
                "172.16.2.35 lab-controller-0.localdomain lab-controller-0", 
                "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", 
                "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", 
                "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", 
                "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", 
                "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", 
                "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", 
                "", 
                "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", 
                "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", 
                "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", 
                "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", 
                "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", 
                "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", 
                "'", 
                "+ local file=/etc/cloud/templates/hosts.debian.tmpl", 
                "+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain", 
                "172.16.1.114  overcloud.storage.localdomain", 
                "172.16.3.106  overcloud.storagemgmt.localdomain", 
                "172.16.2.110  overcloud.internalapi.localdomain", 
                "10.0.0.248  overcloud.localdomain", 
                "172.16.2.35 lab-controller-0.localdomain lab-controller-0", 
                "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", 
                "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", 
                "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", 
                "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", 
                "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", 
                "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", 
                "", 
                "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", 
                "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", 
                "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", 
                "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", 
                "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", 
                "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", 
                "'", 
                "+ '[' '!' -f /etc/cloud/templates/hosts.debian.tmpl ']'", 
                "+ grep -q '^# HEAT_HOSTS_START' /etc/cloud/templates/hosts.debian.tmpl", 
                "++ hostname -s", 
                "+ sed -i /lab-controller-0/d /etc/cloud/templates/hosts.debian.tmpl", 
                "+ echo -ne '\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\n'", 
                "+ echo '192.168.24.19  overcloud.ctlplane.localdomain", 
                "172.16.1.114  overcloud.storage.localdomain", 
                "172.16.3.106  overcloud.storagemgmt.localdomain", 
                "172.16.2.110  overcloud.internalapi.localdomain", 
                "10.0.0.248  overcloud.localdomain", 
                "172.16.2.35 lab-controller-0.localdomain lab-controller-0", 
                "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", 
                "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", 
                "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", 
                "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", 
                "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", 
                "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", 
                "", 
                "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", 
                "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", 
                "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", 
                "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", 
                "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", 
                "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", 
                "'", 
                "+ echo -ne '# HEAT_HOSTS_END\\n\\n'", 
                "+ for tmpl in '/etc/cloud/templates/hosts.*.tmpl'", 
                "+ write_entries /etc/cloud/templates/hosts.freebsd.tmpl '192.168.24.19  overcloud.ctlplane.localdomain", 
                "172.16.1.114  overcloud.storage.localdomain", 
                "172.16.3.106  overcloud.storagemgmt.localdomain", 
                "172.16.2.110  overcloud.internalapi.localdomain", 
                "10.0.0.248  overcloud.localdomain", 
                "172.16.2.35 lab-controller-0.localdomain lab-controller-0", 
                "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", 
                "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", 
                "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", 
                "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", 
                "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", 
                "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", 
                "", 
                "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", 
                "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", 
                "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", 
                "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", 
                "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", 
                "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", 
                "'", 
                "+ local file=/etc/cloud/templates/hosts.freebsd.tmpl", 
                "+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain", 
                "172.16.1.114  overcloud.storage.localdomain", 
                "172.16.3.106  overcloud.storagemgmt.localdomain", 
                "172.16.2.110  overcloud.internalapi.localdomain", 
                "10.0.0.248  overcloud.localdomain", 
                "172.16.2.35 lab-controller-0.localdomain lab-controller-0", 
                "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", 
                "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", 
                "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", 
                "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", 
                "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", 
                "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", 
                "", 
                "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", 
                "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", 
                "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", 
                "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", 
                "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", 
                "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", 
                "'", 
                "+ '[' '!' -f /etc/cloud/templates/hosts.freebsd.tmpl ']'", 
                "+ grep -q '^# HEAT_HOSTS_START' /etc/cloud/templates/hosts.freebsd.tmpl", 
                "++ hostname -s", 
                "+ sed -i /lab-controller-0/d /etc/cloud/templates/hosts.freebsd.tmpl", 
                "+ echo -ne '\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\n'", 
                "+ echo '192.168.24.19  overcloud.ctlplane.localdomain", 
                "172.16.1.114  overcloud.storage.localdomain", 
                "172.16.3.106  overcloud.storagemgmt.localdomain", 
                "172.16.2.110  overcloud.internalapi.localdomain", 
                "10.0.0.248  overcloud.localdomain", 
                "172.16.2.35 lab-controller-0.localdomain lab-controller-0", 
                "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", 
                "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", 
                "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", 
                "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", 
                "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", 
                "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", 
                "", 
                "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", 
                "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", 
                "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", 
                "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", 
                "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", 
                "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", 
                "'", 
                "+ echo -ne '# HEAT_HOSTS_END\\n\\n'", 
                "+ for tmpl in '/etc/cloud/templates/hosts.*.tmpl'", 
                "+ write_entries /etc/cloud/templates/hosts.redhat.tmpl '192.168.24.19  overcloud.ctlplane.localdomain", 
                "172.16.1.114  overcloud.storage.localdomain", 
                "172.16.3.106  overcloud.storagemgmt.localdomain", 
                "172.16.2.110  overcloud.internalapi.localdomain", 
                "10.0.0.248  overcloud.localdomain", 
                "172.16.2.35 lab-controller-0.localdomain lab-controller-0", 
                "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", 
                "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", 
                "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", 
                "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", 
                "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", 
                "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", 
                "", 
                "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", 
                "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", 
                "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", 
                "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", 
                "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", 
                "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", 
                "'", 
                "+ local file=/etc/cloud/templates/hosts.redhat.tmpl", 
                "+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain", 
                "172.16.1.114  overcloud.storage.localdomain", 
                "172.16.3.106  overcloud.storagemgmt.localdomain", 
                "172.16.2.110  overcloud.internalapi.localdomain", 
                "10.0.0.248  overcloud.localdomain", 
                "172.16.2.35 lab-controller-0.localdomain lab-controller-0", 
                "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", 
                "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", 
                "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", 
                "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", 
                "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", 
                "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", 
                "", 
                "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", 
                "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", 
                "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", 
                "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", 
                "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", 
                "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", 
                "'", 
                "+ '[' '!' -f /etc/cloud/templates/hosts.redhat.tmpl ']'", 
                "+ grep -q '^# HEAT_HOSTS_START' /etc/cloud/templates/hosts.redhat.tmpl", 
                "++ hostname -s", 
                "+ sed -i /lab-controller-0/d /etc/cloud/templates/hosts.redhat.tmpl", 
                "+ echo -ne '\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\n'", 
                "+ echo '192.168.24.19  overcloud.ctlplane.localdomain", 
                "172.16.1.114  overcloud.storage.localdomain", 
                "172.16.3.106  overcloud.storagemgmt.localdomain", 
                "172.16.2.110  overcloud.internalapi.localdomain", 
                "10.0.0.248  overcloud.localdomain", 
                "172.16.2.35 lab-controller-0.localdomain lab-controller-0", 
                "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", 
                "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", 
                "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", 
                "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", 
                "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", 
                "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", 
                "", 
                "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", 
                "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", 
                "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", 
                "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", 
                "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", 
                "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", 
                "'", 
                "+ echo -ne '# HEAT_HOSTS_END\\n\\n'", 
                "+ for tmpl in '/etc/cloud/templates/hosts.*.tmpl'", 
                "+ write_entries /etc/cloud/templates/hosts.suse.tmpl '192.168.24.19  overcloud.ctlplane.localdomain", 
                "172.16.1.114  overcloud.storage.localdomain", 
                "172.16.3.106  overcloud.storagemgmt.localdomain", 
                "172.16.2.110  overcloud.internalapi.localdomain", 
                "10.0.0.248  overcloud.localdomain", 
                "172.16.2.35 lab-controller-0.localdomain lab-controller-0", 
                "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", 
                "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", 
                "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", 
                "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", 
                "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", 
                "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", 
                "", 
                "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", 
                "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", 
                "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", 
                "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", 
                "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", 
                "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", 
                "'", 
                "+ local file=/etc/cloud/templates/hosts.suse.tmpl", 
                "+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain", 
                "172.16.1.114  overcloud.storage.localdomain", 
                "172.16.3.106  overcloud.storagemgmt.localdomain", 
                "172.16.2.110  overcloud.internalapi.localdomain", 
                "10.0.0.248  overcloud.localdomain", 
                "172.16.2.35 lab-controller-0.localdomain lab-controller-0", 
                "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", 
                "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", 
                "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", 
                "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", 
                "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", 
                "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", 
                "", 
                "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", 
                "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", 
                "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", 
                "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", 
                "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", 
                "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", 
                "'", 
                "+ '[' '!' -f /etc/cloud/templates/hosts.suse.tmpl ']'", 
                "+ grep -q '^# HEAT_HOSTS_START' /etc/cloud/templates/hosts.suse.tmpl", 
                "++ hostname -s", 
                "+ sed -i /lab-controller-0/d /etc/cloud/templates/hosts.suse.tmpl", 
                "+ echo -ne '\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\n'", 
                "+ echo '192.168.24.19  overcloud.ctlplane.localdomain", 
                "172.16.1.114  overcloud.storage.localdomain", 
                "172.16.3.106  overcloud.storagemgmt.localdomain", 
                "172.16.2.110  overcloud.internalapi.localdomain", 
                "10.0.0.248  overcloud.localdomain", 
                "172.16.2.35 lab-controller-0.localdomain lab-controller-0", 
                "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", 
                "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", 
                "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", 
                "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", 
                "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", 
                "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", 
                "", 
                "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", 
                "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", 
                "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", 
                "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", 
                "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", 
                "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", 
                "'", 
                "+ echo -ne '# HEAT_HOSTS_END\\n\\n'", 
                "+ write_entries /etc/hosts '192.168.24.19  overcloud.ctlplane.localdomain", 
                "172.16.1.114  overcloud.storage.localdomain", 
                "172.16.3.106  overcloud.storagemgmt.localdomain", 
                "172.16.2.110  overcloud.internalapi.localdomain", 
                "10.0.0.248  overcloud.localdomain", 
                "172.16.2.35 lab-controller-0.localdomain lab-controller-0", 
                "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", 
                "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", 
                "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", 
                "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", 
                "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", 
                "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", 
                "", 
                "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", 
                "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", 
                "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", 
                "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", 
                "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", 
                "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", 
                "'", 
                "+ local file=/etc/hosts", 
                "+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain", 
                "172.16.1.114  overcloud.storage.localdomain", 
                "172.16.3.106  overcloud.storagemgmt.localdomain", 
                "172.16.2.110  overcloud.internalapi.localdomain", 
                "10.0.0.248  overcloud.localdomain", 
                "172.16.2.35 lab-controller-0.localdomain lab-controller-0", 
                "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", 
                "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", 
                "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", 
                "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", 
                "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", 
                "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", 
                "", 
                "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", 
                "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", 
                "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", 
                "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", 
                "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", 
                "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", 
                "'", 
                "+ '[' '!' -f /etc/hosts ']'", 
                "+ grep -q '^# HEAT_HOSTS_START' /etc/hosts", 
                "++ hostname -s", 
                "+ sed -i /lab-controller-0/d /etc/hosts", 
                "+ echo -ne '\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\n'", 
                "+ echo '192.168.24.19  overcloud.ctlplane.localdomain", 
                "172.16.1.114  overcloud.storage.localdomain", 
                "172.16.3.106  overcloud.storagemgmt.localdomain", 
                "172.16.2.110  overcloud.internalapi.localdomain", 
                "10.0.0.248  overcloud.localdomain", 
                "172.16.2.35 lab-controller-0.localdomain lab-controller-0", 
                "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", 
                "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", 
                "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", 
                "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", 
                "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", 
                "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", 
                "", 
                "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", 
                "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", 
                "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", 
                "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", 
                "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", 
                "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", 
                "'", 
                "+ echo -ne '# HEAT_HOSTS_END\\n\\n'", 
                "", 
                "[2019-06-05 19:04:12,369] (heat-config) [INFO] Completed /var/lib/heat-config/heat-config-script/68f83282-7d94-4bce-8450-22aadd93df5a", 
                "", 
                "[2019-06-05 19:04:12,385] (heat-config) [INFO] Completed /usr/libexec/heat-config/hooks/script", 
                "[2019-06-05 19:04:12,385] (heat-config) [DEBUG] Running heat-config-notify /var/lib/heat-config/deployed/68f83282-7d94-4bce-8450-22aadd93df5a.json < /var/lib/heat-config/deployed/68f83282-7d94-4bce-8450-22aadd93df5a.notify.json", 
                "[2019-06-05 19:04:12,676] (heat-config) [INFO] ", 
                "[2019-06-05 19:04:12,676] (heat-config) [DEBUG] "
            ]
        }, 
        {
            "status_code": "0"
        }
    ]
}
2019-06-05 14:04:12,845 p=17240 u=mistral |  TASK [Output for async deployment ControllerHostsDeployment] *******************
2019-06-05 14:04:12,845 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:176
2019-06-05 14:04:12,845 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:12 -0500 (0:00:00.056)       0:00:46.615 ******** 
2019-06-05 14:04:12,847 p=17240 u=mistral |  META: noop
2019-06-05 14:04:12,856 p=17240 u=mistral |  skipping: [lab-controller-0] => {}
2019-06-05 14:04:12,874 p=17240 u=mistral |  TASK [Check-mode for Run deployment ControllerHostsDeployment (changed status indicates deployment would run)] ***
2019-06-05 14:04:12,874 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:186
2019-06-05 14:04:12,874 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:12 -0500 (0:00:00.028)       0:00:46.643 ******** 
2019-06-05 14:04:12,876 p=17240 u=mistral |  META: noop
2019-06-05 14:04:12,884 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:12,900 p=17240 u=mistral |  TASK [Lookup deployment UUID] **************************************************
2019-06-05 14:04:12,901 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:1
2019-06-05 14:04:12,901 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:12 -0500 (0:00:00.026)       0:00:46.670 ******** 
2019-06-05 14:04:12,903 p=17240 u=mistral |  META: noop
2019-06-05 14:04:12,989 p=17240 u=mistral |  ok: [lab-controller-0] => {"ansible_facts": {"deployment_uuid": "bc4dc37f-9df5-4500-81ac-c455bfd54598"}, "changed": false}
2019-06-05 14:04:13,005 p=17240 u=mistral |  TASK [Lookup deployment group] *************************************************
2019-06-05 14:04:13,005 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:5
2019-06-05 14:04:13,005 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:13 -0500 (0:00:00.104)       0:00:46.774 ******** 
2019-06-05 14:04:13,007 p=17240 u=mistral |  META: noop
2019-06-05 14:04:13,092 p=17240 u=mistral |  ok: [lab-controller-0] => {"ansible_facts": {"deployment_group": "hiera"}, "changed": false}
2019-06-05 14:04:13,108 p=17240 u=mistral |  TASK [Create hiera check-mode directory] ***************************************
2019-06-05 14:04:13,108 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:13
2019-06-05 14:04:13,109 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:13 -0500 (0:00:00.103)       0:00:46.878 ******** 
2019-06-05 14:04:13,110 p=17240 u=mistral |  META: noop
2019-06-05 14:04:13,119 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:13,135 p=17240 u=mistral |  TASK [Create deployed check-mode directory] ************************************
2019-06-05 14:04:13,135 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:19
2019-06-05 14:04:13,135 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:13 -0500 (0:00:00.026)       0:00:46.905 ******** 
2019-06-05 14:04:13,138 p=17240 u=mistral |  META: noop
2019-06-05 14:04:13,147 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:13,163 p=17240 u=mistral |  TASK [Create tripleo-config-download check-mode directory] *********************
2019-06-05 14:04:13,163 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:25
2019-06-05 14:04:13,163 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:13 -0500 (0:00:00.027)       0:00:46.932 ******** 
2019-06-05 14:04:13,165 p=17240 u=mistral |  META: noop
2019-06-05 14:04:13,174 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:13,191 p=17240 u=mistral |  TASK [Render deployment file for ControllerAllNodesDeployment for check-mode] ***
2019-06-05 14:04:13,191 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:31
2019-06-05 14:04:13,191 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:13 -0500 (0:00:00.028)       0:00:46.961 ******** 
2019-06-05 14:04:13,193 p=17240 u=mistral |  META: noop
2019-06-05 14:04:13,202 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:13,218 p=17240 u=mistral |  TASK [Run hiera deployment for check mode] *************************************
2019-06-05 14:04:13,218 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:38
2019-06-05 14:04:13,218 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:13 -0500 (0:00:00.027)       0:00:46.988 ******** 
2019-06-05 14:04:13,221 p=17240 u=mistral |  META: noop
2019-06-05 14:04:13,230 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:13,246 p=17240 u=mistral |  TASK [List hieradata files for check mode] *************************************
2019-06-05 14:04:13,246 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:54
2019-06-05 14:04:13,246 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:13 -0500 (0:00:00.027)       0:00:47.015 ******** 
2019-06-05 14:04:13,248 p=17240 u=mistral |  META: noop
2019-06-05 14:04:13,256 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:13,273 p=17240 u=mistral |  TASK [diff hieradata changes for check mode] ***********************************
2019-06-05 14:04:13,273 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:60
2019-06-05 14:04:13,273 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:13 -0500 (0:00:00.027)       0:00:47.042 ******** 
2019-06-05 14:04:13,275 p=17240 u=mistral |  META: noop
2019-06-05 14:04:13,284 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:13,300 p=17240 u=mistral |  TASK [diff hieradata changes for check mode] ***********************************
2019-06-05 14:04:13,300 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:73
2019-06-05 14:04:13,300 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:13 -0500 (0:00:00.027)       0:00:47.070 ******** 
2019-06-05 14:04:13,302 p=17240 u=mistral |  META: noop
2019-06-05 14:04:13,312 p=17240 u=mistral |  skipping: [lab-controller-0] => {}
2019-06-05 14:04:13,328 p=17240 u=mistral |  TASK [hiera.yaml changes for check mode] ***************************************
2019-06-05 14:04:13,328 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:82
2019-06-05 14:04:13,329 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:13 -0500 (0:00:00.028)       0:00:47.098 ******** 
2019-06-05 14:04:13,330 p=17240 u=mistral |  META: noop
2019-06-05 14:04:13,339 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:13,355 p=17240 u=mistral |  TASK [diff hiera.yaml changes for check mode] **********************************
2019-06-05 14:04:13,355 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:90
2019-06-05 14:04:13,356 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:13 -0500 (0:00:00.026)       0:00:47.125 ******** 
2019-06-05 14:04:13,357 p=17240 u=mistral |  META: noop
2019-06-05 14:04:13,366 p=17240 u=mistral |  skipping: [lab-controller-0] => {}
2019-06-05 14:04:13,383 p=17240 u=mistral |  TASK [Render deployment file for ControllerAllNodesDeployment] *****************
2019-06-05 14:04:13,384 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:102
2019-06-05 14:04:13,384 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:13 -0500 (0:00:00.028)       0:00:47.153 ******** 
2019-06-05 14:04:13,386 p=17240 u=mistral |  META: noop
2019-06-05 14:04:13,751 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "checksum": "1176a037d0044d74f46404e6b27dc326775851a8", "dest": "/var/lib/heat-config/tripleo-config-download/ControllerAllNodesDeployment-bc4dc37f-9df5-4500-81ac-c455bfd54598", "gid": 0, "group": "root", "md5sum": "24eb0940638640643d5215efd70b8720", "mode": "0644", "owner": "root", "secontext": "system_u:object_r:var_lib_t:s0", "size": 20419, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559761453.48-131077801817834/source", "state": "file", "uid": 0}
2019-06-05 14:04:13,769 p=17240 u=mistral |  TASK [Check if deployed file exists for ControllerAllNodesDeployment] **********
2019-06-05 14:04:13,769 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:108
2019-06-05 14:04:13,769 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:13 -0500 (0:00:00.385)       0:00:47.538 ******** 
2019-06-05 14:04:13,772 p=17240 u=mistral |  META: noop
2019-06-05 14:04:13,878 p=17240 u=mistral |  ok: [lab-controller-0] => {"changed": false, "stat": {"exists": false}}
2019-06-05 14:04:13,896 p=17240 u=mistral |  TASK [Check previous deployment rc for ControllerAllNodesDeployment] ***********
2019-06-05 14:04:13,896 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:113
2019-06-05 14:04:13,896 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:13 -0500 (0:00:00.126)       0:00:47.665 ******** 
2019-06-05 14:04:13,898 p=17240 u=mistral |  META: noop
2019-06-05 14:04:13,910 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:13,929 p=17240 u=mistral |  TASK [Remove deployed file for ControllerAllNodesDeployment when previous deployment failed] ***
2019-06-05 14:04:13,929 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:121
2019-06-05 14:04:13,930 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:13 -0500 (0:00:00.033)       0:00:47.699 ******** 
2019-06-05 14:04:13,932 p=17240 u=mistral |  META: noop
2019-06-05 14:04:13,942 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:13,961 p=17240 u=mistral |  TASK [Force remove deployed file for ControllerAllNodesDeployment] *************
2019-06-05 14:04:13,961 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:131
2019-06-05 14:04:13,961 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:13 -0500 (0:00:00.031)       0:00:47.730 ******** 
2019-06-05 14:04:13,963 p=17240 u=mistral |  META: noop
2019-06-05 14:04:13,971 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:13,988 p=17240 u=mistral |  TASK [Set fact for async_deployment] *******************************************
2019-06-05 14:04:13,988 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:138
2019-06-05 14:04:13,988 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:13 -0500 (0:00:00.026)       0:00:47.757 ******** 
2019-06-05 14:04:13,991 p=17240 u=mistral |  META: noop
2019-06-05 14:04:14,015 p=17240 u=mistral |  ok: [lab-controller-0] => {"ansible_facts": {"use_async_deployment": false}, "changed": false}
2019-06-05 14:04:14,032 p=17240 u=mistral |  TASK [Run deployment ControllerAllNodesDeployment] *****************************
2019-06-05 14:04:14,032 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:142
2019-06-05 14:04:14,032 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:14 -0500 (0:00:00.044)       0:00:47.801 ******** 
2019-06-05 14:04:14,034 p=17240 u=mistral |  META: noop
2019-06-05 14:04:14,640 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "cmd": "/usr/libexec/os-refresh-config/configure.d/55-heat-config\n exit $(jq .deploy_status_code /var/lib/heat-config/deployed/bc4dc37f-9df5-4500-81ac-c455bfd54598.notify.json)", "delta": "0:00:00.501672", "end": "2019-06-05 19:04:14.630387", "rc": 0, "start": "2019-06-05 19:04:14.128715", "stderr": "[2019-06-05 19:04:14,157] (heat-config) [DEBUG] Running /usr/libexec/heat-config/hooks/hiera < /var/lib/heat-config/deployed/bc4dc37f-9df5-4500-81ac-c455bfd54598.json\n[2019-06-05 19:04:14,331] (heat-config) [INFO] |-\n  {\"deploy_stdout\": \"\", \"deploy_stderr\": \"\", \"deploy_status_code\": 0}\n\n[2019-06-05 19:04:14,331] (heat-config) [DEBUG] \n[2019-06-05 19:04:14,331] (heat-config) [INFO] Completed /usr/libexec/heat-config/hooks/hiera\n[2019-06-05 19:04:14,331] (heat-config) [DEBUG] Running heat-config-notify /var/lib/heat-config/deployed/bc4dc37f-9df5-4500-81ac-c455bfd54598.json < /var/lib/heat-config/deployed/bc4dc37f-9df5-4500-81ac-c455bfd54598.notify.json\n[2019-06-05 19:04:14,624] (heat-config) [INFO] \n[2019-06-05 19:04:14,624] (heat-config) [DEBUG] ", "stderr_lines": ["[2019-06-05 19:04:14,157] (heat-config) [DEBUG] Running /usr/libexec/heat-config/hooks/hiera < /var/lib/heat-config/deployed/bc4dc37f-9df5-4500-81ac-c455bfd54598.json", "[2019-06-05 19:04:14,331] (heat-config) [INFO] |-", "  {\"deploy_stdout\": \"\", \"deploy_stderr\": \"\", \"deploy_status_code\": 0}", "", "[2019-06-05 19:04:14,331] (heat-config) [DEBUG] ", "[2019-06-05 19:04:14,331] (heat-config) [INFO] Completed /usr/libexec/heat-config/hooks/hiera", "[2019-06-05 19:04:14,331] (heat-config) [DEBUG] Running heat-config-notify /var/lib/heat-config/deployed/bc4dc37f-9df5-4500-81ac-c455bfd54598.json < /var/lib/heat-config/deployed/bc4dc37f-9df5-4500-81ac-c455bfd54598.notify.json", "[2019-06-05 19:04:14,624] (heat-config) [INFO] ", "[2019-06-05 19:04:14,624] (heat-config) [DEBUG] "], "stdout": "", "stdout_lines": []}
2019-06-05 14:04:14,658 p=17240 u=mistral |  TASK [Run async deployment ControllerAllNodesDeployment] ***********************
2019-06-05 14:04:14,658 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:153
2019-06-05 14:04:14,658 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:14 -0500 (0:00:00.626)       0:00:48.428 ******** 
2019-06-05 14:04:14,661 p=17240 u=mistral |  META: noop
2019-06-05 14:04:14,669 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:14,687 p=17240 u=mistral |  TASK [Output for sync deployment ControllerAllNodesDeployment] *****************
2019-06-05 14:04:14,687 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:166
2019-06-05 14:04:14,687 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:14 -0500 (0:00:00.028)       0:00:48.457 ******** 
2019-06-05 14:04:14,689 p=17240 u=mistral |  META: noop
2019-06-05 14:04:14,719 p=17240 u=mistral |  ok: [lab-controller-0] => {
    "msg": [
        {
            "stderr": [
                "[2019-06-05 19:04:14,157] (heat-config) [DEBUG] Running /usr/libexec/heat-config/hooks/hiera < /var/lib/heat-config/deployed/bc4dc37f-9df5-4500-81ac-c455bfd54598.json", 
                "[2019-06-05 19:04:14,331] (heat-config) [INFO] |-", 
                "  {\"deploy_stdout\": \"\", \"deploy_stderr\": \"\", \"deploy_status_code\": 0}", 
                "", 
                "[2019-06-05 19:04:14,331] (heat-config) [DEBUG] ", 
                "[2019-06-05 19:04:14,331] (heat-config) [INFO] Completed /usr/libexec/heat-config/hooks/hiera", 
                "[2019-06-05 19:04:14,331] (heat-config) [DEBUG] Running heat-config-notify /var/lib/heat-config/deployed/bc4dc37f-9df5-4500-81ac-c455bfd54598.json < /var/lib/heat-config/deployed/bc4dc37f-9df5-4500-81ac-c455bfd54598.notify.json", 
                "[2019-06-05 19:04:14,624] (heat-config) [INFO] ", 
                "[2019-06-05 19:04:14,624] (heat-config) [DEBUG] "
            ]
        }, 
        {
            "status_code": "0"
        }
    ]
}
2019-06-05 14:04:14,737 p=17240 u=mistral |  TASK [Output for async deployment ControllerAllNodesDeployment] ****************
2019-06-05 14:04:14,737 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:176
2019-06-05 14:04:14,737 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:14 -0500 (0:00:00.049)       0:00:48.507 ******** 
2019-06-05 14:04:14,739 p=17240 u=mistral |  META: noop
2019-06-05 14:04:14,748 p=17240 u=mistral |  skipping: [lab-controller-0] => {}
2019-06-05 14:04:14,765 p=17240 u=mistral |  TASK [Check-mode for Run deployment ControllerAllNodesDeployment (changed status indicates deployment would run)] ***
2019-06-05 14:04:14,765 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:186
2019-06-05 14:04:14,765 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:14 -0500 (0:00:00.027)       0:00:48.535 ******** 
2019-06-05 14:04:14,768 p=17240 u=mistral |  META: noop
2019-06-05 14:04:14,774 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:14,790 p=17240 u=mistral |  TASK [Lookup deployment UUID] **************************************************
2019-06-05 14:04:14,790 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:1
2019-06-05 14:04:14,790 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:14 -0500 (0:00:00.024)       0:00:48.559 ******** 
2019-06-05 14:04:14,792 p=17240 u=mistral |  META: noop
2019-06-05 14:04:14,827 p=17240 u=mistral |  ok: [lab-controller-0] => {"ansible_facts": {"deployment_uuid": "bb762510-1dde-46a7-a2f3-c62da169a72c"}, "changed": false}
2019-06-05 14:04:14,843 p=17240 u=mistral |  TASK [Lookup deployment group] *************************************************
2019-06-05 14:04:14,843 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:5
2019-06-05 14:04:14,844 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:14 -0500 (0:00:00.053)       0:00:48.613 ******** 
2019-06-05 14:04:14,845 p=17240 u=mistral |  META: noop
2019-06-05 14:04:14,880 p=17240 u=mistral |  ok: [lab-controller-0] => {"ansible_facts": {"deployment_group": "script"}, "changed": false}
2019-06-05 14:04:14,899 p=17240 u=mistral |  TASK [Create hiera check-mode directory] ***************************************
2019-06-05 14:04:14,899 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:13
2019-06-05 14:04:14,899 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:14 -0500 (0:00:00.055)       0:00:48.668 ******** 
2019-06-05 14:04:14,901 p=17240 u=mistral |  META: noop
2019-06-05 14:04:14,910 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:14,926 p=17240 u=mistral |  TASK [Create deployed check-mode directory] ************************************
2019-06-05 14:04:14,926 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:19
2019-06-05 14:04:14,926 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:14 -0500 (0:00:00.027)       0:00:48.696 ******** 
2019-06-05 14:04:14,928 p=17240 u=mistral |  META: noop
2019-06-05 14:04:14,937 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:14,954 p=17240 u=mistral |  TASK [Create tripleo-config-download check-mode directory] *********************
2019-06-05 14:04:14,954 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:25
2019-06-05 14:04:14,954 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:14 -0500 (0:00:00.027)       0:00:48.723 ******** 
2019-06-05 14:04:14,956 p=17240 u=mistral |  META: noop
2019-06-05 14:04:14,965 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:14,983 p=17240 u=mistral |  TASK [Render deployment file for ControllerAllNodesValidationDeployment for check-mode] ***
2019-06-05 14:04:14,983 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:31
2019-06-05 14:04:14,983 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:14 -0500 (0:00:00.029)       0:00:48.752 ******** 
2019-06-05 14:04:14,985 p=17240 u=mistral |  META: noop
2019-06-05 14:04:14,995 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:15,011 p=17240 u=mistral |  TASK [Run hiera deployment for check mode] *************************************
2019-06-05 14:04:15,011 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:38
2019-06-05 14:04:15,011 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:15 -0500 (0:00:00.028)       0:00:48.781 ******** 
2019-06-05 14:04:15,013 p=17240 u=mistral |  META: noop
2019-06-05 14:04:15,022 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:15,039 p=17240 u=mistral |  TASK [List hieradata files for check mode] *************************************
2019-06-05 14:04:15,039 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:54
2019-06-05 14:04:15,039 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:15 -0500 (0:00:00.027)       0:00:48.808 ******** 
2019-06-05 14:04:15,041 p=17240 u=mistral |  META: noop
2019-06-05 14:04:15,050 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:15,066 p=17240 u=mistral |  TASK [diff hieradata changes for check mode] ***********************************
2019-06-05 14:04:15,066 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:60
2019-06-05 14:04:15,066 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:15 -0500 (0:00:00.026)       0:00:48.835 ******** 
2019-06-05 14:04:15,068 p=17240 u=mistral |  META: noop
2019-06-05 14:04:15,078 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:15,094 p=17240 u=mistral |  TASK [diff hieradata changes for check mode] ***********************************
2019-06-05 14:04:15,094 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:73
2019-06-05 14:04:15,094 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:15 -0500 (0:00:00.028)       0:00:48.864 ******** 
2019-06-05 14:04:15,097 p=17240 u=mistral |  META: noop
2019-06-05 14:04:15,106 p=17240 u=mistral |  skipping: [lab-controller-0] => {}
2019-06-05 14:04:15,122 p=17240 u=mistral |  TASK [hiera.yaml changes for check mode] ***************************************
2019-06-05 14:04:15,123 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:82
2019-06-05 14:04:15,123 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:15 -0500 (0:00:00.028)       0:00:48.892 ******** 
2019-06-05 14:04:15,125 p=17240 u=mistral |  META: noop
2019-06-05 14:04:15,133 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:15,150 p=17240 u=mistral |  TASK [diff hiera.yaml changes for check mode] **********************************
2019-06-05 14:04:15,150 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:90
2019-06-05 14:04:15,150 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:15 -0500 (0:00:00.027)       0:00:48.919 ******** 
2019-06-05 14:04:15,152 p=17240 u=mistral |  META: noop
2019-06-05 14:04:15,161 p=17240 u=mistral |  skipping: [lab-controller-0] => {}
2019-06-05 14:04:15,178 p=17240 u=mistral |  TASK [Render deployment file for ControllerAllNodesValidationDeployment] *******
2019-06-05 14:04:15,178 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:102
2019-06-05 14:04:15,178 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:15 -0500 (0:00:00.028)       0:00:48.948 ******** 
2019-06-05 14:04:15,181 p=17240 u=mistral |  META: noop
2019-06-05 14:04:15,479 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "checksum": "f565655018b5c386cd1fcb6c9b4d916bb6f4cd90", "dest": "/var/lib/heat-config/tripleo-config-download/ControllerAllNodesValidationDeployment-bb762510-1dde-46a7-a2f3-c62da169a72c", "gid": 0, "group": "root", "md5sum": "a1e9df0512844c8da85248e767d89550", "mode": "0644", "owner": "root", "secontext": "system_u:object_r:var_lib_t:s0", "size": 5596, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559761455.22-234118249144267/source", "state": "file", "uid": 0}
2019-06-05 14:04:15,497 p=17240 u=mistral |  TASK [Check if deployed file exists for ControllerAllNodesValidationDeployment] ***
2019-06-05 14:04:15,497 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:108
2019-06-05 14:04:15,497 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:15 -0500 (0:00:00.318)       0:00:49.266 ******** 
2019-06-05 14:04:15,499 p=17240 u=mistral |  META: noop
2019-06-05 14:04:15,600 p=17240 u=mistral |  ok: [lab-controller-0] => {"changed": false, "stat": {"exists": false}}
2019-06-05 14:04:15,618 p=17240 u=mistral |  TASK [Check previous deployment rc for ControllerAllNodesValidationDeployment] ***
2019-06-05 14:04:15,618 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:113
2019-06-05 14:04:15,618 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:15 -0500 (0:00:00.120)       0:00:49.387 ******** 
2019-06-05 14:04:15,620 p=17240 u=mistral |  META: noop
2019-06-05 14:04:15,628 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:15,645 p=17240 u=mistral |  TASK [Remove deployed file for ControllerAllNodesValidationDeployment when previous deployment failed] ***
2019-06-05 14:04:15,645 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:121
2019-06-05 14:04:15,646 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:15 -0500 (0:00:00.027)       0:00:49.415 ******** 
2019-06-05 14:04:15,647 p=17240 u=mistral |  META: noop
2019-06-05 14:04:15,657 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:15,674 p=17240 u=mistral |  TASK [Force remove deployed file for ControllerAllNodesValidationDeployment] ***
2019-06-05 14:04:15,674 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:131
2019-06-05 14:04:15,674 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:15 -0500 (0:00:00.028)       0:00:49.444 ******** 
2019-06-05 14:04:15,676 p=17240 u=mistral |  META: noop
2019-06-05 14:04:15,688 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:15,706 p=17240 u=mistral |  TASK [Set fact for async_deployment] *******************************************
2019-06-05 14:04:15,707 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:138
2019-06-05 14:04:15,707 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:15 -0500 (0:00:00.032)       0:00:49.476 ******** 
2019-06-05 14:04:15,709 p=17240 u=mistral |  META: noop
2019-06-05 14:04:15,733 p=17240 u=mistral |  ok: [lab-controller-0] => {"ansible_facts": {"use_async_deployment": false}, "changed": false}
2019-06-05 14:04:15,751 p=17240 u=mistral |  TASK [Run deployment ControllerAllNodesValidationDeployment] *******************
2019-06-05 14:04:15,751 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:142
2019-06-05 14:04:15,751 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:15 -0500 (0:00:00.044)       0:00:49.520 ******** 
2019-06-05 14:04:15,753 p=17240 u=mistral |  META: noop
2019-06-05 14:04:17,159 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "cmd": "/usr/libexec/os-refresh-config/configure.d/55-heat-config\n exit $(jq .deploy_status_code /var/lib/heat-config/deployed/bb762510-1dde-46a7-a2f3-c62da169a72c.notify.json)", "delta": "0:00:01.302336", "end": "2019-06-05 19:04:17.149218", "rc": 0, "start": "2019-06-05 19:04:15.846882", "stderr": "[2019-06-05 19:04:15,872] (heat-config) [DEBUG] Running /usr/libexec/heat-config/hooks/script < /var/lib/heat-config/deployed/bb762510-1dde-46a7-a2f3-c62da169a72c.json\n[2019-06-05 19:04:16,852] (heat-config) [INFO] |-\n  {\"deploy_stdout\": \"Trying to ping default gateway 192.168.122.1...Ping to 192.168.122.1 succeeded.\\nSUCCESS\\nTrying to ping 10.0.0.8 for local network 10.0.0.0/24.\\nPing to 10.0.0.8 succeeded.\\nSUCCESS\\nTrying to ping 172.16.0.171 for local network 172.16.0.0/24.\\nPing to 172.16.0.171 succeeded.\\nSUCCESS\\nTrying to ping 172.16.1.240 for local network 172.16.1.0/24.\\nPing to 172.16.1.240 succeeded.\\nSUCCESS\\nTrying to ping 172.16.2.35 for local network 172.16.2.0/24.\\nPing to 172.16.2.35 succeeded.\\nSUCCESS\\nTrying to ping 172.16.3.205 for local network 172.16.3.0/24.\\nPing to 172.16.3.205 succeeded.\\nSUCCESS\\nTrying to ping 192.168.24.20 for local network 192.168.24.0/24.\\nPing to 192.168.24.20 succeeded.\\nSUCCESS\\n\", \"deploy_stderr\": \"\", \"deploy_status_code\": 0}\n\n[2019-06-05 19:04:16,852] (heat-config) [DEBUG] [2019-06-05 19:04:15,884] (heat-config) [INFO] ping_test_ips=192.168.24.20 172.16.1.240 172.16.3.205 172.16.2.35 172.16.0.171 10.0.0.8\n[2019-06-05 19:04:15,884] (heat-config) [INFO] validate_fqdn=False\n[2019-06-05 19:04:15,884] (heat-config) [INFO] validate_ntp=True\n[2019-06-05 19:04:15,885] (heat-config) [INFO] validate_controllers_icmp=True\n[2019-06-05 19:04:15,885] (heat-config) [INFO] validate_gateways_icmp=True\n[2019-06-05 19:04:15,885] (heat-config) [INFO] deploy_server_id=cd2dbcc8-25c9-489f-9138-43515c089a76\n[2019-06-05 19:04:15,885] (heat-config) [INFO] deploy_action=CREATE\n[2019-06-05 19:04:15,885] (heat-config) [INFO] deploy_stack_id=lab-ControllerAllNodesValidationDeployment-lta5mn3xy7am-0-ossif4utjtcf/d7990306-7b43-4940-95ae-b3cb2b0a0a4e\n[2019-06-05 19:04:15,885] (heat-config) [INFO] deploy_resource_name=TripleOSoftwareDeployment\n[2019-06-05 19:04:15,885] (heat-config) [INFO] deploy_signal_transport=NO_SIGNAL\n[2019-06-05 19:04:15,885] (heat-config) [DEBUG] Running /var/lib/heat-config/heat-config-script/bb762510-1dde-46a7-a2f3-c62da169a72c\n[2019-06-05 19:04:16,849] (heat-config) [INFO] Trying to ping default gateway 192.168.122.1...Ping to 192.168.122.1 succeeded.\nSUCCESS\nTrying to ping 10.0.0.8 for local network 10.0.0.0/24.\nPing to 10.0.0.8 succeeded.\nSUCCESS\nTrying to ping 172.16.0.171 for local network 172.16.0.0/24.\nPing to 172.16.0.171 succeeded.\nSUCCESS\nTrying to ping 172.16.1.240 for local network 172.16.1.0/24.\nPing to 172.16.1.240 succeeded.\nSUCCESS\nTrying to ping 172.16.2.35 for local network 172.16.2.0/24.\nPing to 172.16.2.35 succeeded.\nSUCCESS\nTrying to ping 172.16.3.205 for local network 172.16.3.0/24.\nPing to 172.16.3.205 succeeded.\nSUCCESS\nTrying to ping 192.168.24.20 for local network 192.168.24.0/24.\nPing to 192.168.24.20 succeeded.\nSUCCESS\n\n[2019-06-05 19:04:16,849] (heat-config) [DEBUG] \n[2019-06-05 19:04:16,849] (heat-config) [INFO] Completed /var/lib/heat-config/heat-config-script/bb762510-1dde-46a7-a2f3-c62da169a72c\n\n[2019-06-05 19:04:16,852] (heat-config) [INFO] Completed /usr/libexec/heat-config/hooks/script\n[2019-06-05 19:04:16,852] (heat-config) [DEBUG] Running heat-config-notify /var/lib/heat-config/deployed/bb762510-1dde-46a7-a2f3-c62da169a72c.json < /var/lib/heat-config/deployed/bb762510-1dde-46a7-a2f3-c62da169a72c.notify.json\n[2019-06-05 19:04:17,143] (heat-config) [INFO] \n[2019-06-05 19:04:17,143] (heat-config) [DEBUG] ", "stderr_lines": ["[2019-06-05 19:04:15,872] (heat-config) [DEBUG] Running /usr/libexec/heat-config/hooks/script < /var/lib/heat-config/deployed/bb762510-1dde-46a7-a2f3-c62da169a72c.json", "[2019-06-05 19:04:16,852] (heat-config) [INFO] |-", "  {\"deploy_stdout\": \"Trying to ping default gateway 192.168.122.1...Ping to 192.168.122.1 succeeded.\\nSUCCESS\\nTrying to ping 10.0.0.8 for local network 10.0.0.0/24.\\nPing to 10.0.0.8 succeeded.\\nSUCCESS\\nTrying to ping 172.16.0.171 for local network 172.16.0.0/24.\\nPing to 172.16.0.171 succeeded.\\nSUCCESS\\nTrying to ping 172.16.1.240 for local network 172.16.1.0/24.\\nPing to 172.16.1.240 succeeded.\\nSUCCESS\\nTrying to ping 172.16.2.35 for local network 172.16.2.0/24.\\nPing to 172.16.2.35 succeeded.\\nSUCCESS\\nTrying to ping 172.16.3.205 for local network 172.16.3.0/24.\\nPing to 172.16.3.205 succeeded.\\nSUCCESS\\nTrying to ping 192.168.24.20 for local network 192.168.24.0/24.\\nPing to 192.168.24.20 succeeded.\\nSUCCESS\\n\", \"deploy_stderr\": \"\", \"deploy_status_code\": 0}", "", "[2019-06-05 19:04:16,852] (heat-config) [DEBUG] [2019-06-05 19:04:15,884] (heat-config) [INFO] ping_test_ips=192.168.24.20 172.16.1.240 172.16.3.205 172.16.2.35 172.16.0.171 10.0.0.8", "[2019-06-05 19:04:15,884] (heat-config) [INFO] validate_fqdn=False", "[2019-06-05 19:04:15,884] (heat-config) [INFO] validate_ntp=True", "[2019-06-05 19:04:15,885] (heat-config) [INFO] validate_controllers_icmp=True", "[2019-06-05 19:04:15,885] (heat-config) [INFO] validate_gateways_icmp=True", "[2019-06-05 19:04:15,885] (heat-config) [INFO] deploy_server_id=cd2dbcc8-25c9-489f-9138-43515c089a76", "[2019-06-05 19:04:15,885] (heat-config) [INFO] deploy_action=CREATE", "[2019-06-05 19:04:15,885] (heat-config) [INFO] deploy_stack_id=lab-ControllerAllNodesValidationDeployment-lta5mn3xy7am-0-ossif4utjtcf/d7990306-7b43-4940-95ae-b3cb2b0a0a4e", "[2019-06-05 19:04:15,885] (heat-config) [INFO] deploy_resource_name=TripleOSoftwareDeployment", "[2019-06-05 19:04:15,885] (heat-config) [INFO] deploy_signal_transport=NO_SIGNAL", "[2019-06-05 19:04:15,885] (heat-config) [DEBUG] Running /var/lib/heat-config/heat-config-script/bb762510-1dde-46a7-a2f3-c62da169a72c", "[2019-06-05 19:04:16,849] (heat-config) [INFO] Trying to ping default gateway 192.168.122.1...Ping to 192.168.122.1 succeeded.", "SUCCESS", "Trying to ping 10.0.0.8 for local network 10.0.0.0/24.", "Ping to 10.0.0.8 succeeded.", "SUCCESS", "Trying to ping 172.16.0.171 for local network 172.16.0.0/24.", "Ping to 172.16.0.171 succeeded.", "SUCCESS", "Trying to ping 172.16.1.240 for local network 172.16.1.0/24.", "Ping to 172.16.1.240 succeeded.", "SUCCESS", "Trying to ping 172.16.2.35 for local network 172.16.2.0/24.", "Ping to 172.16.2.35 succeeded.", "SUCCESS", "Trying to ping 172.16.3.205 for local network 172.16.3.0/24.", "Ping to 172.16.3.205 succeeded.", "SUCCESS", "Trying to ping 192.168.24.20 for local network 192.168.24.0/24.", "Ping to 192.168.24.20 succeeded.", "SUCCESS", "", "[2019-06-05 19:04:16,849] (heat-config) [DEBUG] ", "[2019-06-05 19:04:16,849] (heat-config) [INFO] Completed /var/lib/heat-config/heat-config-script/bb762510-1dde-46a7-a2f3-c62da169a72c", "", "[2019-06-05 19:04:16,852] (heat-config) [INFO] Completed /usr/libexec/heat-config/hooks/script", "[2019-06-05 19:04:16,852] (heat-config) [DEBUG] Running heat-config-notify /var/lib/heat-config/deployed/bb762510-1dde-46a7-a2f3-c62da169a72c.json < /var/lib/heat-config/deployed/bb762510-1dde-46a7-a2f3-c62da169a72c.notify.json", "[2019-06-05 19:04:17,143] (heat-config) [INFO] ", "[2019-06-05 19:04:17,143] (heat-config) [DEBUG] "], "stdout": "", "stdout_lines": []}
2019-06-05 14:04:17,177 p=17240 u=mistral |  TASK [Run async deployment ControllerAllNodesValidationDeployment] *************
2019-06-05 14:04:17,177 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:153
2019-06-05 14:04:17,177 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:17 -0500 (0:00:01.426)       0:00:50.947 ******** 
2019-06-05 14:04:17,179 p=17240 u=mistral |  META: noop
2019-06-05 14:04:17,188 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:17,205 p=17240 u=mistral |  TASK [Output for sync deployment ControllerAllNodesValidationDeployment] *******
2019-06-05 14:04:17,205 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:166
2019-06-05 14:04:17,205 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:17 -0500 (0:00:00.027)       0:00:50.974 ******** 
2019-06-05 14:04:17,207 p=17240 u=mistral |  META: noop
2019-06-05 14:04:17,238 p=17240 u=mistral |  ok: [lab-controller-0] => {
    "msg": [
        {
            "stderr": [
                "[2019-06-05 19:04:15,872] (heat-config) [DEBUG] Running /usr/libexec/heat-config/hooks/script < /var/lib/heat-config/deployed/bb762510-1dde-46a7-a2f3-c62da169a72c.json", 
                "[2019-06-05 19:04:16,852] (heat-config) [INFO] |-", 
                "  {\"deploy_stdout\": \"Trying to ping default gateway 192.168.122.1...Ping to 192.168.122.1 succeeded.\\nSUCCESS\\nTrying to ping 10.0.0.8 for local network 10.0.0.0/24.\\nPing to 10.0.0.8 succeeded.\\nSUCCESS\\nTrying to ping 172.16.0.171 for local network 172.16.0.0/24.\\nPing to 172.16.0.171 succeeded.\\nSUCCESS\\nTrying to ping 172.16.1.240 for local network 172.16.1.0/24.\\nPing to 172.16.1.240 succeeded.\\nSUCCESS\\nTrying to ping 172.16.2.35 for local network 172.16.2.0/24.\\nPing to 172.16.2.35 succeeded.\\nSUCCESS\\nTrying to ping 172.16.3.205 for local network 172.16.3.0/24.\\nPing to 172.16.3.205 succeeded.\\nSUCCESS\\nTrying to ping 192.168.24.20 for local network 192.168.24.0/24.\\nPing to 192.168.24.20 succeeded.\\nSUCCESS\\n\", \"deploy_stderr\": \"\", \"deploy_status_code\": 0}", 
                "", 
                "[2019-06-05 19:04:16,852] (heat-config) [DEBUG] [2019-06-05 19:04:15,884] (heat-config) [INFO] ping_test_ips=192.168.24.20 172.16.1.240 172.16.3.205 172.16.2.35 172.16.0.171 10.0.0.8", 
                "[2019-06-05 19:04:15,884] (heat-config) [INFO] validate_fqdn=False", 
                "[2019-06-05 19:04:15,884] (heat-config) [INFO] validate_ntp=True", 
                "[2019-06-05 19:04:15,885] (heat-config) [INFO] validate_controllers_icmp=True", 
                "[2019-06-05 19:04:15,885] (heat-config) [INFO] validate_gateways_icmp=True", 
                "[2019-06-05 19:04:15,885] (heat-config) [INFO] deploy_server_id=cd2dbcc8-25c9-489f-9138-43515c089a76", 
                "[2019-06-05 19:04:15,885] (heat-config) [INFO] deploy_action=CREATE", 
                "[2019-06-05 19:04:15,885] (heat-config) [INFO] deploy_stack_id=lab-ControllerAllNodesValidationDeployment-lta5mn3xy7am-0-ossif4utjtcf/d7990306-7b43-4940-95ae-b3cb2b0a0a4e", 
                "[2019-06-05 19:04:15,885] (heat-config) [INFO] deploy_resource_name=TripleOSoftwareDeployment", 
                "[2019-06-05 19:04:15,885] (heat-config) [INFO] deploy_signal_transport=NO_SIGNAL", 
                "[2019-06-05 19:04:15,885] (heat-config) [DEBUG] Running /var/lib/heat-config/heat-config-script/bb762510-1dde-46a7-a2f3-c62da169a72c", 
                "[2019-06-05 19:04:16,849] (heat-config) [INFO] Trying to ping default gateway 192.168.122.1...Ping to 192.168.122.1 succeeded.", 
                "SUCCESS", 
                "Trying to ping 10.0.0.8 for local network 10.0.0.0/24.", 
                "Ping to 10.0.0.8 succeeded.", 
                "SUCCESS", 
                "Trying to ping 172.16.0.171 for local network 172.16.0.0/24.", 
                "Ping to 172.16.0.171 succeeded.", 
                "SUCCESS", 
                "Trying to ping 172.16.1.240 for local network 172.16.1.0/24.", 
                "Ping to 172.16.1.240 succeeded.", 
                "SUCCESS", 
                "Trying to ping 172.16.2.35 for local network 172.16.2.0/24.", 
                "Ping to 172.16.2.35 succeeded.", 
                "SUCCESS", 
                "Trying to ping 172.16.3.205 for local network 172.16.3.0/24.", 
                "Ping to 172.16.3.205 succeeded.", 
                "SUCCESS", 
                "Trying to ping 192.168.24.20 for local network 192.168.24.0/24.", 
                "Ping to 192.168.24.20 succeeded.", 
                "SUCCESS", 
                "", 
                "[2019-06-05 19:04:16,849] (heat-config) [DEBUG] ", 
                "[2019-06-05 19:04:16,849] (heat-config) [INFO] Completed /var/lib/heat-config/heat-config-script/bb762510-1dde-46a7-a2f3-c62da169a72c", 
                "", 
                "[2019-06-05 19:04:16,852] (heat-config) [INFO] Completed /usr/libexec/heat-config/hooks/script", 
                "[2019-06-05 19:04:16,852] (heat-config) [DEBUG] Running heat-config-notify /var/lib/heat-config/deployed/bb762510-1dde-46a7-a2f3-c62da169a72c.json < /var/lib/heat-config/deployed/bb762510-1dde-46a7-a2f3-c62da169a72c.notify.json", 
                "[2019-06-05 19:04:17,143] (heat-config) [INFO] ", 
                "[2019-06-05 19:04:17,143] (heat-config) [DEBUG] "
            ]
        }, 
        {
            "status_code": "0"
        }
    ]
}
2019-06-05 14:04:17,255 p=17240 u=mistral |  TASK [Output for async deployment ControllerAllNodesValidationDeployment] ******
2019-06-05 14:04:17,255 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:176
2019-06-05 14:04:17,255 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:17 -0500 (0:00:00.049)       0:00:51.024 ******** 
2019-06-05 14:04:17,257 p=17240 u=mistral |  META: noop
2019-06-05 14:04:17,266 p=17240 u=mistral |  skipping: [lab-controller-0] => {}
2019-06-05 14:04:17,283 p=17240 u=mistral |  TASK [Check-mode for Run deployment ControllerAllNodesValidationDeployment (changed status indicates deployment would run)] ***
2019-06-05 14:04:17,283 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:186
2019-06-05 14:04:17,283 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:17 -0500 (0:00:00.028)       0:00:51.052 ******** 
2019-06-05 14:04:17,285 p=17240 u=mistral |  META: noop
2019-06-05 14:04:17,294 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:17,311 p=17240 u=mistral |  TASK [Lookup deployment UUID] **************************************************
2019-06-05 14:04:17,311 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:1
2019-06-05 14:04:17,311 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:17 -0500 (0:00:00.028)       0:00:51.081 ******** 
2019-06-05 14:04:17,313 p=17240 u=mistral |  META: noop
2019-06-05 14:04:17,343 p=17240 u=mistral |  ok: [lab-controller-0] => {"ansible_facts": {"deployment_uuid": "c0f5064d-7ea6-484e-b315-b6abfe25b255"}, "changed": false}
2019-06-05 14:04:17,359 p=17240 u=mistral |  TASK [Lookup deployment group] *************************************************
2019-06-05 14:04:17,359 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:5
2019-06-05 14:04:17,359 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:17 -0500 (0:00:00.048)       0:00:51.129 ******** 
2019-06-05 14:04:17,361 p=17240 u=mistral |  META: noop
2019-06-05 14:04:17,392 p=17240 u=mistral |  ok: [lab-controller-0] => {"ansible_facts": {"deployment_group": "script"}, "changed": false}
2019-06-05 14:04:17,409 p=17240 u=mistral |  TASK [Create hiera check-mode directory] ***************************************
2019-06-05 14:04:17,409 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:13
2019-06-05 14:04:17,409 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:17 -0500 (0:00:00.049)       0:00:51.178 ******** 
2019-06-05 14:04:17,411 p=17240 u=mistral |  META: noop
2019-06-05 14:04:17,419 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:17,436 p=17240 u=mistral |  TASK [Create deployed check-mode directory] ************************************
2019-06-05 14:04:17,436 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:19
2019-06-05 14:04:17,436 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:17 -0500 (0:00:00.027)       0:00:51.206 ******** 
2019-06-05 14:04:17,438 p=17240 u=mistral |  META: noop
2019-06-05 14:04:17,447 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:17,463 p=17240 u=mistral |  TASK [Create tripleo-config-download check-mode directory] *********************
2019-06-05 14:04:17,463 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:25
2019-06-05 14:04:17,463 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:17 -0500 (0:00:00.026)       0:00:51.232 ******** 
2019-06-05 14:04:17,465 p=17240 u=mistral |  META: noop
2019-06-05 14:04:17,473 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:17,491 p=17240 u=mistral |  TASK [Render deployment file for ControllerArtifactsDeploy for check-mode] *****
2019-06-05 14:04:17,491 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:31
2019-06-05 14:04:17,491 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:17 -0500 (0:00:00.028)       0:00:51.261 ******** 
2019-06-05 14:04:17,493 p=17240 u=mistral |  META: noop
2019-06-05 14:04:17,502 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:17,519 p=17240 u=mistral |  TASK [Run hiera deployment for check mode] *************************************
2019-06-05 14:04:17,519 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:38
2019-06-05 14:04:17,519 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:17 -0500 (0:00:00.027)       0:00:51.288 ******** 
2019-06-05 14:04:17,521 p=17240 u=mistral |  META: noop
2019-06-05 14:04:17,529 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:17,545 p=17240 u=mistral |  TASK [List hieradata files for check mode] *************************************
2019-06-05 14:04:17,545 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:54
2019-06-05 14:04:17,545 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:17 -0500 (0:00:00.026)       0:00:51.315 ******** 
2019-06-05 14:04:17,547 p=17240 u=mistral |  META: noop
2019-06-05 14:04:17,556 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:17,572 p=17240 u=mistral |  TASK [diff hieradata changes for check mode] ***********************************
2019-06-05 14:04:17,572 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:60
2019-06-05 14:04:17,572 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:17 -0500 (0:00:00.027)       0:00:51.342 ******** 
2019-06-05 14:04:17,574 p=17240 u=mistral |  META: noop
2019-06-05 14:04:17,584 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:17,600 p=17240 u=mistral |  TASK [diff hieradata changes for check mode] ***********************************
2019-06-05 14:04:17,600 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:73
2019-06-05 14:04:17,600 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:17 -0500 (0:00:00.027)       0:00:51.370 ******** 
2019-06-05 14:04:17,603 p=17240 u=mistral |  META: noop
2019-06-05 14:04:17,612 p=17240 u=mistral |  skipping: [lab-controller-0] => {}
2019-06-05 14:04:17,629 p=17240 u=mistral |  TASK [hiera.yaml changes for check mode] ***************************************
2019-06-05 14:04:17,629 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:82
2019-06-05 14:04:17,629 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:17 -0500 (0:00:00.028)       0:00:51.399 ******** 
2019-06-05 14:04:17,632 p=17240 u=mistral |  META: noop
2019-06-05 14:04:17,642 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:17,660 p=17240 u=mistral |  TASK [diff hiera.yaml changes for check mode] **********************************
2019-06-05 14:04:17,660 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:90
2019-06-05 14:04:17,660 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:17 -0500 (0:00:00.030)       0:00:51.429 ******** 
2019-06-05 14:04:17,662 p=17240 u=mistral |  META: noop
2019-06-05 14:04:17,675 p=17240 u=mistral |  skipping: [lab-controller-0] => {}
2019-06-05 14:04:17,693 p=17240 u=mistral |  TASK [Render deployment file for ControllerArtifactsDeploy] ********************
2019-06-05 14:04:17,693 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:102
2019-06-05 14:04:17,693 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:17 -0500 (0:00:00.033)       0:00:51.462 ******** 
2019-06-05 14:04:17,695 p=17240 u=mistral |  META: noop
2019-06-05 14:04:17,996 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "checksum": "4fac403508f743d551d995ffbc747b4ce82fd4b3", "dest": "/var/lib/heat-config/tripleo-config-download/ControllerArtifactsDeploy-c0f5064d-7ea6-484e-b315-b6abfe25b255", "gid": 0, "group": "root", "md5sum": "6682eb5560748cb186763a88412ca4d6", "mode": "0644", "owner": "root", "secontext": "system_u:object_r:var_lib_t:s0", "size": 2015, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559761457.73-270916913166606/source", "state": "file", "uid": 0}
2019-06-05 14:04:18,014 p=17240 u=mistral |  TASK [Check if deployed file exists for ControllerArtifactsDeploy] *************
2019-06-05 14:04:18,014 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:108
2019-06-05 14:04:18,014 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:18 -0500 (0:00:00.320)       0:00:51.783 ******** 
2019-06-05 14:04:18,017 p=17240 u=mistral |  META: noop
2019-06-05 14:04:18,116 p=17240 u=mistral |  ok: [lab-controller-0] => {"changed": false, "stat": {"exists": false}}
2019-06-05 14:04:18,134 p=17240 u=mistral |  TASK [Check previous deployment rc for ControllerArtifactsDeploy] **************
2019-06-05 14:04:18,134 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:113
2019-06-05 14:04:18,134 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:18 -0500 (0:00:00.119)       0:00:51.903 ******** 
2019-06-05 14:04:18,136 p=17240 u=mistral |  META: noop
2019-06-05 14:04:18,149 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:18,168 p=17240 u=mistral |  TASK [Remove deployed file for ControllerArtifactsDeploy when previous deployment failed] ***
2019-06-05 14:04:18,168 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:121
2019-06-05 14:04:18,168 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:18 -0500 (0:00:00.034)       0:00:51.938 ******** 
2019-06-05 14:04:18,170 p=17240 u=mistral |  META: noop
2019-06-05 14:04:18,180 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:18,198 p=17240 u=mistral |  TASK [Force remove deployed file for ControllerArtifactsDeploy] ****************
2019-06-05 14:04:18,198 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:131
2019-06-05 14:04:18,198 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:18 -0500 (0:00:00.029)       0:00:51.967 ******** 
2019-06-05 14:04:18,200 p=17240 u=mistral |  META: noop
2019-06-05 14:04:18,209 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:18,225 p=17240 u=mistral |  TASK [Set fact for async_deployment] *******************************************
2019-06-05 14:04:18,225 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:138
2019-06-05 14:04:18,225 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:18 -0500 (0:00:00.027)       0:00:51.994 ******** 
2019-06-05 14:04:18,228 p=17240 u=mistral |  META: noop
2019-06-05 14:04:18,253 p=17240 u=mistral |  ok: [lab-controller-0] => {"ansible_facts": {"use_async_deployment": false}, "changed": false}
2019-06-05 14:04:18,270 p=17240 u=mistral |  TASK [Run deployment ControllerArtifactsDeploy] ********************************
2019-06-05 14:04:18,270 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:142
2019-06-05 14:04:18,271 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:18 -0500 (0:00:00.045)       0:00:52.040 ******** 
2019-06-05 14:04:18,272 p=17240 u=mistral |  META: noop
2019-06-05 14:04:18,723 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "cmd": "/usr/libexec/os-refresh-config/configure.d/55-heat-config\n exit $(jq .deploy_status_code /var/lib/heat-config/deployed/c0f5064d-7ea6-484e-b315-b6abfe25b255.notify.json)", "delta": "0:00:00.344644", "end": "2019-06-05 19:04:18.713947", "rc": 0, "start": "2019-06-05 19:04:18.369303", "stderr": "[2019-06-05 19:04:18,395] (heat-config) [DEBUG] Running /usr/libexec/heat-config/hooks/script < /var/lib/heat-config/deployed/c0f5064d-7ea6-484e-b315-b6abfe25b255.json\n[2019-06-05 19:04:18,414] (heat-config) [INFO] |-\n  {\"deploy_stdout\": \"No artifact_urls was set. Skipping...\\n\", \"deploy_stderr\": \"\", \"deploy_status_code\": 0}\n\n[2019-06-05 19:04:18,414] (heat-config) [DEBUG] [2019-06-05 19:04:18,408] (heat-config) [INFO] artifact_urls=\n[2019-06-05 19:04:18,408] (heat-config) [INFO] deploy_server_id=cd2dbcc8-25c9-489f-9138-43515c089a76\n[2019-06-05 19:04:18,408] (heat-config) [INFO] deploy_action=CREATE\n[2019-06-05 19:04:18,408] (heat-config) [INFO] deploy_stack_id=lab-AllNodesDeploySteps-vnf37mzchjlf-ControllerArtifactsDeploy-kkjrmxyr5lky-0-pdikypjaloug/d01e5cd2-de00-48e8-80e5-a06ddc5bd9be\n[2019-06-05 19:04:18,408] (heat-config) [INFO] deploy_resource_name=TripleOSoftwareDeployment\n[2019-06-05 19:04:18,408] (heat-config) [INFO] deploy_signal_transport=NO_SIGNAL\n[2019-06-05 19:04:18,408] (heat-config) [DEBUG] Running /var/lib/heat-config/heat-config-script/c0f5064d-7ea6-484e-b315-b6abfe25b255\n[2019-06-05 19:04:18,411] (heat-config) [INFO] No artifact_urls was set. Skipping...\n\n[2019-06-05 19:04:18,411] (heat-config) [DEBUG] \n[2019-06-05 19:04:18,411] (heat-config) [INFO] Completed /var/lib/heat-config/heat-config-script/c0f5064d-7ea6-484e-b315-b6abfe25b255\n\n[2019-06-05 19:04:18,414] (heat-config) [INFO] Completed /usr/libexec/heat-config/hooks/script\n[2019-06-05 19:04:18,414] (heat-config) [DEBUG] Running heat-config-notify /var/lib/heat-config/deployed/c0f5064d-7ea6-484e-b315-b6abfe25b255.json < /var/lib/heat-config/deployed/c0f5064d-7ea6-484e-b315-b6abfe25b255.notify.json\n[2019-06-05 19:04:18,707] (heat-config) [INFO] \n[2019-06-05 19:04:18,707] (heat-config) [DEBUG] ", "stderr_lines": ["[2019-06-05 19:04:18,395] (heat-config) [DEBUG] Running /usr/libexec/heat-config/hooks/script < /var/lib/heat-config/deployed/c0f5064d-7ea6-484e-b315-b6abfe25b255.json", "[2019-06-05 19:04:18,414] (heat-config) [INFO] |-", "  {\"deploy_stdout\": \"No artifact_urls was set. Skipping...\\n\", \"deploy_stderr\": \"\", \"deploy_status_code\": 0}", "", "[2019-06-05 19:04:18,414] (heat-config) [DEBUG] [2019-06-05 19:04:18,408] (heat-config) [INFO] artifact_urls=", "[2019-06-05 19:04:18,408] (heat-config) [INFO] deploy_server_id=cd2dbcc8-25c9-489f-9138-43515c089a76", "[2019-06-05 19:04:18,408] (heat-config) [INFO] deploy_action=CREATE", "[2019-06-05 19:04:18,408] (heat-config) [INFO] deploy_stack_id=lab-AllNodesDeploySteps-vnf37mzchjlf-ControllerArtifactsDeploy-kkjrmxyr5lky-0-pdikypjaloug/d01e5cd2-de00-48e8-80e5-a06ddc5bd9be", "[2019-06-05 19:04:18,408] (heat-config) [INFO] deploy_resource_name=TripleOSoftwareDeployment", "[2019-06-05 19:04:18,408] (heat-config) [INFO] deploy_signal_transport=NO_SIGNAL", "[2019-06-05 19:04:18,408] (heat-config) [DEBUG] Running /var/lib/heat-config/heat-config-script/c0f5064d-7ea6-484e-b315-b6abfe25b255", "[2019-06-05 19:04:18,411] (heat-config) [INFO] No artifact_urls was set. Skipping...", "", "[2019-06-05 19:04:18,411] (heat-config) [DEBUG] ", "[2019-06-05 19:04:18,411] (heat-config) [INFO] Completed /var/lib/heat-config/heat-config-script/c0f5064d-7ea6-484e-b315-b6abfe25b255", "", "[2019-06-05 19:04:18,414] (heat-config) [INFO] Completed /usr/libexec/heat-config/hooks/script", "[2019-06-05 19:04:18,414] (heat-config) [DEBUG] Running heat-config-notify /var/lib/heat-config/deployed/c0f5064d-7ea6-484e-b315-b6abfe25b255.json < /var/lib/heat-config/deployed/c0f5064d-7ea6-484e-b315-b6abfe25b255.notify.json", "[2019-06-05 19:04:18,707] (heat-config) [INFO] ", "[2019-06-05 19:04:18,707] (heat-config) [DEBUG] "], "stdout": "", "stdout_lines": []}
2019-06-05 14:04:18,742 p=17240 u=mistral |  TASK [Run async deployment ControllerArtifactsDeploy] **************************
2019-06-05 14:04:18,742 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:153
2019-06-05 14:04:18,742 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:18 -0500 (0:00:00.471)       0:00:52.511 ******** 
2019-06-05 14:04:18,744 p=17240 u=mistral |  META: noop
2019-06-05 14:04:18,751 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:18,769 p=17240 u=mistral |  TASK [Output for sync deployment ControllerArtifactsDeploy] ********************
2019-06-05 14:04:18,769 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:166
2019-06-05 14:04:18,769 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:18 -0500 (0:00:00.026)       0:00:52.538 ******** 
2019-06-05 14:04:18,771 p=17240 u=mistral |  META: noop
2019-06-05 14:04:18,800 p=17240 u=mistral |  ok: [lab-controller-0] => {
    "msg": [
        {
            "stderr": [
                "[2019-06-05 19:04:18,395] (heat-config) [DEBUG] Running /usr/libexec/heat-config/hooks/script < /var/lib/heat-config/deployed/c0f5064d-7ea6-484e-b315-b6abfe25b255.json", 
                "[2019-06-05 19:04:18,414] (heat-config) [INFO] |-", 
                "  {\"deploy_stdout\": \"No artifact_urls was set. Skipping...\\n\", \"deploy_stderr\": \"\", \"deploy_status_code\": 0}", 
                "", 
                "[2019-06-05 19:04:18,414] (heat-config) [DEBUG] [2019-06-05 19:04:18,408] (heat-config) [INFO] artifact_urls=", 
                "[2019-06-05 19:04:18,408] (heat-config) [INFO] deploy_server_id=cd2dbcc8-25c9-489f-9138-43515c089a76", 
                "[2019-06-05 19:04:18,408] (heat-config) [INFO] deploy_action=CREATE", 
                "[2019-06-05 19:04:18,408] (heat-config) [INFO] deploy_stack_id=lab-AllNodesDeploySteps-vnf37mzchjlf-ControllerArtifactsDeploy-kkjrmxyr5lky-0-pdikypjaloug/d01e5cd2-de00-48e8-80e5-a06ddc5bd9be", 
                "[2019-06-05 19:04:18,408] (heat-config) [INFO] deploy_resource_name=TripleOSoftwareDeployment", 
                "[2019-06-05 19:04:18,408] (heat-config) [INFO] deploy_signal_transport=NO_SIGNAL", 
                "[2019-06-05 19:04:18,408] (heat-config) [DEBUG] Running /var/lib/heat-config/heat-config-script/c0f5064d-7ea6-484e-b315-b6abfe25b255", 
                "[2019-06-05 19:04:18,411] (heat-config) [INFO] No artifact_urls was set. Skipping...", 
                "", 
                "[2019-06-05 19:04:18,411] (heat-config) [DEBUG] ", 
                "[2019-06-05 19:04:18,411] (heat-config) [INFO] Completed /var/lib/heat-config/heat-config-script/c0f5064d-7ea6-484e-b315-b6abfe25b255", 
                "", 
                "[2019-06-05 19:04:18,414] (heat-config) [INFO] Completed /usr/libexec/heat-config/hooks/script", 
                "[2019-06-05 19:04:18,414] (heat-config) [DEBUG] Running heat-config-notify /var/lib/heat-config/deployed/c0f5064d-7ea6-484e-b315-b6abfe25b255.json < /var/lib/heat-config/deployed/c0f5064d-7ea6-484e-b315-b6abfe25b255.notify.json", 
                "[2019-06-05 19:04:18,707] (heat-config) [INFO] ", 
                "[2019-06-05 19:04:18,707] (heat-config) [DEBUG] "
            ]
        }, 
        {
            "status_code": "0"
        }
    ]
}
2019-06-05 14:04:18,818 p=17240 u=mistral |  TASK [Output for async deployment ControllerArtifactsDeploy] *******************
2019-06-05 14:04:18,818 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:176
2019-06-05 14:04:18,818 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:18 -0500 (0:00:00.049)       0:00:52.587 ******** 
2019-06-05 14:04:18,820 p=17240 u=mistral |  META: noop
2019-06-05 14:04:18,828 p=17240 u=mistral |  skipping: [lab-controller-0] => {}
2019-06-05 14:04:18,848 p=17240 u=mistral |  TASK [Check-mode for Run deployment ControllerArtifactsDeploy (changed status indicates deployment would run)] ***
2019-06-05 14:04:18,848 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:186
2019-06-05 14:04:18,848 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:18 -0500 (0:00:00.029)       0:00:52.617 ******** 
2019-06-05 14:04:18,850 p=17240 u=mistral |  META: noop
2019-06-05 14:04:18,858 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:18,858 p=17240 u=mistral |  META: noop
2019-06-05 14:04:18,872 p=17240 u=mistral |  TASK [Lookup deployment UUID] **************************************************
2019-06-05 14:04:18,872 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:1
2019-06-05 14:04:18,872 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:18 -0500 (0:00:00.024)       0:00:52.641 ******** 
2019-06-05 14:04:18,957 p=17240 u=mistral |  ok: [lab-computehci-0] => {"ansible_facts": {"deployment_uuid": "5885321f-5d2e-49bc-b098-55206a34d855"}, "changed": false}
2019-06-05 14:04:18,957 p=17240 u=mistral |  META: noop
2019-06-05 14:04:18,972 p=17240 u=mistral |  TASK [Lookup deployment group] *************************************************
2019-06-05 14:04:18,972 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:5
2019-06-05 14:04:18,972 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:18 -0500 (0:00:00.099)       0:00:52.741 ******** 
2019-06-05 14:04:19,059 p=17240 u=mistral |  ok: [lab-computehci-0] => {"ansible_facts": {"deployment_group": "hiera"}, "changed": false}
2019-06-05 14:04:19,060 p=17240 u=mistral |  META: noop
2019-06-05 14:04:19,074 p=17240 u=mistral |  TASK [Create hiera check-mode directory] ***************************************
2019-06-05 14:04:19,074 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:13
2019-06-05 14:04:19,074 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:19 -0500 (0:00:00.102)       0:00:52.843 ******** 
2019-06-05 14:04:19,091 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:19,091 p=17240 u=mistral |  META: noop
2019-06-05 14:04:19,105 p=17240 u=mistral |  TASK [Create deployed check-mode directory] ************************************
2019-06-05 14:04:19,105 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:19
2019-06-05 14:04:19,105 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:19 -0500 (0:00:00.030)       0:00:52.874 ******** 
2019-06-05 14:04:19,116 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:19,117 p=17240 u=mistral |  META: noop
2019-06-05 14:04:19,131 p=17240 u=mistral |  TASK [Create tripleo-config-download check-mode directory] *********************
2019-06-05 14:04:19,131 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:25
2019-06-05 14:04:19,132 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:19 -0500 (0:00:00.026)       0:00:52.901 ******** 
2019-06-05 14:04:19,142 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:19,143 p=17240 u=mistral |  META: noop
2019-06-05 14:04:19,158 p=17240 u=mistral |  TASK [Render deployment file for ComputeHCIDeployment for check-mode] **********
2019-06-05 14:04:19,158 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:31
2019-06-05 14:04:19,158 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:19 -0500 (0:00:00.026)       0:00:52.927 ******** 
2019-06-05 14:04:19,168 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:19,169 p=17240 u=mistral |  META: noop
2019-06-05 14:04:19,183 p=17240 u=mistral |  TASK [Run hiera deployment for check mode] *************************************
2019-06-05 14:04:19,183 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:38
2019-06-05 14:04:19,183 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:19 -0500 (0:00:00.025)       0:00:52.953 ******** 
2019-06-05 14:04:19,195 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:19,195 p=17240 u=mistral |  META: noop
2019-06-05 14:04:19,210 p=17240 u=mistral |  TASK [List hieradata files for check mode] *************************************
2019-06-05 14:04:19,210 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:54
2019-06-05 14:04:19,210 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:19 -0500 (0:00:00.026)       0:00:52.979 ******** 
2019-06-05 14:04:19,221 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:19,222 p=17240 u=mistral |  META: noop
2019-06-05 14:04:19,236 p=17240 u=mistral |  TASK [diff hieradata changes for check mode] ***********************************
2019-06-05 14:04:19,236 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:60
2019-06-05 14:04:19,236 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:19 -0500 (0:00:00.025)       0:00:53.005 ******** 
2019-06-05 14:04:19,248 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:19,249 p=17240 u=mistral |  META: noop
2019-06-05 14:04:19,263 p=17240 u=mistral |  TASK [diff hieradata changes for check mode] ***********************************
2019-06-05 14:04:19,263 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:73
2019-06-05 14:04:19,264 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:19 -0500 (0:00:00.027)       0:00:53.033 ******** 
2019-06-05 14:04:19,276 p=17240 u=mistral |  skipping: [lab-computehci-0] => {}
2019-06-05 14:04:19,277 p=17240 u=mistral |  META: noop
2019-06-05 14:04:19,291 p=17240 u=mistral |  TASK [hiera.yaml changes for check mode] ***************************************
2019-06-05 14:04:19,291 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:82
2019-06-05 14:04:19,291 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:19 -0500 (0:00:00.027)       0:00:53.061 ******** 
2019-06-05 14:04:19,302 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:19,304 p=17240 u=mistral |  META: noop
2019-06-05 14:04:19,317 p=17240 u=mistral |  TASK [diff hiera.yaml changes for check mode] **********************************
2019-06-05 14:04:19,317 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:90
2019-06-05 14:04:19,317 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:19 -0500 (0:00:00.026)       0:00:53.087 ******** 
2019-06-05 14:04:19,329 p=17240 u=mistral |  skipping: [lab-computehci-0] => {}
2019-06-05 14:04:19,329 p=17240 u=mistral |  META: noop
2019-06-05 14:04:19,345 p=17240 u=mistral |  TASK [Render deployment file for ComputeHCIDeployment] *************************
2019-06-05 14:04:19,345 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:102
2019-06-05 14:04:19,345 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:19 -0500 (0:00:00.027)       0:00:53.114 ******** 
2019-06-05 14:04:19,704 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "checksum": "badc5ce7823af83933382c0a668bcef326eee060", "dest": "/var/lib/heat-config/tripleo-config-download/ComputeHCIDeployment-5885321f-5d2e-49bc-b098-55206a34d855", "gid": 0, "group": "root", "md5sum": "103cba44ac26f72b783e74e9c9d0cc83", "mode": "0644", "owner": "root", "secontext": "system_u:object_r:var_lib_t:s0", "size": 23679, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559761459.43-169670050216425/source", "state": "file", "uid": 0}
2019-06-05 14:04:19,704 p=17240 u=mistral |  META: noop
2019-06-05 14:04:19,720 p=17240 u=mistral |  TASK [Check if deployed file exists for ComputeHCIDeployment] ******************
2019-06-05 14:04:19,720 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:108
2019-06-05 14:04:19,720 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:19 -0500 (0:00:00.375)       0:00:53.489 ******** 
2019-06-05 14:04:19,824 p=17240 u=mistral |  ok: [lab-computehci-0] => {"changed": false, "stat": {"exists": false}}
2019-06-05 14:04:19,825 p=17240 u=mistral |  META: noop
2019-06-05 14:04:19,840 p=17240 u=mistral |  TASK [Check previous deployment rc for ComputeHCIDeployment] *******************
2019-06-05 14:04:19,840 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:113
2019-06-05 14:04:19,840 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:19 -0500 (0:00:00.120)       0:00:53.610 ******** 
2019-06-05 14:04:19,851 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:19,852 p=17240 u=mistral |  META: noop
2019-06-05 14:04:19,867 p=17240 u=mistral |  TASK [Remove deployed file for ComputeHCIDeployment when previous deployment failed] ***
2019-06-05 14:04:19,867 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:121
2019-06-05 14:04:19,868 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:19 -0500 (0:00:00.027)       0:00:53.637 ******** 
2019-06-05 14:04:19,882 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:19,883 p=17240 u=mistral |  META: noop
2019-06-05 14:04:19,900 p=17240 u=mistral |  TASK [Force remove deployed file for ComputeHCIDeployment] *********************
2019-06-05 14:04:19,900 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:131
2019-06-05 14:04:19,900 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:19 -0500 (0:00:00.032)       0:00:53.669 ******** 
2019-06-05 14:04:19,911 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:19,912 p=17240 u=mistral |  META: noop
2019-06-05 14:04:19,926 p=17240 u=mistral |  TASK [Set fact for async_deployment] *******************************************
2019-06-05 14:04:19,926 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:138
2019-06-05 14:04:19,926 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:19 -0500 (0:00:00.026)       0:00:53.696 ******** 
2019-06-05 14:04:19,953 p=17240 u=mistral |  ok: [lab-computehci-0] => {"ansible_facts": {"use_async_deployment": false}, "changed": false}
2019-06-05 14:04:19,954 p=17240 u=mistral |  META: noop
2019-06-05 14:04:19,969 p=17240 u=mistral |  TASK [Run deployment ComputeHCIDeployment] *************************************
2019-06-05 14:04:19,969 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:142
2019-06-05 14:04:19,969 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:19 -0500 (0:00:00.042)       0:00:53.738 ******** 
2019-06-05 14:04:20,566 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "cmd": "/usr/libexec/os-refresh-config/configure.d/55-heat-config\n exit $(jq .deploy_status_code /var/lib/heat-config/deployed/5885321f-5d2e-49bc-b098-55206a34d855.notify.json)", "delta": "0:00:00.491326", "end": "2019-06-05 19:04:20.558483", "rc": 0, "start": "2019-06-05 19:04:20.067157", "stderr": "[2019-06-05 19:04:20,094] (heat-config) [DEBUG] Running /usr/libexec/heat-config/hooks/hiera < /var/lib/heat-config/deployed/5885321f-5d2e-49bc-b098-55206a34d855.json\n[2019-06-05 19:04:20,259] (heat-config) [INFO] |-\n  {\"deploy_stdout\": \"\", \"deploy_stderr\": \"\", \"deploy_status_code\": 0}\n\n[2019-06-05 19:04:20,259] (heat-config) [DEBUG] \n[2019-06-05 19:04:20,259] (heat-config) [INFO] Completed /usr/libexec/heat-config/hooks/hiera\n[2019-06-05 19:04:20,259] (heat-config) [DEBUG] Running heat-config-notify /var/lib/heat-config/deployed/5885321f-5d2e-49bc-b098-55206a34d855.json < /var/lib/heat-config/deployed/5885321f-5d2e-49bc-b098-55206a34d855.notify.json\n[2019-06-05 19:04:20,552] (heat-config) [INFO] \n[2019-06-05 19:04:20,552] (heat-config) [DEBUG] ", "stderr_lines": ["[2019-06-05 19:04:20,094] (heat-config) [DEBUG] Running /usr/libexec/heat-config/hooks/hiera < /var/lib/heat-config/deployed/5885321f-5d2e-49bc-b098-55206a34d855.json", "[2019-06-05 19:04:20,259] (heat-config) [INFO] |-", "  {\"deploy_stdout\": \"\", \"deploy_stderr\": \"\", \"deploy_status_code\": 0}", "", "[2019-06-05 19:04:20,259] (heat-config) [DEBUG] ", "[2019-06-05 19:04:20,259] (heat-config) [INFO] Completed /usr/libexec/heat-config/hooks/hiera", "[2019-06-05 19:04:20,259] (heat-config) [DEBUG] Running heat-config-notify /var/lib/heat-config/deployed/5885321f-5d2e-49bc-b098-55206a34d855.json < /var/lib/heat-config/deployed/5885321f-5d2e-49bc-b098-55206a34d855.notify.json", "[2019-06-05 19:04:20,552] (heat-config) [INFO] ", "[2019-06-05 19:04:20,552] (heat-config) [DEBUG] "], "stdout": "", "stdout_lines": []}
2019-06-05 14:04:20,567 p=17240 u=mistral |  META: noop
2019-06-05 14:04:20,582 p=17240 u=mistral |  TASK [Run async deployment ComputeHCIDeployment] *******************************
2019-06-05 14:04:20,582 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:153
2019-06-05 14:04:20,582 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:20 -0500 (0:00:00.613)       0:00:54.352 ******** 
2019-06-05 14:04:20,591 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:20,592 p=17240 u=mistral |  META: noop
2019-06-05 14:04:20,607 p=17240 u=mistral |  TASK [Output for sync deployment ComputeHCIDeployment] *************************
2019-06-05 14:04:20,607 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:166
2019-06-05 14:04:20,607 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:20 -0500 (0:00:00.024)       0:00:54.376 ******** 
2019-06-05 14:04:20,638 p=17240 u=mistral |  ok: [lab-computehci-0] => {
    "msg": [
        {
            "stderr": [
                "[2019-06-05 19:04:20,094] (heat-config) [DEBUG] Running /usr/libexec/heat-config/hooks/hiera < /var/lib/heat-config/deployed/5885321f-5d2e-49bc-b098-55206a34d855.json", 
                "[2019-06-05 19:04:20,259] (heat-config) [INFO] |-", 
                "  {\"deploy_stdout\": \"\", \"deploy_stderr\": \"\", \"deploy_status_code\": 0}", 
                "", 
                "[2019-06-05 19:04:20,259] (heat-config) [DEBUG] ", 
                "[2019-06-05 19:04:20,259] (heat-config) [INFO] Completed /usr/libexec/heat-config/hooks/hiera", 
                "[2019-06-05 19:04:20,259] (heat-config) [DEBUG] Running heat-config-notify /var/lib/heat-config/deployed/5885321f-5d2e-49bc-b098-55206a34d855.json < /var/lib/heat-config/deployed/5885321f-5d2e-49bc-b098-55206a34d855.notify.json", 
                "[2019-06-05 19:04:20,552] (heat-config) [INFO] ", 
                "[2019-06-05 19:04:20,552] (heat-config) [DEBUG] "
            ]
        }, 
        {
            "status_code": "0"
        }
    ]
}
2019-06-05 14:04:20,639 p=17240 u=mistral |  META: noop
2019-06-05 14:04:20,653 p=17240 u=mistral |  TASK [Output for async deployment ComputeHCIDeployment] ************************
2019-06-05 14:04:20,653 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:176
2019-06-05 14:04:20,654 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:20 -0500 (0:00:00.046)       0:00:54.423 ******** 
2019-06-05 14:04:20,665 p=17240 u=mistral |  skipping: [lab-computehci-0] => {}
2019-06-05 14:04:20,666 p=17240 u=mistral |  META: noop
2019-06-05 14:04:20,681 p=17240 u=mistral |  TASK [Check-mode for Run deployment ComputeHCIDeployment (changed status indicates deployment would run)] ***
2019-06-05 14:04:20,681 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:186
2019-06-05 14:04:20,681 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:20 -0500 (0:00:00.027)       0:00:54.450 ******** 
2019-06-05 14:04:20,690 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:20,691 p=17240 u=mistral |  META: noop
2019-06-05 14:04:20,705 p=17240 u=mistral |  TASK [Lookup deployment UUID] **************************************************
2019-06-05 14:04:20,705 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:1
2019-06-05 14:04:20,705 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:20 -0500 (0:00:00.023)       0:00:54.474 ******** 
2019-06-05 14:04:20,740 p=17240 u=mistral |  ok: [lab-computehci-0] => {"ansible_facts": {"deployment_uuid": "37223a91-98c1-40b5-ba31-1d79751e71c1"}, "changed": false}
2019-06-05 14:04:20,740 p=17240 u=mistral |  META: noop
2019-06-05 14:04:20,755 p=17240 u=mistral |  TASK [Lookup deployment group] *************************************************
2019-06-05 14:04:20,755 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:5
2019-06-05 14:04:20,755 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:20 -0500 (0:00:00.050)       0:00:54.524 ******** 
2019-06-05 14:04:20,790 p=17240 u=mistral |  ok: [lab-computehci-0] => {"ansible_facts": {"deployment_group": "script"}, "changed": false}
2019-06-05 14:04:20,790 p=17240 u=mistral |  META: noop
2019-06-05 14:04:20,804 p=17240 u=mistral |  TASK [Create hiera check-mode directory] ***************************************
2019-06-05 14:04:20,805 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:13
2019-06-05 14:04:20,805 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:20 -0500 (0:00:00.049)       0:00:54.574 ******** 
2019-06-05 14:04:20,818 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:20,819 p=17240 u=mistral |  META: noop
2019-06-05 14:04:20,833 p=17240 u=mistral |  TASK [Create deployed check-mode directory] ************************************
2019-06-05 14:04:20,833 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:19
2019-06-05 14:04:20,833 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:20 -0500 (0:00:00.028)       0:00:54.602 ******** 
2019-06-05 14:04:20,849 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:20,850 p=17240 u=mistral |  META: noop
2019-06-05 14:04:20,863 p=17240 u=mistral |  TASK [Create tripleo-config-download check-mode directory] *********************
2019-06-05 14:04:20,863 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:25
2019-06-05 14:04:20,863 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:20 -0500 (0:00:00.030)       0:00:54.632 ******** 
2019-06-05 14:04:20,874 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:20,875 p=17240 u=mistral |  META: noop
2019-06-05 14:04:20,890 p=17240 u=mistral |  TASK [Render deployment file for ComputeHCIHostsDeployment for check-mode] *****
2019-06-05 14:04:20,891 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:31
2019-06-05 14:04:20,891 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:20 -0500 (0:00:00.027)       0:00:54.660 ******** 
2019-06-05 14:04:20,902 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:20,902 p=17240 u=mistral |  META: noop
2019-06-05 14:04:20,916 p=17240 u=mistral |  TASK [Run hiera deployment for check mode] *************************************
2019-06-05 14:04:20,916 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:38
2019-06-05 14:04:20,917 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:20 -0500 (0:00:00.025)       0:00:54.686 ******** 
2019-06-05 14:04:20,928 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:20,929 p=17240 u=mistral |  META: noop
2019-06-05 14:04:20,943 p=17240 u=mistral |  TASK [List hieradata files for check mode] *************************************
2019-06-05 14:04:20,943 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:54
2019-06-05 14:04:20,943 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:20 -0500 (0:00:00.026)       0:00:54.712 ******** 
2019-06-05 14:04:20,954 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:20,955 p=17240 u=mistral |  META: noop
2019-06-05 14:04:20,969 p=17240 u=mistral |  TASK [diff hieradata changes for check mode] ***********************************
2019-06-05 14:04:20,969 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:60
2019-06-05 14:04:20,969 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:20 -0500 (0:00:00.026)       0:00:54.739 ******** 
2019-06-05 14:04:20,982 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:20,982 p=17240 u=mistral |  META: noop
2019-06-05 14:04:20,997 p=17240 u=mistral |  TASK [diff hieradata changes for check mode] ***********************************
2019-06-05 14:04:20,997 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:73
2019-06-05 14:04:20,997 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:20 -0500 (0:00:00.027)       0:00:54.766 ******** 
2019-06-05 14:04:21,009 p=17240 u=mistral |  skipping: [lab-computehci-0] => {}
2019-06-05 14:04:21,010 p=17240 u=mistral |  META: noop
2019-06-05 14:04:21,024 p=17240 u=mistral |  TASK [hiera.yaml changes for check mode] ***************************************
2019-06-05 14:04:21,024 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:82
2019-06-05 14:04:21,024 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:21 -0500 (0:00:00.027)       0:00:54.793 ******** 
2019-06-05 14:04:21,035 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:21,036 p=17240 u=mistral |  META: noop
2019-06-05 14:04:21,050 p=17240 u=mistral |  TASK [diff hiera.yaml changes for check mode] **********************************
2019-06-05 14:04:21,050 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:90
2019-06-05 14:04:21,050 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:21 -0500 (0:00:00.025)       0:00:54.819 ******** 
2019-06-05 14:04:21,062 p=17240 u=mistral |  skipping: [lab-computehci-0] => {}
2019-06-05 14:04:21,062 p=17240 u=mistral |  META: noop
2019-06-05 14:04:21,077 p=17240 u=mistral |  TASK [Render deployment file for ComputeHCIHostsDeployment] ********************
2019-06-05 14:04:21,077 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:102
2019-06-05 14:04:21,077 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:21 -0500 (0:00:00.026)       0:00:54.846 ******** 
2019-06-05 14:04:21,370 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "checksum": "57b0cd168bdcc39a0a60ffdf8d239bc1dc67e2e4", "dest": "/var/lib/heat-config/tripleo-config-download/ComputeHCIHostsDeployment-37223a91-98c1-40b5-ba31-1d79751e71c1", "gid": 0, "group": "root", "md5sum": "99c00c35ff790a1c84d690d9ab701397", "mode": "0644", "owner": "root", "secontext": "system_u:object_r:var_lib_t:s0", "size": 3845, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559761461.11-130033039064917/source", "state": "file", "uid": 0}
2019-06-05 14:04:21,371 p=17240 u=mistral |  META: noop
2019-06-05 14:04:21,386 p=17240 u=mistral |  TASK [Check if deployed file exists for ComputeHCIHostsDeployment] *************
2019-06-05 14:04:21,386 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:108
2019-06-05 14:04:21,386 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:21 -0500 (0:00:00.308)       0:00:55.155 ******** 
2019-06-05 14:04:21,531 p=17240 u=mistral |  ok: [lab-computehci-0] => {"changed": false, "stat": {"exists": false}}
2019-06-05 14:04:21,532 p=17240 u=mistral |  META: noop
2019-06-05 14:04:21,547 p=17240 u=mistral |  TASK [Check previous deployment rc for ComputeHCIHostsDeployment] **************
2019-06-05 14:04:21,547 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:113
2019-06-05 14:04:21,547 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:21 -0500 (0:00:00.161)       0:00:55.316 ******** 
2019-06-05 14:04:21,558 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:21,559 p=17240 u=mistral |  META: noop
2019-06-05 14:04:21,574 p=17240 u=mistral |  TASK [Remove deployed file for ComputeHCIHostsDeployment when previous deployment failed] ***
2019-06-05 14:04:21,574 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:121
2019-06-05 14:04:21,574 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:21 -0500 (0:00:00.026)       0:00:55.343 ******** 
2019-06-05 14:04:21,586 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:21,587 p=17240 u=mistral |  META: noop
2019-06-05 14:04:21,602 p=17240 u=mistral |  TASK [Force remove deployed file for ComputeHCIHostsDeployment] ****************
2019-06-05 14:04:21,602 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:131
2019-06-05 14:04:21,602 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:21 -0500 (0:00:00.027)       0:00:55.371 ******** 
2019-06-05 14:04:21,617 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:21,617 p=17240 u=mistral |  META: noop
2019-06-05 14:04:21,634 p=17240 u=mistral |  TASK [Set fact for async_deployment] *******************************************
2019-06-05 14:04:21,634 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:138
2019-06-05 14:04:21,634 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:21 -0500 (0:00:00.032)       0:00:55.403 ******** 
2019-06-05 14:04:21,661 p=17240 u=mistral |  ok: [lab-computehci-0] => {"ansible_facts": {"use_async_deployment": false}, "changed": false}
2019-06-05 14:04:21,661 p=17240 u=mistral |  META: noop
2019-06-05 14:04:21,677 p=17240 u=mistral |  TASK [Run deployment ComputeHCIHostsDeployment] ********************************
2019-06-05 14:04:21,677 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:142
2019-06-05 14:04:21,677 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:21 -0500 (0:00:00.043)       0:00:55.446 ******** 
2019-06-05 14:04:22,203 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "cmd": "/usr/libexec/os-refresh-config/configure.d/55-heat-config\n exit $(jq .deploy_status_code /var/lib/heat-config/deployed/37223a91-98c1-40b5-ba31-1d79751e71c1.notify.json)", "delta": "0:00:00.368802", "end": "2019-06-05 19:04:22.142700", "rc": 0, "start": "2019-06-05 19:04:21.773898", "stderr": "[2019-06-05 19:04:21,800] (heat-config) [DEBUG] Running /usr/libexec/heat-config/hooks/script < /var/lib/heat-config/deployed/37223a91-98c1-40b5-ba31-1d79751e71c1.json\n[2019-06-05 19:04:21,845] (heat-config) [INFO] |-\n  {\"deploy_stdout\": \"\", \"deploy_stderr\": \"+ set -o pipefail\\n+ hosts='192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ '[' '!' -z '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n' ']'\\n+ for tmpl in '/etc/cloud/templates/hosts.*.tmpl'\\n+ write_entries /etc/cloud/templates/hosts.debian.tmpl '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ local file=/etc/cloud/templates/hosts.debian.tmpl\\n+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ '[' '!' -f /etc/cloud/templates/hosts.debian.tmpl ']'\\n+ grep -q '^# HEAT_HOSTS_START' /etc/cloud/templates/hosts.debian.tmpl\\n++ hostname -s\\n+ sed -i /lab-computehci-0/d /etc/cloud/templates/hosts.debian.tmpl\\n+ echo -ne '\\\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\\\n'\\n+ echo '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ echo -ne '# HEAT_HOSTS_END\\\\n\\\\n'\\n+ for tmpl in '/etc/cloud/templates/hosts.*.tmpl'\\n+ write_entries /etc/cloud/templates/hosts.freebsd.tmpl '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ local file=/etc/cloud/templates/hosts.freebsd.tmpl\\n+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ '[' '!' -f /etc/cloud/templates/hosts.freebsd.tmpl ']'\\n+ grep -q '^# HEAT_HOSTS_START' /etc/cloud/templates/hosts.freebsd.tmpl\\n++ hostname -s\\n+ sed -i /lab-computehci-0/d /etc/cloud/templates/hosts.freebsd.tmpl\\n+ echo -ne '\\\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\\\n'\\n+ echo '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ echo -ne '# HEAT_HOSTS_END\\\\n\\\\n'\\n+ for tmpl in '/etc/cloud/templates/hosts.*.tmpl'\\n+ write_entries /etc/cloud/templates/hosts.redhat.tmpl '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ local file=/etc/cloud/templates/hosts.redhat.tmpl\\n+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ '[' '!' -f /etc/cloud/templates/hosts.redhat.tmpl ']'\\n+ grep -q '^# HEAT_HOSTS_START' /etc/cloud/templates/hosts.redhat.tmpl\\n++ hostname -s\\n+ sed -i /lab-computehci-0/d /etc/cloud/templates/hosts.redhat.tmpl\\n+ echo -ne '\\\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\\\n'\\n+ echo '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ echo -ne '# HEAT_HOSTS_END\\\\n\\\\n'\\n+ for tmpl in '/etc/cloud/templates/hosts.*.tmpl'\\n+ write_entries /etc/cloud/templates/hosts.suse.tmpl '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ local file=/etc/cloud/templates/hosts.suse.tmpl\\n+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ '[' '!' -f /etc/cloud/templates/hosts.suse.tmpl ']'\\n+ grep -q '^# HEAT_HOSTS_START' /etc/cloud/templates/hosts.suse.tmpl\\n++ hostname -s\\n+ sed -i /lab-computehci-0/d /etc/cloud/templates/hosts.suse.tmpl\\n+ echo -ne '\\\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\\\n'\\n+ echo '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ echo -ne '# HEAT_HOSTS_END\\\\n\\\\n'\\n+ write_entries /etc/hosts '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ local file=/etc/hosts\\n+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ '[' '!' -f /etc/hosts ']'\\n+ grep -q '^# HEAT_HOSTS_START' /etc/hosts\\n++ hostname -s\\n+ sed -i /lab-computehci-0/d /etc/hosts\\n+ echo -ne '\\\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\\\n'\\n+ echo '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ echo -ne '# HEAT_HOSTS_END\\\\n\\\\n'\\n\", \"deploy_status_code\": 0}\n\n[2019-06-05 19:04:21,845] (heat-config) [DEBUG] [2019-06-05 19:04:21,812] (heat-config) [INFO] deploy_server_id=97f857d8-5e72-44c1-aebf-24385a2d79de\n[2019-06-05 19:04:21,812] (heat-config) [INFO] deploy_action=CREATE\n[2019-06-05 19:04:21,812] (heat-config) [INFO] deploy_stack_id=lab-ComputeHCIHostsDeployment-ueyrowzfb4hm-0-mtgcs45dmjpm/46750f97-3e63-455f-a051-95784ad14b94\n[2019-06-05 19:04:21,812] (heat-config) [INFO] deploy_resource_name=TripleOSoftwareDeployment\n[2019-06-05 19:04:21,812] (heat-config) [INFO] deploy_signal_transport=NO_SIGNAL\n[2019-06-05 19:04:21,812] (heat-config) [DEBUG] Running /var/lib/heat-config/heat-config-script/37223a91-98c1-40b5-ba31-1d79751e71c1\n[2019-06-05 19:04:21,829] (heat-config) [INFO] \n[2019-06-05 19:04:21,829] (heat-config) [DEBUG] + set -o pipefail\n+ hosts='192.168.24.19  overcloud.ctlplane.localdomain\n172.16.1.114  overcloud.storage.localdomain\n172.16.3.106  overcloud.storagemgmt.localdomain\n172.16.2.110  overcloud.internalapi.localdomain\n10.0.0.248  overcloud.localdomain\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\n\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\n'\n+ '[' '!' -z '192.168.24.19  overcloud.ctlplane.localdomain\n172.16.1.114  overcloud.storage.localdomain\n172.16.3.106  overcloud.storagemgmt.localdomain\n172.16.2.110  overcloud.internalapi.localdomain\n10.0.0.248  overcloud.localdomain\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\n\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\n' ']'\n+ for tmpl in '/etc/cloud/templates/hosts.*.tmpl'\n+ write_entries /etc/cloud/templates/hosts.debian.tmpl '192.168.24.19  overcloud.ctlplane.localdomain\n172.16.1.114  overcloud.storage.localdomain\n172.16.3.106  overcloud.storagemgmt.localdomain\n172.16.2.110  overcloud.internalapi.localdomain\n10.0.0.248  overcloud.localdomain\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\n\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\n'\n+ local file=/etc/cloud/templates/hosts.debian.tmpl\n+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain\n172.16.1.114  overcloud.storage.localdomain\n172.16.3.106  overcloud.storagemgmt.localdomain\n172.16.2.110  overcloud.internalapi.localdomain\n10.0.0.248  overcloud.localdomain\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\n\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\n'\n+ '[' '!' -f /etc/cloud/templates/hosts.debian.tmpl ']'\n+ grep -q '^# HEAT_HOSTS_START' /etc/cloud/templates/hosts.debian.tmpl\n++ hostname -s\n+ sed -i /lab-computehci-0/d /etc/cloud/templates/hosts.debian.tmpl\n+ echo -ne '\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\n'\n+ echo '192.168.24.19  overcloud.ctlplane.localdomain\n172.16.1.114  overcloud.storage.localdomain\n172.16.3.106  overcloud.storagemgmt.localdomain\n172.16.2.110  overcloud.internalapi.localdomain\n10.0.0.248  overcloud.localdomain\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\n\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\n'\n+ echo -ne '# HEAT_HOSTS_END\\n\\n'\n+ for tmpl in '/etc/cloud/templates/hosts.*.tmpl'\n+ write_entries /etc/cloud/templates/hosts.freebsd.tmpl '192.168.24.19  overcloud.ctlplane.localdomain\n172.16.1.114  overcloud.storage.localdomain\n172.16.3.106  overcloud.storagemgmt.localdomain\n172.16.2.110  overcloud.internalapi.localdomain\n10.0.0.248  overcloud.localdomain\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\n\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\n'\n+ local file=/etc/cloud/templates/hosts.freebsd.tmpl\n+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain\n172.16.1.114  overcloud.storage.localdomain\n172.16.3.106  overcloud.storagemgmt.localdomain\n172.16.2.110  overcloud.internalapi.localdomain\n10.0.0.248  overcloud.localdomain\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\n\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\n'\n+ '[' '!' -f /etc/cloud/templates/hosts.freebsd.tmpl ']'\n+ grep -q '^# HEAT_HOSTS_START' /etc/cloud/templates/hosts.freebsd.tmpl\n++ hostname -s\n+ sed -i /lab-computehci-0/d /etc/cloud/templates/hosts.freebsd.tmpl\n+ echo -ne '\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\n'\n+ echo '192.168.24.19  overcloud.ctlplane.localdomain\n172.16.1.114  overcloud.storage.localdomain\n172.16.3.106  overcloud.storagemgmt.localdomain\n172.16.2.110  overcloud.internalapi.localdomain\n10.0.0.248  overcloud.localdomain\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\n\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\n'\n+ echo -ne '# HEAT_HOSTS_END\\n\\n'\n+ for tmpl in '/etc/cloud/templates/hosts.*.tmpl'\n+ write_entries /etc/cloud/templates/hosts.redhat.tmpl '192.168.24.19  overcloud.ctlplane.localdomain\n172.16.1.114  overcloud.storage.localdomain\n172.16.3.106  overcloud.storagemgmt.localdomain\n172.16.2.110  overcloud.internalapi.localdomain\n10.0.0.248  overcloud.localdomain\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\n\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\n'\n+ local file=/etc/cloud/templates/hosts.redhat.tmpl\n+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain\n172.16.1.114  overcloud.storage.localdomain\n172.16.3.106  overcloud.storagemgmt.localdomain\n172.16.2.110  overcloud.internalapi.localdomain\n10.0.0.248  overcloud.localdomain\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\n\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\n'\n+ '[' '!' -f /etc/cloud/templates/hosts.redhat.tmpl ']'\n+ grep -q '^# HEAT_HOSTS_START' /etc/cloud/templates/hosts.redhat.tmpl\n++ hostname -s\n+ sed -i /lab-computehci-0/d /etc/cloud/templates/hosts.redhat.tmpl\n+ echo -ne '\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\n'\n+ echo '192.168.24.19  overcloud.ctlplane.localdomain\n172.16.1.114  overcloud.storage.localdomain\n172.16.3.106  overcloud.storagemgmt.localdomain\n172.16.2.110  overcloud.internalapi.localdomain\n10.0.0.248  overcloud.localdomain\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\n\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\n'\n+ echo -ne '# HEAT_HOSTS_END\\n\\n'\n+ for tmpl in '/etc/cloud/templates/hosts.*.tmpl'\n+ write_entries /etc/cloud/templates/hosts.suse.tmpl '192.168.24.19  overcloud.ctlplane.localdomain\n172.16.1.114  overcloud.storage.localdomain\n172.16.3.106  overcloud.storagemgmt.localdomain\n172.16.2.110  overcloud.internalapi.localdomain\n10.0.0.248  overcloud.localdomain\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\n\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\n'\n+ local file=/etc/cloud/templates/hosts.suse.tmpl\n+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain\n172.16.1.114  overcloud.storage.localdomain\n172.16.3.106  overcloud.storagemgmt.localdomain\n172.16.2.110  overcloud.internalapi.localdomain\n10.0.0.248  overcloud.localdomain\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\n\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\n'\n+ '[' '!' -f /etc/cloud/templates/hosts.suse.tmpl ']'\n+ grep -q '^# HEAT_HOSTS_START' /etc/cloud/templates/hosts.suse.tmpl\n++ hostname -s\n+ sed -i /lab-computehci-0/d /etc/cloud/templates/hosts.suse.tmpl\n+ echo -ne '\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\n'\n+ echo '192.168.24.19  overcloud.ctlplane.localdomain\n172.16.1.114  overcloud.storage.localdomain\n172.16.3.106  overcloud.storagemgmt.localdomain\n172.16.2.110  overcloud.internalapi.localdomain\n10.0.0.248  overcloud.localdomain\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\n\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\n'\n+ echo -ne '# HEAT_HOSTS_END\\n\\n'\n+ write_entries /etc/hosts '192.168.24.19  overcloud.ctlplane.localdomain\n172.16.1.114  overcloud.storage.localdomain\n172.16.3.106  overcloud.storagemgmt.localdomain\n172.16.2.110  overcloud.internalapi.localdomain\n10.0.0.248  overcloud.localdomain\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\n\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\n'\n+ local file=/etc/hosts\n+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain\n172.16.1.114  overcloud.storage.localdomain\n172.16.3.106  overcloud.storagemgmt.localdomain\n172.16.2.110  overcloud.internalapi.localdomain\n10.0.0.248  overcloud.localdomain\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\n\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\n'\n+ '[' '!' -f /etc/hosts ']'\n+ grep -q '^# HEAT_HOSTS_START' /etc/hosts\n++ hostname -s\n+ sed -i /lab-computehci-0/d /etc/hosts\n+ echo -ne '\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\n'\n+ echo '192.168.24.19  overcloud.ctlplane.localdomain\n172.16.1.114  overcloud.storage.localdomain\n172.16.3.106  overcloud.storagemgmt.localdomain\n172.16.2.110  overcloud.internalapi.localdomain\n10.0.0.248  overcloud.localdomain\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\n\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\n'\n+ echo -ne '# HEAT_HOSTS_END\\n\\n'\n\n[2019-06-05 19:04:21,829] (heat-config) [INFO] Completed /var/lib/heat-config/heat-config-script/37223a91-98c1-40b5-ba31-1d79751e71c1\n\n[2019-06-05 19:04:21,845] (heat-config) [INFO] Completed /usr/libexec/heat-config/hooks/script\n[2019-06-05 19:04:21,846] (heat-config) [DEBUG] Running heat-config-notify /var/lib/heat-config/deployed/37223a91-98c1-40b5-ba31-1d79751e71c1.json < /var/lib/heat-config/deployed/37223a91-98c1-40b5-ba31-1d79751e71c1.notify.json\n[2019-06-05 19:04:22,136] (heat-config) [INFO] \n[2019-06-05 19:04:22,136] (heat-config) [DEBUG] ", "stderr_lines": ["[2019-06-05 19:04:21,800] (heat-config) [DEBUG] Running /usr/libexec/heat-config/hooks/script < /var/lib/heat-config/deployed/37223a91-98c1-40b5-ba31-1d79751e71c1.json", "[2019-06-05 19:04:21,845] (heat-config) [INFO] |-", "  {\"deploy_stdout\": \"\", \"deploy_stderr\": \"+ set -o pipefail\\n+ hosts='192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ '[' '!' -z '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n' ']'\\n+ for tmpl in '/etc/cloud/templates/hosts.*.tmpl'\\n+ write_entries /etc/cloud/templates/hosts.debian.tmpl '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ local file=/etc/cloud/templates/hosts.debian.tmpl\\n+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ '[' '!' -f /etc/cloud/templates/hosts.debian.tmpl ']'\\n+ grep -q '^# HEAT_HOSTS_START' /etc/cloud/templates/hosts.debian.tmpl\\n++ hostname -s\\n+ sed -i /lab-computehci-0/d /etc/cloud/templates/hosts.debian.tmpl\\n+ echo -ne '\\\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\\\n'\\n+ echo '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ echo -ne '# HEAT_HOSTS_END\\\\n\\\\n'\\n+ for tmpl in '/etc/cloud/templates/hosts.*.tmpl'\\n+ write_entries /etc/cloud/templates/hosts.freebsd.tmpl '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ local file=/etc/cloud/templates/hosts.freebsd.tmpl\\n+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ '[' '!' -f /etc/cloud/templates/hosts.freebsd.tmpl ']'\\n+ grep -q '^# HEAT_HOSTS_START' /etc/cloud/templates/hosts.freebsd.tmpl\\n++ hostname -s\\n+ sed -i /lab-computehci-0/d /etc/cloud/templates/hosts.freebsd.tmpl\\n+ echo -ne '\\\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\\\n'\\n+ echo '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ echo -ne '# HEAT_HOSTS_END\\\\n\\\\n'\\n+ for tmpl in '/etc/cloud/templates/hosts.*.tmpl'\\n+ write_entries /etc/cloud/templates/hosts.redhat.tmpl '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ local file=/etc/cloud/templates/hosts.redhat.tmpl\\n+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ '[' '!' -f /etc/cloud/templates/hosts.redhat.tmpl ']'\\n+ grep -q '^# HEAT_HOSTS_START' /etc/cloud/templates/hosts.redhat.tmpl\\n++ hostname -s\\n+ sed -i /lab-computehci-0/d /etc/cloud/templates/hosts.redhat.tmpl\\n+ echo -ne '\\\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\\\n'\\n+ echo '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ echo -ne '# HEAT_HOSTS_END\\\\n\\\\n'\\n+ for tmpl in '/etc/cloud/templates/hosts.*.tmpl'\\n+ write_entries /etc/cloud/templates/hosts.suse.tmpl '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ local file=/etc/cloud/templates/hosts.suse.tmpl\\n+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ '[' '!' -f /etc/cloud/templates/hosts.suse.tmpl ']'\\n+ grep -q '^# HEAT_HOSTS_START' /etc/cloud/templates/hosts.suse.tmpl\\n++ hostname -s\\n+ sed -i /lab-computehci-0/d /etc/cloud/templates/hosts.suse.tmpl\\n+ echo -ne '\\\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\\\n'\\n+ echo '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ echo -ne '# HEAT_HOSTS_END\\\\n\\\\n'\\n+ write_entries /etc/hosts '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ local file=/etc/hosts\\n+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ '[' '!' -f /etc/hosts ']'\\n+ grep -q '^# HEAT_HOSTS_START' /etc/hosts\\n++ hostname -s\\n+ sed -i /lab-computehci-0/d /etc/hosts\\n+ echo -ne '\\\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\\\n'\\n+ echo '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ echo -ne '# HEAT_HOSTS_END\\\\n\\\\n'\\n\", \"deploy_status_code\": 0}", "", "[2019-06-05 19:04:21,845] (heat-config) [DEBUG] [2019-06-05 19:04:21,812] (heat-config) [INFO] deploy_server_id=97f857d8-5e72-44c1-aebf-24385a2d79de", "[2019-06-05 19:04:21,812] (heat-config) [INFO] deploy_action=CREATE", "[2019-06-05 19:04:21,812] (heat-config) [INFO] deploy_stack_id=lab-ComputeHCIHostsDeployment-ueyrowzfb4hm-0-mtgcs45dmjpm/46750f97-3e63-455f-a051-95784ad14b94", "[2019-06-05 19:04:21,812] (heat-config) [INFO] deploy_resource_name=TripleOSoftwareDeployment", "[2019-06-05 19:04:21,812] (heat-config) [INFO] deploy_signal_transport=NO_SIGNAL", "[2019-06-05 19:04:21,812] (heat-config) [DEBUG] Running /var/lib/heat-config/heat-config-script/37223a91-98c1-40b5-ba31-1d79751e71c1", "[2019-06-05 19:04:21,829] (heat-config) [INFO] ", "[2019-06-05 19:04:21,829] (heat-config) [DEBUG] + set -o pipefail", "+ hosts='192.168.24.19  overcloud.ctlplane.localdomain", "172.16.1.114  overcloud.storage.localdomain", "172.16.3.106  overcloud.storagemgmt.localdomain", "172.16.2.110  overcloud.internalapi.localdomain", "10.0.0.248  overcloud.localdomain", "172.16.2.35 lab-controller-0.localdomain lab-controller-0", "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", "", "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", "'", "+ '[' '!' -z '192.168.24.19  overcloud.ctlplane.localdomain", "172.16.1.114  overcloud.storage.localdomain", "172.16.3.106  overcloud.storagemgmt.localdomain", "172.16.2.110  overcloud.internalapi.localdomain", "10.0.0.248  overcloud.localdomain", "172.16.2.35 lab-controller-0.localdomain lab-controller-0", "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", "", "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", "' ']'", "+ for tmpl in '/etc/cloud/templates/hosts.*.tmpl'", "+ write_entries /etc/cloud/templates/hosts.debian.tmpl '192.168.24.19  overcloud.ctlplane.localdomain", "172.16.1.114  overcloud.storage.localdomain", "172.16.3.106  overcloud.storagemgmt.localdomain", "172.16.2.110  overcloud.internalapi.localdomain", "10.0.0.248  overcloud.localdomain", "172.16.2.35 lab-controller-0.localdomain lab-controller-0", "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", "", "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", "'", "+ local file=/etc/cloud/templates/hosts.debian.tmpl", "+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain", "172.16.1.114  overcloud.storage.localdomain", "172.16.3.106  overcloud.storagemgmt.localdomain", "172.16.2.110  overcloud.internalapi.localdomain", "10.0.0.248  overcloud.localdomain", "172.16.2.35 lab-controller-0.localdomain lab-controller-0", "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", "", "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", "'", "+ '[' '!' -f /etc/cloud/templates/hosts.debian.tmpl ']'", "+ grep -q '^# HEAT_HOSTS_START' /etc/cloud/templates/hosts.debian.tmpl", "++ hostname -s", "+ sed -i /lab-computehci-0/d /etc/cloud/templates/hosts.debian.tmpl", "+ echo -ne '\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\n'", "+ echo '192.168.24.19  overcloud.ctlplane.localdomain", "172.16.1.114  overcloud.storage.localdomain", "172.16.3.106  overcloud.storagemgmt.localdomain", "172.16.2.110  overcloud.internalapi.localdomain", "10.0.0.248  overcloud.localdomain", "172.16.2.35 lab-controller-0.localdomain lab-controller-0", "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", "", "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", "'", "+ echo -ne '# HEAT_HOSTS_END\\n\\n'", "+ for tmpl in '/etc/cloud/templates/hosts.*.tmpl'", "+ write_entries /etc/cloud/templates/hosts.freebsd.tmpl '192.168.24.19  overcloud.ctlplane.localdomain", "172.16.1.114  overcloud.storage.localdomain", "172.16.3.106  overcloud.storagemgmt.localdomain", "172.16.2.110  overcloud.internalapi.localdomain", "10.0.0.248  overcloud.localdomain", "172.16.2.35 lab-controller-0.localdomain lab-controller-0", "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", "", "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", "'", "+ local file=/etc/cloud/templates/hosts.freebsd.tmpl", "+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain", "172.16.1.114  overcloud.storage.localdomain", "172.16.3.106  overcloud.storagemgmt.localdomain", "172.16.2.110  overcloud.internalapi.localdomain", "10.0.0.248  overcloud.localdomain", "172.16.2.35 lab-controller-0.localdomain lab-controller-0", "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", "", "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", "'", "+ '[' '!' -f /etc/cloud/templates/hosts.freebsd.tmpl ']'", "+ grep -q '^# HEAT_HOSTS_START' /etc/cloud/templates/hosts.freebsd.tmpl", "++ hostname -s", "+ sed -i /lab-computehci-0/d /etc/cloud/templates/hosts.freebsd.tmpl", "+ echo -ne '\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\n'", "+ echo '192.168.24.19  overcloud.ctlplane.localdomain", "172.16.1.114  overcloud.storage.localdomain", "172.16.3.106  overcloud.storagemgmt.localdomain", "172.16.2.110  overcloud.internalapi.localdomain", "10.0.0.248  overcloud.localdomain", "172.16.2.35 lab-controller-0.localdomain lab-controller-0", "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", "", "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", "'", "+ echo -ne '# HEAT_HOSTS_END\\n\\n'", "+ for tmpl in '/etc/cloud/templates/hosts.*.tmpl'", "+ write_entries /etc/cloud/templates/hosts.redhat.tmpl '192.168.24.19  overcloud.ctlplane.localdomain", "172.16.1.114  overcloud.storage.localdomain", "172.16.3.106  overcloud.storagemgmt.localdomain", "172.16.2.110  overcloud.internalapi.localdomain", "10.0.0.248  overcloud.localdomain", "172.16.2.35 lab-controller-0.localdomain lab-controller-0", "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", "", "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", "'", "+ local file=/etc/cloud/templates/hosts.redhat.tmpl", "+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain", "172.16.1.114  overcloud.storage.localdomain", "172.16.3.106  overcloud.storagemgmt.localdomain", "172.16.2.110  overcloud.internalapi.localdomain", "10.0.0.248  overcloud.localdomain", "172.16.2.35 lab-controller-0.localdomain lab-controller-0", "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", "", "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", "'", "+ '[' '!' -f /etc/cloud/templates/hosts.redhat.tmpl ']'", "+ grep -q '^# HEAT_HOSTS_START' /etc/cloud/templates/hosts.redhat.tmpl", "++ hostname -s", "+ sed -i /lab-computehci-0/d /etc/cloud/templates/hosts.redhat.tmpl", "+ echo -ne '\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\n'", "+ echo '192.168.24.19  overcloud.ctlplane.localdomain", "172.16.1.114  overcloud.storage.localdomain", "172.16.3.106  overcloud.storagemgmt.localdomain", "172.16.2.110  overcloud.internalapi.localdomain", "10.0.0.248  overcloud.localdomain", "172.16.2.35 lab-controller-0.localdomain lab-controller-0", "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", "", "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", "'", "+ echo -ne '# HEAT_HOSTS_END\\n\\n'", "+ for tmpl in '/etc/cloud/templates/hosts.*.tmpl'", "+ write_entries /etc/cloud/templates/hosts.suse.tmpl '192.168.24.19  overcloud.ctlplane.localdomain", "172.16.1.114  overcloud.storage.localdomain", "172.16.3.106  overcloud.storagemgmt.localdomain", "172.16.2.110  overcloud.internalapi.localdomain", "10.0.0.248  overcloud.localdomain", "172.16.2.35 lab-controller-0.localdomain lab-controller-0", "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", "", "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", "'", "+ local file=/etc/cloud/templates/hosts.suse.tmpl", "+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain", "172.16.1.114  overcloud.storage.localdomain", "172.16.3.106  overcloud.storagemgmt.localdomain", "172.16.2.110  overcloud.internalapi.localdomain", "10.0.0.248  overcloud.localdomain", "172.16.2.35 lab-controller-0.localdomain lab-controller-0", "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", "", "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", "'", "+ '[' '!' -f /etc/cloud/templates/hosts.suse.tmpl ']'", "+ grep -q '^# HEAT_HOSTS_START' /etc/cloud/templates/hosts.suse.tmpl", "++ hostname -s", "+ sed -i /lab-computehci-0/d /etc/cloud/templates/hosts.suse.tmpl", "+ echo -ne '\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\n'", "+ echo '192.168.24.19  overcloud.ctlplane.localdomain", "172.16.1.114  overcloud.storage.localdomain", "172.16.3.106  overcloud.storagemgmt.localdomain", "172.16.2.110  overcloud.internalapi.localdomain", "10.0.0.248  overcloud.localdomain", "172.16.2.35 lab-controller-0.localdomain lab-controller-0", "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", "", "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", "'", "+ echo -ne '# HEAT_HOSTS_END\\n\\n'", "+ write_entries /etc/hosts '192.168.24.19  overcloud.ctlplane.localdomain", "172.16.1.114  overcloud.storage.localdomain", "172.16.3.106  overcloud.storagemgmt.localdomain", "172.16.2.110  overcloud.internalapi.localdomain", "10.0.0.248  overcloud.localdomain", "172.16.2.35 lab-controller-0.localdomain lab-controller-0", "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", "", "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", "'", "+ local file=/etc/hosts", "+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain", "172.16.1.114  overcloud.storage.localdomain", "172.16.3.106  overcloud.storagemgmt.localdomain", "172.16.2.110  overcloud.internalapi.localdomain", "10.0.0.248  overcloud.localdomain", "172.16.2.35 lab-controller-0.localdomain lab-controller-0", "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", "", "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", "'", "+ '[' '!' -f /etc/hosts ']'", "+ grep -q '^# HEAT_HOSTS_START' /etc/hosts", "++ hostname -s", "+ sed -i /lab-computehci-0/d /etc/hosts", "+ echo -ne '\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\n'", "+ echo '192.168.24.19  overcloud.ctlplane.localdomain", "172.16.1.114  overcloud.storage.localdomain", "172.16.3.106  overcloud.storagemgmt.localdomain", "172.16.2.110  overcloud.internalapi.localdomain", "10.0.0.248  overcloud.localdomain", "172.16.2.35 lab-controller-0.localdomain lab-controller-0", "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", "", "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", "'", "+ echo -ne '# HEAT_HOSTS_END\\n\\n'", "", "[2019-06-05 19:04:21,829] (heat-config) [INFO] Completed /var/lib/heat-config/heat-config-script/37223a91-98c1-40b5-ba31-1d79751e71c1", "", "[2019-06-05 19:04:21,845] (heat-config) [INFO] Completed /usr/libexec/heat-config/hooks/script", "[2019-06-05 19:04:21,846] (heat-config) [DEBUG] Running heat-config-notify /var/lib/heat-config/deployed/37223a91-98c1-40b5-ba31-1d79751e71c1.json < /var/lib/heat-config/deployed/37223a91-98c1-40b5-ba31-1d79751e71c1.notify.json", "[2019-06-05 19:04:22,136] (heat-config) [INFO] ", "[2019-06-05 19:04:22,136] (heat-config) [DEBUG] "], "stdout": "", "stdout_lines": []}
2019-06-05 14:04:22,204 p=17240 u=mistral |  META: noop
2019-06-05 14:04:22,219 p=17240 u=mistral |  TASK [Run async deployment ComputeHCIHostsDeployment] **************************
2019-06-05 14:04:22,219 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:153
2019-06-05 14:04:22,219 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:22 -0500 (0:00:00.542)       0:00:55.988 ******** 
2019-06-05 14:04:22,230 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:22,231 p=17240 u=mistral |  META: noop
2019-06-05 14:04:22,247 p=17240 u=mistral |  TASK [Output for sync deployment ComputeHCIHostsDeployment] ********************
2019-06-05 14:04:22,247 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:166
2019-06-05 14:04:22,247 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:22 -0500 (0:00:00.027)       0:00:56.016 ******** 
2019-06-05 14:04:22,328 p=17240 u=mistral |  ok: [lab-computehci-0] => {
    "msg": [
        {
            "stderr": [
                "[2019-06-05 19:04:21,800] (heat-config) [DEBUG] Running /usr/libexec/heat-config/hooks/script < /var/lib/heat-config/deployed/37223a91-98c1-40b5-ba31-1d79751e71c1.json", 
                "[2019-06-05 19:04:21,845] (heat-config) [INFO] |-", 
                "  {\"deploy_stdout\": \"\", \"deploy_stderr\": \"+ set -o pipefail\\n+ hosts='192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ '[' '!' -z '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n' ']'\\n+ for tmpl in '/etc/cloud/templates/hosts.*.tmpl'\\n+ write_entries /etc/cloud/templates/hosts.debian.tmpl '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ local file=/etc/cloud/templates/hosts.debian.tmpl\\n+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ '[' '!' -f /etc/cloud/templates/hosts.debian.tmpl ']'\\n+ grep -q '^# HEAT_HOSTS_START' /etc/cloud/templates/hosts.debian.tmpl\\n++ hostname -s\\n+ sed -i /lab-computehci-0/d /etc/cloud/templates/hosts.debian.tmpl\\n+ echo -ne '\\\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\\\n'\\n+ echo '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ echo -ne '# HEAT_HOSTS_END\\\\n\\\\n'\\n+ for tmpl in '/etc/cloud/templates/hosts.*.tmpl'\\n+ write_entries /etc/cloud/templates/hosts.freebsd.tmpl '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ local file=/etc/cloud/templates/hosts.freebsd.tmpl\\n+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ '[' '!' -f /etc/cloud/templates/hosts.freebsd.tmpl ']'\\n+ grep -q '^# HEAT_HOSTS_START' /etc/cloud/templates/hosts.freebsd.tmpl\\n++ hostname -s\\n+ sed -i /lab-computehci-0/d /etc/cloud/templates/hosts.freebsd.tmpl\\n+ echo -ne '\\\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\\\n'\\n+ echo '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ echo -ne '# HEAT_HOSTS_END\\\\n\\\\n'\\n+ for tmpl in '/etc/cloud/templates/hosts.*.tmpl'\\n+ write_entries /etc/cloud/templates/hosts.redhat.tmpl '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ local file=/etc/cloud/templates/hosts.redhat.tmpl\\n+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ '[' '!' -f /etc/cloud/templates/hosts.redhat.tmpl ']'\\n+ grep -q '^# HEAT_HOSTS_START' /etc/cloud/templates/hosts.redhat.tmpl\\n++ hostname -s\\n+ sed -i /lab-computehci-0/d /etc/cloud/templates/hosts.redhat.tmpl\\n+ echo -ne '\\\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\\\n'\\n+ echo '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ echo -ne '# HEAT_HOSTS_END\\\\n\\\\n'\\n+ for tmpl in '/etc/cloud/templates/hosts.*.tmpl'\\n+ write_entries /etc/cloud/templates/hosts.suse.tmpl '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ local file=/etc/cloud/templates/hosts.suse.tmpl\\n+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ '[' '!' -f /etc/cloud/templates/hosts.suse.tmpl ']'\\n+ grep -q '^# HEAT_HOSTS_START' /etc/cloud/templates/hosts.suse.tmpl\\n++ hostname -s\\n+ sed -i /lab-computehci-0/d /etc/cloud/templates/hosts.suse.tmpl\\n+ echo -ne '\\\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\\\n'\\n+ echo '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ echo -ne '# HEAT_HOSTS_END\\\\n\\\\n'\\n+ write_entries /etc/hosts '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ local file=/etc/hosts\\n+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ '[' '!' -f /etc/hosts ']'\\n+ grep -q '^# HEAT_HOSTS_START' /etc/hosts\\n++ hostname -s\\n+ sed -i /lab-computehci-0/d /etc/hosts\\n+ echo -ne '\\\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\\\n'\\n+ echo '192.168.24.19  overcloud.ctlplane.localdomain\\n172.16.1.114  overcloud.storage.localdomain\\n172.16.3.106  overcloud.storagemgmt.localdomain\\n172.16.2.110  overcloud.internalapi.localdomain\\n10.0.0.248  overcloud.localdomain\\n172.16.2.35 lab-controller-0.localdomain lab-controller-0\\n172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage\\n172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt\\n172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi\\n172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant\\n10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external\\n192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane\\n\\n172.16.2.227 lab-computehci-0.localdomain lab-computehci-0\\n172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage\\n172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt\\n172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi\\n172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant\\n192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane\\n'\\n+ echo -ne '# HEAT_HOSTS_END\\\\n\\\\n'\\n\", \"deploy_status_code\": 0}", 
                "", 
                "[2019-06-05 19:04:21,845] (heat-config) [DEBUG] [2019-06-05 19:04:21,812] (heat-config) [INFO] deploy_server_id=97f857d8-5e72-44c1-aebf-24385a2d79de", 
                "[2019-06-05 19:04:21,812] (heat-config) [INFO] deploy_action=CREATE", 
                "[2019-06-05 19:04:21,812] (heat-config) [INFO] deploy_stack_id=lab-ComputeHCIHostsDeployment-ueyrowzfb4hm-0-mtgcs45dmjpm/46750f97-3e63-455f-a051-95784ad14b94", 
                "[2019-06-05 19:04:21,812] (heat-config) [INFO] deploy_resource_name=TripleOSoftwareDeployment", 
                "[2019-06-05 19:04:21,812] (heat-config) [INFO] deploy_signal_transport=NO_SIGNAL", 
                "[2019-06-05 19:04:21,812] (heat-config) [DEBUG] Running /var/lib/heat-config/heat-config-script/37223a91-98c1-40b5-ba31-1d79751e71c1", 
                "[2019-06-05 19:04:21,829] (heat-config) [INFO] ", 
                "[2019-06-05 19:04:21,829] (heat-config) [DEBUG] + set -o pipefail", 
                "+ hosts='192.168.24.19  overcloud.ctlplane.localdomain", 
                "172.16.1.114  overcloud.storage.localdomain", 
                "172.16.3.106  overcloud.storagemgmt.localdomain", 
                "172.16.2.110  overcloud.internalapi.localdomain", 
                "10.0.0.248  overcloud.localdomain", 
                "172.16.2.35 lab-controller-0.localdomain lab-controller-0", 
                "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", 
                "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", 
                "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", 
                "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", 
                "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", 
                "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", 
                "", 
                "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", 
                "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", 
                "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", 
                "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", 
                "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", 
                "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", 
                "'", 
                "+ '[' '!' -z '192.168.24.19  overcloud.ctlplane.localdomain", 
                "172.16.1.114  overcloud.storage.localdomain", 
                "172.16.3.106  overcloud.storagemgmt.localdomain", 
                "172.16.2.110  overcloud.internalapi.localdomain", 
                "10.0.0.248  overcloud.localdomain", 
                "172.16.2.35 lab-controller-0.localdomain lab-controller-0", 
                "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", 
                "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", 
                "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", 
                "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", 
                "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", 
                "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", 
                "", 
                "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", 
                "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", 
                "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", 
                "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", 
                "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", 
                "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", 
                "' ']'", 
                "+ for tmpl in '/etc/cloud/templates/hosts.*.tmpl'", 
                "+ write_entries /etc/cloud/templates/hosts.debian.tmpl '192.168.24.19  overcloud.ctlplane.localdomain", 
                "172.16.1.114  overcloud.storage.localdomain", 
                "172.16.3.106  overcloud.storagemgmt.localdomain", 
                "172.16.2.110  overcloud.internalapi.localdomain", 
                "10.0.0.248  overcloud.localdomain", 
                "172.16.2.35 lab-controller-0.localdomain lab-controller-0", 
                "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", 
                "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", 
                "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", 
                "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", 
                "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", 
                "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", 
                "", 
                "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", 
                "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", 
                "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", 
                "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", 
                "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", 
                "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", 
                "'", 
                "+ local file=/etc/cloud/templates/hosts.debian.tmpl", 
                "+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain", 
                "172.16.1.114  overcloud.storage.localdomain", 
                "172.16.3.106  overcloud.storagemgmt.localdomain", 
                "172.16.2.110  overcloud.internalapi.localdomain", 
                "10.0.0.248  overcloud.localdomain", 
                "172.16.2.35 lab-controller-0.localdomain lab-controller-0", 
                "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", 
                "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", 
                "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", 
                "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", 
                "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", 
                "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", 
                "", 
                "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", 
                "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", 
                "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", 
                "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", 
                "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", 
                "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", 
                "'", 
                "+ '[' '!' -f /etc/cloud/templates/hosts.debian.tmpl ']'", 
                "+ grep -q '^# HEAT_HOSTS_START' /etc/cloud/templates/hosts.debian.tmpl", 
                "++ hostname -s", 
                "+ sed -i /lab-computehci-0/d /etc/cloud/templates/hosts.debian.tmpl", 
                "+ echo -ne '\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\n'", 
                "+ echo '192.168.24.19  overcloud.ctlplane.localdomain", 
                "172.16.1.114  overcloud.storage.localdomain", 
                "172.16.3.106  overcloud.storagemgmt.localdomain", 
                "172.16.2.110  overcloud.internalapi.localdomain", 
                "10.0.0.248  overcloud.localdomain", 
                "172.16.2.35 lab-controller-0.localdomain lab-controller-0", 
                "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", 
                "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", 
                "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", 
                "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", 
                "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", 
                "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", 
                "", 
                "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", 
                "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", 
                "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", 
                "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", 
                "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", 
                "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", 
                "'", 
                "+ echo -ne '# HEAT_HOSTS_END\\n\\n'", 
                "+ for tmpl in '/etc/cloud/templates/hosts.*.tmpl'", 
                "+ write_entries /etc/cloud/templates/hosts.freebsd.tmpl '192.168.24.19  overcloud.ctlplane.localdomain", 
                "172.16.1.114  overcloud.storage.localdomain", 
                "172.16.3.106  overcloud.storagemgmt.localdomain", 
                "172.16.2.110  overcloud.internalapi.localdomain", 
                "10.0.0.248  overcloud.localdomain", 
                "172.16.2.35 lab-controller-0.localdomain lab-controller-0", 
                "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", 
                "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", 
                "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", 
                "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", 
                "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", 
                "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", 
                "", 
                "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", 
                "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", 
                "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", 
                "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", 
                "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", 
                "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", 
                "'", 
                "+ local file=/etc/cloud/templates/hosts.freebsd.tmpl", 
                "+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain", 
                "172.16.1.114  overcloud.storage.localdomain", 
                "172.16.3.106  overcloud.storagemgmt.localdomain", 
                "172.16.2.110  overcloud.internalapi.localdomain", 
                "10.0.0.248  overcloud.localdomain", 
                "172.16.2.35 lab-controller-0.localdomain lab-controller-0", 
                "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", 
                "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", 
                "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", 
                "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", 
                "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", 
                "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", 
                "", 
                "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", 
                "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", 
                "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", 
                "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", 
                "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", 
                "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", 
                "'", 
                "+ '[' '!' -f /etc/cloud/templates/hosts.freebsd.tmpl ']'", 
                "+ grep -q '^# HEAT_HOSTS_START' /etc/cloud/templates/hosts.freebsd.tmpl", 
                "++ hostname -s", 
                "+ sed -i /lab-computehci-0/d /etc/cloud/templates/hosts.freebsd.tmpl", 
                "+ echo -ne '\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\n'", 
                "+ echo '192.168.24.19  overcloud.ctlplane.localdomain", 
                "172.16.1.114  overcloud.storage.localdomain", 
                "172.16.3.106  overcloud.storagemgmt.localdomain", 
                "172.16.2.110  overcloud.internalapi.localdomain", 
                "10.0.0.248  overcloud.localdomain", 
                "172.16.2.35 lab-controller-0.localdomain lab-controller-0", 
                "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", 
                "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", 
                "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", 
                "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", 
                "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", 
                "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", 
                "", 
                "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", 
                "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", 
                "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", 
                "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", 
                "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", 
                "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", 
                "'", 
                "+ echo -ne '# HEAT_HOSTS_END\\n\\n'", 
                "+ for tmpl in '/etc/cloud/templates/hosts.*.tmpl'", 
                "+ write_entries /etc/cloud/templates/hosts.redhat.tmpl '192.168.24.19  overcloud.ctlplane.localdomain", 
                "172.16.1.114  overcloud.storage.localdomain", 
                "172.16.3.106  overcloud.storagemgmt.localdomain", 
                "172.16.2.110  overcloud.internalapi.localdomain", 
                "10.0.0.248  overcloud.localdomain", 
                "172.16.2.35 lab-controller-0.localdomain lab-controller-0", 
                "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", 
                "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", 
                "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", 
                "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", 
                "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", 
                "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", 
                "", 
                "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", 
                "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", 
                "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", 
                "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", 
                "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", 
                "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", 
                "'", 
                "+ local file=/etc/cloud/templates/hosts.redhat.tmpl", 
                "+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain", 
                "172.16.1.114  overcloud.storage.localdomain", 
                "172.16.3.106  overcloud.storagemgmt.localdomain", 
                "172.16.2.110  overcloud.internalapi.localdomain", 
                "10.0.0.248  overcloud.localdomain", 
                "172.16.2.35 lab-controller-0.localdomain lab-controller-0", 
                "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", 
                "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", 
                "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", 
                "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", 
                "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", 
                "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", 
                "", 
                "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", 
                "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", 
                "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", 
                "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", 
                "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", 
                "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", 
                "'", 
                "+ '[' '!' -f /etc/cloud/templates/hosts.redhat.tmpl ']'", 
                "+ grep -q '^# HEAT_HOSTS_START' /etc/cloud/templates/hosts.redhat.tmpl", 
                "++ hostname -s", 
                "+ sed -i /lab-computehci-0/d /etc/cloud/templates/hosts.redhat.tmpl", 
                "+ echo -ne '\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\n'", 
                "+ echo '192.168.24.19  overcloud.ctlplane.localdomain", 
                "172.16.1.114  overcloud.storage.localdomain", 
                "172.16.3.106  overcloud.storagemgmt.localdomain", 
                "172.16.2.110  overcloud.internalapi.localdomain", 
                "10.0.0.248  overcloud.localdomain", 
                "172.16.2.35 lab-controller-0.localdomain lab-controller-0", 
                "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", 
                "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", 
                "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", 
                "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", 
                "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", 
                "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", 
                "", 
                "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", 
                "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", 
                "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", 
                "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", 
                "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", 
                "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", 
                "'", 
                "+ echo -ne '# HEAT_HOSTS_END\\n\\n'", 
                "+ for tmpl in '/etc/cloud/templates/hosts.*.tmpl'", 
                "+ write_entries /etc/cloud/templates/hosts.suse.tmpl '192.168.24.19  overcloud.ctlplane.localdomain", 
                "172.16.1.114  overcloud.storage.localdomain", 
                "172.16.3.106  overcloud.storagemgmt.localdomain", 
                "172.16.2.110  overcloud.internalapi.localdomain", 
                "10.0.0.248  overcloud.localdomain", 
                "172.16.2.35 lab-controller-0.localdomain lab-controller-0", 
                "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", 
                "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", 
                "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", 
                "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", 
                "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", 
                "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", 
                "", 
                "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", 
                "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", 
                "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", 
                "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", 
                "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", 
                "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", 
                "'", 
                "+ local file=/etc/cloud/templates/hosts.suse.tmpl", 
                "+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain", 
                "172.16.1.114  overcloud.storage.localdomain", 
                "172.16.3.106  overcloud.storagemgmt.localdomain", 
                "172.16.2.110  overcloud.internalapi.localdomain", 
                "10.0.0.248  overcloud.localdomain", 
                "172.16.2.35 lab-controller-0.localdomain lab-controller-0", 
                "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", 
                "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", 
                "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", 
                "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", 
                "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", 
                "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", 
                "", 
                "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", 
                "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", 
                "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", 
                "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", 
                "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", 
                "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", 
                "'", 
                "+ '[' '!' -f /etc/cloud/templates/hosts.suse.tmpl ']'", 
                "+ grep -q '^# HEAT_HOSTS_START' /etc/cloud/templates/hosts.suse.tmpl", 
                "++ hostname -s", 
                "+ sed -i /lab-computehci-0/d /etc/cloud/templates/hosts.suse.tmpl", 
                "+ echo -ne '\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\n'", 
                "+ echo '192.168.24.19  overcloud.ctlplane.localdomain", 
                "172.16.1.114  overcloud.storage.localdomain", 
                "172.16.3.106  overcloud.storagemgmt.localdomain", 
                "172.16.2.110  overcloud.internalapi.localdomain", 
                "10.0.0.248  overcloud.localdomain", 
                "172.16.2.35 lab-controller-0.localdomain lab-controller-0", 
                "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", 
                "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", 
                "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", 
                "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", 
                "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", 
                "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", 
                "", 
                "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", 
                "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", 
                "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", 
                "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", 
                "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", 
                "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", 
                "'", 
                "+ echo -ne '# HEAT_HOSTS_END\\n\\n'", 
                "+ write_entries /etc/hosts '192.168.24.19  overcloud.ctlplane.localdomain", 
                "172.16.1.114  overcloud.storage.localdomain", 
                "172.16.3.106  overcloud.storagemgmt.localdomain", 
                "172.16.2.110  overcloud.internalapi.localdomain", 
                "10.0.0.248  overcloud.localdomain", 
                "172.16.2.35 lab-controller-0.localdomain lab-controller-0", 
                "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", 
                "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", 
                "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", 
                "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", 
                "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", 
                "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", 
                "", 
                "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", 
                "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", 
                "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", 
                "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", 
                "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", 
                "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", 
                "'", 
                "+ local file=/etc/hosts", 
                "+ local 'entries=192.168.24.19  overcloud.ctlplane.localdomain", 
                "172.16.1.114  overcloud.storage.localdomain", 
                "172.16.3.106  overcloud.storagemgmt.localdomain", 
                "172.16.2.110  overcloud.internalapi.localdomain", 
                "10.0.0.248  overcloud.localdomain", 
                "172.16.2.35 lab-controller-0.localdomain lab-controller-0", 
                "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", 
                "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", 
                "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", 
                "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", 
                "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", 
                "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", 
                "", 
                "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", 
                "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", 
                "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", 
                "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", 
                "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", 
                "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", 
                "'", 
                "+ '[' '!' -f /etc/hosts ']'", 
                "+ grep -q '^# HEAT_HOSTS_START' /etc/hosts", 
                "++ hostname -s", 
                "+ sed -i /lab-computehci-0/d /etc/hosts", 
                "+ echo -ne '\\n# HEAT_HOSTS_START - Do not edit manually within this section!\\n'", 
                "+ echo '192.168.24.19  overcloud.ctlplane.localdomain", 
                "172.16.1.114  overcloud.storage.localdomain", 
                "172.16.3.106  overcloud.storagemgmt.localdomain", 
                "172.16.2.110  overcloud.internalapi.localdomain", 
                "10.0.0.248  overcloud.localdomain", 
                "172.16.2.35 lab-controller-0.localdomain lab-controller-0", 
                "172.16.1.240 lab-controller-0.storage.localdomain lab-controller-0.storage", 
                "172.16.3.205 lab-controller-0.storagemgmt.localdomain lab-controller-0.storagemgmt", 
                "172.16.2.35 lab-controller-0.internalapi.localdomain lab-controller-0.internalapi", 
                "172.16.0.171 lab-controller-0.tenant.localdomain lab-controller-0.tenant", 
                "10.0.0.8 lab-controller-0.external.localdomain lab-controller-0.external", 
                "192.168.24.20 lab-controller-0.ctlplane.localdomain lab-controller-0.ctlplane", 
                "", 
                "172.16.2.227 lab-computehci-0.localdomain lab-computehci-0", 
                "172.16.1.107 lab-computehci-0.storage.localdomain lab-computehci-0.storage", 
                "172.16.3.54 lab-computehci-0.storagemgmt.localdomain lab-computehci-0.storagemgmt", 
                "172.16.2.227 lab-computehci-0.internalapi.localdomain lab-computehci-0.internalapi", 
                "172.16.0.133 lab-computehci-0.tenant.localdomain lab-computehci-0.tenant", 
                "192.168.24.17 lab-computehci-0.ctlplane.localdomain lab-computehci-0.ctlplane", 
                "'", 
                "+ echo -ne '# HEAT_HOSTS_END\\n\\n'", 
                "", 
                "[2019-06-05 19:04:21,829] (heat-config) [INFO] Completed /var/lib/heat-config/heat-config-script/37223a91-98c1-40b5-ba31-1d79751e71c1", 
                "", 
                "[2019-06-05 19:04:21,845] (heat-config) [INFO] Completed /usr/libexec/heat-config/hooks/script", 
                "[2019-06-05 19:04:21,846] (heat-config) [DEBUG] Running heat-config-notify /var/lib/heat-config/deployed/37223a91-98c1-40b5-ba31-1d79751e71c1.json < /var/lib/heat-config/deployed/37223a91-98c1-40b5-ba31-1d79751e71c1.notify.json", 
                "[2019-06-05 19:04:22,136] (heat-config) [INFO] ", 
                "[2019-06-05 19:04:22,136] (heat-config) [DEBUG] "
            ]
        }, 
        {
            "status_code": "0"
        }
    ]
}
2019-06-05 14:04:22,329 p=17240 u=mistral |  META: noop
2019-06-05 14:04:22,343 p=17240 u=mistral |  TASK [Output for async deployment ComputeHCIHostsDeployment] *******************
2019-06-05 14:04:22,343 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:176
2019-06-05 14:04:22,343 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:22 -0500 (0:00:00.096)       0:00:56.113 ******** 
2019-06-05 14:04:22,355 p=17240 u=mistral |  skipping: [lab-computehci-0] => {}
2019-06-05 14:04:22,356 p=17240 u=mistral |  META: noop
2019-06-05 14:04:22,371 p=17240 u=mistral |  TASK [Check-mode for Run deployment ComputeHCIHostsDeployment (changed status indicates deployment would run)] ***
2019-06-05 14:04:22,371 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:186
2019-06-05 14:04:22,371 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:22 -0500 (0:00:00.027)       0:00:56.141 ******** 
2019-06-05 14:04:22,380 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:22,381 p=17240 u=mistral |  META: noop
2019-06-05 14:04:22,396 p=17240 u=mistral |  TASK [Lookup deployment UUID] **************************************************
2019-06-05 14:04:22,396 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:1
2019-06-05 14:04:22,396 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:22 -0500 (0:00:00.024)       0:00:56.165 ******** 
2019-06-05 14:04:22,524 p=17240 u=mistral |  ok: [lab-computehci-0] => {"ansible_facts": {"deployment_uuid": "eeee6d66-e284-4e25-816b-46303e0f98ac"}, "changed": false}
2019-06-05 14:04:22,525 p=17240 u=mistral |  META: noop
2019-06-05 14:04:22,538 p=17240 u=mistral |  TASK [Lookup deployment group] *************************************************
2019-06-05 14:04:22,538 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:5
2019-06-05 14:04:22,539 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:22 -0500 (0:00:00.142)       0:00:56.308 ******** 
2019-06-05 14:04:22,665 p=17240 u=mistral |  ok: [lab-computehci-0] => {"ansible_facts": {"deployment_group": "hiera"}, "changed": false}
2019-06-05 14:04:22,665 p=17240 u=mistral |  META: noop
2019-06-05 14:04:22,679 p=17240 u=mistral |  TASK [Create hiera check-mode directory] ***************************************
2019-06-05 14:04:22,679 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:13
2019-06-05 14:04:22,680 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:22 -0500 (0:00:00.140)       0:00:56.449 ******** 
2019-06-05 14:04:22,691 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:22,692 p=17240 u=mistral |  META: noop
2019-06-05 14:04:22,706 p=17240 u=mistral |  TASK [Create deployed check-mode directory] ************************************
2019-06-05 14:04:22,706 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:19
2019-06-05 14:04:22,706 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:22 -0500 (0:00:00.026)       0:00:56.475 ******** 
2019-06-05 14:04:22,718 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:22,719 p=17240 u=mistral |  META: noop
2019-06-05 14:04:22,733 p=17240 u=mistral |  TASK [Create tripleo-config-download check-mode directory] *********************
2019-06-05 14:04:22,733 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:25
2019-06-05 14:04:22,733 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:22 -0500 (0:00:00.027)       0:00:56.502 ******** 
2019-06-05 14:04:22,744 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:22,745 p=17240 u=mistral |  META: noop
2019-06-05 14:04:22,760 p=17240 u=mistral |  TASK [Render deployment file for ComputeHCIAllNodesDeployment for check-mode] ***
2019-06-05 14:04:22,760 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:31
2019-06-05 14:04:22,760 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:22 -0500 (0:00:00.026)       0:00:56.529 ******** 
2019-06-05 14:04:22,772 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:22,773 p=17240 u=mistral |  META: noop
2019-06-05 14:04:22,786 p=17240 u=mistral |  TASK [Run hiera deployment for check mode] *************************************
2019-06-05 14:04:22,786 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:38
2019-06-05 14:04:22,786 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:22 -0500 (0:00:00.026)       0:00:56.556 ******** 
2019-06-05 14:04:22,799 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:22,799 p=17240 u=mistral |  META: noop
2019-06-05 14:04:22,814 p=17240 u=mistral |  TASK [List hieradata files for check mode] *************************************
2019-06-05 14:04:22,814 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:54
2019-06-05 14:04:22,814 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:22 -0500 (0:00:00.027)       0:00:56.583 ******** 
2019-06-05 14:04:22,825 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:22,825 p=17240 u=mistral |  META: noop
2019-06-05 14:04:22,839 p=17240 u=mistral |  TASK [diff hieradata changes for check mode] ***********************************
2019-06-05 14:04:22,840 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:60
2019-06-05 14:04:22,840 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:22 -0500 (0:00:00.025)       0:00:56.609 ******** 
2019-06-05 14:04:22,852 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:22,853 p=17240 u=mistral |  META: noop
2019-06-05 14:04:22,867 p=17240 u=mistral |  TASK [diff hieradata changes for check mode] ***********************************
2019-06-05 14:04:22,867 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:73
2019-06-05 14:04:22,867 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:22 -0500 (0:00:00.027)       0:00:56.636 ******** 
2019-06-05 14:04:22,879 p=17240 u=mistral |  skipping: [lab-computehci-0] => {}
2019-06-05 14:04:22,880 p=17240 u=mistral |  META: noop
2019-06-05 14:04:22,894 p=17240 u=mistral |  TASK [hiera.yaml changes for check mode] ***************************************
2019-06-05 14:04:22,894 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:82
2019-06-05 14:04:22,894 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:22 -0500 (0:00:00.026)       0:00:56.663 ******** 
2019-06-05 14:04:22,906 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:22,907 p=17240 u=mistral |  META: noop
2019-06-05 14:04:22,921 p=17240 u=mistral |  TASK [diff hiera.yaml changes for check mode] **********************************
2019-06-05 14:04:22,921 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:90
2019-06-05 14:04:22,921 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:22 -0500 (0:00:00.027)       0:00:56.691 ******** 
2019-06-05 14:04:22,932 p=17240 u=mistral |  skipping: [lab-computehci-0] => {}
2019-06-05 14:04:22,933 p=17240 u=mistral |  META: noop
2019-06-05 14:04:22,948 p=17240 u=mistral |  TASK [Render deployment file for ComputeHCIAllNodesDeployment] *****************
2019-06-05 14:04:22,948 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:102
2019-06-05 14:04:22,948 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:22 -0500 (0:00:00.027)       0:00:56.718 ******** 
2019-06-05 14:04:23,351 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "checksum": "2062463b5328b26fc38e592dbcca8310159c17d9", "dest": "/var/lib/heat-config/tripleo-config-download/ComputeHCIAllNodesDeployment-eeee6d66-e284-4e25-816b-46303e0f98ac", "gid": 0, "group": "root", "md5sum": "755f3873cc5c429965d7fa9021b9c53d", "mode": "0644", "owner": "root", "secontext": "system_u:object_r:var_lib_t:s0", "size": 20419, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559761463.09-39958635088061/source", "state": "file", "uid": 0}
2019-06-05 14:04:23,352 p=17240 u=mistral |  META: noop
2019-06-05 14:04:23,367 p=17240 u=mistral |  TASK [Check if deployed file exists for ComputeHCIAllNodesDeployment] **********
2019-06-05 14:04:23,367 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:108
2019-06-05 14:04:23,367 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:23 -0500 (0:00:00.418)       0:00:57.136 ******** 
2019-06-05 14:04:23,513 p=17240 u=mistral |  ok: [lab-computehci-0] => {"changed": false, "stat": {"exists": false}}
2019-06-05 14:04:23,514 p=17240 u=mistral |  META: noop
2019-06-05 14:04:23,528 p=17240 u=mistral |  TASK [Check previous deployment rc for ComputeHCIAllNodesDeployment] ***********
2019-06-05 14:04:23,528 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:113
2019-06-05 14:04:23,529 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:23 -0500 (0:00:00.161)       0:00:57.298 ******** 
2019-06-05 14:04:23,541 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:23,542 p=17240 u=mistral |  META: noop
2019-06-05 14:04:23,557 p=17240 u=mistral |  TASK [Remove deployed file for ComputeHCIAllNodesDeployment when previous deployment failed] ***
2019-06-05 14:04:23,557 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:121
2019-06-05 14:04:23,558 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:23 -0500 (0:00:00.028)       0:00:57.327 ******** 
2019-06-05 14:04:23,570 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:23,571 p=17240 u=mistral |  META: noop
2019-06-05 14:04:23,586 p=17240 u=mistral |  TASK [Force remove deployed file for ComputeHCIAllNodesDeployment] *************
2019-06-05 14:04:23,586 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:131
2019-06-05 14:04:23,586 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:23 -0500 (0:00:00.028)       0:00:57.355 ******** 
2019-06-05 14:04:23,597 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:23,598 p=17240 u=mistral |  META: noop
2019-06-05 14:04:23,612 p=17240 u=mistral |  TASK [Set fact for async_deployment] *******************************************
2019-06-05 14:04:23,612 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:138
2019-06-05 14:04:23,612 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:23 -0500 (0:00:00.026)       0:00:57.382 ******** 
2019-06-05 14:04:23,640 p=17240 u=mistral |  ok: [lab-computehci-0] => {"ansible_facts": {"use_async_deployment": false}, "changed": false}
2019-06-05 14:04:23,641 p=17240 u=mistral |  META: noop
2019-06-05 14:04:23,656 p=17240 u=mistral |  TASK [Run deployment ComputeHCIAllNodesDeployment] *****************************
2019-06-05 14:04:23,656 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:142
2019-06-05 14:04:23,656 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:23 -0500 (0:00:00.044)       0:00:57.426 ******** 
2019-06-05 14:04:24,247 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "cmd": "/usr/libexec/os-refresh-config/configure.d/55-heat-config\n exit $(jq .deploy_status_code /var/lib/heat-config/deployed/eeee6d66-e284-4e25-816b-46303e0f98ac.notify.json)", "delta": "0:00:00.485151", "end": "2019-06-05 19:04:24.239529", "rc": 0, "start": "2019-06-05 19:04:23.754378", "stderr": "[2019-06-05 19:04:23,781] (heat-config) [DEBUG] Running /usr/libexec/heat-config/hooks/hiera < /var/lib/heat-config/deployed/eeee6d66-e284-4e25-816b-46303e0f98ac.json\n[2019-06-05 19:04:23,942] (heat-config) [INFO] |-\n  {\"deploy_stdout\": \"\", \"deploy_stderr\": \"\", \"deploy_status_code\": 0}\n\n[2019-06-05 19:04:23,942] (heat-config) [DEBUG] \n[2019-06-05 19:04:23,942] (heat-config) [INFO] Completed /usr/libexec/heat-config/hooks/hiera\n[2019-06-05 19:04:23,943] (heat-config) [DEBUG] Running heat-config-notify /var/lib/heat-config/deployed/eeee6d66-e284-4e25-816b-46303e0f98ac.json < /var/lib/heat-config/deployed/eeee6d66-e284-4e25-816b-46303e0f98ac.notify.json\n[2019-06-05 19:04:24,233] (heat-config) [INFO] \n[2019-06-05 19:04:24,233] (heat-config) [DEBUG] ", "stderr_lines": ["[2019-06-05 19:04:23,781] (heat-config) [DEBUG] Running /usr/libexec/heat-config/hooks/hiera < /var/lib/heat-config/deployed/eeee6d66-e284-4e25-816b-46303e0f98ac.json", "[2019-06-05 19:04:23,942] (heat-config) [INFO] |-", "  {\"deploy_stdout\": \"\", \"deploy_stderr\": \"\", \"deploy_status_code\": 0}", "", "[2019-06-05 19:04:23,942] (heat-config) [DEBUG] ", "[2019-06-05 19:04:23,942] (heat-config) [INFO] Completed /usr/libexec/heat-config/hooks/hiera", "[2019-06-05 19:04:23,943] (heat-config) [DEBUG] Running heat-config-notify /var/lib/heat-config/deployed/eeee6d66-e284-4e25-816b-46303e0f98ac.json < /var/lib/heat-config/deployed/eeee6d66-e284-4e25-816b-46303e0f98ac.notify.json", "[2019-06-05 19:04:24,233] (heat-config) [INFO] ", "[2019-06-05 19:04:24,233] (heat-config) [DEBUG] "], "stdout": "", "stdout_lines": []}
2019-06-05 14:04:24,248 p=17240 u=mistral |  META: noop
2019-06-05 14:04:24,263 p=17240 u=mistral |  TASK [Run async deployment ComputeHCIAllNodesDeployment] ***********************
2019-06-05 14:04:24,263 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:153
2019-06-05 14:04:24,263 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:24 -0500 (0:00:00.606)       0:00:58.033 ******** 
2019-06-05 14:04:24,273 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:24,274 p=17240 u=mistral |  META: noop
2019-06-05 14:04:24,289 p=17240 u=mistral |  TASK [Output for sync deployment ComputeHCIAllNodesDeployment] *****************
2019-06-05 14:04:24,289 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:166
2019-06-05 14:04:24,289 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:24 -0500 (0:00:00.026)       0:00:58.059 ******** 
2019-06-05 14:04:24,365 p=17240 u=mistral |  ok: [lab-computehci-0] => {
    "msg": [
        {
            "stderr": [
                "[2019-06-05 19:04:23,781] (heat-config) [DEBUG] Running /usr/libexec/heat-config/hooks/hiera < /var/lib/heat-config/deployed/eeee6d66-e284-4e25-816b-46303e0f98ac.json", 
                "[2019-06-05 19:04:23,942] (heat-config) [INFO] |-", 
                "  {\"deploy_stdout\": \"\", \"deploy_stderr\": \"\", \"deploy_status_code\": 0}", 
                "", 
                "[2019-06-05 19:04:23,942] (heat-config) [DEBUG] ", 
                "[2019-06-05 19:04:23,942] (heat-config) [INFO] Completed /usr/libexec/heat-config/hooks/hiera", 
                "[2019-06-05 19:04:23,943] (heat-config) [DEBUG] Running heat-config-notify /var/lib/heat-config/deployed/eeee6d66-e284-4e25-816b-46303e0f98ac.json < /var/lib/heat-config/deployed/eeee6d66-e284-4e25-816b-46303e0f98ac.notify.json", 
                "[2019-06-05 19:04:24,233] (heat-config) [INFO] ", 
                "[2019-06-05 19:04:24,233] (heat-config) [DEBUG] "
            ]
        }, 
        {
            "status_code": "0"
        }
    ]
}
2019-06-05 14:04:24,365 p=17240 u=mistral |  META: noop
2019-06-05 14:04:24,380 p=17240 u=mistral |  TASK [Output for async deployment ComputeHCIAllNodesDeployment] ****************
2019-06-05 14:04:24,380 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:176
2019-06-05 14:04:24,381 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:24 -0500 (0:00:00.091)       0:00:58.150 ******** 
2019-06-05 14:04:24,391 p=17240 u=mistral |  skipping: [lab-computehci-0] => {}
2019-06-05 14:04:24,391 p=17240 u=mistral |  META: noop
2019-06-05 14:04:24,407 p=17240 u=mistral |  TASK [Check-mode for Run deployment ComputeHCIAllNodesDeployment (changed status indicates deployment would run)] ***
2019-06-05 14:04:24,407 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:186
2019-06-05 14:04:24,407 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:24 -0500 (0:00:00.026)       0:00:58.176 ******** 
2019-06-05 14:04:24,416 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:24,416 p=17240 u=mistral |  META: noop
2019-06-05 14:04:24,430 p=17240 u=mistral |  TASK [Lookup deployment UUID] **************************************************
2019-06-05 14:04:24,430 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:1
2019-06-05 14:04:24,430 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:24 -0500 (0:00:00.023)       0:00:58.200 ******** 
2019-06-05 14:04:24,471 p=17240 u=mistral |  ok: [lab-computehci-0] => {"ansible_facts": {"deployment_uuid": "7a80ffe2-cd86-4f9c-9289-900c6e01587f"}, "changed": false}
2019-06-05 14:04:24,472 p=17240 u=mistral |  META: noop
2019-06-05 14:04:24,485 p=17240 u=mistral |  TASK [Lookup deployment group] *************************************************
2019-06-05 14:04:24,485 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:5
2019-06-05 14:04:24,485 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:24 -0500 (0:00:00.054)       0:00:58.254 ******** 
2019-06-05 14:04:24,562 p=17240 u=mistral |  ok: [lab-computehci-0] => {"ansible_facts": {"deployment_group": "script"}, "changed": false}
2019-06-05 14:04:24,562 p=17240 u=mistral |  META: noop
2019-06-05 14:04:24,577 p=17240 u=mistral |  TASK [Create hiera check-mode directory] ***************************************
2019-06-05 14:04:24,577 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:13
2019-06-05 14:04:24,577 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:24 -0500 (0:00:00.091)       0:00:58.346 ******** 
2019-06-05 14:04:24,588 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:24,589 p=17240 u=mistral |  META: noop
2019-06-05 14:04:24,603 p=17240 u=mistral |  TASK [Create deployed check-mode directory] ************************************
2019-06-05 14:04:24,603 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:19
2019-06-05 14:04:24,603 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:24 -0500 (0:00:00.026)       0:00:58.372 ******** 
2019-06-05 14:04:24,614 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:24,615 p=17240 u=mistral |  META: noop
2019-06-05 14:04:24,629 p=17240 u=mistral |  TASK [Create tripleo-config-download check-mode directory] *********************
2019-06-05 14:04:24,629 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:25
2019-06-05 14:04:24,629 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:24 -0500 (0:00:00.026)       0:00:58.398 ******** 
2019-06-05 14:04:24,640 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:24,641 p=17240 u=mistral |  META: noop
2019-06-05 14:04:24,656 p=17240 u=mistral |  TASK [Render deployment file for ComputeHCIAllNodesValidationDeployment for check-mode] ***
2019-06-05 14:04:24,656 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:31
2019-06-05 14:04:24,656 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:24 -0500 (0:00:00.027)       0:00:58.425 ******** 
2019-06-05 14:04:24,667 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:24,668 p=17240 u=mistral |  META: noop
2019-06-05 14:04:24,682 p=17240 u=mistral |  TASK [Run hiera deployment for check mode] *************************************
2019-06-05 14:04:24,682 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:38
2019-06-05 14:04:24,682 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:24 -0500 (0:00:00.026)       0:00:58.452 ******** 
2019-06-05 14:04:24,695 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:24,695 p=17240 u=mistral |  META: noop
2019-06-05 14:04:24,709 p=17240 u=mistral |  TASK [List hieradata files for check mode] *************************************
2019-06-05 14:04:24,709 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:54
2019-06-05 14:04:24,709 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:24 -0500 (0:00:00.027)       0:00:58.479 ******** 
2019-06-05 14:04:24,721 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:24,721 p=17240 u=mistral |  META: noop
2019-06-05 14:04:24,735 p=17240 u=mistral |  TASK [diff hieradata changes for check mode] ***********************************
2019-06-05 14:04:24,735 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:60
2019-06-05 14:04:24,735 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:24 -0500 (0:00:00.026)       0:00:58.505 ******** 
2019-06-05 14:04:24,748 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:24,748 p=17240 u=mistral |  META: noop
2019-06-05 14:04:24,762 p=17240 u=mistral |  TASK [diff hieradata changes for check mode] ***********************************
2019-06-05 14:04:24,762 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:73
2019-06-05 14:04:24,762 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:24 -0500 (0:00:00.026)       0:00:58.532 ******** 
2019-06-05 14:04:24,775 p=17240 u=mistral |  skipping: [lab-computehci-0] => {}
2019-06-05 14:04:24,776 p=17240 u=mistral |  META: noop
2019-06-05 14:04:24,789 p=17240 u=mistral |  TASK [hiera.yaml changes for check mode] ***************************************
2019-06-05 14:04:24,789 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:82
2019-06-05 14:04:24,789 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:24 -0500 (0:00:00.027)       0:00:58.559 ******** 
2019-06-05 14:04:24,800 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:24,801 p=17240 u=mistral |  META: noop
2019-06-05 14:04:24,815 p=17240 u=mistral |  TASK [diff hiera.yaml changes for check mode] **********************************
2019-06-05 14:04:24,815 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:90
2019-06-05 14:04:24,815 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:24 -0500 (0:00:00.025)       0:00:58.585 ******** 
2019-06-05 14:04:24,825 p=17240 u=mistral |  skipping: [lab-computehci-0] => {}
2019-06-05 14:04:24,826 p=17240 u=mistral |  META: noop
2019-06-05 14:04:24,841 p=17240 u=mistral |  TASK [Render deployment file for ComputeHCIAllNodesValidationDeployment] *******
2019-06-05 14:04:24,841 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:102
2019-06-05 14:04:24,841 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:24 -0500 (0:00:00.025)       0:00:58.610 ******** 
2019-06-05 14:04:25,184 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "checksum": "3fded11220cc1733911f682c08bd394d4fca3d75", "dest": "/var/lib/heat-config/tripleo-config-download/ComputeHCIAllNodesValidationDeployment-7a80ffe2-cd86-4f9c-9289-900c6e01587f", "gid": 0, "group": "root", "md5sum": "f14cbdc5bed04544199844869752c09d", "mode": "0644", "owner": "root", "secontext": "system_u:object_r:var_lib_t:s0", "size": 5587, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559761464.92-54942583815709/source", "state": "file", "uid": 0}
2019-06-05 14:04:25,185 p=17240 u=mistral |  META: noop
2019-06-05 14:04:25,200 p=17240 u=mistral |  TASK [Check if deployed file exists for ComputeHCIAllNodesValidationDeployment] ***
2019-06-05 14:04:25,200 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:108
2019-06-05 14:04:25,200 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:25 -0500 (0:00:00.358)       0:00:58.969 ******** 
2019-06-05 14:04:25,345 p=17240 u=mistral |  ok: [lab-computehci-0] => {"changed": false, "stat": {"exists": false}}
2019-06-05 14:04:25,346 p=17240 u=mistral |  META: noop
2019-06-05 14:04:25,363 p=17240 u=mistral |  TASK [Check previous deployment rc for ComputeHCIAllNodesValidationDeployment] ***
2019-06-05 14:04:25,363 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:113
2019-06-05 14:04:25,363 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:25 -0500 (0:00:00.163)       0:00:59.133 ******** 
2019-06-05 14:04:25,375 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:25,375 p=17240 u=mistral |  META: noop
2019-06-05 14:04:25,390 p=17240 u=mistral |  TASK [Remove deployed file for ComputeHCIAllNodesValidationDeployment when previous deployment failed] ***
2019-06-05 14:04:25,390 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:121
2019-06-05 14:04:25,390 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:25 -0500 (0:00:00.026)       0:00:59.160 ******** 
2019-06-05 14:04:25,402 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:25,403 p=17240 u=mistral |  META: noop
2019-06-05 14:04:25,418 p=17240 u=mistral |  TASK [Force remove deployed file for ComputeHCIAllNodesValidationDeployment] ***
2019-06-05 14:04:25,418 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:131
2019-06-05 14:04:25,418 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:25 -0500 (0:00:00.028)       0:00:59.188 ******** 
2019-06-05 14:04:25,429 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:25,430 p=17240 u=mistral |  META: noop
2019-06-05 14:04:25,444 p=17240 u=mistral |  TASK [Set fact for async_deployment] *******************************************
2019-06-05 14:04:25,444 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:138
2019-06-05 14:04:25,444 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:25 -0500 (0:00:00.026)       0:00:59.214 ******** 
2019-06-05 14:04:25,512 p=17240 u=mistral |  ok: [lab-computehci-0] => {"ansible_facts": {"use_async_deployment": false}, "changed": false}
2019-06-05 14:04:25,513 p=17240 u=mistral |  META: noop
2019-06-05 14:04:25,528 p=17240 u=mistral |  TASK [Run deployment ComputeHCIAllNodesValidationDeployment] *******************
2019-06-05 14:04:25,528 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:142
2019-06-05 14:04:25,529 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:25 -0500 (0:00:00.084)       0:00:59.298 ******** 
2019-06-05 14:04:26,722 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "cmd": "/usr/libexec/os-refresh-config/configure.d/55-heat-config\n exit $(jq .deploy_status_code /var/lib/heat-config/deployed/7a80ffe2-cd86-4f9c-9289-900c6e01587f.notify.json)", "delta": "0:00:01.043548", "end": "2019-06-05 19:04:26.713178", "rc": 0, "start": "2019-06-05 19:04:25.669630", "stderr": "[2019-06-05 19:04:25,696] (heat-config) [DEBUG] Running /usr/libexec/heat-config/hooks/script < /var/lib/heat-config/deployed/7a80ffe2-cd86-4f9c-9289-900c6e01587f.json\n[2019-06-05 19:04:26,415] (heat-config) [INFO] |-\n  {\"deploy_stdout\": \"Trying to ping default gateway 192.168.122.1...Ping to 192.168.122.1 succeeded.\\nSUCCESS\\nTrying to ping 172.16.0.133 for local network 172.16.0.0/24.\\nPing to 172.16.0.133 succeeded.\\nSUCCESS\\nTrying to ping 172.16.1.107 for local network 172.16.1.0/24.\\nPing to 172.16.1.107 succeeded.\\nSUCCESS\\nTrying to ping 172.16.2.227 for local network 172.16.2.0/24.\\nPing to 172.16.2.227 succeeded.\\nSUCCESS\\nTrying to ping 172.16.3.54 for local network 172.16.3.0/24.\\nPing to 172.16.3.54 succeeded.\\nSUCCESS\\nTrying to ping 192.168.24.17 for local network 192.168.24.0/24.\\nPing to 192.168.24.17 succeeded.\\nSUCCESS\\n\", \"deploy_stderr\": \"\", \"deploy_status_code\": 0}\n\n[2019-06-05 19:04:26,415] (heat-config) [DEBUG] [2019-06-05 19:04:25,708] (heat-config) [INFO] ping_test_ips=192.168.24.17 172.16.1.107 172.16.3.54 172.16.2.227 172.16.0.133\n[2019-06-05 19:04:25,708] (heat-config) [INFO] validate_fqdn=False\n[2019-06-05 19:04:25,708] (heat-config) [INFO] validate_ntp=True\n[2019-06-05 19:04:25,709] (heat-config) [INFO] validate_controllers_icmp=True\n[2019-06-05 19:04:25,709] (heat-config) [INFO] validate_gateways_icmp=True\n[2019-06-05 19:04:25,709] (heat-config) [INFO] deploy_server_id=97f857d8-5e72-44c1-aebf-24385a2d79de\n[2019-06-05 19:04:25,709] (heat-config) [INFO] deploy_action=CREATE\n[2019-06-05 19:04:25,709] (heat-config) [INFO] deploy_stack_id=lab-ComputeHCIAllNodesValidationDeployment-s5kf2ql2jtbq-0-avn5feupjlsa/0e267139-0f5f-4a53-975a-9ff6831ecb62\n[2019-06-05 19:04:25,709] (heat-config) [INFO] deploy_resource_name=TripleOSoftwareDeployment\n[2019-06-05 19:04:25,709] (heat-config) [INFO] deploy_signal_transport=NO_SIGNAL\n[2019-06-05 19:04:25,709] (heat-config) [DEBUG] Running /var/lib/heat-config/heat-config-script/7a80ffe2-cd86-4f9c-9289-900c6e01587f\n[2019-06-05 19:04:26,412] (heat-config) [INFO] Trying to ping default gateway 192.168.122.1...Ping to 192.168.122.1 succeeded.\nSUCCESS\nTrying to ping 172.16.0.133 for local network 172.16.0.0/24.\nPing to 172.16.0.133 succeeded.\nSUCCESS\nTrying to ping 172.16.1.107 for local network 172.16.1.0/24.\nPing to 172.16.1.107 succeeded.\nSUCCESS\nTrying to ping 172.16.2.227 for local network 172.16.2.0/24.\nPing to 172.16.2.227 succeeded.\nSUCCESS\nTrying to ping 172.16.3.54 for local network 172.16.3.0/24.\nPing to 172.16.3.54 succeeded.\nSUCCESS\nTrying to ping 192.168.24.17 for local network 192.168.24.0/24.\nPing to 192.168.24.17 succeeded.\nSUCCESS\n\n[2019-06-05 19:04:26,412] (heat-config) [DEBUG] \n[2019-06-05 19:04:26,412] (heat-config) [INFO] Completed /var/lib/heat-config/heat-config-script/7a80ffe2-cd86-4f9c-9289-900c6e01587f\n\n[2019-06-05 19:04:26,415] (heat-config) [INFO] Completed /usr/libexec/heat-config/hooks/script\n[2019-06-05 19:04:26,415] (heat-config) [DEBUG] Running heat-config-notify /var/lib/heat-config/deployed/7a80ffe2-cd86-4f9c-9289-900c6e01587f.json < /var/lib/heat-config/deployed/7a80ffe2-cd86-4f9c-9289-900c6e01587f.notify.json\n[2019-06-05 19:04:26,707] (heat-config) [INFO] \n[2019-06-05 19:04:26,707] (heat-config) [DEBUG] ", "stderr_lines": ["[2019-06-05 19:04:25,696] (heat-config) [DEBUG] Running /usr/libexec/heat-config/hooks/script < /var/lib/heat-config/deployed/7a80ffe2-cd86-4f9c-9289-900c6e01587f.json", "[2019-06-05 19:04:26,415] (heat-config) [INFO] |-", "  {\"deploy_stdout\": \"Trying to ping default gateway 192.168.122.1...Ping to 192.168.122.1 succeeded.\\nSUCCESS\\nTrying to ping 172.16.0.133 for local network 172.16.0.0/24.\\nPing to 172.16.0.133 succeeded.\\nSUCCESS\\nTrying to ping 172.16.1.107 for local network 172.16.1.0/24.\\nPing to 172.16.1.107 succeeded.\\nSUCCESS\\nTrying to ping 172.16.2.227 for local network 172.16.2.0/24.\\nPing to 172.16.2.227 succeeded.\\nSUCCESS\\nTrying to ping 172.16.3.54 for local network 172.16.3.0/24.\\nPing to 172.16.3.54 succeeded.\\nSUCCESS\\nTrying to ping 192.168.24.17 for local network 192.168.24.0/24.\\nPing to 192.168.24.17 succeeded.\\nSUCCESS\\n\", \"deploy_stderr\": \"\", \"deploy_status_code\": 0}", "", "[2019-06-05 19:04:26,415] (heat-config) [DEBUG] [2019-06-05 19:04:25,708] (heat-config) [INFO] ping_test_ips=192.168.24.17 172.16.1.107 172.16.3.54 172.16.2.227 172.16.0.133", "[2019-06-05 19:04:25,708] (heat-config) [INFO] validate_fqdn=False", "[2019-06-05 19:04:25,708] (heat-config) [INFO] validate_ntp=True", "[2019-06-05 19:04:25,709] (heat-config) [INFO] validate_controllers_icmp=True", "[2019-06-05 19:04:25,709] (heat-config) [INFO] validate_gateways_icmp=True", "[2019-06-05 19:04:25,709] (heat-config) [INFO] deploy_server_id=97f857d8-5e72-44c1-aebf-24385a2d79de", "[2019-06-05 19:04:25,709] (heat-config) [INFO] deploy_action=CREATE", "[2019-06-05 19:04:25,709] (heat-config) [INFO] deploy_stack_id=lab-ComputeHCIAllNodesValidationDeployment-s5kf2ql2jtbq-0-avn5feupjlsa/0e267139-0f5f-4a53-975a-9ff6831ecb62", "[2019-06-05 19:04:25,709] (heat-config) [INFO] deploy_resource_name=TripleOSoftwareDeployment", "[2019-06-05 19:04:25,709] (heat-config) [INFO] deploy_signal_transport=NO_SIGNAL", "[2019-06-05 19:04:25,709] (heat-config) [DEBUG] Running /var/lib/heat-config/heat-config-script/7a80ffe2-cd86-4f9c-9289-900c6e01587f", "[2019-06-05 19:04:26,412] (heat-config) [INFO] Trying to ping default gateway 192.168.122.1...Ping to 192.168.122.1 succeeded.", "SUCCESS", "Trying to ping 172.16.0.133 for local network 172.16.0.0/24.", "Ping to 172.16.0.133 succeeded.", "SUCCESS", "Trying to ping 172.16.1.107 for local network 172.16.1.0/24.", "Ping to 172.16.1.107 succeeded.", "SUCCESS", "Trying to ping 172.16.2.227 for local network 172.16.2.0/24.", "Ping to 172.16.2.227 succeeded.", "SUCCESS", "Trying to ping 172.16.3.54 for local network 172.16.3.0/24.", "Ping to 172.16.3.54 succeeded.", "SUCCESS", "Trying to ping 192.168.24.17 for local network 192.168.24.0/24.", "Ping to 192.168.24.17 succeeded.", "SUCCESS", "", "[2019-06-05 19:04:26,412] (heat-config) [DEBUG] ", "[2019-06-05 19:04:26,412] (heat-config) [INFO] Completed /var/lib/heat-config/heat-config-script/7a80ffe2-cd86-4f9c-9289-900c6e01587f", "", "[2019-06-05 19:04:26,415] (heat-config) [INFO] Completed /usr/libexec/heat-config/hooks/script", "[2019-06-05 19:04:26,415] (heat-config) [DEBUG] Running heat-config-notify /var/lib/heat-config/deployed/7a80ffe2-cd86-4f9c-9289-900c6e01587f.json < /var/lib/heat-config/deployed/7a80ffe2-cd86-4f9c-9289-900c6e01587f.notify.json", "[2019-06-05 19:04:26,707] (heat-config) [INFO] ", "[2019-06-05 19:04:26,707] (heat-config) [DEBUG] "], "stdout": "", "stdout_lines": []}
2019-06-05 14:04:26,723 p=17240 u=mistral |  META: noop
2019-06-05 14:04:26,738 p=17240 u=mistral |  TASK [Run async deployment ComputeHCIAllNodesValidationDeployment] *************
2019-06-05 14:04:26,738 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:153
2019-06-05 14:04:26,738 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:26 -0500 (0:00:01.209)       0:01:00.507 ******** 
2019-06-05 14:04:26,747 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:26,748 p=17240 u=mistral |  META: noop
2019-06-05 14:04:26,764 p=17240 u=mistral |  TASK [Output for sync deployment ComputeHCIAllNodesValidationDeployment] *******
2019-06-05 14:04:26,764 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:166
2019-06-05 14:04:26,765 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:26 -0500 (0:00:00.026)       0:01:00.534 ******** 
2019-06-05 14:04:26,838 p=17240 u=mistral |  ok: [lab-computehci-0] => {
    "msg": [
        {
            "stderr": [
                "[2019-06-05 19:04:25,696] (heat-config) [DEBUG] Running /usr/libexec/heat-config/hooks/script < /var/lib/heat-config/deployed/7a80ffe2-cd86-4f9c-9289-900c6e01587f.json", 
                "[2019-06-05 19:04:26,415] (heat-config) [INFO] |-", 
                "  {\"deploy_stdout\": \"Trying to ping default gateway 192.168.122.1...Ping to 192.168.122.1 succeeded.\\nSUCCESS\\nTrying to ping 172.16.0.133 for local network 172.16.0.0/24.\\nPing to 172.16.0.133 succeeded.\\nSUCCESS\\nTrying to ping 172.16.1.107 for local network 172.16.1.0/24.\\nPing to 172.16.1.107 succeeded.\\nSUCCESS\\nTrying to ping 172.16.2.227 for local network 172.16.2.0/24.\\nPing to 172.16.2.227 succeeded.\\nSUCCESS\\nTrying to ping 172.16.3.54 for local network 172.16.3.0/24.\\nPing to 172.16.3.54 succeeded.\\nSUCCESS\\nTrying to ping 192.168.24.17 for local network 192.168.24.0/24.\\nPing to 192.168.24.17 succeeded.\\nSUCCESS\\n\", \"deploy_stderr\": \"\", \"deploy_status_code\": 0}", 
                "", 
                "[2019-06-05 19:04:26,415] (heat-config) [DEBUG] [2019-06-05 19:04:25,708] (heat-config) [INFO] ping_test_ips=192.168.24.17 172.16.1.107 172.16.3.54 172.16.2.227 172.16.0.133", 
                "[2019-06-05 19:04:25,708] (heat-config) [INFO] validate_fqdn=False", 
                "[2019-06-05 19:04:25,708] (heat-config) [INFO] validate_ntp=True", 
                "[2019-06-05 19:04:25,709] (heat-config) [INFO] validate_controllers_icmp=True", 
                "[2019-06-05 19:04:25,709] (heat-config) [INFO] validate_gateways_icmp=True", 
                "[2019-06-05 19:04:25,709] (heat-config) [INFO] deploy_server_id=97f857d8-5e72-44c1-aebf-24385a2d79de", 
                "[2019-06-05 19:04:25,709] (heat-config) [INFO] deploy_action=CREATE", 
                "[2019-06-05 19:04:25,709] (heat-config) [INFO] deploy_stack_id=lab-ComputeHCIAllNodesValidationDeployment-s5kf2ql2jtbq-0-avn5feupjlsa/0e267139-0f5f-4a53-975a-9ff6831ecb62", 
                "[2019-06-05 19:04:25,709] (heat-config) [INFO] deploy_resource_name=TripleOSoftwareDeployment", 
                "[2019-06-05 19:04:25,709] (heat-config) [INFO] deploy_signal_transport=NO_SIGNAL", 
                "[2019-06-05 19:04:25,709] (heat-config) [DEBUG] Running /var/lib/heat-config/heat-config-script/7a80ffe2-cd86-4f9c-9289-900c6e01587f", 
                "[2019-06-05 19:04:26,412] (heat-config) [INFO] Trying to ping default gateway 192.168.122.1...Ping to 192.168.122.1 succeeded.", 
                "SUCCESS", 
                "Trying to ping 172.16.0.133 for local network 172.16.0.0/24.", 
                "Ping to 172.16.0.133 succeeded.", 
                "SUCCESS", 
                "Trying to ping 172.16.1.107 for local network 172.16.1.0/24.", 
                "Ping to 172.16.1.107 succeeded.", 
                "SUCCESS", 
                "Trying to ping 172.16.2.227 for local network 172.16.2.0/24.", 
                "Ping to 172.16.2.227 succeeded.", 
                "SUCCESS", 
                "Trying to ping 172.16.3.54 for local network 172.16.3.0/24.", 
                "Ping to 172.16.3.54 succeeded.", 
                "SUCCESS", 
                "Trying to ping 192.168.24.17 for local network 192.168.24.0/24.", 
                "Ping to 192.168.24.17 succeeded.", 
                "SUCCESS", 
                "", 
                "[2019-06-05 19:04:26,412] (heat-config) [DEBUG] ", 
                "[2019-06-05 19:04:26,412] (heat-config) [INFO] Completed /var/lib/heat-config/heat-config-script/7a80ffe2-cd86-4f9c-9289-900c6e01587f", 
                "", 
                "[2019-06-05 19:04:26,415] (heat-config) [INFO] Completed /usr/libexec/heat-config/hooks/script", 
                "[2019-06-05 19:04:26,415] (heat-config) [DEBUG] Running heat-config-notify /var/lib/heat-config/deployed/7a80ffe2-cd86-4f9c-9289-900c6e01587f.json < /var/lib/heat-config/deployed/7a80ffe2-cd86-4f9c-9289-900c6e01587f.notify.json", 
                "[2019-06-05 19:04:26,707] (heat-config) [INFO] ", 
                "[2019-06-05 19:04:26,707] (heat-config) [DEBUG] "
            ]
        }, 
        {
            "status_code": "0"
        }
    ]
}
2019-06-05 14:04:26,838 p=17240 u=mistral |  META: noop
2019-06-05 14:04:26,855 p=17240 u=mistral |  TASK [Output for async deployment ComputeHCIAllNodesValidationDeployment] ******
2019-06-05 14:04:26,855 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:176
2019-06-05 14:04:26,855 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:26 -0500 (0:00:00.090)       0:01:00.625 ******** 
2019-06-05 14:04:26,867 p=17240 u=mistral |  skipping: [lab-computehci-0] => {}
2019-06-05 14:04:26,867 p=17240 u=mistral |  META: noop
2019-06-05 14:04:26,883 p=17240 u=mistral |  TASK [Check-mode for Run deployment ComputeHCIAllNodesValidationDeployment (changed status indicates deployment would run)] ***
2019-06-05 14:04:26,883 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:186
2019-06-05 14:04:26,883 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:26 -0500 (0:00:00.027)       0:01:00.652 ******** 
2019-06-05 14:04:26,892 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:26,892 p=17240 u=mistral |  META: noop
2019-06-05 14:04:26,907 p=17240 u=mistral |  TASK [Lookup deployment UUID] **************************************************
2019-06-05 14:04:26,907 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:1
2019-06-05 14:04:26,907 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:26 -0500 (0:00:00.024)       0:01:00.676 ******** 
2019-06-05 14:04:26,982 p=17240 u=mistral |  ok: [lab-computehci-0] => {"ansible_facts": {"deployment_uuid": "0d795f97-9e0a-418f-88d9-c7e827343757"}, "changed": false}
2019-06-05 14:04:26,983 p=17240 u=mistral |  META: noop
2019-06-05 14:04:26,997 p=17240 u=mistral |  TASK [Lookup deployment group] *************************************************
2019-06-05 14:04:26,997 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:5
2019-06-05 14:04:26,997 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:26 -0500 (0:00:00.090)       0:01:00.766 ******** 
2019-06-05 14:04:27,070 p=17240 u=mistral |  ok: [lab-computehci-0] => {"ansible_facts": {"deployment_group": "script"}, "changed": false}
2019-06-05 14:04:27,071 p=17240 u=mistral |  META: noop
2019-06-05 14:04:27,085 p=17240 u=mistral |  TASK [Create hiera check-mode directory] ***************************************
2019-06-05 14:04:27,085 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:13
2019-06-05 14:04:27,085 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:27 -0500 (0:00:00.088)       0:01:00.855 ******** 
2019-06-05 14:04:27,097 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:27,097 p=17240 u=mistral |  META: noop
2019-06-05 14:04:27,111 p=17240 u=mistral |  TASK [Create deployed check-mode directory] ************************************
2019-06-05 14:04:27,111 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:19
2019-06-05 14:04:27,112 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:27 -0500 (0:00:00.026)       0:01:00.881 ******** 
2019-06-05 14:04:27,123 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:27,123 p=17240 u=mistral |  META: noop
2019-06-05 14:04:27,137 p=17240 u=mistral |  TASK [Create tripleo-config-download check-mode directory] *********************
2019-06-05 14:04:27,137 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:25
2019-06-05 14:04:27,138 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:27 -0500 (0:00:00.025)       0:01:00.907 ******** 
2019-06-05 14:04:27,149 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:27,149 p=17240 u=mistral |  META: noop
2019-06-05 14:04:27,165 p=17240 u=mistral |  TASK [Render deployment file for ComputeHCIArtifactsDeploy for check-mode] *****
2019-06-05 14:04:27,165 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:31
2019-06-05 14:04:27,165 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:27 -0500 (0:00:00.027)       0:01:00.934 ******** 
2019-06-05 14:04:27,175 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:27,176 p=17240 u=mistral |  META: noop
2019-06-05 14:04:27,190 p=17240 u=mistral |  TASK [Run hiera deployment for check mode] *************************************
2019-06-05 14:04:27,190 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:38
2019-06-05 14:04:27,190 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:27 -0500 (0:00:00.025)       0:01:00.959 ******** 
2019-06-05 14:04:27,201 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:27,202 p=17240 u=mistral |  META: noop
2019-06-05 14:04:27,216 p=17240 u=mistral |  TASK [List hieradata files for check mode] *************************************
2019-06-05 14:04:27,216 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:54
2019-06-05 14:04:27,216 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:27 -0500 (0:00:00.026)       0:01:00.985 ******** 
2019-06-05 14:04:27,226 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:27,227 p=17240 u=mistral |  META: noop
2019-06-05 14:04:27,241 p=17240 u=mistral |  TASK [diff hieradata changes for check mode] ***********************************
2019-06-05 14:04:27,241 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:60
2019-06-05 14:04:27,241 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:27 -0500 (0:00:00.024)       0:01:01.010 ******** 
2019-06-05 14:04:27,254 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:27,254 p=17240 u=mistral |  META: noop
2019-06-05 14:04:27,268 p=17240 u=mistral |  TASK [diff hieradata changes for check mode] ***********************************
2019-06-05 14:04:27,268 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:73
2019-06-05 14:04:27,268 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:27 -0500 (0:00:00.027)       0:01:01.037 ******** 
2019-06-05 14:04:27,280 p=17240 u=mistral |  skipping: [lab-computehci-0] => {}
2019-06-05 14:04:27,281 p=17240 u=mistral |  META: noop
2019-06-05 14:04:27,295 p=17240 u=mistral |  TASK [hiera.yaml changes for check mode] ***************************************
2019-06-05 14:04:27,295 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:82
2019-06-05 14:04:27,296 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:27 -0500 (0:00:00.027)       0:01:01.065 ******** 
2019-06-05 14:04:27,306 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:27,307 p=17240 u=mistral |  META: noop
2019-06-05 14:04:27,320 p=17240 u=mistral |  TASK [diff hiera.yaml changes for check mode] **********************************
2019-06-05 14:04:27,320 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:90
2019-06-05 14:04:27,321 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:27 -0500 (0:00:00.024)       0:01:01.090 ******** 
2019-06-05 14:04:27,331 p=17240 u=mistral |  skipping: [lab-computehci-0] => {}
2019-06-05 14:04:27,331 p=17240 u=mistral |  META: noop
2019-06-05 14:04:27,346 p=17240 u=mistral |  TASK [Render deployment file for ComputeHCIArtifactsDeploy] ********************
2019-06-05 14:04:27,347 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:102
2019-06-05 14:04:27,347 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:27 -0500 (0:00:00.026)       0:01:01.116 ******** 
2019-06-05 14:04:27,688 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "checksum": "8ae0a532dd3f488f94721348e41bd597eabfa5a6", "dest": "/var/lib/heat-config/tripleo-config-download/ComputeHCIArtifactsDeploy-0d795f97-9e0a-418f-88d9-c7e827343757", "gid": 0, "group": "root", "md5sum": "cfc51c510a85840ad0b55190aa4118c6", "mode": "0644", "owner": "root", "secontext": "system_u:object_r:var_lib_t:s0", "size": 2015, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559761467.42-43229647242908/source", "state": "file", "uid": 0}
2019-06-05 14:04:27,689 p=17240 u=mistral |  META: noop
2019-06-05 14:04:27,705 p=17240 u=mistral |  TASK [Check if deployed file exists for ComputeHCIArtifactsDeploy] *************
2019-06-05 14:04:27,705 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:108
2019-06-05 14:04:27,705 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:27 -0500 (0:00:00.358)       0:01:01.474 ******** 
2019-06-05 14:04:27,849 p=17240 u=mistral |  ok: [lab-computehci-0] => {"changed": false, "stat": {"exists": false}}
2019-06-05 14:04:27,850 p=17240 u=mistral |  META: noop
2019-06-05 14:04:27,865 p=17240 u=mistral |  TASK [Check previous deployment rc for ComputeHCIArtifactsDeploy] **************
2019-06-05 14:04:27,865 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:113
2019-06-05 14:04:27,866 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:27 -0500 (0:00:00.160)       0:01:01.635 ******** 
2019-06-05 14:04:27,877 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:27,877 p=17240 u=mistral |  META: noop
2019-06-05 14:04:27,893 p=17240 u=mistral |  TASK [Remove deployed file for ComputeHCIArtifactsDeploy when previous deployment failed] ***
2019-06-05 14:04:27,893 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:121
2019-06-05 14:04:27,893 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:27 -0500 (0:00:00.027)       0:01:01.662 ******** 
2019-06-05 14:04:27,905 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:27,906 p=17240 u=mistral |  META: noop
2019-06-05 14:04:27,921 p=17240 u=mistral |  TASK [Force remove deployed file for ComputeHCIArtifactsDeploy] ****************
2019-06-05 14:04:27,921 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:131
2019-06-05 14:04:27,921 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:27 -0500 (0:00:00.028)       0:01:01.691 ******** 
2019-06-05 14:04:27,932 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:27,933 p=17240 u=mistral |  META: noop
2019-06-05 14:04:27,947 p=17240 u=mistral |  TASK [Set fact for async_deployment] *******************************************
2019-06-05 14:04:27,947 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:138
2019-06-05 14:04:27,948 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:27 -0500 (0:00:00.026)       0:01:01.717 ******** 
2019-06-05 14:04:28,017 p=17240 u=mistral |  ok: [lab-computehci-0] => {"ansible_facts": {"use_async_deployment": false}, "changed": false}
2019-06-05 14:04:28,018 p=17240 u=mistral |  META: noop
2019-06-05 14:04:28,033 p=17240 u=mistral |  TASK [Run deployment ComputeHCIArtifactsDeploy] ********************************
2019-06-05 14:04:28,033 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:142
2019-06-05 14:04:28,033 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:28 -0500 (0:00:00.085)       0:01:01.802 ******** 
2019-06-05 14:04:28,481 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "cmd": "/usr/libexec/os-refresh-config/configure.d/55-heat-config\n exit $(jq .deploy_status_code /var/lib/heat-config/deployed/0d795f97-9e0a-418f-88d9-c7e827343757.notify.json)", "delta": "0:00:00.341333", "end": "2019-06-05 19:04:28.472345", "rc": 0, "start": "2019-06-05 19:04:28.131012", "stderr": "[2019-06-05 19:04:28,156] (heat-config) [DEBUG] Running /usr/libexec/heat-config/hooks/script < /var/lib/heat-config/deployed/0d795f97-9e0a-418f-88d9-c7e827343757.json\n[2019-06-05 19:04:28,175] (heat-config) [INFO] |-\n  {\"deploy_stdout\": \"No artifact_urls was set. Skipping...\\n\", \"deploy_stderr\": \"\", \"deploy_status_code\": 0}\n\n[2019-06-05 19:04:28,175] (heat-config) [DEBUG] [2019-06-05 19:04:28,168] (heat-config) [INFO] artifact_urls=\n[2019-06-05 19:04:28,169] (heat-config) [INFO] deploy_server_id=97f857d8-5e72-44c1-aebf-24385a2d79de\n[2019-06-05 19:04:28,169] (heat-config) [INFO] deploy_action=CREATE\n[2019-06-05 19:04:28,169] (heat-config) [INFO] deploy_stack_id=lab-AllNodesDeploySteps-vnf37mzchjlf-ComputeHCIArtifactsDeploy-zlk4vest4o6z-0-hgoltkpsfbu6/4e0458ea-e1e5-41e3-baaf-d8a3006cc0d3\n[2019-06-05 19:04:28,169] (heat-config) [INFO] deploy_resource_name=TripleOSoftwareDeployment\n[2019-06-05 19:04:28,169] (heat-config) [INFO] deploy_signal_transport=NO_SIGNAL\n[2019-06-05 19:04:28,169] (heat-config) [DEBUG] Running /var/lib/heat-config/heat-config-script/0d795f97-9e0a-418f-88d9-c7e827343757\n[2019-06-05 19:04:28,172] (heat-config) [INFO] No artifact_urls was set. Skipping...\n\n[2019-06-05 19:04:28,173] (heat-config) [DEBUG] \n[2019-06-05 19:04:28,173] (heat-config) [INFO] Completed /var/lib/heat-config/heat-config-script/0d795f97-9e0a-418f-88d9-c7e827343757\n\n[2019-06-05 19:04:28,175] (heat-config) [INFO] Completed /usr/libexec/heat-config/hooks/script\n[2019-06-05 19:04:28,175] (heat-config) [DEBUG] Running heat-config-notify /var/lib/heat-config/deployed/0d795f97-9e0a-418f-88d9-c7e827343757.json < /var/lib/heat-config/deployed/0d795f97-9e0a-418f-88d9-c7e827343757.notify.json\n[2019-06-05 19:04:28,465] (heat-config) [INFO] \n[2019-06-05 19:04:28,466] (heat-config) [DEBUG] ", "stderr_lines": ["[2019-06-05 19:04:28,156] (heat-config) [DEBUG] Running /usr/libexec/heat-config/hooks/script < /var/lib/heat-config/deployed/0d795f97-9e0a-418f-88d9-c7e827343757.json", "[2019-06-05 19:04:28,175] (heat-config) [INFO] |-", "  {\"deploy_stdout\": \"No artifact_urls was set. Skipping...\\n\", \"deploy_stderr\": \"\", \"deploy_status_code\": 0}", "", "[2019-06-05 19:04:28,175] (heat-config) [DEBUG] [2019-06-05 19:04:28,168] (heat-config) [INFO] artifact_urls=", "[2019-06-05 19:04:28,169] (heat-config) [INFO] deploy_server_id=97f857d8-5e72-44c1-aebf-24385a2d79de", "[2019-06-05 19:04:28,169] (heat-config) [INFO] deploy_action=CREATE", "[2019-06-05 19:04:28,169] (heat-config) [INFO] deploy_stack_id=lab-AllNodesDeploySteps-vnf37mzchjlf-ComputeHCIArtifactsDeploy-zlk4vest4o6z-0-hgoltkpsfbu6/4e0458ea-e1e5-41e3-baaf-d8a3006cc0d3", "[2019-06-05 19:04:28,169] (heat-config) [INFO] deploy_resource_name=TripleOSoftwareDeployment", "[2019-06-05 19:04:28,169] (heat-config) [INFO] deploy_signal_transport=NO_SIGNAL", "[2019-06-05 19:04:28,169] (heat-config) [DEBUG] Running /var/lib/heat-config/heat-config-script/0d795f97-9e0a-418f-88d9-c7e827343757", "[2019-06-05 19:04:28,172] (heat-config) [INFO] No artifact_urls was set. Skipping...", "", "[2019-06-05 19:04:28,173] (heat-config) [DEBUG] ", "[2019-06-05 19:04:28,173] (heat-config) [INFO] Completed /var/lib/heat-config/heat-config-script/0d795f97-9e0a-418f-88d9-c7e827343757", "", "[2019-06-05 19:04:28,175] (heat-config) [INFO] Completed /usr/libexec/heat-config/hooks/script", "[2019-06-05 19:04:28,175] (heat-config) [DEBUG] Running heat-config-notify /var/lib/heat-config/deployed/0d795f97-9e0a-418f-88d9-c7e827343757.json < /var/lib/heat-config/deployed/0d795f97-9e0a-418f-88d9-c7e827343757.notify.json", "[2019-06-05 19:04:28,465] (heat-config) [INFO] ", "[2019-06-05 19:04:28,466] (heat-config) [DEBUG] "], "stdout": "", "stdout_lines": []}
2019-06-05 14:04:28,481 p=17240 u=mistral |  META: noop
2019-06-05 14:04:28,496 p=17240 u=mistral |  TASK [Run async deployment ComputeHCIArtifactsDeploy] **************************
2019-06-05 14:04:28,497 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:153
2019-06-05 14:04:28,497 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:28 -0500 (0:00:00.463)       0:01:02.266 ******** 
2019-06-05 14:04:28,506 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:28,506 p=17240 u=mistral |  META: noop
2019-06-05 14:04:28,521 p=17240 u=mistral |  TASK [Output for sync deployment ComputeHCIArtifactsDeploy] ********************
2019-06-05 14:04:28,521 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:166
2019-06-05 14:04:28,522 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:28 -0500 (0:00:00.024)       0:01:02.291 ******** 
2019-06-05 14:04:28,596 p=17240 u=mistral |  ok: [lab-computehci-0] => {
    "msg": [
        {
            "stderr": [
                "[2019-06-05 19:04:28,156] (heat-config) [DEBUG] Running /usr/libexec/heat-config/hooks/script < /var/lib/heat-config/deployed/0d795f97-9e0a-418f-88d9-c7e827343757.json", 
                "[2019-06-05 19:04:28,175] (heat-config) [INFO] |-", 
                "  {\"deploy_stdout\": \"No artifact_urls was set. Skipping...\\n\", \"deploy_stderr\": \"\", \"deploy_status_code\": 0}", 
                "", 
                "[2019-06-05 19:04:28,175] (heat-config) [DEBUG] [2019-06-05 19:04:28,168] (heat-config) [INFO] artifact_urls=", 
                "[2019-06-05 19:04:28,169] (heat-config) [INFO] deploy_server_id=97f857d8-5e72-44c1-aebf-24385a2d79de", 
                "[2019-06-05 19:04:28,169] (heat-config) [INFO] deploy_action=CREATE", 
                "[2019-06-05 19:04:28,169] (heat-config) [INFO] deploy_stack_id=lab-AllNodesDeploySteps-vnf37mzchjlf-ComputeHCIArtifactsDeploy-zlk4vest4o6z-0-hgoltkpsfbu6/4e0458ea-e1e5-41e3-baaf-d8a3006cc0d3", 
                "[2019-06-05 19:04:28,169] (heat-config) [INFO] deploy_resource_name=TripleOSoftwareDeployment", 
                "[2019-06-05 19:04:28,169] (heat-config) [INFO] deploy_signal_transport=NO_SIGNAL", 
                "[2019-06-05 19:04:28,169] (heat-config) [DEBUG] Running /var/lib/heat-config/heat-config-script/0d795f97-9e0a-418f-88d9-c7e827343757", 
                "[2019-06-05 19:04:28,172] (heat-config) [INFO] No artifact_urls was set. Skipping...", 
                "", 
                "[2019-06-05 19:04:28,173] (heat-config) [DEBUG] ", 
                "[2019-06-05 19:04:28,173] (heat-config) [INFO] Completed /var/lib/heat-config/heat-config-script/0d795f97-9e0a-418f-88d9-c7e827343757", 
                "", 
                "[2019-06-05 19:04:28,175] (heat-config) [INFO] Completed /usr/libexec/heat-config/hooks/script", 
                "[2019-06-05 19:04:28,175] (heat-config) [DEBUG] Running heat-config-notify /var/lib/heat-config/deployed/0d795f97-9e0a-418f-88d9-c7e827343757.json < /var/lib/heat-config/deployed/0d795f97-9e0a-418f-88d9-c7e827343757.notify.json", 
                "[2019-06-05 19:04:28,465] (heat-config) [INFO] ", 
                "[2019-06-05 19:04:28,466] (heat-config) [DEBUG] "
            ]
        }, 
        {
            "status_code": "0"
        }
    ]
}
2019-06-05 14:04:28,597 p=17240 u=mistral |  META: noop
2019-06-05 14:04:28,614 p=17240 u=mistral |  TASK [Output for async deployment ComputeHCIArtifactsDeploy] *******************
2019-06-05 14:04:28,614 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:176
2019-06-05 14:04:28,614 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:28 -0500 (0:00:00.092)       0:01:02.384 ******** 
2019-06-05 14:04:28,626 p=17240 u=mistral |  skipping: [lab-computehci-0] => {}
2019-06-05 14:04:28,626 p=17240 u=mistral |  META: noop
2019-06-05 14:04:28,641 p=17240 u=mistral |  TASK [Check-mode for Run deployment ComputeHCIArtifactsDeploy (changed status indicates deployment would run)] ***
2019-06-05 14:04:28,641 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deployments.yaml:186
2019-06-05 14:04:28,642 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:28 -0500 (0:00:00.027)       0:01:02.411 ******** 
2019-06-05 14:04:28,652 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:28,652 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:04:28,653 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:04:28,657 p=17240 u=mistral |  PLAY [Host prep steps] *********************************************************
2019-06-05 14:04:28,669 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:04:28,684 p=17240 u=mistral |  TASK [create persistent logs directory] ****************************************
2019-06-05 14:04:28,684 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:1
2019-06-05 14:04:28,684 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:28 -0500 (0:00:00.042)       0:01:02.454 ******** 
2019-06-05 14:04:28,718 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/containers/aodh', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/containers/aodh", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:28,725 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/containers/httpd/aodh-api', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/containers/httpd/aodh-api", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:28,727 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/aodh', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/aodh", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:28,839 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/containers/aodh', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/containers/aodh", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/containers/aodh", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:28,924 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/containers/httpd/aodh-api', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/containers/httpd/aodh-api", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/containers/httpd/aodh-api", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:29,012 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/aodh', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/aodh", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/aodh", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:29,030 p=17240 u=mistral |  TASK [aodh logs readme] ********************************************************
2019-06-05 14:04:29,031 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:13
2019-06-05 14:04:29,031 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:29 -0500 (0:00:00.346)       0:01:02.800 ******** 
2019-06-05 14:04:29,061 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:29,359 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "checksum": "b6cf6dbe054f430c33d39c1a1a88593536d6e659", "dest": "/var/log/aodh/readme.txt", "gid": 0, "group": "root", "md5sum": "796abd23c8439668f80418e57132463f", "mode": "0644", "owner": "root", "secontext": "system_u:object_r:var_log_t:s0", "size": 115, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559761469.1-90628781312860/source", "state": "file", "uid": 0}
2019-06-05 14:04:29,376 p=17240 u=mistral |  TASK [create persistent directories] *******************************************
2019-06-05 14:04:29,376 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:22
2019-06-05 14:04:29,376 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:29 -0500 (0:00:00.345)       0:01:03.146 ******** 
2019-06-05 14:04:29,411 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/containers/aodh', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/containers/aodh", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:29,414 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/aodh', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/aodh", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:29,531 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/containers/aodh', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/containers/aodh", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/containers/aodh", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:29,619 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/aodh', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/aodh", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/aodh", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 24, "state": "directory", "uid": 0}
2019-06-05 14:04:29,636 p=17240 u=mistral |  TASK [create persistent directories] *******************************************
2019-06-05 14:04:29,636 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:32
2019-06-05 14:04:29,637 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:29 -0500 (0:00:00.260)       0:01:03.406 ******** 
2019-06-05 14:04:29,679 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/ceilometer', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/ceilometer", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:29,684 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/containers/ceilometer', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/containers/ceilometer", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:29,814 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/ceilometer', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/ceilometer", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/ceilometer", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:29,895 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/containers/ceilometer', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/containers/ceilometer", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/containers/ceilometer", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:29,912 p=17240 u=mistral |  TASK [ceilometer logs readme] **************************************************
2019-06-05 14:04:29,912 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:42
2019-06-05 14:04:29,912 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:29 -0500 (0:00:00.275)       0:01:03.681 ******** 
2019-06-05 14:04:29,942 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:30,242 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "checksum": "ddd9b447be4ffb7bbfc2fa4cf7f104a4e7b2a6f3", "dest": "/var/log/ceilometer/readme.txt", "gid": 0, "group": "root", "md5sum": "ee2022bdaec66717a669185c935b18d9", "mode": "0644", "owner": "root", "secontext": "system_u:object_r:var_log_t:s0", "size": 88, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559761469.98-92332097735209/source", "state": "file", "uid": 0}
2019-06-05 14:04:30,258 p=17240 u=mistral |  TASK [create persistent directories] *******************************************
2019-06-05 14:04:30,259 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:51
2019-06-05 14:04:30,259 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:30 -0500 (0:00:00.346)       0:01:04.028 ******** 
2019-06-05 14:04:30,293 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/containers/ceilometer', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/containers/ceilometer", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:30,296 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/ceilometer', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/ceilometer", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:30,414 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/containers/ceilometer', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/containers/ceilometer", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/containers/ceilometer", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:30,499 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/ceilometer', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/ceilometer", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/ceilometer", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 24, "state": "directory", "uid": 0}
2019-06-05 14:04:30,518 p=17240 u=mistral |  TASK [enable virt_sandbox_use_netlink for healthcheck] *************************
2019-06-05 14:04:30,518 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:61
2019-06-05 14:04:30,518 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:30 -0500 (0:00:00.259)       0:01:04.287 ******** 
2019-06-05 14:04:30,547 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:31,147 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "name": "virt_sandbox_use_netlink"}
2019-06-05 14:04:31,164 p=17240 u=mistral |  TASK [create persistent directories] *******************************************
2019-06-05 14:04:31,164 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:66
2019-06-05 14:04:31,164 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:31 -0500 (0:00:00.645)       0:01:04.933 ******** 
2019-06-05 14:04:31,198 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/containers/cinder', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/containers/cinder", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:31,201 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/containers/httpd/cinder-api', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/containers/httpd/cinder-api", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:31,204 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/cinder', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/cinder", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:31,327 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/containers/cinder', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/containers/cinder", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/containers/cinder", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:31,414 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/containers/httpd/cinder-api', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/containers/httpd/cinder-api", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/containers/httpd/cinder-api", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:31,499 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/cinder', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/cinder", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/cinder", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:31,517 p=17240 u=mistral |  TASK [cinder logs readme] ******************************************************
2019-06-05 14:04:31,517 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:78
2019-06-05 14:04:31,517 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:31 -0500 (0:00:00.353)       0:01:05.286 ******** 
2019-06-05 14:04:31,547 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:31,844 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "checksum": "0a3814f5aad089ba842c13ffc2c7bb7a7b3e8292", "dest": "/var/log/cinder/readme.txt", "gid": 0, "group": "root", "md5sum": "9611ca9ca6ebd825a9ed036cd6c4bb6e", "mode": "0644", "owner": "root", "secontext": "system_u:object_r:cinder_log_t:s0", "size": 121, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559761471.58-147211058005703/source", "state": "file", "uid": 0}
2019-06-05 14:04:31,861 p=17240 u=mistral |  TASK [create persistent directories] *******************************************
2019-06-05 14:04:31,861 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:87
2019-06-05 14:04:31,861 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:31 -0500 (0:00:00.344)       0:01:05.631 ******** 
2019-06-05 14:04:31,894 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/containers/cinder', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/containers/cinder", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:31,897 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/cinder', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/cinder", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:32,014 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/containers/cinder', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/containers/cinder", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/containers/cinder", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:32,099 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/cinder', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/cinder", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/cinder", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 24, "state": "directory", "uid": 0}
2019-06-05 14:04:32,116 p=17240 u=mistral |  TASK [create persistent directories] *******************************************
2019-06-05 14:04:32,116 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:97
2019-06-05 14:04:32,116 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:32 -0500 (0:00:00.254)       0:01:05.886 ******** 
2019-06-05 14:04:32,149 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/containers/cinder', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/containers/cinder", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:32,159 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/lib/cinder', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/lib/cinder", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:32,159 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/cinder', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/cinder", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:32,269 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/containers/cinder', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/containers/cinder", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/containers/cinder", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:32,357 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/lib/cinder', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/lib/cinder", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/lib/cinder", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:32,442 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/cinder', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/cinder", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/cinder", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 24, "state": "directory", "uid": 0}
2019-06-05 14:04:32,459 p=17240 u=mistral |  TASK [ensure ceph configurations exist] ****************************************
2019-06-05 14:04:32,459 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:109
2019-06-05 14:04:32,459 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:32 -0500 (0:00:00.343)       0:01:06.229 ******** 
2019-06-05 14:04:32,492 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:32,610 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "gid": 0, "group": "root", "mode": "0755", "owner": "root", "path": "/etc/ceph", "secontext": "unconfined_u:object_r:etc_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:32,627 p=17240 u=mistral |  TASK [cinder_enable_iscsi_backend fact] ****************************************
2019-06-05 14:04:32,627 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:113
2019-06-05 14:04:32,627 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:32 -0500 (0:00:00.167)       0:01:06.396 ******** 
2019-06-05 14:04:32,657 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:32,698 p=17240 u=mistral |  ok: [lab-controller-0] => {"ansible_facts": {"cinder_enable_iscsi_backend": false}, "changed": false}
2019-06-05 14:04:32,715 p=17240 u=mistral |  TASK [ensure LVM rpm dependencies are installed] *******************************
2019-06-05 14:04:32,715 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:117
2019-06-05 14:04:32,715 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:32 -0500 (0:00:00.087)       0:01:06.484 ******** 
2019-06-05 14:04:32,735 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:32,742 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:32,759 p=17240 u=mistral |  TASK [cinder create LVM volume group dd] ***************************************
2019-06-05 14:04:32,759 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:121
2019-06-05 14:04:32,759 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:32 -0500 (0:00:00.044)       0:01:06.528 ******** 
2019-06-05 14:04:32,780 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:32,788 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:32,805 p=17240 u=mistral |  TASK [cinder create LVM volume group] ******************************************
2019-06-05 14:04:32,805 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:125
2019-06-05 14:04:32,806 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:32 -0500 (0:00:00.046)       0:01:06.575 ******** 
2019-06-05 14:04:32,825 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:32,833 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:32,850 p=17240 u=mistral |  TASK [cinder create service to run losetup for LVM on startup] *****************
2019-06-05 14:04:32,850 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:133
2019-06-05 14:04:32,850 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:32 -0500 (0:00:00.044)       0:01:06.619 ******** 
2019-06-05 14:04:32,870 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:32,877 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:32,894 p=17240 u=mistral |  TASK [cinder enable the LVM losetup service] ***********************************
2019-06-05 14:04:32,894 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:160
2019-06-05 14:04:32,894 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:32 -0500 (0:00:00.044)       0:01:06.664 ******** 
2019-06-05 14:04:32,914 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:32,921 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:32,938 p=17240 u=mistral |  TASK [set_fact] ****************************************************************
2019-06-05 14:04:32,938 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:167
2019-06-05 14:04:32,938 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:32 -0500 (0:00:00.044)       0:01:06.708 ******** 
2019-06-05 14:04:32,968 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:33,009 p=17240 u=mistral |  ok: [lab-controller-0] => {"ansible_facts": {"container_registry_additional_sockets": ["/var/lib/openstack/docker.sock"], "container_registry_debug": false, "container_registry_deployment_user": "", "container_registry_docker_options": "--log-driver=journald --signature-verification=false --iptables=false --live-restore", "container_registry_insecure_registries": [], "container_registry_mirror": "", "container_registry_network_options": "--bip=172.31.0.1/24", "container_registry_selinux": true, "container_registry_skip_reconfiguration": false}, "changed": false}
2019-06-05 14:04:33,026 p=17240 u=mistral |  TASK [include_role : container-registry] ***************************************
2019-06-05 14:04:33,026 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:179
2019-06-05 14:04:33,026 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:33 -0500 (0:00:00.087)       0:01:06.795 ******** 
2019-06-05 14:04:33,055 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:33,153 p=17240 u=mistral |  TASK [container-registry : Check that the configuration mark exists in /etc/sysconfig/docker] ***
2019-06-05 14:04:33,153 p=17240 u=mistral |  task path: /usr/share/ansible/roles/container-registry/tasks/docker.yml:7
2019-06-05 14:04:33,153 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:33 -0500 (0:00:00.127)       0:01:06.923 ******** 
2019-06-05 14:04:33,156 p=17240 u=mistral |  META: noop
2019-06-05 14:04:33,272 p=17240 u=mistral |  ok: [lab-controller-0] => {"changed": false, "cmd": ["grep", "-Fq", "# Configured by Ansible container registry role", "/etc/sysconfig/docker"], "delta": "0:00:00.002651", "end": "2019-06-05 19:04:33.256518", "failed_when_result": false, "msg": "non-zero return code", "rc": 1, "start": "2019-06-05 19:04:33.253867", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}
2019-06-05 14:04:33,290 p=17240 u=mistral |  TASK [container-registry : enable net.ipv4.ip_forward] *************************
2019-06-05 14:04:33,291 p=17240 u=mistral |  task path: /usr/share/ansible/roles/container-registry/tasks/docker.yml:20
2019-06-05 14:04:33,291 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:33 -0500 (0:00:00.137)       0:01:07.060 ******** 
2019-06-05 14:04:33,293 p=17240 u=mistral |  META: noop
2019-06-05 14:04:33,490 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true}
2019-06-05 14:04:33,508 p=17240 u=mistral |  TASK [container-registry : Check if there are XFS volumes with ftype=0] ********
2019-06-05 14:04:33,508 p=17240 u=mistral |  task path: /usr/share/ansible/roles/container-registry/tasks/docker.yml:30
2019-06-05 14:04:33,508 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:33 -0500 (0:00:00.217)       0:01:07.277 ******** 
2019-06-05 14:04:33,510 p=17240 u=mistral |  META: noop
2019-06-05 14:04:33,624 p=17240 u=mistral |  ok: [lab-controller-0] => {"changed": false, "cmd": "for dev in $(df -h | grep '/dev/' | grep -v 'tmp' | cut -d' ' -f1)\n do\n parseftype=$(xfs_info $dev | grep ftype=0);\n if [[ ! -z \"$parseftype\" ]]; then\n ftype=\"ftype=0\";\n break;\n fi\n done\n echo $ftype;", "delta": "0:00:00.008398", "end": "2019-06-05 19:04:33.614186", "rc": 0, "start": "2019-06-05 19:04:33.605788", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}
2019-06-05 14:04:33,643 p=17240 u=mistral |  TASK [container-registry : Check ftype] ****************************************
2019-06-05 14:04:33,643 p=17240 u=mistral |  task path: /usr/share/ansible/roles/container-registry/tasks/docker.yml:44
2019-06-05 14:04:33,643 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:33 -0500 (0:00:00.135)       0:01:07.413 ******** 
2019-06-05 14:04:33,646 p=17240 u=mistral |  META: noop
2019-06-05 14:04:33,663 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:33,682 p=17240 u=mistral |  TASK [container-registry : ensure docker is installed] *************************
2019-06-05 14:04:33,682 p=17240 u=mistral |  task path: /usr/share/ansible/roles/container-registry/tasks/docker.yml:53
2019-06-05 14:04:33,683 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:33 -0500 (0:00:00.039)       0:01:07.452 ******** 
2019-06-05 14:04:33,685 p=17240 u=mistral |  META: noop
2019-06-05 14:04:33,958 p=17240 u=mistral |  ok: [lab-controller-0] => {"changed": false, "msg": "", "rc": 0, "results": ["2:docker-1.13.1-96.gitb2f74b2.el7.centos.x86_64 providing docker is already installed"]}
2019-06-05 14:04:33,975 p=17240 u=mistral |  TASK [container-registry : manage /etc/systemd/system/docker.service.d] ********
2019-06-05 14:04:33,975 p=17240 u=mistral |  task path: /usr/share/ansible/roles/container-registry/tasks/docker.yml:58
2019-06-05 14:04:33,976 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:33 -0500 (0:00:00.293)       0:01:07.745 ******** 
2019-06-05 14:04:33,977 p=17240 u=mistral |  META: noop
2019-06-05 14:04:34,088 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "gid": 0, "group": "root", "mode": "0755", "owner": "root", "path": "/etc/systemd/system/docker.service.d", "secontext": "unconfined_u:object_r:systemd_unit_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:34,104 p=17240 u=mistral |  TASK [container-registry : unset mountflags] ***********************************
2019-06-05 14:04:34,105 p=17240 u=mistral |  task path: /usr/share/ansible/roles/container-registry/tasks/docker.yml:64
2019-06-05 14:04:34,105 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:34 -0500 (0:00:00.129)       0:01:07.874 ******** 
2019-06-05 14:04:34,107 p=17240 u=mistral |  META: noop
2019-06-05 14:04:34,300 p=17240 u=mistral |   [WARNING]: Module remote_tmp /root/.ansible/tmp did not exist and was created
with a mode of 0700, this may cause issues when running as another user. To
avoid this, create the remote_tmp dir with the correct permissions manually

2019-06-05 14:04:34,300 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "gid": 0, "group": "root", "mode": "0644", "msg": "section and option added", "owner": "root", "path": "/etc/systemd/system/docker.service.d/99-unset-mountflags.conf", "secontext": "system_u:object_r:container_unit_file_t:s0", "size": 25, "state": "file", "uid": 0}
2019-06-05 14:04:34,316 p=17240 u=mistral |  TASK [container-registry : configure OPTIONS in /etc/sysconfig/docker] *********
2019-06-05 14:04:34,316 p=17240 u=mistral |  task path: /usr/share/ansible/roles/container-registry/tasks/docker.yml:74
2019-06-05 14:04:34,316 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:34 -0500 (0:00:00.211)       0:01:08.085 ******** 
2019-06-05 14:04:34,318 p=17240 u=mistral |  META: noop
2019-06-05 14:04:34,447 p=17240 u=mistral |  changed: [lab-controller-0] => {"backup": "", "changed": true, "msg": "line replaced"}
2019-06-05 14:04:34,464 p=17240 u=mistral |  TASK [container-registry : configure INSECURE_REGISTRY in /etc/sysconfig/docker] ***
2019-06-05 14:04:34,464 p=17240 u=mistral |  task path: /usr/share/ansible/roles/container-registry/tasks/docker.yml:82
2019-06-05 14:04:34,464 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:34 -0500 (0:00:00.147)       0:01:08.233 ******** 
2019-06-05 14:04:34,466 p=17240 u=mistral |  META: noop
2019-06-05 14:04:34,480 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:34,496 p=17240 u=mistral |  TASK [container-registry : Create additional socket directories] ***************
2019-06-05 14:04:34,496 p=17240 u=mistral |  task path: /usr/share/ansible/roles/container-registry/tasks/docker.yml:92
2019-06-05 14:04:34,496 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:34 -0500 (0:00:00.032)       0:01:08.266 ******** 
2019-06-05 14:04:34,498 p=17240 u=mistral |  META: noop
2019-06-05 14:04:34,614 p=17240 u=mistral |  changed: [lab-controller-0] => (item=/var/lib/openstack/docker.sock) => {"changed": true, "gid": 0, "group": "root", "item": "/var/lib/openstack/docker.sock", "mode": "0755", "owner": "root", "path": "/var/lib/openstack", "secontext": "unconfined_u:object_r:var_lib_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:34,652 p=17240 u=mistral |  TASK [container-registry : manage /etc/docker/daemon.json] *********************
2019-06-05 14:04:34,653 p=17240 u=mistral |  task path: /usr/share/ansible/roles/container-registry/tasks/docker.yml:100
2019-06-05 14:04:34,653 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:34 -0500 (0:00:00.156)       0:01:08.422 ******** 
2019-06-05 14:04:34,655 p=17240 u=mistral |  META: noop
2019-06-05 14:04:34,978 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "checksum": "e3daa85cf4ce54ae4bc7babe814c188ccc73a0c7", "dest": "/etc/docker/daemon.json", "gid": 0, "group": "root", "md5sum": "a3102ec9797a64d1a8262c7462c3d50d", "mode": "0644", "owner": "root", "secontext": "system_u:object_r:container_config_t:s0", "size": 21, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559761474.68-113741572604357/source", "state": "file", "uid": 0}
2019-06-05 14:04:34,994 p=17240 u=mistral |  TASK [container-registry : configure DOCKER_STORAGE_OPTIONS in /etc/sysconfig/docker-storage] ***
2019-06-05 14:04:34,994 p=17240 u=mistral |  task path: /usr/share/ansible/roles/container-registry/tasks/docker.yml:106
2019-06-05 14:04:34,994 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:34 -0500 (0:00:00.341)       0:01:08.763 ******** 
2019-06-05 14:04:34,996 p=17240 u=mistral |  META: noop
2019-06-05 14:04:35,123 p=17240 u=mistral |  changed: [lab-controller-0] => {"backup": "", "changed": true, "msg": "line replaced"}
2019-06-05 14:04:35,140 p=17240 u=mistral |  TASK [container-registry : configure DOCKER_NETWORK_OPTIONS in /etc/sysconfig/docker-network] ***
2019-06-05 14:04:35,140 p=17240 u=mistral |  task path: /usr/share/ansible/roles/container-registry/tasks/docker.yml:115
2019-06-05 14:04:35,140 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:35 -0500 (0:00:00.146)       0:01:08.910 ******** 
2019-06-05 14:04:35,143 p=17240 u=mistral |  META: noop
2019-06-05 14:04:35,275 p=17240 u=mistral |  changed: [lab-controller-0] => {"backup": "", "changed": true, "msg": "line replaced"}
2019-06-05 14:04:35,291 p=17240 u=mistral |  TASK [container-registry : ensure docker group exists] *************************
2019-06-05 14:04:35,291 p=17240 u=mistral |  task path: /usr/share/ansible/roles/container-registry/tasks/docker.yml:124
2019-06-05 14:04:35,291 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:35 -0500 (0:00:00.150)       0:01:09.060 ******** 
2019-06-05 14:04:35,293 p=17240 u=mistral |  META: noop
2019-06-05 14:04:35,522 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "gid": 1003, "name": "docker", "state": "present", "system": false}
2019-06-05 14:04:35,539 p=17240 u=mistral |  TASK [container-registry : add deployment user to docker group] ****************
2019-06-05 14:04:35,539 p=17240 u=mistral |  task path: /usr/share/ansible/roles/container-registry/tasks/docker.yml:129
2019-06-05 14:04:35,539 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:35 -0500 (0:00:00.248)       0:01:09.309 ******** 
2019-06-05 14:04:35,542 p=17240 u=mistral |  META: noop
2019-06-05 14:04:35,555 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:35,572 p=17240 u=mistral |   [WARNING]: reset_connection task does not support when conditional

2019-06-05 14:04:35,594 p=17240 u=mistral |  META: reset connection
2019-06-05 14:04:35,594 p=17240 u=mistral |  META: noop
2019-06-05 14:04:35,595 p=17240 u=mistral |   [WARNING]: flush_handlers task does not support when conditional

2019-06-05 14:04:35,597 p=17240 u=mistral |  RUNNING HANDLER [container-registry : restart docker] **************************
2019-06-05 14:04:35,597 p=17240 u=mistral |  task path: /usr/share/ansible/roles/container-registry/handlers/main.yml:2
2019-06-05 14:04:35,597 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:35 -0500 (0:00:00.057)       0:01:09.366 ******** 
2019-06-05 14:04:35,958 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "cmd": ["/bin/true"], "delta": "0:00:00.001794", "end": "2019-06-05 19:04:35.933675", "rc": 0, "start": "2019-06-05 19:04:35.931881", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}
2019-06-05 14:04:35,959 p=17240 u=mistral |  RUNNING HANDLER [container-registry : Docker | reload systemd] *****************
2019-06-05 14:04:35,959 p=17240 u=mistral |  task path: /usr/share/ansible/roles/container-registry/handlers/main.yml:19
2019-06-05 14:04:35,959 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:35 -0500 (0:00:00.361)       0:01:09.728 ******** 
2019-06-05 14:04:36,156 p=17240 u=mistral |  ok: [lab-controller-0] => {"changed": false, "name": null, "status": {}}
2019-06-05 14:04:36,159 p=17240 u=mistral |  RUNNING HANDLER [container-registry : Docker | reload docker] ******************
2019-06-05 14:04:36,159 p=17240 u=mistral |  task path: /usr/share/ansible/roles/container-registry/handlers/main.yml:25
2019-06-05 14:04:36,159 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:36 -0500 (0:00:00.199)       0:01:09.928 ******** 
2019-06-05 14:04:37,540 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "name": "docker", "state": "started", "status": {"ActiveEnterTimestampMonotonic": "0", "ActiveExitTimestampMonotonic": "0", "ActiveState": "inactive", "After": "systemd-journald.socket network.target basic.target system.slice docker-storage-setup.service", "AllowIsolate": "no", "AmbientCapabilities": "0", "AssertResult": "no", "AssertTimestampMonotonic": "0", "Before": "shutdown.target paunch-container-shutdown.service", "BlockIOAccounting": "no", "BlockIOWeight": "18446744073709551615", "CPUAccounting": "no", "CPUQuotaPerSecUSec": "infinity", "CPUSchedulingPolicy": "0", "CPUSchedulingPriority": "0", "CPUSchedulingResetOnFork": "no", "CPUShares": "18446744073709551615", "CanIsolate": "no", "CanReload": "yes", "CanStart": "yes", "CanStop": "yes", "CapabilityBoundingSet": "18446744073709551615", "ConditionResult": "no", "ConditionTimestampMonotonic": "0", "Conflicts": "shutdown.target", "ControlPID": "0", "DefaultDependencies": "yes", "Delegate": "no", "Description": "Docker Application Container Engine", "DevicePolicy": "auto", "Documentation": "http://docs.docker.com", "DropInPaths": "/etc/systemd/system/docker.service.d/99-unset-mountflags.conf", "Environment": "GOTRACEBACK=crash DOCKER_HTTP_HOST_COMPAT=1 PATH=/usr/libexec/docker:/usr/bin:/usr/sbin", "EnvironmentFile": "/etc/sysconfig/docker-network (ignore_errors=yes)", "ExecMainCode": "0", "ExecMainExitTimestampMonotonic": "0", "ExecMainPID": "0", "ExecMainStartTimestampMonotonic": "0", "ExecMainStatus": "0", "ExecReload": "{ path=/bin/kill ; argv[]=/bin/kill -s HUP $MAINPID ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }", "ExecStart": "{ path=/usr/bin/dockerd-current ; argv[]=/usr/bin/dockerd-current --add-runtime docker-runc=/usr/libexec/docker/docker-runc-current --default-runtime=docker-runc --exec-opt native.cgroupdriver=systemd --userland-proxy-path=/usr/libexec/docker/docker-proxy-current --init-path=/usr/libexec/docker/docker-init-current --seccomp-profile=/etc/docker/seccomp.json $OPTIONS $DOCKER_STORAGE_OPTIONS $DOCKER_NETWORK_OPTIONS $ADD_REGISTRY $BLOCK_REGISTRY $INSECURE_REGISTRY $REGISTRIES ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }", "FailureAction": "none", "FileDescriptorStoreMax": "0", "FragmentPath": "/usr/lib/systemd/system/docker.service", "GuessMainPID": "yes", "IOScheduling": "0", "Id": "docker.service", "IgnoreOnIsolate": "no", "IgnoreOnSnapshot": "no", "IgnoreSIGPIPE": "yes", "InactiveEnterTimestampMonotonic": "0", "InactiveExitTimestampMonotonic": "0", "JobTimeoutAction": "none", "JobTimeoutUSec": "0", "KillMode": "process", "KillSignal": "15", "LimitAS": "18446744073709551615", "LimitCORE": "18446744073709551615", "LimitCPU": "18446744073709551615", "LimitDATA": "18446744073709551615", "LimitFSIZE": "18446744073709551615", "LimitLOCKS": "18446744073709551615", "LimitMEMLOCK": "65536", "LimitMSGQUEUE": "819200", "LimitNICE": "0", "LimitNOFILE": "1048576", "LimitNPROC": "1048576", "LimitRSS": "18446744073709551615", "LimitRTPRIO": "0", "LimitRTTIME": "18446744073709551615", "LimitSIGPENDING": "61816", "LimitSTACK": "18446744073709551615", "LoadState": "loaded", "MainPID": "0", "MemoryAccounting": "no", "MemoryCurrent": "18446744073709551615", "MemoryLimit": "18446744073709551615", "MountFlags": "0", "Names": "docker.service", "NeedDaemonReload": "no", "Nice": "0", "NoNewPrivileges": "no", "NonBlocking": "no", "NotifyAccess": "main", "OOMScoreAdjust": "0", "OnFailureJobMode": "replace", "PermissionsStartOnly": "no", "PrivateDevices": "no", "PrivateNetwork": "no", "PrivateTmp": "no", "ProtectHome": "no", "ProtectSystem": "no", "RefuseManualStart": "no", "RefuseManualStop": "no", "RemainAfterExit": "no", "RequiredBy": "docker-cleanup.service", "Requires": "docker-cleanup.timer basic.target", "Restart": "on-abnormal", "RestartUSec": "100ms", "Result": "success", "RootDirectoryStartOnly": "no", "RuntimeDirectoryMode": "0755", "SameProcessGroup": "no", "SecureBits": "0", "SendSIGHUP": "no", "SendSIGKILL": "yes", "Slice": "system.slice", "StandardError": "inherit", "StandardInput": "null", "StandardOutput": "journal", "StartLimitAction": "none", "StartLimitBurst": "5", "StartLimitInterval": "10000000", "StartupBlockIOWeight": "18446744073709551615", "StartupCPUShares": "18446744073709551615", "StatusErrno": "0", "StopWhenUnneeded": "no", "SubState": "dead", "SyslogLevelPrefix": "yes", "SyslogPriority": "30", "SystemCallErrorNumber": "0", "TTYReset": "no", "TTYVHangup": "no", "TTYVTDisallocate": "no", "TasksAccounting": "no", "TasksCurrent": "18446744073709551615", "TasksMax": "18446744073709551615", "TimeoutStartUSec": "0", "TimeoutStopUSec": "1min 30s", "TimerSlackNSec": "50000", "Transient": "no", "Type": "notify", "UMask": "0022", "UnitFilePreset": "disabled", "UnitFileState": "disabled", "Wants": "system.slice docker-storage-setup.service", "WatchdogTimestampMonotonic": "0", "WatchdogUSec": "0"}}
2019-06-05 14:04:37,543 p=17240 u=mistral |  RUNNING HANDLER [container-registry : Docker | pause while Docker restarts] ****
2019-06-05 14:04:37,543 p=17240 u=mistral |  task path: /usr/share/ansible/roles/container-registry/handlers/main.yml:31
2019-06-05 14:04:37,543 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:37 -0500 (0:00:01.384)       0:01:11.312 ******** 
2019-06-05 14:04:37,573 p=17240 u=mistral |  Pausing for 10 seconds
2019-06-05 14:04:37,573 p=17240 u=mistral |  (ctrl+C then 'C' = continue early, ctrl+C then 'A' = abort)
2019-06-05 14:04:37,573 p=17240 u=mistral |  [container-registry : Docker | pause while Docker restarts]
Waiting for docker restart:
2019-06-05 14:04:47,576 p=17240 u=mistral |  ok: [lab-controller-0] => {"changed": false, "delta": 10, "echo": true, "rc": 0, "start": "2019-06-05 14:04:37.573315", "stderr": "", "stdout": "Paused for 10.0 seconds", "stop": "2019-06-05 14:04:47.573433", "user_input": ""}
2019-06-05 14:04:47,578 p=17240 u=mistral |  RUNNING HANDLER [container-registry : Docker | wait for docker] ****************
2019-06-05 14:04:47,578 p=17240 u=mistral |  task path: /usr/share/ansible/roles/container-registry/handlers/main.yml:36
2019-06-05 14:04:47,578 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:47 -0500 (0:00:10.035)       0:01:21.348 ******** 
2019-06-05 14:04:47,725 p=17240 u=mistral |  changed: [lab-controller-0] => {"attempts": 1, "changed": true, "cmd": ["/usr/bin/docker", "images"], "delta": "0:00:00.025202", "end": "2019-06-05 19:04:47.710813", "rc": 0, "start": "2019-06-05 19:04:47.685611", "stderr": "", "stderr_lines": [], "stdout": "REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE", "stdout_lines": ["REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE"]}
2019-06-05 14:04:47,725 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:04:47,741 p=17240 u=mistral |  TASK [container-registry : enable and start docker] ****************************
2019-06-05 14:04:47,741 p=17240 u=mistral |  task path: /usr/share/ansible/roles/container-registry/tasks/docker.yml:143
2019-06-05 14:04:47,742 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:47 -0500 (0:00:00.163)       0:01:21.511 ******** 
2019-06-05 14:04:47,744 p=17240 u=mistral |  META: noop
2019-06-05 14:04:47,928 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "enabled": true, "name": "docker", "state": "started", "status": {"ActiveEnterTimestamp": "Wed 2019-06-05 19:04:37 UTC", "ActiveEnterTimestampMonotonic": "189806450", "ActiveExitTimestampMonotonic": "0", "ActiveState": "active", "After": "systemd-journald.socket network.target basic.target system.slice docker-storage-setup.service", "AllowIsolate": "no", "AmbientCapabilities": "0", "AssertResult": "yes", "AssertTimestamp": "Wed 2019-06-05 19:04:36 UTC", "AssertTimestampMonotonic": "188635879", "Before": "shutdown.target paunch-container-shutdown.service", "BlockIOAccounting": "no", "BlockIOWeight": "18446744073709551615", "CPUAccounting": "no", "CPUQuotaPerSecUSec": "infinity", "CPUSchedulingPolicy": "0", "CPUSchedulingPriority": "0", "CPUSchedulingResetOnFork": "no", "CPUShares": "18446744073709551615", "CanIsolate": "no", "CanReload": "yes", "CanStart": "yes", "CanStop": "yes", "CapabilityBoundingSet": "18446744073709551615", "ConditionResult": "yes", "ConditionTimestamp": "Wed 2019-06-05 19:04:36 UTC", "ConditionTimestampMonotonic": "188635879", "Conflicts": "shutdown.target", "ControlGroup": "/system.slice/docker.service", "ControlPID": "0", "DefaultDependencies": "yes", "Delegate": "no", "Description": "Docker Application Container Engine", "DevicePolicy": "auto", "Documentation": "http://docs.docker.com", "DropInPaths": "/etc/systemd/system/docker.service.d/99-unset-mountflags.conf", "Environment": "GOTRACEBACK=crash DOCKER_HTTP_HOST_COMPAT=1 PATH=/usr/libexec/docker:/usr/bin:/usr/sbin", "EnvironmentFile": "/etc/sysconfig/docker-network (ignore_errors=yes)", "ExecMainCode": "0", "ExecMainExitTimestampMonotonic": "0", "ExecMainPID": "17853", "ExecMainStartTimestamp": "Wed 2019-06-05 19:04:36 UTC", "ExecMainStartTimestampMonotonic": "188636385", "ExecMainStatus": "0", "ExecReload": "{ path=/bin/kill ; argv[]=/bin/kill -s HUP $MAINPID ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }", "ExecStart": "{ path=/usr/bin/dockerd-current ; argv[]=/usr/bin/dockerd-current --add-runtime docker-runc=/usr/libexec/docker/docker-runc-current --default-runtime=docker-runc --exec-opt native.cgroupdriver=systemd --userland-proxy-path=/usr/libexec/docker/docker-proxy-current --init-path=/usr/libexec/docker/docker-init-current --seccomp-profile=/etc/docker/seccomp.json $OPTIONS $DOCKER_STORAGE_OPTIONS $DOCKER_NETWORK_OPTIONS $ADD_REGISTRY $BLOCK_REGISTRY $INSECURE_REGISTRY $REGISTRIES ; ignore_errors=no ; start_time=[Wed 2019-06-05 19:04:36 UTC] ; stop_time=[n/a] ; pid=17853 ; code=(null) ; status=0/0 }", "FailureAction": "none", "FileDescriptorStoreMax": "0", "FragmentPath": "/usr/lib/systemd/system/docker.service", "GuessMainPID": "yes", "IOScheduling": "0", "Id": "docker.service", "IgnoreOnIsolate": "no", "IgnoreOnSnapshot": "no", "IgnoreSIGPIPE": "yes", "InactiveEnterTimestampMonotonic": "0", "InactiveExitTimestamp": "Wed 2019-06-05 19:04:36 UTC", "InactiveExitTimestampMonotonic": "188636405", "JobTimeoutAction": "none", "JobTimeoutUSec": "0", "KillMode": "process", "KillSignal": "15", "LimitAS": "18446744073709551615", "LimitCORE": "18446744073709551615", "LimitCPU": "18446744073709551615", "LimitDATA": "18446744073709551615", "LimitFSIZE": "18446744073709551615", "LimitLOCKS": "18446744073709551615", "LimitMEMLOCK": "65536", "LimitMSGQUEUE": "819200", "LimitNICE": "0", "LimitNOFILE": "1048576", "LimitNPROC": "1048576", "LimitRSS": "18446744073709551615", "LimitRTPRIO": "0", "LimitRTTIME": "18446744073709551615", "LimitSIGPENDING": "61816", "LimitSTACK": "18446744073709551615", "LoadState": "loaded", "MainPID": "17853", "MemoryAccounting": "no", "MemoryCurrent": "18446744073709551615", "MemoryLimit": "18446744073709551615", "MountFlags": "0", "Names": "docker.service", "NeedDaemonReload": "no", "Nice": "0", "NoNewPrivileges": "no", "NonBlocking": "no", "NotifyAccess": "main", "OOMScoreAdjust": "0", "OnFailureJobMode": "replace", "PermissionsStartOnly": "no", "PrivateDevices": "no", "PrivateNetwork": "no", "PrivateTmp": "no", "ProtectHome": "no", "ProtectSystem": "no", "RefuseManualStart": "no", "RefuseManualStop": "no", "RemainAfterExit": "no", "RequiredBy": "docker-cleanup.service", "Requires": "docker-cleanup.timer basic.target", "Restart": "on-abnormal", "RestartUSec": "100ms", "Result": "success", "RootDirectoryStartOnly": "no", "RuntimeDirectoryMode": "0755", "SameProcessGroup": "no", "SecureBits": "0", "SendSIGHUP": "no", "SendSIGKILL": "yes", "Slice": "system.slice", "StandardError": "inherit", "StandardInput": "null", "StandardOutput": "journal", "StartLimitAction": "none", "StartLimitBurst": "5", "StartLimitInterval": "10000000", "StartupBlockIOWeight": "18446744073709551615", "StartupCPUShares": "18446744073709551615", "StatusErrno": "0", "StopWhenUnneeded": "no", "SubState": "running", "SyslogLevelPrefix": "yes", "SyslogPriority": "30", "SystemCallErrorNumber": "0", "TTYReset": "no", "TTYVHangup": "no", "TTYVTDisallocate": "no", "TasksAccounting": "no", "TasksCurrent": "23", "TasksMax": "18446744073709551615", "TimeoutStartUSec": "0", "TimeoutStopUSec": "1min 30s", "TimerSlackNSec": "50000", "Transient": "no", "Type": "notify", "UMask": "0022", "UnitFilePreset": "disabled", "UnitFileState": "disabled", "Wants": "system.slice docker-storage-setup.service", "WatchdogTimestamp": "Wed 2019-06-05 19:04:37 UTC", "WatchdogTimestampMonotonic": "189806401", "WatchdogUSec": "0"}}
2019-06-05 14:04:47,945 p=17240 u=mistral |  TASK [container-registry : mark docker configured] *****************************
2019-06-05 14:04:47,945 p=17240 u=mistral |  task path: /usr/share/ansible/roles/container-registry/tasks/docker.yml:150
2019-06-05 14:04:47,945 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:47 -0500 (0:00:00.203)       0:01:21.715 ******** 
2019-06-05 14:04:47,947 p=17240 u=mistral |  META: noop
2019-06-05 14:04:48,044 p=17240 u=mistral |  changed: [lab-controller-0] => {"backup": "", "changed": true, "msg": "line added"}
2019-06-05 14:04:48,061 p=17240 u=mistral |  TASK [create persistent logs directory] ****************************************
2019-06-05 14:04:48,061 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:183
2019-06-05 14:04:48,061 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:48 -0500 (0:00:00.115)       0:01:21.831 ******** 
2019-06-05 14:04:48,092 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/containers/glance', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/containers/glance", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:48,096 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/glance', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/glance", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:48,158 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/containers/glance', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/containers/glance", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/containers/glance", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:48,245 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/glance', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/glance", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/glance", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:48,263 p=17240 u=mistral |  TASK [glance logs readme] ******************************************************
2019-06-05 14:04:48,263 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:193
2019-06-05 14:04:48,263 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:48 -0500 (0:00:00.201)       0:01:22.032 ******** 
2019-06-05 14:04:48,292 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:48,532 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "checksum": "e368ae3272baeb19e1113009ea5dae00e797c919", "dest": "/var/log/glance/readme.txt", "gid": 0, "group": "root", "md5sum": "2db67679f049ab445db62bea2ab06795", "mode": "0644", "owner": "root", "secontext": "system_u:object_r:glance_log_t:s0", "size": 80, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559761488.27-1359914467718/source", "state": "file", "uid": 0}
2019-06-05 14:04:48,549 p=17240 u=mistral |  TASK [Mount NFS on host] *******************************************************
2019-06-05 14:04:48,549 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:202
2019-06-05 14:04:48,549 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:48 -0500 (0:00:00.286)       0:01:22.318 ******** 
2019-06-05 14:04:48,569 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:48,576 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:48,593 p=17240 u=mistral |  TASK [Mount Node Staging Location] *********************************************
2019-06-05 14:04:48,593 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:214
2019-06-05 14:04:48,593 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:48 -0500 (0:00:00.044)       0:01:22.363 ******** 
2019-06-05 14:04:48,613 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:48,622 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:48,638 p=17240 u=mistral |  TASK [ensure /var/lib/glance exists] *******************************************
2019-06-05 14:04:48,638 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:222
2019-06-05 14:04:48,639 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:48 -0500 (0:00:00.045)       0:01:22.408 ******** 
2019-06-05 14:04:48,668 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:48,732 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "gid": 0, "group": "root", "mode": "0755", "owner": "root", "path": "/var/lib/glance", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:48,748 p=17240 u=mistral |  TASK [create persistent data and logs directory] *******************************
2019-06-05 14:04:48,748 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:227
2019-06-05 14:04:48,748 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:48 -0500 (0:00:00.109)       0:01:22.517 ******** 
2019-06-05 14:04:48,780 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/containers/gnocchi', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/containers/gnocchi", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:48,784 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/containers/httpd/gnocchi-api', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/containers/httpd/gnocchi-api", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:48,788 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/lib/gnocchi', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/lib/gnocchi", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:48,792 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/gnocchi', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/gnocchi", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:48,846 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/containers/gnocchi', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/containers/gnocchi", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/containers/gnocchi", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:48,932 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/containers/httpd/gnocchi-api', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/containers/httpd/gnocchi-api", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/containers/httpd/gnocchi-api", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:49,017 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/lib/gnocchi', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/lib/gnocchi", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/lib/gnocchi", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:49,103 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/gnocchi', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/gnocchi", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/gnocchi", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:49,122 p=17240 u=mistral |  TASK [gnocchi logs readme] *****************************************************
2019-06-05 14:04:49,122 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:241
2019-06-05 14:04:49,122 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:49 -0500 (0:00:00.373)       0:01:22.891 ******** 
2019-06-05 14:04:49,153 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:49,393 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "checksum": "2f6114e0f135d7222e70a07579ab0b2b6f967ff8", "dest": "/var/log/gnocchi/readme.txt", "gid": 0, "group": "root", "md5sum": "f23cdb898e7a45bcc0bbc169d7746fbe", "mode": "0644", "owner": "root", "secontext": "system_u:object_r:var_log_t:s0", "size": 124, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559761489.13-48949342162134/source", "state": "file", "uid": 0}
2019-06-05 14:04:49,410 p=17240 u=mistral |  TASK [create persistent directories] *******************************************
2019-06-05 14:04:49,410 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:250
2019-06-05 14:04:49,410 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:49 -0500 (0:00:00.288)       0:01:23.179 ******** 
2019-06-05 14:04:49,442 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/containers/gnocchi', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/containers/gnocchi", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:49,445 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/gnocchi', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/gnocchi", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:49,506 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/containers/gnocchi', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/containers/gnocchi", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/containers/gnocchi", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:49,592 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/gnocchi', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/gnocchi", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/gnocchi", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 24, "state": "directory", "uid": 0}
2019-06-05 14:04:49,609 p=17240 u=mistral |  TASK [create persistent data directory] ****************************************
2019-06-05 14:04:49,609 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:260
2019-06-05 14:04:49,609 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:49 -0500 (0:00:00.199)       0:01:23.379 ******** 
2019-06-05 14:04:49,638 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:49,701 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "gid": 0, "group": "root", "mode": "0755", "owner": "root", "path": "/var/lib/gnocchi", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:49,717 p=17240 u=mistral |  TASK [get parameters] **********************************************************
2019-06-05 14:04:49,717 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:265
2019-06-05 14:04:49,717 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:49 -0500 (0:00:00.107)       0:01:23.487 ******** 
2019-06-05 14:04:49,737 p=17240 u=mistral |  ok: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:04:49,745 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:04:49,761 p=17240 u=mistral |  TASK [get DeployedSSLCertificatePath attributes] *******************************
2019-06-05 14:04:49,761 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:273
2019-06-05 14:04:49,761 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:49 -0500 (0:00:00.043)       0:01:23.530 ******** 
2019-06-05 14:04:49,781 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:49,789 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:49,806 p=17240 u=mistral |  TASK [set is_haproxy_bootstrap_node fact] **************************************
2019-06-05 14:04:49,806 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:277
2019-06-05 14:04:49,806 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:49 -0500 (0:00:00.044)       0:01:23.575 ******** 
2019-06-05 14:04:49,826 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:49,833 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:49,850 p=17240 u=mistral |  TASK [get haproxy status] ******************************************************
2019-06-05 14:04:49,850 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:279
2019-06-05 14:04:49,850 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:49 -0500 (0:00:00.043)       0:01:23.619 ******** 
2019-06-05 14:04:49,870 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:49,877 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:49,893 p=17240 u=mistral |  TASK [get pacemaker status] ****************************************************
2019-06-05 14:04:49,893 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:283
2019-06-05 14:04:49,894 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:49 -0500 (0:00:00.043)       0:01:23.663 ******** 
2019-06-05 14:04:49,913 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:49,922 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:49,938 p=17240 u=mistral |  TASK [get docker status] *******************************************************
2019-06-05 14:04:49,938 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:287
2019-06-05 14:04:49,938 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:49 -0500 (0:00:00.044)       0:01:23.708 ******** 
2019-06-05 14:04:49,959 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:49,966 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:49,982 p=17240 u=mistral |  TASK [get container_id] ********************************************************
2019-06-05 14:04:49,983 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:291
2019-06-05 14:04:49,983 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:49 -0500 (0:00:00.044)       0:01:23.752 ******** 
2019-06-05 14:04:50,003 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:50,013 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:50,030 p=17240 u=mistral |  TASK [get pcs resource name for haproxy container] *****************************
2019-06-05 14:04:50,030 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:298
2019-06-05 14:04:50,030 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:50 -0500 (0:00:00.047)       0:01:23.799 ******** 
2019-06-05 14:04:50,053 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:50,061 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:50,078 p=17240 u=mistral |  TASK [remove DeployedSSLCertificatePath if is dir] *****************************
2019-06-05 14:04:50,078 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:309
2019-06-05 14:04:50,078 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:50 -0500 (0:00:00.048)       0:01:23.847 ******** 
2019-06-05 14:04:50,098 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:50,105 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:50,122 p=17240 u=mistral |  TASK [push certificate content] ************************************************
2019-06-05 14:04:50,122 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:314
2019-06-05 14:04:50,122 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:50 -0500 (0:00:00.044)       0:01:23.891 ******** 
2019-06-05 14:04:50,142 p=17240 u=mistral |  skipping: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:04:50,149 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:04:50,166 p=17240 u=mistral |  TASK [set certificate ownership] ***********************************************
2019-06-05 14:04:50,166 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:328
2019-06-05 14:04:50,166 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:50 -0500 (0:00:00.044)       0:01:23.935 ******** 
2019-06-05 14:04:50,186 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:50,194 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:50,210 p=17240 u=mistral |  TASK [reload haproxy if enabled] ***********************************************
2019-06-05 14:04:50,210 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:332
2019-06-05 14:04:50,210 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:50 -0500 (0:00:00.044)       0:01:23.979 ******** 
2019-06-05 14:04:50,230 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:50,237 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:50,254 p=17240 u=mistral |  TASK [restart pacemaker resource for haproxy] **********************************
2019-06-05 14:04:50,254 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:338
2019-06-05 14:04:50,254 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:50 -0500 (0:00:00.043)       0:01:24.023 ******** 
2019-06-05 14:04:50,274 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:50,282 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:50,298 p=17240 u=mistral |  TASK [set kolla_dir fact] ******************************************************
2019-06-05 14:04:50,298 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:345
2019-06-05 14:04:50,298 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:50 -0500 (0:00:00.044)       0:01:24.068 ******** 
2019-06-05 14:04:50,319 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:50,326 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:50,343 p=17240 u=mistral |  TASK [assert {{ kolla_dir }}{{ cert_path }} exists] ****************************
2019-06-05 14:04:50,344 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:347
2019-06-05 14:04:50,344 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:50 -0500 (0:00:00.045)       0:01:24.113 ******** 
2019-06-05 14:04:50,364 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:50,372 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:50,388 p=17240 u=mistral |  TASK [set certificate group on host via container] *****************************
2019-06-05 14:04:50,388 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:351
2019-06-05 14:04:50,388 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:50 -0500 (0:00:00.044)       0:01:24.157 ******** 
2019-06-05 14:04:50,408 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:50,415 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:50,431 p=17240 u=mistral |  TASK [copy certificate from kolla directory to final location] *****************
2019-06-05 14:04:50,431 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:360
2019-06-05 14:04:50,431 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:50 -0500 (0:00:00.043)       0:01:24.201 ******** 
2019-06-05 14:04:50,451 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:50,458 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:50,475 p=17240 u=mistral |  TASK [send restart order to haproxy container] *********************************
2019-06-05 14:04:50,475 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:369
2019-06-05 14:04:50,475 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:50 -0500 (0:00:00.043)       0:01:24.244 ******** 
2019-06-05 14:04:50,495 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:50,502 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:50,518 p=17240 u=mistral |  TASK [Check if rsyslog exists] *************************************************
2019-06-05 14:04:50,518 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:381
2019-06-05 14:04:50,518 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:50 -0500 (0:00:00.043)       0:01:24.288 ******** 
2019-06-05 14:04:50,552 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:50,614 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "cmd": "systemctl is-active rsyslog", "delta": "0:00:00.005668", "end": "2019-06-05 19:04:50.606256", "rc": 0, "start": "2019-06-05 19:04:50.600588", "stderr": "", "stderr_lines": [], "stdout": "active", "stdout_lines": ["active"]}
2019-06-05 14:04:50,633 p=17240 u=mistral |  TASK [Forward logging to haproxy.log file] *************************************
2019-06-05 14:04:50,633 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:385
2019-06-05 14:04:50,633 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:50 -0500 (0:00:00.114)       0:01:24.402 ******** 
2019-06-05 14:04:50,663 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:50,829 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "msg": "File created"}
2019-06-05 14:04:50,846 p=17240 u=mistral |  TASK [restart rsyslog service after logging conf change] ***********************
2019-06-05 14:04:50,846 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:398
2019-06-05 14:04:50,846 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:50 -0500 (0:00:00.212)       0:01:24.615 ******** 
2019-06-05 14:04:50,876 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:51,015 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "name": "rsyslog", "state": "started", "status": {"ActiveEnterTimestamp": "Wed 2019-06-05 19:01:39 UTC", "ActiveEnterTimestampMonotonic": "12822740", "ActiveExitTimestampMonotonic": "0", "ActiveState": "active", "After": "system.slice basic.target network.target network-online.target", "AllowIsolate": "no", "AmbientCapabilities": "0", "AssertResult": "yes", "AssertTimestamp": "Wed 2019-06-05 19:01:39 UTC", "AssertTimestampMonotonic": "12808736", "Before": "multi-user.target shutdown.target pacemaker.service", "BlockIOAccounting": "no", "BlockIOWeight": "18446744073709551615", "CPUAccounting": "no", "CPUQuotaPerSecUSec": "infinity", "CPUSchedulingPolicy": "0", "CPUSchedulingPriority": "0", "CPUSchedulingResetOnFork": "no", "CPUShares": "18446744073709551615", "CanIsolate": "no", "CanReload": "no", "CanStart": "yes", "CanStop": "yes", "CapabilityBoundingSet": "18446744073709551615", "ConditionResult": "yes", "ConditionTimestamp": "Wed 2019-06-05 19:01:39 UTC", "ConditionTimestampMonotonic": "12808736", "Conflicts": "shutdown.target", "ControlGroup": "/system.slice/rsyslog.service", "ControlPID": "0", "DefaultDependencies": "yes", "Delegate": "no", "Description": "System Logging Service", "DevicePolicy": "auto", "Documentation": "man:rsyslogd(8) http://www.rsyslog.com/doc/", "EnvironmentFile": "/etc/sysconfig/rsyslog (ignore_errors=yes)", "ExecMainCode": "0", "ExecMainExitTimestampMonotonic": "0", "ExecMainPID": "4107", "ExecMainStartTimestamp": "Wed 2019-06-05 19:01:39 UTC", "ExecMainStartTimestampMonotonic": "12809412", "ExecMainStatus": "0", "ExecStart": "{ path=/usr/sbin/rsyslogd ; argv[]=/usr/sbin/rsyslogd -n $SYSLOGD_OPTIONS ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }", "FailureAction": "none", "FileDescriptorStoreMax": "0", "FragmentPath": "/usr/lib/systemd/system/rsyslog.service", "GuessMainPID": "yes", "IOScheduling": "0", "Id": "rsyslog.service", "IgnoreOnIsolate": "no", "IgnoreOnSnapshot": "no", "IgnoreSIGPIPE": "yes", "InactiveEnterTimestampMonotonic": "0", "InactiveExitTimestamp": "Wed 2019-06-05 19:01:39 UTC", "InactiveExitTimestampMonotonic": "12809435", "JobTimeoutAction": "none", "JobTimeoutUSec": "0", "KillMode": "control-group", "KillSignal": "15", "LimitAS": "18446744073709551615", "LimitCORE": "18446744073709551615", "LimitCPU": "18446744073709551615", "LimitDATA": "18446744073709551615", "LimitFSIZE": "18446744073709551615", "LimitLOCKS": "18446744073709551615", "LimitMEMLOCK": "65536", "LimitMSGQUEUE": "819200", "LimitNICE": "0", "LimitNOFILE": "4096", "LimitNPROC": "61816", "LimitRSS": "18446744073709551615", "LimitRTPRIO": "0", "LimitRTTIME": "18446744073709551615", "LimitSIGPENDING": "61816", "LimitSTACK": "18446744073709551615", "LoadState": "loaded", "MainPID": "4107", "MemoryAccounting": "no", "MemoryCurrent": "18446744073709551615", "MemoryLimit": "18446744073709551615", "MountFlags": "0", "Names": "rsyslog.service", "NeedDaemonReload": "no", "Nice": "0", "NoNewPrivileges": "no", "NonBlocking": "no", "NotifyAccess": "main", "OOMScoreAdjust": "0", "OnFailureJobMode": "replace", "PermissionsStartOnly": "no", "PrivateDevices": "no", "PrivateNetwork": "no", "PrivateTmp": "no", "ProtectHome": "no", "ProtectSystem": "no", "RefuseManualStart": "no", "RefuseManualStop": "no", "RemainAfterExit": "no", "Requires": "basic.target", "Restart": "on-failure", "RestartUSec": "100ms", "Result": "success", "RootDirectoryStartOnly": "no", "RuntimeDirectoryMode": "0755", "SameProcessGroup": "no", "SecureBits": "0", "SendSIGHUP": "no", "SendSIGKILL": "yes", "Slice": "system.slice", "StandardError": "inherit", "StandardInput": "null", "StandardOutput": "null", "StartLimitAction": "none", "StartLimitBurst": "5", "StartLimitInterval": "10000000", "StartupBlockIOWeight": "18446744073709551615", "StartupCPUShares": "18446744073709551615", "StatusErrno": "0", "StopWhenUnneeded": "no", "SubState": "running", "SyslogLevelPrefix": "yes", "SyslogPriority": "30", "SystemCallErrorNumber": "0", "TTYReset": "no", "TTYVHangup": "no", "TTYVTDisallocate": "no", "TasksAccounting": "no", "TasksCurrent": "18446744073709551615", "TasksMax": "18446744073709551615", "TimeoutStartUSec": "1min 30s", "TimeoutStopUSec": "1min 30s", "TimerSlackNSec": "50000", "Transient": "no", "Type": "notify", "UMask": "0066", "UnitFilePreset": "enabled", "UnitFileState": "enabled", "WantedBy": "multi-user.target", "Wants": "system.slice network.target network-online.target", "WatchdogTimestamp": "Wed 2019-06-05 19:01:39 UTC", "WatchdogTimestampMonotonic": "12822714", "WatchdogUSec": "0"}}
2019-06-05 14:04:51,032 p=17240 u=mistral |  TASK [create persistent directories] *******************************************
2019-06-05 14:04:51,032 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:406
2019-06-05 14:04:51,032 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:51 -0500 (0:00:00.186)       0:01:24.801 ******** 
2019-06-05 14:04:51,066 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/containers/haproxy', u'setype': u'var_log_t'})  => {"changed": false, "item": {"path": "/var/log/containers/haproxy", "setype": "var_log_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:51,074 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/lib/haproxy', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/lib/haproxy", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:51,074 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/haproxy', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/haproxy", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:51,131 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/containers/haproxy', u'setype': u'var_log_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/containers/haproxy", "setype": "var_log_t"}, "mode": "0755", "owner": "root", "path": "/var/log/containers/haproxy", "secontext": "unconfined_u:object_r:var_log_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:51,218 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/lib/haproxy', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/lib/haproxy", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/lib/haproxy", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:51,304 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/haproxy', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/haproxy", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/haproxy", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:51,322 p=17240 u=mistral |  TASK [haproxy logs readme] *****************************************************
2019-06-05 14:04:51,322 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:418
2019-06-05 14:04:51,322 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:51 -0500 (0:00:00.289)       0:01:25.091 ******** 
2019-06-05 14:04:51,351 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:51,603 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "checksum": "43946c55a0d97d06625b748b1c4b851696d79a84", "dest": "/var/log/haproxy/readme.txt", "gid": 0, "group": "root", "md5sum": "ad237e0174ba2c593baaecd6c5c6d559", "mode": "0644", "owner": "root", "secontext": "system_u:object_r:var_log_t:s0", "size": 86, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559761491.33-119889005588042/source", "state": "file", "uid": 0}
2019-06-05 14:04:51,620 p=17240 u=mistral |  TASK [create persistent directories] *******************************************
2019-06-05 14:04:51,620 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:427
2019-06-05 14:04:51,620 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:51 -0500 (0:00:00.297)       0:01:25.389 ******** 
2019-06-05 14:04:51,653 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/containers/heat', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/containers/heat", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:51,656 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/containers/httpd/heat-api', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/containers/httpd/heat-api", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:51,659 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/heat', u'setype': u'var_log_t'})  => {"changed": false, "item": {"path": "/var/log/heat", "setype": "var_log_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:51,717 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/containers/heat', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/containers/heat", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/containers/heat", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:51,803 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/containers/httpd/heat-api', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/containers/httpd/heat-api", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/containers/httpd/heat-api", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:51,889 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/heat', u'setype': u'var_log_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/heat", "setype": "var_log_t"}, "mode": "0755", "owner": "root", "path": "/var/log/heat", "secontext": "unconfined_u:object_r:var_log_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:51,906 p=17240 u=mistral |  TASK [heat logs readme] ********************************************************
2019-06-05 14:04:51,906 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:439
2019-06-05 14:04:51,906 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:51 -0500 (0:00:00.286)       0:01:25.675 ******** 
2019-06-05 14:04:51,936 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:52,177 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "checksum": "d30ca3bda176434d31659e7379616dd162ddb246", "dest": "/var/log/heat/readme.txt", "gid": 0, "group": "root", "md5sum": "c6363a522331b97dee66de127d658623", "mode": "0644", "owner": "root", "secontext": "system_u:object_r:var_log_t:s0", "size": 116, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559761491.92-166543413499286/source", "state": "file", "uid": 0}
2019-06-05 14:04:52,193 p=17240 u=mistral |  TASK [create persistent directories] *******************************************
2019-06-05 14:04:52,194 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:448
2019-06-05 14:04:52,194 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:52 -0500 (0:00:00.287)       0:01:25.963 ******** 
2019-06-05 14:04:52,226 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/containers/heat', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/containers/heat", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:52,233 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/containers/httpd/heat-api-cfn', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/containers/httpd/heat-api-cfn", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:52,233 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/heat', u'setype': u'var_log_t'})  => {"changed": false, "item": {"path": "/var/log/heat", "setype": "var_log_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:52,291 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/containers/heat', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/containers/heat", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/containers/heat", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:52,376 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/containers/httpd/heat-api-cfn', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/containers/httpd/heat-api-cfn", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/containers/httpd/heat-api-cfn", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:52,462 p=17240 u=mistral |  ok: [lab-controller-0] => (item={u'path': u'/var/log/heat', u'setype': u'var_log_t'}) => {"changed": false, "gid": 0, "group": "root", "item": {"path": "/var/log/heat", "setype": "var_log_t"}, "mode": "0755", "owner": "root", "path": "/var/log/heat", "secontext": "unconfined_u:object_r:var_log_t:s0", "size": 24, "state": "directory", "uid": 0}
2019-06-05 14:04:52,478 p=17240 u=mistral |  TASK [create persistent directories] *******************************************
2019-06-05 14:04:52,479 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:460
2019-06-05 14:04:52,479 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:52 -0500 (0:00:00.284)       0:01:26.248 ******** 
2019-06-05 14:04:52,511 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/containers/heat', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/containers/heat", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:52,515 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/heat', u'setype': u'var_log_t'})  => {"changed": false, "item": {"path": "/var/log/heat", "setype": "var_log_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:52,575 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/containers/heat', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/containers/heat", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/containers/heat", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:52,663 p=17240 u=mistral |  ok: [lab-controller-0] => (item={u'path': u'/var/log/heat', u'setype': u'var_log_t'}) => {"changed": false, "gid": 0, "group": "root", "item": {"path": "/var/log/heat", "setype": "var_log_t"}, "mode": "0755", "owner": "root", "path": "/var/log/heat", "secontext": "unconfined_u:object_r:var_log_t:s0", "size": 24, "state": "directory", "uid": 0}
2019-06-05 14:04:52,680 p=17240 u=mistral |  TASK [create persistent directories] *******************************************
2019-06-05 14:04:52,680 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:470
2019-06-05 14:04:52,680 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:52 -0500 (0:00:00.201)       0:01:26.449 ******** 
2019-06-05 14:04:52,713 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/containers/horizon', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/containers/horizon", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:52,716 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/containers/httpd/horizon', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/containers/httpd/horizon", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:52,721 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/www', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/www", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:52,725 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/horizon', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/horizon", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:52,778 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/containers/horizon', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/containers/horizon", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/containers/horizon", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:52,863 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/containers/httpd/horizon', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/containers/httpd/horizon", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/containers/httpd/horizon", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:52,950 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/www', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/www", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/www", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:53,035 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/horizon', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/horizon", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/horizon", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:53,052 p=17240 u=mistral |  TASK [horizon logs readme] *****************************************************
2019-06-05 14:04:53,052 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:484
2019-06-05 14:04:53,052 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:53 -0500 (0:00:00.372)       0:01:26.821 ******** 
2019-06-05 14:04:53,081 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:53,320 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "checksum": "ac324739761cb36b925d6e309482e26f7fe49b91", "dest": "/var/log/horizon/readme.txt", "gid": 0, "group": "root", "md5sum": "bb6f6b162959d08b7876b742eba37714", "mode": "0644", "owner": "root", "secontext": "system_u:object_r:httpd_log_t:s0", "size": 120, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559761493.06-274363807409059/source", "state": "file", "uid": 0}
2019-06-05 14:04:53,338 p=17240 u=mistral |  TASK [ensure /etc/iscsi exists] ************************************************
2019-06-05 14:04:53,338 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:493
2019-06-05 14:04:53,339 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:53 -0500 (0:00:00.286)       0:01:27.108 ******** 
2019-06-05 14:04:53,367 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:53,431 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "gid": 0, "group": "root", "mode": "0755", "owner": "root", "path": "/etc/iscsi", "secontext": "system_u:object_r:container_file_t:s0", "size": 52, "state": "directory", "uid": 0}
2019-06-05 14:04:53,447 p=17240 u=mistral |  TASK [ensure /var/lib/iscsi exists] ********************************************
2019-06-05 14:04:53,447 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:498
2019-06-05 14:04:53,447 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:53 -0500 (0:00:00.108)       0:01:27.217 ******** 
2019-06-05 14:04:53,477 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:53,540 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "gid": 0, "group": "root", "mode": "0755", "owner": "root", "path": "/var/lib/iscsi", "secontext": "system_u:object_r:container_file_t:s0", "size": 90, "state": "directory", "uid": 0}
2019-06-05 14:04:53,557 p=17240 u=mistral |  TASK [stat /lib/systemd/system/iscsid.socket] **********************************
2019-06-05 14:04:53,557 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:503
2019-06-05 14:04:53,557 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:53 -0500 (0:00:00.109)       0:01:27.326 ******** 
2019-06-05 14:04:53,586 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:53,655 p=17240 u=mistral |  ok: [lab-controller-0] => {"changed": false, "stat": {"atime": 1559761415.0648966, "attr_flags": "", "attributes": [], "block_size": 4096, "blocks": 8, "charset": "us-ascii", "checksum": "424de87cd6ae66547b285288742255731a46ab83", "ctime": 1559694316.28692, "dev": 64514, "device_type": 0, "executable": false, "exists": true, "gid": 0, "gr_name": "root", "inode": 1183379, "isblk": false, "ischr": false, "isdir": false, "isfifo": false, "isgid": false, "islnk": false, "isreg": true, "issock": false, "isuid": false, "mimetype": "text/plain", "mode": "0644", "mtime": 1540940995.0, "nlink": 1, "path": "/lib/systemd/system/iscsid.socket", "pw_name": "root", "readable": true, "rgrp": true, "roth": true, "rusr": true, "size": 175, "uid": 0, "version": "2073033812", "wgrp": false, "woth": false, "writeable": true, "wusr": true, "xgrp": false, "xoth": false, "xusr": false}}
2019-06-05 14:04:53,672 p=17240 u=mistral |  TASK [Stop and disable iscsid.socket service] **********************************
2019-06-05 14:04:53,672 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:506
2019-06-05 14:04:53,672 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:53 -0500 (0:00:00.115)       0:01:27.442 ******** 
2019-06-05 14:04:53,701 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:53,861 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "enabled": false, "name": "iscsid.socket", "state": "stopped", "status": {"Accept": "no", "ActiveEnterTimestamp": "Wed 2019-06-05 19:01:33 UTC", "ActiveEnterTimestampMonotonic": "7157598", "ActiveExitTimestampMonotonic": "0", "ActiveState": "active", "After": "-.slice sysinit.target", "AllowIsolate": "no", "AmbientCapabilities": "0", "AssertResult": "yes", "AssertTimestamp": "Wed 2019-06-05 19:01:33 UTC", "AssertTimestampMonotonic": "7156622", "Backlog": "128", "Before": "iscsid.service shutdown.target sockets.target", "BindIPv6Only": "default", "BlockIOAccounting": "no", "BlockIOWeight": "18446744073709551615", "Broadcast": "no", "CPUAccounting": "no", "CPUQuotaPerSecUSec": "infinity", "CPUSchedulingPolicy": "0", "CPUSchedulingPriority": "0", "CPUSchedulingResetOnFork": "no", "CPUShares": "18446744073709551615", "CanIsolate": "no", "CanReload": "no", "CanStart": "yes", "CanStop": "yes", "CapabilityBoundingSet": "18446744073709551615", "ConditionResult": "yes", "ConditionTimestamp": "Wed 2019-06-05 19:01:33 UTC", "ConditionTimestampMonotonic": "7156622", "Conflicts": "shutdown.target", "ControlPID": "0", "DefaultDependencies": "yes", "DeferAcceptUSec": "0", "Delegate": "no", "Description": "Open-iSCSI iscsid Socket", "DevicePolicy": "auto", "DirectoryMode": "0755", "Documentation": "man:iscsid(8) man:iscsiadm(8)", "FragmentPath": "/usr/lib/systemd/system/iscsid.socket", "FreeBind": "no", "IOScheduling": "0", "IPTOS": "-1", "IPTTL": "-1", "Id": "iscsid.socket", "IgnoreOnIsolate": "no", "IgnoreOnSnapshot": "no", "IgnoreSIGPIPE": "yes", "InactiveEnterTimestampMonotonic": "0", "InactiveExitTimestamp": "Wed 2019-06-05 19:01:33 UTC", "InactiveExitTimestampMonotonic": "7157598", "JobTimeoutAction": "none", "JobTimeoutUSec": "0", "KeepAlive": "no", "KeepAliveIntervalUSec": "0", "KeepAliveProbes": "0", "KeepAliveTimeUSec": "0", "KillMode": "control-group", "KillSignal": "15", "LimitAS": "18446744073709551615", "LimitCORE": "18446744073709551615", "LimitCPU": "18446744073709551615", "LimitDATA": "18446744073709551615", "LimitFSIZE": "18446744073709551615", "LimitLOCKS": "18446744073709551615", "LimitMEMLOCK": "65536", "LimitMSGQUEUE": "819200", "LimitNICE": "0", "LimitNOFILE": "4096", "LimitNPROC": "61816", "LimitRSS": "18446744073709551615", "LimitRTPRIO": "0", "LimitRTTIME": "18446744073709551615", "LimitSIGPENDING": "61816", "LimitSTACK": "18446744073709551615", "ListenStream": "@ISCSIADM_ABSTRACT_NAMESPACE", "LoadState": "loaded", "Mark": "-1", "MaxConnections": "64", "MemoryAccounting": "no", "MemoryCurrent": "18446744073709551615", "MemoryLimit": "18446744073709551615", "MountFlags": "0", "NAccepted": "0", "NConnections": "0", "Names": "iscsid.socket", "NeedDaemonReload": "no", "Nice": "0", "NoDelay": "no", "NoNewPrivileges": "no", "NonBlocking": "no", "OOMScoreAdjust": "0", "OnFailureJobMode": "replace", "PassCredentials": "no", "PassSecurity": "no", "PipeSize": "0", "Priority": "-1", "PrivateDevices": "no", "PrivateNetwork": "no", "PrivateTmp": "no", "ProtectHome": "no", "ProtectSystem": "no", "ReceiveBuffer": "0", "RefuseManualStart": "no", "RefuseManualStop": "no", "RemoveOnStop": "no", "Requires": "sysinit.target", "Result": "success", "ReusePort": "no", "RuntimeDirectoryMode": "0755", "SameProcessGroup": "no", "SecureBits": "0", "SendBuffer": "0", "SendSIGHUP": "no", "SendSIGKILL": "yes", "SocketMode": "0666", "StandardError": "inherit", "StandardInput": "null", "StandardOutput": "journal", "StartupBlockIOWeight": "18446744073709551615", "StartupCPUShares": "18446744073709551615", "StopWhenUnneeded": "no", "SubState": "listening", "SyslogLevelPrefix": "yes", "SyslogPriority": "30", "SystemCallErrorNumber": "0", "TTYReset": "no", "TTYVHangup": "no", "TTYVTDisallocate": "no", "TasksAccounting": "no", "TasksCurrent": "18446744073709551615", "TasksMax": "18446744073709551615", "TimeoutUSec": "1min 30s", "TimerSlackNSec": "50000", "Transient": "no", "Transparent": "no", "Triggers": "iscsid.service", "UMask": "0022", "UnitFilePreset": "disabled", "UnitFileState": "enabled", "WantedBy": "sockets.target", "Wants": "-.slice"}}
2019-06-05 14:04:53,878 p=17240 u=mistral |  TASK [Set fact for restarting Keepalived container] ****************************
2019-06-05 14:04:53,878 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:509
2019-06-05 14:04:53,878 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:53 -0500 (0:00:00.205)       0:01:27.647 ******** 
2019-06-05 14:04:53,898 p=17240 u=mistral |  ok: [lab-controller-0] => {"ansible_facts": {"restart_keepalived": false}, "changed": false}
2019-06-05 14:04:53,907 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:53,923 p=17240 u=mistral |  TASK [Restart Keepalived container] ********************************************
2019-06-05 14:04:53,923 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:512
2019-06-05 14:04:53,923 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:53 -0500 (0:00:00.044)       0:01:27.692 ******** 
2019-06-05 14:04:53,945 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:53,951 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:53,968 p=17240 u=mistral |  TASK [tripleo-module-load : Check whether /etc/modules-load.d exists] **********
2019-06-05 14:04:53,968 p=17240 u=mistral |  task path: /usr/share/ansible/roles/tripleo-module-load/tasks/main.yaml:4
2019-06-05 14:04:53,968 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:53 -0500 (0:00:00.045)       0:01:27.737 ******** 
2019-06-05 14:04:53,997 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:54,064 p=17240 u=mistral |  ok: [lab-controller-0] => {"changed": false, "stat": {"atime": 1559761289.064, "attr_flags": "", "attributes": [], "block_size": 4096, "blocks": 0, "charset": "binary", "ctime": 1559694306.8517835, "dev": 64514, "device_type": 0, "executable": true, "exists": true, "gid": 0, "gr_name": "root", "inode": 6291861, "isblk": false, "ischr": false, "isdir": true, "isfifo": false, "isgid": false, "islnk": false, "isreg": false, "issock": false, "isuid": false, "mimetype": "inode/directory", "mode": "0755", "mtime": 1556212769.0, "nlink": 2, "path": "/etc/modules-load.d", "pw_name": "root", "readable": true, "rgrp": true, "roth": true, "rusr": true, "size": 6, "uid": 0, "version": "18446744071768788004", "wgrp": false, "woth": false, "writeable": true, "wusr": true, "xgrp": true, "xoth": true, "xusr": true}}
2019-06-05 14:04:54,081 p=17240 u=mistral |  TASK [tripleo-module-load : Load modules] **************************************
2019-06-05 14:04:54,081 p=17240 u=mistral |  task path: /usr/share/ansible/roles/tripleo-module-load/tasks/main.yaml:9
2019-06-05 14:04:54,081 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:54 -0500 (0:00:00.113)       0:01:27.851 ******** 
2019-06-05 14:04:54,114 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=ip_vs)  => {"changed": false, "item": {"name": "ip_vs"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:54,289 p=17240 u=mistral |  changed: [lab-controller-0] => (item=ip_vs) => {"changed": true, "item": {"name": "ip_vs"}, "name": "ip_vs", "params": "", "state": "present"}
2019-06-05 14:04:54,308 p=17240 u=mistral |  TASK [tripleo-module-load : Persist modules via modules-load.d] ****************
2019-06-05 14:04:54,308 p=17240 u=mistral |  task path: /usr/share/ansible/roles/tripleo-module-load/tasks/main.yaml:19
2019-06-05 14:04:54,309 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:54 -0500 (0:00:00.227)       0:01:28.078 ******** 
2019-06-05 14:04:54,382 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=ip_vs)  => {"changed": false, "item": {"name": "ip_vs"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:54,632 p=17240 u=mistral |  changed: [lab-controller-0] => (item=ip_vs) => {"changed": true, "checksum": "946b94c34ba96c4823933f2912d9d431cbc5b742", "dest": "/etc/modules-load.d/ip_vs.conf", "gid": 0, "group": "root", "item": {"name": "ip_vs"}, "md5sum": "611767e4923e25e8905b7d7670d8a29d", "mode": "0644", "owner": "root", "secontext": "system_u:object_r:etc_t:s0", "size": 25, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559761494.36-73040712525227/source", "state": "file", "uid": 0}
2019-06-05 14:04:54,648 p=17240 u=mistral |  TASK [tripleo-module-load : Drop module persistence] ***************************
2019-06-05 14:04:54,648 p=17240 u=mistral |  task path: /usr/share/ansible/roles/tripleo-module-load/tasks/main.yaml:31
2019-06-05 14:04:54,648 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:54 -0500 (0:00:00.339)       0:01:28.417 ******** 
2019-06-05 14:04:54,669 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=ip_vs)  => {"changed": false, "item": {"name": "ip_vs"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:54,680 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=ip_vs)  => {"changed": false, "item": {"name": "ip_vs"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:54,697 p=17240 u=mistral |  TASK [tripleo-module-load : Set modules persistence via /etc/modules] **********
2019-06-05 14:04:54,698 p=17240 u=mistral |  task path: /usr/share/ansible/roles/tripleo-module-load/tasks/main.yaml:43
2019-06-05 14:04:54,698 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:54 -0500 (0:00:00.049)       0:01:28.467 ******** 
2019-06-05 14:04:54,717 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=ip_vs)  => {"changed": false, "item": {"name": "ip_vs"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:54,730 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=ip_vs)  => {"changed": false, "item": {"name": "ip_vs"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:54,746 p=17240 u=mistral |  TASK [create persistent directories] *******************************************
2019-06-05 14:04:54,746 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:522
2019-06-05 14:04:54,746 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:54 -0500 (0:00:00.048)       0:01:28.516 ******** 
2019-06-05 14:04:54,778 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/containers/keepalived', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/containers/keepalived", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:54,782 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/keepalived', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/keepalived", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:54,843 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/containers/keepalived', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/containers/keepalived", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/containers/keepalived", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:54,929 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/keepalived', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/keepalived", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/keepalived", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:54,945 p=17240 u=mistral |  TASK [keepalived logs readme] **************************************************
2019-06-05 14:04:54,946 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:532
2019-06-05 14:04:54,946 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:54 -0500 (0:00:00.199)       0:01:28.715 ******** 
2019-06-05 14:04:54,975 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:55,217 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "checksum": "6138faab0f7e4f930c7b6b1b81a72eb1b16eb7e8", "dest": "/var/log/keepalived/readme.txt", "gid": 0, "group": "root", "md5sum": "7ffa6301ab09dcc5d1c90ecaa6ee2fee", "mode": "0644", "owner": "root", "secontext": "system_u:object_r:var_log_t:s0", "size": 88, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559761494.96-28555850655314/source", "state": "file", "uid": 0}
2019-06-05 14:04:55,233 p=17240 u=mistral |  TASK [create persistent directories] *******************************************
2019-06-05 14:04:55,233 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:541
2019-06-05 14:04:55,234 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:55 -0500 (0:00:00.287)       0:01:29.003 ******** 
2019-06-05 14:04:55,266 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/containers/keystone', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/containers/keystone", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:55,270 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/containers/httpd/keystone', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/containers/httpd/keystone", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:55,272 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/keystone', u'setype': u'var_log_t'})  => {"changed": false, "item": {"path": "/var/log/keystone", "setype": "var_log_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:55,331 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/containers/keystone', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/containers/keystone", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/containers/keystone", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:55,417 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/containers/httpd/keystone', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/containers/httpd/keystone", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/containers/httpd/keystone", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:55,502 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/keystone', u'setype': u'var_log_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/keystone", "setype": "var_log_t"}, "mode": "0755", "owner": "root", "path": "/var/log/keystone", "secontext": "unconfined_u:object_r:var_log_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:55,520 p=17240 u=mistral |  TASK [keystone logs readme] ****************************************************
2019-06-05 14:04:55,520 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:553
2019-06-05 14:04:55,520 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:55 -0500 (0:00:00.286)       0:01:29.290 ******** 
2019-06-05 14:04:55,551 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:55,795 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "checksum": "910be882addb6df99267e9bd303f6d9bf658562e", "dest": "/var/log/keystone/readme.txt", "gid": 0, "group": "root", "md5sum": "d88b8d6dcbd7e706d0ae05156d240bd8", "mode": "0644", "owner": "root", "secontext": "system_u:object_r:keystone_log_t:s0", "size": 123, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559761495.53-272868884904498/source", "state": "file", "uid": 0}
2019-06-05 14:04:55,812 p=17240 u=mistral |  TASK [create persistent directories] *******************************************
2019-06-05 14:04:55,812 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:562
2019-06-05 14:04:55,812 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:55 -0500 (0:00:00.291)       0:01:29.581 ******** 
2019-06-05 14:04:55,844 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/memcached', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/memcached", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:55,910 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/memcached', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/memcached", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/memcached", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:55,927 p=17240 u=mistral |  TASK [memcached logs readme] ***************************************************
2019-06-05 14:04:55,927 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:570
2019-06-05 14:04:55,927 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:55 -0500 (0:00:00.115)       0:01:29.696 ******** 
2019-06-05 14:04:55,956 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:56,197 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "checksum": "3b6f3952a077d2e5003df30c8c439478917cb6c4", "dest": "/var/log/memcached/readme.txt", "gid": 0, "group": "root", "md5sum": "ffdb1524e5789470856ae32ded4e2f80", "mode": "0644", "owner": "root", "secontext": "system_u:object_r:var_log_t:s0", "size": 48, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559761495.94-63173272201966/source", "state": "file", "uid": 0}
2019-06-05 14:04:56,214 p=17240 u=mistral |  TASK [create persistent directories] *******************************************
2019-06-05 14:04:56,214 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:577
2019-06-05 14:04:56,214 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:56 -0500 (0:00:00.287)       0:01:29.984 ******** 
2019-06-05 14:04:56,246 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/containers/mysql', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/containers/mysql", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:56,250 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/lib/mysql', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/lib/mysql", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:56,254 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/mariadb', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/mariadb", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:56,317 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/containers/mysql', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/containers/mysql", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/containers/mysql", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:56,399 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/lib/mysql', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/lib/mysql", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/lib/mysql", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:56,488 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/mariadb', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/mariadb", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/mariadb", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:56,505 p=17240 u=mistral |  TASK [mysql logs readme] *******************************************************
2019-06-05 14:04:56,505 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:589
2019-06-05 14:04:56,505 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:56 -0500 (0:00:00.290)       0:01:30.274 ******** 
2019-06-05 14:04:56,535 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:56,796 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "checksum": "de8fb5fe96200ab286121f8a09419702bd693743", "dest": "/var/log/mariadb/readme.txt", "gid": 0, "group": "root", "md5sum": "1f3e80eed7060dfe5ee49c8063244c53", "mode": "0644", "owner": "root", "secontext": "system_u:object_r:mysqld_log_t:s0", "size": 78, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559761496.52-275227472707124/source", "state": "file", "uid": 0}
2019-06-05 14:04:56,814 p=17240 u=mistral |  TASK [create persistent directories] *******************************************
2019-06-05 14:04:56,814 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:598
2019-06-05 14:04:56,814 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:56 -0500 (0:00:00.309)       0:01:30.584 ******** 
2019-06-05 14:04:56,856 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/containers/neutron', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/containers/neutron", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:56,857 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/containers/httpd/neutron-api', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/containers/httpd/neutron-api", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:56,860 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/neutron', u'setype': u'var_log_t'})  => {"changed": false, "item": {"path": "/var/log/neutron", "setype": "var_log_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:56,918 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/containers/neutron', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/containers/neutron", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/containers/neutron", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:57,007 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/containers/httpd/neutron-api', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/containers/httpd/neutron-api", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/containers/httpd/neutron-api", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:57,093 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/neutron', u'setype': u'var_log_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/neutron", "setype": "var_log_t"}, "mode": "0755", "owner": "root", "path": "/var/log/neutron", "secontext": "unconfined_u:object_r:var_log_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:57,110 p=17240 u=mistral |  TASK [neutron logs readme] *****************************************************
2019-06-05 14:04:57,111 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:610
2019-06-05 14:04:57,111 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:57 -0500 (0:00:00.296)       0:01:30.880 ******** 
2019-06-05 14:04:57,139 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:57,380 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "checksum": "f5a95f434a4aad25a9a81a045dec39159a6e8864", "dest": "/var/log/neutron/readme.txt", "gid": 0, "group": "root", "md5sum": "5f0556f928d9bce18671eead8048ea17", "mode": "0644", "owner": "root", "secontext": "system_u:object_r:neutron_log_t:s0", "size": 124, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559761497.12-247871349812705/source", "state": "file", "uid": 0}
2019-06-05 14:04:57,397 p=17240 u=mistral |  TASK [create persistent directories] *******************************************
2019-06-05 14:04:57,397 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:619
2019-06-05 14:04:57,397 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:57 -0500 (0:00:00.286)       0:01:31.167 ******** 
2019-06-05 14:04:57,432 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/containers/nova', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/containers/nova", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:57,437 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/containers/httpd/nova-api', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/containers/httpd/nova-api", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:57,441 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/nova', u'setype': u'var_log_t'})  => {"changed": false, "item": {"path": "/var/log/nova", "setype": "var_log_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:57,506 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/containers/nova', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/containers/nova", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/containers/nova", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:57,593 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/containers/httpd/nova-api', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/containers/httpd/nova-api", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/containers/httpd/nova-api", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:57,678 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/nova', u'setype': u'var_log_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/nova", "setype": "var_log_t"}, "mode": "0755", "owner": "root", "path": "/var/log/nova", "secontext": "unconfined_u:object_r:var_log_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:57,696 p=17240 u=mistral |  TASK [nova logs readme] ********************************************************
2019-06-05 14:04:57,696 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:631
2019-06-05 14:04:57,696 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:57 -0500 (0:00:00.298)       0:01:31.466 ******** 
2019-06-05 14:04:57,725 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:57,966 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "checksum": "c2216cc4edf5d3ce90f10748c3243db4e1842a85", "dest": "/var/log/nova/readme.txt", "gid": 0, "group": "root", "md5sum": "9d8ea066cd36b60e7e3fb5ff27f03339", "mode": "0644", "owner": "root", "secontext": "system_u:object_r:nova_log_t:s0", "size": 113, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559761497.71-236069875170571/source", "state": "file", "uid": 0}
2019-06-05 14:04:57,983 p=17240 u=mistral |  TASK [create persistent directories] *******************************************
2019-06-05 14:04:57,983 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:640
2019-06-05 14:04:57,983 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:57 -0500 (0:00:00.286)       0:01:31.753 ******** 
2019-06-05 14:04:58,015 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/containers/nova', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/containers/nova", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:58,019 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/nova', u'setype': u'var_log_t'})  => {"changed": false, "item": {"path": "/var/log/nova", "setype": "var_log_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:58,080 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/containers/nova', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/containers/nova", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/containers/nova", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:58,165 p=17240 u=mistral |  ok: [lab-controller-0] => (item={u'path': u'/var/log/nova', u'setype': u'var_log_t'}) => {"changed": false, "gid": 0, "group": "root", "item": {"path": "/var/log/nova", "setype": "var_log_t"}, "mode": "0755", "owner": "root", "path": "/var/log/nova", "secontext": "unconfined_u:object_r:var_log_t:s0", "size": 24, "state": "directory", "uid": 0}
2019-06-05 14:04:58,183 p=17240 u=mistral |  TASK [create persistent directories] *******************************************
2019-06-05 14:04:58,183 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:650
2019-06-05 14:04:58,183 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:58 -0500 (0:00:00.199)       0:01:31.952 ******** 
2019-06-05 14:04:58,216 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/containers/nova', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/containers/nova", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:58,222 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/containers/httpd/nova-metadata', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/containers/httpd/nova-metadata", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:58,224 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/nova', u'setype': u'var_log_t'})  => {"changed": false, "item": {"path": "/var/log/nova", "setype": "var_log_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:58,282 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/containers/nova', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/containers/nova", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/containers/nova", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:58,368 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/containers/httpd/nova-metadata', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/containers/httpd/nova-metadata", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/containers/httpd/nova-metadata", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:58,455 p=17240 u=mistral |  ok: [lab-controller-0] => (item={u'path': u'/var/log/nova', u'setype': u'var_log_t'}) => {"changed": false, "gid": 0, "group": "root", "item": {"path": "/var/log/nova", "setype": "var_log_t"}, "mode": "0755", "owner": "root", "path": "/var/log/nova", "secontext": "unconfined_u:object_r:var_log_t:s0", "size": 24, "state": "directory", "uid": 0}
2019-06-05 14:04:58,472 p=17240 u=mistral |  TASK [create persistent directories] *******************************************
2019-06-05 14:04:58,472 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:662
2019-06-05 14:04:58,472 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:58 -0500 (0:00:00.289)       0:01:32.242 ******** 
2019-06-05 14:04:58,506 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/containers/nova', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/containers/nova", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:58,507 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/containers/httpd/nova-placement', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/containers/httpd/nova-placement", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:58,512 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/nova', u'setype': u'var_log_t'})  => {"changed": false, "item": {"path": "/var/log/nova", "setype": "var_log_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:58,569 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/containers/nova', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/containers/nova", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/containers/nova", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:58,655 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/containers/httpd/nova-placement', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/containers/httpd/nova-placement", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/containers/httpd/nova-placement", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:58,741 p=17240 u=mistral |  ok: [lab-controller-0] => (item={u'path': u'/var/log/nova', u'setype': u'var_log_t'}) => {"changed": false, "gid": 0, "group": "root", "item": {"path": "/var/log/nova", "setype": "var_log_t"}, "mode": "0755", "owner": "root", "path": "/var/log/nova", "secontext": "unconfined_u:object_r:var_log_t:s0", "size": 24, "state": "directory", "uid": 0}
2019-06-05 14:04:58,758 p=17240 u=mistral |  TASK [create persistent directory] *********************************************
2019-06-05 14:04:58,759 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:674
2019-06-05 14:04:58,759 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:58 -0500 (0:00:00.286)       0:01:32.528 ******** 
2019-06-05 14:04:58,787 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:58,851 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "gid": 0, "group": "root", "mode": "0755", "owner": "root", "path": "/var/lib/nova", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:58,868 p=17240 u=mistral |  TASK [create persistent directories] *******************************************
2019-06-05 14:04:58,868 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:679
2019-06-05 14:04:58,868 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:58 -0500 (0:00:00.109)       0:01:32.637 ******** 
2019-06-05 14:04:58,900 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/containers/openvswitch', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/containers/openvswitch", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:58,903 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/lib/openvswitch/ovn', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/lib/openvswitch/ovn", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:58,907 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/openvswitch', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/openvswitch", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:58,967 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/containers/openvswitch', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/containers/openvswitch", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/containers/openvswitch", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:59,054 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/lib/openvswitch/ovn', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/lib/openvswitch/ovn", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/lib/openvswitch/ovn", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:59,139 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/openvswitch', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 1000, "group": "hugetlbfs", "item": {"path": "/var/log/openvswitch", "setype": "svirt_sandbox_file_t"}, "mode": "0750", "owner": "openvswitch", "path": "/var/log/openvswitch", "secontext": "system_u:object_r:container_file_t:s0", "size": 54, "state": "directory", "uid": 992}
2019-06-05 14:04:59,158 p=17240 u=mistral |  TASK [openvswitch logs readme] *************************************************
2019-06-05 14:04:59,158 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:691
2019-06-05 14:04:59,158 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:59 -0500 (0:00:00.290)       0:01:32.927 ******** 
2019-06-05 14:04:59,188 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:59,426 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "checksum": "a42a1d799da8bbfe9279a54cdb49379733320d91", "dest": "/var/log/openvswitch/readme.txt", "gid": 0, "group": "root", "md5sum": "de2f90ebdd31015721582bd406ba9900", "mode": "0644", "owner": "root", "secontext": "system_u:object_r:openvswitch_log_t:s0", "size": 90, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559761499.17-251653539476617/source", "state": "file", "uid": 0}
2019-06-05 14:04:59,443 p=17240 u=mistral |  TASK [create persistent directories] *******************************************
2019-06-05 14:04:59,443 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:700
2019-06-05 14:04:59,443 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:59 -0500 (0:00:00.284)       0:01:33.212 ******** 
2019-06-05 14:04:59,475 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/containers/openvswitch', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/containers/openvswitch", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:59,482 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/openvswitch', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/openvswitch", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:59,538 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/containers/openvswitch', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/containers/openvswitch", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/containers/openvswitch", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:59,627 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/openvswitch', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 1000, "group": "hugetlbfs", "item": {"path": "/var/log/openvswitch", "setype": "svirt_sandbox_file_t"}, "mode": "0750", "owner": "openvswitch", "path": "/var/log/openvswitch", "secontext": "system_u:object_r:container_file_t:s0", "size": 72, "state": "directory", "uid": 992}
2019-06-05 14:04:59,645 p=17240 u=mistral |  TASK [create persistent directories] *******************************************
2019-06-05 14:04:59,646 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:710
2019-06-05 14:04:59,646 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:59 -0500 (0:00:00.202)       0:01:33.415 ******** 
2019-06-05 14:04:59,682 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/containers/panko', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/containers/panko", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:59,697 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/containers/httpd/panko-api', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/containers/httpd/panko-api", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:59,698 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/panko', u'setype': u'var_log_t'})  => {"changed": false, "item": {"path": "/var/log/panko", "setype": "var_log_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:04:59,752 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/containers/panko', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/containers/panko", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/containers/panko", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:59,838 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/containers/httpd/panko-api', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/containers/httpd/panko-api", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/containers/httpd/panko-api", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:59,925 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/panko', u'setype': u'var_log_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/panko", "setype": "var_log_t"}, "mode": "0755", "owner": "root", "path": "/var/log/panko", "secontext": "unconfined_u:object_r:var_log_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:04:59,942 p=17240 u=mistral |  TASK [panko logs readme] *******************************************************
2019-06-05 14:04:59,942 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:722
2019-06-05 14:04:59,942 p=17240 u=mistral |  Wednesday 05 June 2019  14:04:59 -0500 (0:00:00.296)       0:01:33.711 ******** 
2019-06-05 14:04:59,971 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:00,212 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "checksum": "903397bbd82e9b1f53087e3d7e8975d851857ce2", "dest": "/var/log/panko/readme.txt", "gid": 0, "group": "root", "md5sum": "14a94d667b6fd4a9f59069fc77019fd2", "mode": "0644", "owner": "root", "secontext": "system_u:object_r:var_log_t:s0", "size": 118, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559761499.95-279255367217399/source", "state": "file", "uid": 0}
2019-06-05 14:05:00,229 p=17240 u=mistral |  TASK [create persistent directories] *******************************************
2019-06-05 14:05:00,229 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:731
2019-06-05 14:05:00,229 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:00 -0500 (0:00:00.286)       0:01:33.998 ******** 
2019-06-05 14:05:00,261 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/containers/rabbitmq', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/containers/rabbitmq", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:00,265 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/lib/rabbitmq', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/lib/rabbitmq", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:00,269 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/rabbitmq', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/rabbitmq", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:00,326 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/containers/rabbitmq', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/containers/rabbitmq", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/containers/rabbitmq", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:05:00,414 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/lib/rabbitmq', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/lib/rabbitmq", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/lib/rabbitmq", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:05:00,500 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/rabbitmq', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/rabbitmq", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/rabbitmq", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:05:00,517 p=17240 u=mistral |  TASK [rabbitmq logs readme] ****************************************************
2019-06-05 14:05:00,517 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:743
2019-06-05 14:05:00,518 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:00 -0500 (0:00:00.288)       0:01:34.287 ******** 
2019-06-05 14:05:00,547 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:00,787 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "checksum": "ee241f2199f264c9d0f384cf389fe255e8bf8a77", "dest": "/var/log/rabbitmq/readme.txt", "gid": 0, "group": "root", "md5sum": "425dfecbbb1380a12acf083fa35e4921", "mode": "0644", "owner": "root", "secontext": "system_u:object_r:rabbitmq_var_log_t:s0", "size": 84, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559761500.53-3420298044160/source", "state": "file", "uid": 0}
2019-06-05 14:05:00,803 p=17240 u=mistral |  TASK [create persistent directories] *******************************************
2019-06-05 14:05:00,803 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:752
2019-06-05 14:05:00,804 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:00 -0500 (0:00:00.286)       0:01:34.573 ******** 
2019-06-05 14:05:00,835 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/containers/redis', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/containers/redis", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:00,841 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/run/redis', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/run/redis", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:00,847 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/redis', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/redis", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:00,900 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/containers/redis', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/containers/redis", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/containers/redis", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:05:00,991 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/run/redis', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/run/redis", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/run/redis", "secontext": "unconfined_u:object_r:var_run_t:s0", "size": 40, "state": "directory", "uid": 0}
2019-06-05 14:05:01,074 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/redis', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/redis", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/redis", "secontext": "unconfined_u:object_r:var_log_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:05:01,091 p=17240 u=mistral |  TASK [ensure /var/run/redis is present upon reboot] ****************************
2019-06-05 14:05:01,091 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:763
2019-06-05 14:05:01,091 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:01 -0500 (0:00:00.287)       0:01:34.861 ******** 
2019-06-05 14:05:01,121 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:01,359 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "checksum": "d3fad5ca3be4a7dbdc3d96368a3af1cb7becc95f", "dest": "/etc/tmpfiles.d/var-run-redis.conf", "gid": 0, "group": "root", "md5sum": "2162dae449c41f30d844a2b09f73b19c", "mode": "0644", "owner": "root", "secontext": "system_u:object_r:etc_t:s0", "size": 36, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559761501.1-223432159932324/source", "state": "file", "uid": 0}
2019-06-05 14:05:01,376 p=17240 u=mistral |  TASK [redis logs readme] *******************************************************
2019-06-05 14:05:01,376 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:769
2019-06-05 14:05:01,376 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:01 -0500 (0:00:00.284)       0:01:35.145 ******** 
2019-06-05 14:05:01,405 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:01,645 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "checksum": "42d03af8abf93e87fdb3fc69702638fc81d943fb", "dest": "/var/log/redis/readme.txt", "gid": 0, "group": "root", "md5sum": "26fc3dbfb40d3414a608e987cc577748", "mode": "0644", "owner": "root", "secontext": "system_u:object_r:redis_log_t:s0", "size": 78, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559761501.39-224120640494319/source", "state": "file", "uid": 0}
2019-06-05 14:05:01,662 p=17240 u=mistral |  TASK [create persistent directories] *******************************************
2019-06-05 14:05:01,663 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:778
2019-06-05 14:05:01,663 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:01 -0500 (0:00:00.286)       0:01:35.432 ******** 
2019-06-05 14:05:01,695 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/srv/node', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/srv/node", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:01,699 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/swift', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/swift", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:01,759 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/srv/node', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/srv/node", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/srv/node", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:05:01,844 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/swift', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/swift", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/swift", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:05:01,862 p=17240 u=mistral |  TASK [stat] ********************************************************************
2019-06-05 14:05:01,862 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:788
2019-06-05 14:05:01,862 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:01 -0500 (0:00:00.199)       0:01:35.631 ******** 
2019-06-05 14:05:01,890 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:01,955 p=17240 u=mistral |  ok: [lab-controller-0] => {"changed": false, "stat": {"atime": 1559761501.834688, "attr_flags": "", "attributes": [], "block_size": 4096, "blocks": 0, "charset": "binary", "ctime": 1559761501.834688, "dev": 64514, "device_type": 0, "executable": true, "exists": true, "gid": 0, "gr_name": "root", "inode": 48234802, "isblk": false, "ischr": false, "isdir": true, "isfifo": false, "isgid": false, "islnk": false, "isreg": false, "issock": false, "isuid": false, "mimetype": "inode/directory", "mode": "0755", "mtime": 1559761501.834688, "nlink": 2, "path": "/var/log/swift", "pw_name": "root", "readable": true, "rgrp": true, "roth": true, "rusr": true, "size": 6, "uid": 0, "version": "504403173", "wgrp": false, "woth": false, "writeable": true, "wusr": true, "xgrp": true, "xoth": true, "xusr": true}}
2019-06-05 14:05:01,972 p=17240 u=mistral |  TASK [Create swift logging symlink] ********************************************
2019-06-05 14:05:01,972 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:790
2019-06-05 14:05:01,973 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:01 -0500 (0:00:00.110)       0:01:35.742 ******** 
2019-06-05 14:05:02,001 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:02,066 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "dest": "/var/log/containers/swift", "gid": 0, "group": "root", "mode": "0777", "owner": "root", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 14, "src": "/var/log/swift", "state": "link", "uid": 0}
2019-06-05 14:05:02,082 p=17240 u=mistral |  TASK [Check if rsyslog exists] *************************************************
2019-06-05 14:05:02,082 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:796
2019-06-05 14:05:02,082 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:02 -0500 (0:00:00.109)       0:01:35.852 ******** 
2019-06-05 14:05:02,114 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:02,266 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "cmd": "systemctl list-unit-files --type=service | grep -q rsyslog", "delta": "0:00:00.093255", "end": "2019-06-05 19:05:02.255571", "failed_when_result": false, "rc": 0, "start": "2019-06-05 19:05:02.162316", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}
2019-06-05 14:05:02,282 p=17240 u=mistral |  TASK [Forward logging to swift.log file] ***************************************
2019-06-05 14:05:02,283 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:801
2019-06-05 14:05:02,283 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:02 -0500 (0:00:00.200)       0:01:36.052 ******** 
2019-06-05 14:05:02,312 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:02,557 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "checksum": "828097d22e649626706b267b5a61f05e49999586", "dest": "/etc/rsyslog.d/openstack-swift.conf", "gid": 0, "group": "root", "md5sum": "2118142de3156b2432c5c12816a4967c", "mode": "0644", "owner": "root", "secontext": "system_u:object_r:syslog_conf_t:s0", "size": 138, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559761502.29-194645433103013/source", "state": "file", "uid": 0}
2019-06-05 14:05:02,573 p=17240 u=mistral |  TASK [Restart rsyslogd service after logging conf change] **********************
2019-06-05 14:05:02,573 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:812
2019-06-05 14:05:02,574 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:02 -0500 (0:00:00.290)       0:01:36.343 ******** 
2019-06-05 14:05:02,603 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:02,742 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "name": "rsyslog", "state": "started", "status": {"ActiveEnterTimestamp": "Wed 2019-06-05 19:04:51 UTC", "ActiveEnterTimestampMonotonic": "203284239", "ActiveExitTimestamp": "Wed 2019-06-05 19:04:50 UTC", "ActiveExitTimestampMonotonic": "203258377", "ActiveState": "active", "After": "system.slice basic.target network.target network-online.target", "AllowIsolate": "no", "AmbientCapabilities": "0", "AssertResult": "yes", "AssertTimestamp": "Wed 2019-06-05 19:04:50 UTC", "AssertTimestampMonotonic": "203261296", "Before": "pacemaker.service multi-user.target shutdown.target", "BlockIOAccounting": "no", "BlockIOWeight": "18446744073709551615", "CPUAccounting": "no", "CPUQuotaPerSecUSec": "infinity", "CPUSchedulingPolicy": "0", "CPUSchedulingPriority": "0", "CPUSchedulingResetOnFork": "no", "CPUShares": "18446744073709551615", "CanIsolate": "no", "CanReload": "no", "CanStart": "yes", "CanStop": "yes", "CapabilityBoundingSet": "18446744073709551615", "ConditionResult": "yes", "ConditionTimestamp": "Wed 2019-06-05 19:04:50 UTC", "ConditionTimestampMonotonic": "203261296", "Conflicts": "shutdown.target", "ControlGroup": "/system.slice/rsyslog.service", "ControlPID": "0", "DefaultDependencies": "yes", "Delegate": "no", "Description": "System Logging Service", "DevicePolicy": "auto", "Documentation": "man:rsyslogd(8) http://www.rsyslog.com/doc/", "EnvironmentFile": "/etc/sysconfig/rsyslog (ignore_errors=yes)", "ExecMainCode": "0", "ExecMainExitTimestampMonotonic": "0", "ExecMainPID": "18332", "ExecMainStartTimestamp": "Wed 2019-06-05 19:04:50 UTC", "ExecMainStartTimestampMonotonic": "203261819", "ExecMainStatus": "0", "ExecStart": "{ path=/usr/sbin/rsyslogd ; argv[]=/usr/sbin/rsyslogd -n $SYSLOGD_OPTIONS ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }", "FailureAction": "none", "FileDescriptorStoreMax": "0", "FragmentPath": "/usr/lib/systemd/system/rsyslog.service", "GuessMainPID": "yes", "IOScheduling": "0", "Id": "rsyslog.service", "IgnoreOnIsolate": "no", "IgnoreOnSnapshot": "no", "IgnoreSIGPIPE": "yes", "InactiveEnterTimestamp": "Wed 2019-06-05 19:04:50 UTC", "InactiveEnterTimestampMonotonic": "203260935", "InactiveExitTimestamp": "Wed 2019-06-05 19:04:50 UTC", "InactiveExitTimestampMonotonic": "203261840", "JobTimeoutAction": "none", "JobTimeoutUSec": "0", "KillMode": "control-group", "KillSignal": "15", "LimitAS": "18446744073709551615", "LimitCORE": "18446744073709551615", "LimitCPU": "18446744073709551615", "LimitDATA": "18446744073709551615", "LimitFSIZE": "18446744073709551615", "LimitLOCKS": "18446744073709551615", "LimitMEMLOCK": "65536", "LimitMSGQUEUE": "819200", "LimitNICE": "0", "LimitNOFILE": "4096", "LimitNPROC": "61816", "LimitRSS": "18446744073709551615", "LimitRTPRIO": "0", "LimitRTTIME": "18446744073709551615", "LimitSIGPENDING": "61816", "LimitSTACK": "18446744073709551615", "LoadState": "loaded", "MainPID": "18332", "MemoryAccounting": "no", "MemoryCurrent": "18446744073709551615", "MemoryLimit": "18446744073709551615", "MountFlags": "0", "Names": "rsyslog.service", "NeedDaemonReload": "no", "Nice": "0", "NoNewPrivileges": "no", "NonBlocking": "no", "NotifyAccess": "main", "OOMScoreAdjust": "0", "OnFailureJobMode": "replace", "PermissionsStartOnly": "no", "PrivateDevices": "no", "PrivateNetwork": "no", "PrivateTmp": "no", "ProtectHome": "no", "ProtectSystem": "no", "RefuseManualStart": "no", "RefuseManualStop": "no", "RemainAfterExit": "no", "Requires": "basic.target", "Restart": "on-failure", "RestartUSec": "100ms", "Result": "success", "RootDirectoryStartOnly": "no", "RuntimeDirectoryMode": "0755", "SameProcessGroup": "no", "SecureBits": "0", "SendSIGHUP": "no", "SendSIGKILL": "yes", "Slice": "system.slice", "StandardError": "inherit", "StandardInput": "null", "StandardOutput": "null", "StartLimitAction": "none", "StartLimitBurst": "5", "StartLimitInterval": "10000000", "StartupBlockIOWeight": "18446744073709551615", "StartupCPUShares": "18446744073709551615", "StatusErrno": "0", "StopWhenUnneeded": "no", "SubState": "running", "SyslogLevelPrefix": "yes", "SyslogPriority": "30", "SystemCallErrorNumber": "0", "TTYReset": "no", "TTYVHangup": "no", "TTYVTDisallocate": "no", "TasksAccounting": "no", "TasksCurrent": "18446744073709551615", "TasksMax": "18446744073709551615", "TimeoutStartUSec": "1min 30s", "TimeoutStopUSec": "1min 30s", "TimerSlackNSec": "50000", "Transient": "no", "Type": "notify", "UMask": "0066", "UnitFilePreset": "enabled", "UnitFileState": "enabled", "WantedBy": "multi-user.target", "Wants": "system.slice network.target network-online.target", "WatchdogTimestamp": "Wed 2019-06-05 19:04:51 UTC", "WatchdogTimestampMonotonic": "203284223", "WatchdogUSec": "0"}}
2019-06-05 14:05:02,760 p=17240 u=mistral |  TASK [create persistent directories] *******************************************
2019-06-05 14:05:02,760 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:817
2019-06-05 14:05:02,760 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:02 -0500 (0:00:00.186)       0:01:36.530 ******** 
2019-06-05 14:05:02,794 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/srv/node', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/srv/node", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:02,798 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/cache/swift', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/cache/swift", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:02,802 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/swift', u'setype': u'var_log_t'})  => {"changed": false, "item": {"path": "/var/log/swift", "setype": "var_log_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:02,806 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item={u'path': u'/var/log/containers', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/containers", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:02,860 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/srv/node', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/srv/node", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/srv/node", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:05:02,946 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/cache/swift', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/cache/swift", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/cache/swift", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:05:03,031 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/swift', u'setype': u'var_log_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/swift", "setype": "var_log_t"}, "mode": "0755", "owner": "root", "path": "/var/log/swift", "secontext": "unconfined_u:object_r:var_log_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:05:03,116 p=17240 u=mistral |  changed: [lab-controller-0] => (item={u'path': u'/var/log/containers', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/containers", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/containers", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 4096, "state": "directory", "uid": 0}
2019-06-05 14:05:03,134 p=17240 u=mistral |  TASK [Set swift_use_local_disks fact] ******************************************
2019-06-05 14:05:03,134 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:831
2019-06-05 14:05:03,135 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:03 -0500 (0:00:00.374)       0:01:36.904 ******** 
2019-06-05 14:05:03,154 p=17240 u=mistral |  ok: [lab-controller-0] => {"ansible_facts": {"swift_use_local_disks": true}, "changed": false}
2019-06-05 14:05:03,163 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:03,179 p=17240 u=mistral |  TASK [Create Swift d1 directory if needed] *************************************
2019-06-05 14:05:03,179 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:834
2019-06-05 14:05:03,180 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:03 -0500 (0:00:00.044)       0:01:36.949 ******** 
2019-06-05 14:05:03,209 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:03,272 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "gid": 0, "group": "root", "mode": "0755", "owner": "root", "path": "/srv/node/d1", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:05:03,289 p=17240 u=mistral |  TASK [Create swift logging symlink] ********************************************
2019-06-05 14:05:03,289 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:839
2019-06-05 14:05:03,289 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:03 -0500 (0:00:00.109)       0:01:37.058 ******** 
2019-06-05 14:05:03,321 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:03,384 p=17240 u=mistral |  ok: [lab-controller-0] => {"changed": false, "dest": "/var/log/containers/swift", "gid": 0, "group": "root", "mode": "0777", "owner": "root", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 14, "src": "/var/log/swift", "state": "link", "uid": 0}
2019-06-05 14:05:03,403 p=17240 u=mistral |  TASK [swift logs readme] *******************************************************
2019-06-05 14:05:03,403 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:846
2019-06-05 14:05:03,404 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:03 -0500 (0:00:00.114)       0:01:37.173 ******** 
2019-06-05 14:05:03,435 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:03,686 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "checksum": "42510a6de124722d6efbc2b1bb038bfe97e5b6d3", "dest": "/var/log/swift/readme.txt", "gid": 0, "group": "root", "md5sum": "23163287d564762945ee1738f049dc10", "mode": "0644", "owner": "root", "secontext": "system_u:object_r:var_log_t:s0", "size": 116, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559761503.41-129547164071684/source", "state": "file", "uid": 0}
2019-06-05 14:05:03,703 p=17240 u=mistral |  TASK [Set fact for SwiftRawDisks] **********************************************
2019-06-05 14:05:03,703 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:855
2019-06-05 14:05:03,704 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:03 -0500 (0:00:00.300)       0:01:37.473 ******** 
2019-06-05 14:05:03,724 p=17240 u=mistral |  ok: [lab-controller-0] => {"ansible_facts": {"swift_raw_disks": {}}, "changed": false}
2019-06-05 14:05:03,732 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:03,748 p=17240 u=mistral |  TASK [Format SwiftRawDisks] ****************************************************
2019-06-05 14:05:03,749 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:858
2019-06-05 14:05:03,749 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:03 -0500 (0:00:00.045)       0:01:37.518 ******** 
2019-06-05 14:05:03,777 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:03,794 p=17240 u=mistral |  TASK [Mount devices defined in SwiftRawDisks] **********************************
2019-06-05 14:05:03,794 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:865
2019-06-05 14:05:03,794 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:03 -0500 (0:00:00.045)       0:01:37.563 ******** 
2019-06-05 14:05:03,823 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:03,841 p=17240 u=mistral |  TASK [Populate service facts (chrony)] *****************************************
2019-06-05 14:05:03,841 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:874
2019-06-05 14:05:03,841 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:03 -0500 (0:00:00.047)       0:01:37.610 ******** 
2019-06-05 14:05:03,871 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:04,087 p=17240 u=mistral |  ok: [lab-controller-0] => {"ansible_facts": {"services": {"auditd.service": {"name": "auditd.service", "source": "systemd", "state": "running"}, "auth-rpcgss-module.service": {"name": "auth-rpcgss-module.service", "source": "systemd", "state": "stopped"}, "blk-availability.service": {"name": "blk-availability.service", "source": "systemd", "state": "stopped"}, "chronyd.service": {"name": "chronyd.service", "source": "systemd", "state": "running"}, "cloud-config.service": {"name": "cloud-config.service", "source": "systemd", "state": "stopped"}, "cloud-final.service": {"name": "cloud-final.service", "source": "systemd", "state": "stopped"}, "cloud-init-local.service": {"name": "cloud-init-local.service", "source": "systemd", "state": "stopped"}, "cloud-init.service": {"name": "cloud-init.service", "source": "systemd", "state": "stopped"}, "corosync.service": {"name": "corosync.service", "source": "systemd", "state": "stopped"}, "cpupower.service": {"name": "cpupower.service", "source": "systemd", "state": "stopped"}, "crond.service": {"name": "crond.service", "source": "systemd", "state": "running"}, "dbus.service": {"name": "dbus.service", "source": "systemd", "state": "running"}, "dhcp-interface@br-ex.service": {"name": "dhcp-interface@br-ex.service", "source": "systemd", "state": "stopped"}, "dhcp-interface@eth0.service": {"name": "dhcp-interface@eth0.service", "source": "systemd", "state": "stopped"}, "dhcp-interface@eth1.service": {"name": "dhcp-interface@eth1.service", "source": "systemd", "state": "stopped"}, "dhcp-interface@ovs-system.service": {"name": "dhcp-interface@ovs-system.service", "source": "systemd", "state": "stopped"}, "dhcp-interface@vlan10.service": {"name": "dhcp-interface@vlan10.service", "source": "systemd", "state": "stopped"}, "dhcp-interface@vlan20.service": {"name": "dhcp-interface@vlan20.service", "source": "systemd", "state": "stopped"}, "dhcp-interface@vlan30.service": {"name": "dhcp-interface@vlan30.service", "source": "systemd", "state": "stopped"}, "dhcp-interface@vlan40.service": {"name": "dhcp-interface@vlan40.service", "source": "systemd", "state": "stopped"}, "dhcp-interface@vlan50.service": {"name": "dhcp-interface@vlan50.service", "source": "systemd", "state": "stopped"}, "dm-event.service": {"name": "dm-event.service", "source": "systemd", "state": "stopped"}, "docker-cleanup.service": {"name": "docker-cleanup.service", "source": "systemd", "state": "stopped"}, "docker-storage-setup.service": {"name": "docker-storage-setup.service", "source": "systemd", "state": "stopped"}, "docker.service": {"name": "docker.service", "source": "systemd", "state": "running"}, "dracut-shutdown.service": {"name": "dracut-shutdown.service", "source": "systemd", "state": "stopped"}, "dynamic-login.service": {"name": "dynamic-login.service", "source": "systemd", "state": "stopped"}, "emergency.service": {"name": "emergency.service", "source": "systemd", "state": "stopped"}, "getty@tty1.service": {"name": "getty@tty1.service", "source": "systemd", "state": "running"}, "gssproxy.service": {"name": "gssproxy.service", "source": "systemd", "state": "running"}, "ip6tables.service": {"name": "ip6tables.service", "source": "systemd", "state": "stopped"}, "iptables.service": {"name": "iptables.service", "source": "systemd", "state": "stopped"}, "irqbalance.service": {"name": "irqbalance.service", "source": "systemd", "state": "running"}, "iscsi-shutdown.service": {"name": "iscsi-shutdown.service", "source": "systemd", "state": "stopped"}, "iscsi.service": {"name": "iscsi.service", "source": "systemd", "state": "stopped"}, "iscsid.service": {"name": "iscsid.service", "source": "systemd", "state": "stopped"}, "iscsiuio.service": {"name": "iscsiuio.service", "source": "systemd", "state": "stopped"}, "kdump.service": {"name": "kdump.service", "source": "systemd", "state": "stopped"}, "kmod-static-nodes.service": {"name": "kmod-static-nodes.service", "source": "systemd", "state": "stopped"}, "libvirt-guests.service": {"name": "libvirt-guests.service", "source": "systemd", "state": "stopped"}, "libvirtd.service": {"name": "libvirtd.service", "source": "systemd", "state": "running"}, "lvm2-lvmetad.service": {"name": "lvm2-lvmetad.service", "source": "systemd", "state": "running"}, "lvm2-lvmpolld.service": {"name": "lvm2-lvmpolld.service", "source": "systemd", "state": "stopped"}, "lvm2-monitor.service": {"name": "lvm2-monitor.service", "source": "systemd", "state": "stopped"}, "microcode.service": {"name": "microcode.service", "source": "systemd", "state": "stopped"}, "multipathd.service": {"name": "multipathd.service", "source": "systemd", "state": "stopped"}, "netcf-transaction.service": {"name": "netcf-transaction.service", "source": "systemd", "state": "stopped"}, "netconsole": {"name": "netconsole", "source": "sysv", "state": "stopped"}, "netns-placeholder.service": {"name": "netns-placeholder.service", "source": "systemd", "state": "stopped"}, "network": {"name": "network", "source": "sysv", "state": "running"}, "network.service": {"name": "network.service", "source": "systemd", "state": "stopped"}, "nfs-config.service": {"name": "nfs-config.service", "source": "systemd", "state": "stopped"}, "nfs-idmapd.service": {"name": "nfs-idmapd.service", "source": "systemd", "state": "stopped"}, "nfs-mountd.service": {"name": "nfs-mountd.service", "source": "systemd", "state": "stopped"}, "nfs-server.service": {"name": "nfs-server.service", "source": "systemd", "state": "stopped"}, "nfs-utils.service": {"name": "nfs-utils.service", "source": "systemd", "state": "stopped"}, "ntpd.service": {"name": "ntpd.service", "source": "systemd", "state": "stopped"}, "ntpdate.service": {"name": "ntpdate.service", "source": "systemd", "state": "stopped"}, "openvswitch.service": {"name": "openvswitch.service", "source": "systemd", "state": "stopped"}, "ovs-delete-transient-ports.service": {"name": "ovs-delete-transient-ports.service", "source": "systemd", "state": "stopped"}, "ovs-vswitchd.service": {"name": "ovs-vswitchd.service", "source": "systemd", "state": "running"}, "ovsdb-server.service": {"name": "ovsdb-server.service", "source": "systemd", "state": "running"}, "pacemaker.service": {"name": "pacemaker.service", "source": "systemd", "state": "stopped"}, "paunch-container-shutdown.service": {"name": "paunch-container-shutdown.service", "source": "systemd", "state": "stopped"}, "polkit.service": {"name": "polkit.service", "source": "systemd", "state": "running"}, "postfix.service": {"name": "postfix.service", "source": "systemd", "state": "running"}, "qemu-guest-agent.service": {"name": "qemu-guest-agent.service", "source": "systemd", "state": "running"}, "rc-local.service": {"name": "rc-local.service", "source": "systemd", "state": "stopped"}, "rescue.service": {"name": "rescue.service", "source": "systemd", "state": "stopped"}, "rhel-autorelabel.service": {"name": "rhel-autorelabel.service", "source": "systemd", "state": "stopped"}, "rhel-configure.service": {"name": "rhel-configure.service", "source": "systemd", "state": "stopped"}, "rhel-dmesg.service": {"name": "rhel-dmesg.service", "source": "systemd", "state": "stopped"}, "rhel-domainname.service": {"name": "rhel-domainname.service", "source": "systemd", "state": "stopped"}, "rhel-import-state.service": {"name": "rhel-import-state.service", "source": "systemd", "state": "stopped"}, "rhel-loadmodules.service": {"name": "rhel-loadmodules.service", "source": "systemd", "state": "stopped"}, "rhel-readonly.service": {"name": "rhel-readonly.service", "source": "systemd", "state": "stopped"}, "rpc-gssd.service": {"name": "rpc-gssd.service", "source": "systemd", "state": "stopped"}, "rpc-statd-notify.service": {"name": "rpc-statd-notify.service", "source": "systemd", "state": "stopped"}, "rpc-statd.service": {"name": "rpc-statd.service", "source": "systemd", "state": "stopped"}, "rpcbind.service": {"name": "rpcbind.service", "source": "systemd", "state": "running"}, "rsyslog.service": {"name": "rsyslog.service", "source": "systemd", "state": "running"}, "selinux-policy-migrate-local-changes@targeted.service": {"name": "selinux-policy-migrate-local-changes@targeted.service", "source": "systemd", "state": "stopped"}, "serial-getty@ttyS0.service": {"name": "serial-getty@ttyS0.service", "source": "systemd", "state": "running"}, "sshd-keygen.service": {"name": "sshd-keygen.service", "source": "systemd", "state": "stopped"}, "sshd.service": {"name": "sshd.service", "source": "systemd", "state": "running"}, "systemd-ask-password-console.service": {"name": "systemd-ask-password-console.service", "source": "systemd", "state": "stopped"}, "systemd-ask-password-wall.service": {"name": "systemd-ask-password-wall.service", "source": "systemd", "state": "stopped"}, "systemd-binfmt.service": {"name": "systemd-binfmt.service", "source": "systemd", "state": "stopped"}, "systemd-firstboot.service": {"name": "systemd-firstboot.service", "source": "systemd", "state": "stopped"}, "systemd-fsck-root.service": {"name": "systemd-fsck-root.service", "source": "systemd", "state": "stopped"}, "systemd-hwdb-update.service": {"name": "systemd-hwdb-update.service", "source": "systemd", "state": "stopped"}, "systemd-initctl.service": {"name": "systemd-initctl.service", "source": "systemd", "state": "stopped"}, "systemd-journal-catalog-update.service": {"name": "systemd-journal-catalog-update.service", "source": "systemd", "state": "stopped"}, "systemd-journal-flush.service": {"name": "systemd-journal-flush.service", "source": "systemd", "state": "stopped"}, "systemd-journald.service": {"name": "systemd-journald.service", "source": "systemd", "state": "running"}, "systemd-logind.service": {"name": "systemd-logind.service", "source": "systemd", "state": "running"}, "systemd-machine-id-commit.service": {"name": "systemd-machine-id-commit.service", "source": "systemd", "state": "stopped"}, "systemd-machined.service": {"name": "systemd-machined.service", "source": "systemd", "state": "stopped"}, "systemd-modules-load.service": {"name": "systemd-modules-load.service", "source": "systemd", "state": "stopped"}, "systemd-random-seed.service": {"name": "systemd-random-seed.service", "source": "systemd", "state": "stopped"}, "systemd-readahead-collect.service": {"name": "systemd-readahead-collect.service", "source": "systemd", "state": "stopped"}, "systemd-readahead-done.service": {"name": "systemd-readahead-done.service", "source": "systemd", "state": "stopped"}, "systemd-readahead-replay.service": {"name": "systemd-readahead-replay.service", "source": "systemd", "state": "stopped"}, "systemd-reboot.service": {"name": "systemd-reboot.service", "source": "systemd", "state": "stopped"}, "systemd-remount-fs.service": {"name": "systemd-remount-fs.service", "source": "systemd", "state": "stopped"}, "systemd-shutdownd.service": {"name": "systemd-shutdownd.service", "source": "systemd", "state": "stopped"}, "systemd-sysctl.service": {"name": "systemd-sysctl.service", "source": "systemd", "state": "stopped"}, "systemd-tmpfiles-clean.service": {"name": "systemd-tmpfiles-clean.service", "source": "systemd", "state": "stopped"}, "systemd-tmpfiles-setup-dev.service": {"name": "systemd-tmpfiles-setup-dev.service", "source": "systemd", "state": "stopped"}, "systemd-tmpfiles-setup.service": {"name": "systemd-tmpfiles-setup.service", "source": "systemd", "state": "stopped"}, "systemd-udev-settle.service": {"name": "systemd-udev-settle.service", "source": "systemd", "state": "stopped"}, "systemd-udev-trigger.service": {"name": "systemd-udev-trigger.service", "source": "systemd", "state": "stopped"}, "systemd-udevd.service": {"name": "systemd-udevd.service", "source": "systemd", "state": "running"}, "systemd-update-done.service": {"name": "systemd-update-done.service", "source": "systemd", "state": "stopped"}, "systemd-update-utmp-runlevel.service": {"name": "systemd-update-utmp-runlevel.service", "source": "systemd", "state": "stopped"}, "systemd-update-utmp.service": {"name": "systemd-update-utmp.service", "source": "systemd", "state": "stopped"}, "systemd-user-sessions.service": {"name": "systemd-user-sessions.service", "source": "systemd", "state": "stopped"}, "systemd-vconsole-setup.service": {"name": "systemd-vconsole-setup.service", "source": "systemd", "state": "stopped"}, "tripleo-ip6tables.service": {"name": "tripleo-ip6tables.service", "source": "systemd", "state": "stopped"}, "tripleo-iptables.service": {"name": "tripleo-iptables.service", "source": "systemd", "state": "stopped"}, "tuned.service": {"name": "tuned.service", "source": "systemd", "state": "running"}, "unbound-anchor.service": {"name": "unbound-anchor.service", "source": "systemd", "state": "stopped"}, "virtlockd.service": {"name": "virtlockd.service", "source": "systemd", "state": "stopped"}, "virtlogd.service": {"name": "virtlogd.service", "source": "systemd", "state": "stopped"}}}, "changed": false}
2019-06-05 14:05:04,111 p=17240 u=mistral |  TASK [Disable NTP before configuring Chrony] ***********************************
2019-06-05 14:05:04,111 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:876
2019-06-05 14:05:04,111 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:04 -0500 (0:00:00.270)       0:01:37.880 ******** 
2019-06-05 14:05:04,140 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:04,254 p=17240 u=mistral |  ok: [lab-controller-0] => {"changed": false, "enabled": false, "name": "ntpd", "state": "stopped", "status": {"ActiveEnterTimestampMonotonic": "0", "ActiveExitTimestampMonotonic": "0", "ActiveState": "inactive", "After": "systemd-journald.socket tmp.mount -.mount ntpdate.service syslog.target sntp.service basic.target system.slice", "AllowIsolate": "no", "AmbientCapabilities": "0", "AssertResult": "no", "AssertTimestampMonotonic": "0", "Before": "chronyd.service shutdown.target", "BlockIOAccounting": "no", "BlockIOWeight": "18446744073709551615", "CPUAccounting": "no", "CPUQuotaPerSecUSec": "infinity", "CPUSchedulingPolicy": "0", "CPUSchedulingPriority": "0", "CPUSchedulingResetOnFork": "no", "CPUShares": "18446744073709551615", "CanIsolate": "no", "CanReload": "no", "CanStart": "yes", "CanStop": "yes", "CapabilityBoundingSet": "18446744073709551615", "ConditionResult": "no", "ConditionTimestampMonotonic": "0", "ConflictedBy": "chronyd.service", "Conflicts": "shutdown.target", "ControlPID": "0", "DefaultDependencies": "yes", "Delegate": "no", "Description": "Network Time Service", "DevicePolicy": "auto", "EnvironmentFile": "/etc/sysconfig/ntpd (ignore_errors=yes)", "ExecMainCode": "0", "ExecMainExitTimestampMonotonic": "0", "ExecMainPID": "0", "ExecMainStartTimestampMonotonic": "0", "ExecMainStatus": "0", "ExecStart": "{ path=/usr/sbin/ntpd ; argv[]=/usr/sbin/ntpd -u ntp:ntp $OPTIONS ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }", "FailureAction": "none", "FileDescriptorStoreMax": "0", "FragmentPath": "/usr/lib/systemd/system/ntpd.service", "GuessMainPID": "yes", "IOScheduling": "0", "Id": "ntpd.service", "IgnoreOnIsolate": "no", "IgnoreOnSnapshot": "no", "IgnoreSIGPIPE": "yes", "InactiveEnterTimestampMonotonic": "0", "InactiveExitTimestampMonotonic": "0", "JobTimeoutAction": "none", "JobTimeoutUSec": "0", "KillMode": "control-group", "KillSignal": "15", "LimitAS": "18446744073709551615", "LimitCORE": "18446744073709551615", "LimitCPU": "18446744073709551615", "LimitDATA": "18446744073709551615", "LimitFSIZE": "18446744073709551615", "LimitLOCKS": "18446744073709551615", "LimitMEMLOCK": "65536", "LimitMSGQUEUE": "819200", "LimitNICE": "0", "LimitNOFILE": "4096", "LimitNPROC": "61816", "LimitRSS": "18446744073709551615", "LimitRTPRIO": "0", "LimitRTTIME": "18446744073709551615", "LimitSIGPENDING": "61816", "LimitSTACK": "18446744073709551615", "LoadState": "loaded", "MainPID": "0", "MemoryAccounting": "no", "MemoryCurrent": "18446744073709551615", "MemoryLimit": "18446744073709551615", "MountFlags": "0", "Names": "ntpd.service", "NeedDaemonReload": "no", "Nice": "0", "NoNewPrivileges": "no", "NonBlocking": "no", "NotifyAccess": "none", "OOMScoreAdjust": "0", "OnFailureJobMode": "replace", "PermissionsStartOnly": "no", "PrivateDevices": "no", "PrivateNetwork": "no", "PrivateTmp": "yes", "ProtectHome": "no", "ProtectSystem": "no", "RefuseManualStart": "no", "RefuseManualStop": "no", "RemainAfterExit": "no", "Requires": "basic.target -.mount", "RequiresMountsFor": "/var/tmp", "Restart": "no", "RestartUSec": "100ms", "Result": "success", "RootDirectoryStartOnly": "no", "RuntimeDirectoryMode": "0755", "SameProcessGroup": "no", "SecureBits": "0", "SendSIGHUP": "no", "SendSIGKILL": "yes", "Slice": "system.slice", "StandardError": "inherit", "StandardInput": "null", "StandardOutput": "journal", "StartLimitAction": "none", "StartLimitBurst": "5", "StartLimitInterval": "10000000", "StartupBlockIOWeight": "18446744073709551615", "StartupCPUShares": "18446744073709551615", "StatusErrno": "0", "StopWhenUnneeded": "no", "SubState": "dead", "SyslogLevelPrefix": "yes", "SyslogPriority": "30", "SystemCallErrorNumber": "0", "TTYReset": "no", "TTYVHangup": "no", "TTYVTDisallocate": "no", "TasksAccounting": "no", "TasksCurrent": "18446744073709551615", "TasksMax": "18446744073709551615", "TimeoutStartUSec": "1min 30s", "TimeoutStopUSec": "1min 30s", "TimerSlackNSec": "50000", "Transient": "no", "Type": "forking", "UMask": "0022", "UnitFilePreset": "disabled", "UnitFileState": "disabled", "Wants": "system.slice", "WatchdogTimestampMonotonic": "0", "WatchdogUSec": "0"}}
2019-06-05 14:05:04,278 p=17240 u=mistral |  TASK [Install, Configure and Run Chrony] ***************************************
2019-06-05 14:05:04,278 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:882
2019-06-05 14:05:04,278 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:04 -0500 (0:00:00.166)       0:01:38.047 ******** 
2019-06-05 14:05:04,308 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:04,371 p=17240 u=mistral |  TASK [chrony : Load distro-specific variables] *********************************
2019-06-05 14:05:04,371 p=17240 u=mistral |  task path: /usr/share/ansible/roles/chrony/tasks/main.yml:2
2019-06-05 14:05:04,372 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:04 -0500 (0:00:00.093)       0:01:38.141 ******** 
2019-06-05 14:05:04,374 p=17240 u=mistral |  META: noop
2019-06-05 14:05:04,392 p=17240 u=mistral |  ok: [lab-controller-0] => (item=/usr/share/ansible/roles/chrony/vars/RedHat.yml) => {"ansible_facts": {"chrony_config_file_location": "/etc/chrony.conf", "chrony_driftfile_path": "/var/lib/chrony/drift", "chrony_logdir_path": "/var/log/chrony", "chrony_makestep": "1.0 3", "chrony_package_name": "chrony", "chrony_rtc_settings": ["rtcsync"], "chrony_service_name": "chronyd"}, "ansible_included_var_files": ["/usr/share/ansible/roles/chrony/vars/RedHat.yml"], "changed": false, "item": "/usr/share/ansible/roles/chrony/vars/RedHat.yml"}
2019-06-05 14:05:04,418 p=17240 u=mistral |  TASK [chrony : Install chronyd] ************************************************
2019-06-05 14:05:04,418 p=17240 u=mistral |  task path: /usr/share/ansible/roles/chrony/tasks/main.yml:9
2019-06-05 14:05:04,418 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:04 -0500 (0:00:00.046)       0:01:38.187 ******** 
2019-06-05 14:05:04,420 p=17240 u=mistral |  META: noop
2019-06-05 14:05:04,457 p=17240 u=mistral |  included: /usr/share/ansible/roles/chrony/tasks/install.yml for lab-controller-0
2019-06-05 14:05:04,481 p=17240 u=mistral |  TASK [chrony : Install chronyd package] ****************************************
2019-06-05 14:05:04,481 p=17240 u=mistral |  task path: /usr/share/ansible/roles/chrony/tasks/install.yml:2
2019-06-05 14:05:04,481 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:04 -0500 (0:00:00.063)       0:01:38.251 ******** 
2019-06-05 14:05:04,483 p=17240 u=mistral |  META: noop
2019-06-05 14:05:04,494 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:04,518 p=17240 u=mistral |  TASK [chrony : Upgrade chronyd] ************************************************
2019-06-05 14:05:04,518 p=17240 u=mistral |  task path: /usr/share/ansible/roles/chrony/tasks/main.yml:13
2019-06-05 14:05:04,518 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:04 -0500 (0:00:00.036)       0:01:38.287 ******** 
2019-06-05 14:05:04,520 p=17240 u=mistral |   [WARNING]: noop task does not support when conditional

2019-06-05 14:05:04,520 p=17240 u=mistral |  META: noop
2019-06-05 14:05:04,533 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:04,558 p=17240 u=mistral |  TASK [chrony : Configure chronyd] **********************************************
2019-06-05 14:05:04,558 p=17240 u=mistral |  task path: /usr/share/ansible/roles/chrony/tasks/main.yml:17
2019-06-05 14:05:04,558 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:04 -0500 (0:00:00.040)       0:01:38.328 ******** 
2019-06-05 14:05:04,561 p=17240 u=mistral |  META: noop
2019-06-05 14:05:04,596 p=17240 u=mistral |  included: /usr/share/ansible/roles/chrony/tasks/config.yml for lab-controller-0
2019-06-05 14:05:04,621 p=17240 u=mistral |  TASK [chrony : Install chrony configuration file] ******************************
2019-06-05 14:05:04,621 p=17240 u=mistral |  task path: /usr/share/ansible/roles/chrony/tasks/config.yml:2
2019-06-05 14:05:04,621 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:04 -0500 (0:00:00.063)       0:01:38.391 ******** 
2019-06-05 14:05:04,624 p=17240 u=mistral |  META: noop
2019-06-05 14:05:04,935 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "checksum": "e59a5fd99e85f19be5ec8a0e0867fff357dc3433", "dest": "/etc/chrony.conf", "gid": 0, "group": "root", "md5sum": "64319715d9b3798711b4d004c1c280d3", "mode": "0644", "owner": "root", "secontext": "system_u:object_r:etc_t:s0", "size": 398, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559761504.63-146329234000304/source", "state": "file", "uid": 0}
2019-06-05 14:05:04,958 p=17240 u=mistral |  TASK [chrony : Ensure chronyd is running] **************************************
2019-06-05 14:05:04,958 p=17240 u=mistral |  task path: /usr/share/ansible/roles/chrony/tasks/config.yml:12
2019-06-05 14:05:04,958 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:04 -0500 (0:00:00.336)       0:01:38.727 ******** 
2019-06-05 14:05:04,960 p=17240 u=mistral |  META: noop
2019-06-05 14:05:05,097 p=17240 u=mistral |  ok: [lab-controller-0] => {"changed": false, "name": "chronyd", "state": "started", "status": {"ActiveEnterTimestamp": "Wed 2019-06-05 19:01:33 UTC", "ActiveEnterTimestampMonotonic": "7261990", "ActiveExitTimestampMonotonic": "0", "ActiveState": "active", "After": "sntp.service ntpd.service tmp.mount basic.target ntpdate.service systemd-journald.socket system.slice -.mount", "AllowIsolate": "no", "AmbientCapabilities": "0", "AssertResult": "yes", "AssertTimestamp": "Wed 2019-06-05 19:01:33 UTC", "AssertTimestampMonotonic": "7218821", "Before": "multi-user.target shutdown.target", "BlockIOAccounting": "no", "BlockIOWeight": "18446744073709551615", "CPUAccounting": "no", "CPUQuotaPerSecUSec": "infinity", "CPUSchedulingPolicy": "0", "CPUSchedulingPriority": "0", "CPUSchedulingResetOnFork": "no", "CPUShares": "18446744073709551615", "CanIsolate": "no", "CanReload": "no", "CanStart": "yes", "CanStop": "yes", "CapabilityBoundingSet": "18446744073709551615", "ConditionResult": "yes", "ConditionTimestamp": "Wed 2019-06-05 19:01:33 UTC", "ConditionTimestampMonotonic": "7218774", "Conflicts": "ntpd.service systemd-timesyncd.service shutdown.target", "ControlGroup": "/system.slice/chronyd.service", "ControlPID": "0", "DefaultDependencies": "yes", "Delegate": "no", "Description": "NTP client/server", "DevicePolicy": "auto", "Documentation": "man:chronyd(8) man:chrony.conf(5)", "EnvironmentFile": "/etc/sysconfig/chronyd (ignore_errors=yes)", "ExecMainCode": "0", "ExecMainExitTimestampMonotonic": "0", "ExecMainPID": "3265", "ExecMainStartTimestamp": "Wed 2019-06-05 19:01:33 UTC", "ExecMainStartTimestampMonotonic": "7249694", "ExecMainStatus": "0", "ExecStart": "{ path=/usr/sbin/chronyd ; argv[]=/usr/sbin/chronyd $OPTIONS ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }", "ExecStartPost": "{ path=/usr/libexec/chrony-helper ; argv[]=/usr/libexec/chrony-helper update-daemon ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }", "FailureAction": "none", "FileDescriptorStoreMax": "0", "FragmentPath": "/usr/lib/systemd/system/chronyd.service", "GuessMainPID": "yes", "IOScheduling": "0", "Id": "chronyd.service", "IgnoreOnIsolate": "no", "IgnoreOnSnapshot": "no", "IgnoreSIGPIPE": "yes", "InactiveEnterTimestampMonotonic": "0", "InactiveExitTimestamp": "Wed 2019-06-05 19:01:33 UTC", "InactiveExitTimestampMonotonic": "7220812", "JobTimeoutAction": "none", "JobTimeoutUSec": "0", "KillMode": "control-group", "KillSignal": "15", "LimitAS": "18446744073709551615", "LimitCORE": "18446744073709551615", "LimitCPU": "18446744073709551615", "LimitDATA": "18446744073709551615", "LimitFSIZE": "18446744073709551615", "LimitLOCKS": "18446744073709551615", "LimitMEMLOCK": "65536", "LimitMSGQUEUE": "819200", "LimitNICE": "0", "LimitNOFILE": "4096", "LimitNPROC": "61816", "LimitRSS": "18446744073709551615", "LimitRTPRIO": "0", "LimitRTTIME": "18446744073709551615", "LimitSIGPENDING": "61816", "LimitSTACK": "18446744073709551615", "LoadState": "loaded", "MainPID": "3265", "MemoryAccounting": "no", "MemoryCurrent": "18446744073709551615", "MemoryLimit": "18446744073709551615", "MountFlags": "0", "Names": "chronyd.service", "NeedDaemonReload": "no", "Nice": "0", "NoNewPrivileges": "no", "NonBlocking": "no", "NotifyAccess": "none", "OOMScoreAdjust": "0", "OnFailureJobMode": "replace", "PIDFile": "/var/run/chronyd.pid", "PermissionsStartOnly": "no", "PrivateDevices": "no", "PrivateNetwork": "no", "PrivateTmp": "yes", "ProtectHome": "yes", "ProtectSystem": "full", "RefuseManualStart": "no", "RefuseManualStop": "no", "RemainAfterExit": "no", "Requires": "basic.target -.mount", "RequiresMountsFor": "/var/tmp", "Restart": "no", "RestartUSec": "100ms", "Result": "success", "RootDirectoryStartOnly": "no", "RuntimeDirectoryMode": "0755", "SameProcessGroup": "no", "SecureBits": "0", "SendSIGHUP": "no", "SendSIGKILL": "yes", "Slice": "system.slice", "StandardError": "inherit", "StandardInput": "null", "StandardOutput": "journal", "StartLimitAction": "none", "StartLimitBurst": "5", "StartLimitInterval": "10000000", "StartupBlockIOWeight": "18446744073709551615", "StartupCPUShares": "18446744073709551615", "StatusErrno": "0", "StopWhenUnneeded": "no", "SubState": "running", "SyslogLevelPrefix": "yes", "SyslogPriority": "30", "SystemCallErrorNumber": "0", "TTYReset": "no", "TTYVHangup": "no", "TTYVTDisallocate": "no", "TasksAccounting": "no", "TasksCurrent": "1", "TasksMax": "18446744073709551615", "TimeoutStartUSec": "1min 30s", "TimeoutStopUSec": "1min 30s", "TimerSlackNSec": "50000", "Transient": "no", "Type": "forking", "UMask": "0022", "UnitFilePreset": "enabled", "UnitFileState": "enabled", "WantedBy": "multi-user.target", "Wants": "system.slice", "WatchdogTimestamp": "Wed 2019-06-05 19:01:33 UTC", "WatchdogTimestampMonotonic": "7249710", "WatchdogUSec": "0"}}
2019-06-05 14:05:05,121 p=17240 u=mistral |  TASK [chrony : Force chronyd restart] ******************************************
2019-06-05 14:05:05,121 p=17240 u=mistral |  task path: /usr/share/ansible/roles/chrony/tasks/config.yml:23
2019-06-05 14:05:05,121 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:05 -0500 (0:00:00.162)       0:01:38.890 ******** 
2019-06-05 14:05:05,123 p=17240 u=mistral |  META: noop
2019-06-05 14:05:05,316 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "name": "chronyd", "state": "started", "status": {"ActiveEnterTimestamp": "Wed 2019-06-05 19:01:33 UTC", "ActiveEnterTimestampMonotonic": "7261990", "ActiveExitTimestampMonotonic": "0", "ActiveState": "active", "After": "sntp.service ntpd.service tmp.mount basic.target ntpdate.service systemd-journald.socket system.slice -.mount", "AllowIsolate": "no", "AmbientCapabilities": "0", "AssertResult": "yes", "AssertTimestamp": "Wed 2019-06-05 19:01:33 UTC", "AssertTimestampMonotonic": "7218821", "Before": "multi-user.target shutdown.target", "BlockIOAccounting": "no", "BlockIOWeight": "18446744073709551615", "CPUAccounting": "no", "CPUQuotaPerSecUSec": "infinity", "CPUSchedulingPolicy": "0", "CPUSchedulingPriority": "0", "CPUSchedulingResetOnFork": "no", "CPUShares": "18446744073709551615", "CanIsolate": "no", "CanReload": "no", "CanStart": "yes", "CanStop": "yes", "CapabilityBoundingSet": "18446744073709551615", "ConditionResult": "yes", "ConditionTimestamp": "Wed 2019-06-05 19:01:33 UTC", "ConditionTimestampMonotonic": "7218774", "Conflicts": "ntpd.service systemd-timesyncd.service shutdown.target", "ControlGroup": "/system.slice/chronyd.service", "ControlPID": "0", "DefaultDependencies": "yes", "Delegate": "no", "Description": "NTP client/server", "DevicePolicy": "auto", "Documentation": "man:chronyd(8) man:chrony.conf(5)", "EnvironmentFile": "/etc/sysconfig/chronyd (ignore_errors=yes)", "ExecMainCode": "0", "ExecMainExitTimestampMonotonic": "0", "ExecMainPID": "3265", "ExecMainStartTimestamp": "Wed 2019-06-05 19:01:33 UTC", "ExecMainStartTimestampMonotonic": "7249694", "ExecMainStatus": "0", "ExecStart": "{ path=/usr/sbin/chronyd ; argv[]=/usr/sbin/chronyd $OPTIONS ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }", "ExecStartPost": "{ path=/usr/libexec/chrony-helper ; argv[]=/usr/libexec/chrony-helper update-daemon ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }", "FailureAction": "none", "FileDescriptorStoreMax": "0", "FragmentPath": "/usr/lib/systemd/system/chronyd.service", "GuessMainPID": "yes", "IOScheduling": "0", "Id": "chronyd.service", "IgnoreOnIsolate": "no", "IgnoreOnSnapshot": "no", "IgnoreSIGPIPE": "yes", "InactiveEnterTimestampMonotonic": "0", "InactiveExitTimestamp": "Wed 2019-06-05 19:01:33 UTC", "InactiveExitTimestampMonotonic": "7220812", "JobTimeoutAction": "none", "JobTimeoutUSec": "0", "KillMode": "control-group", "KillSignal": "15", "LimitAS": "18446744073709551615", "LimitCORE": "18446744073709551615", "LimitCPU": "18446744073709551615", "LimitDATA": "18446744073709551615", "LimitFSIZE": "18446744073709551615", "LimitLOCKS": "18446744073709551615", "LimitMEMLOCK": "65536", "LimitMSGQUEUE": "819200", "LimitNICE": "0", "LimitNOFILE": "4096", "LimitNPROC": "61816", "LimitRSS": "18446744073709551615", "LimitRTPRIO": "0", "LimitRTTIME": "18446744073709551615", "LimitSIGPENDING": "61816", "LimitSTACK": "18446744073709551615", "LoadState": "loaded", "MainPID": "3265", "MemoryAccounting": "no", "MemoryCurrent": "18446744073709551615", "MemoryLimit": "18446744073709551615", "MountFlags": "0", "Names": "chronyd.service", "NeedDaemonReload": "no", "Nice": "0", "NoNewPrivileges": "no", "NonBlocking": "no", "NotifyAccess": "none", "OOMScoreAdjust": "0", "OnFailureJobMode": "replace", "PIDFile": "/var/run/chronyd.pid", "PermissionsStartOnly": "no", "PrivateDevices": "no", "PrivateNetwork": "no", "PrivateTmp": "yes", "ProtectHome": "yes", "ProtectSystem": "full", "RefuseManualStart": "no", "RefuseManualStop": "no", "RemainAfterExit": "no", "Requires": "basic.target -.mount", "RequiresMountsFor": "/var/tmp", "Restart": "no", "RestartUSec": "100ms", "Result": "success", "RootDirectoryStartOnly": "no", "RuntimeDirectoryMode": "0755", "SameProcessGroup": "no", "SecureBits": "0", "SendSIGHUP": "no", "SendSIGKILL": "yes", "Slice": "system.slice", "StandardError": "inherit", "StandardInput": "null", "StandardOutput": "journal", "StartLimitAction": "none", "StartLimitBurst": "5", "StartLimitInterval": "10000000", "StartupBlockIOWeight": "18446744073709551615", "StartupCPUShares": "18446744073709551615", "StatusErrno": "0", "StopWhenUnneeded": "no", "SubState": "running", "SyslogLevelPrefix": "yes", "SyslogPriority": "30", "SystemCallErrorNumber": "0", "TTYReset": "no", "TTYVHangup": "no", "TTYVTDisallocate": "no", "TasksAccounting": "no", "TasksCurrent": "1", "TasksMax": "18446744073709551615", "TimeoutStartUSec": "1min 30s", "TimeoutStopUSec": "1min 30s", "TimerSlackNSec": "50000", "Transient": "no", "Type": "forking", "UMask": "0022", "UnitFilePreset": "enabled", "UnitFileState": "enabled", "WantedBy": "multi-user.target", "Wants": "system.slice", "WatchdogTimestamp": "Wed 2019-06-05 19:01:33 UTC", "WatchdogTimestampMonotonic": "7249710", "WatchdogUSec": "0"}}
2019-06-05 14:05:05,319 p=17240 u=mistral |  RUNNING HANDLER [chrony : Restart chronyd] *************************************
2019-06-05 14:05:05,319 p=17240 u=mistral |  task path: /usr/share/ansible/roles/chrony/handlers/main.yml:2
2019-06-05 14:05:05,319 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:05 -0500 (0:00:00.198)       0:01:39.089 ******** 
2019-06-05 14:05:05,536 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "name": "chronyd", "state": "started", "status": {"ActiveEnterTimestamp": "Wed 2019-06-05 19:05:05 UTC", "ActiveEnterTimestampMonotonic": "217584259", "ActiveExitTimestamp": "Wed 2019-06-05 19:05:05 UTC", "ActiveExitTimestampMonotonic": "217531283", "ActiveState": "active", "After": "sntp.service ntpd.service tmp.mount basic.target ntpdate.service systemd-journald.socket system.slice -.mount", "AllowIsolate": "no", "AmbientCapabilities": "0", "AssertResult": "yes", "AssertTimestamp": "Wed 2019-06-05 19:05:05 UTC", "AssertTimestampMonotonic": "217540027", "Before": "multi-user.target shutdown.target", "BlockIOAccounting": "no", "BlockIOWeight": "18446744073709551615", "CPUAccounting": "no", "CPUQuotaPerSecUSec": "infinity", "CPUSchedulingPolicy": "0", "CPUSchedulingPriority": "0", "CPUSchedulingResetOnFork": "no", "CPUShares": "18446744073709551615", "CanIsolate": "no", "CanReload": "no", "CanStart": "yes", "CanStop": "yes", "CapabilityBoundingSet": "18446744073709551615", "ConditionResult": "yes", "ConditionTimestamp": "Wed 2019-06-05 19:05:05 UTC", "ConditionTimestampMonotonic": "217539989", "Conflicts": "ntpd.service systemd-timesyncd.service shutdown.target", "ControlGroup": "/system.slice/chronyd.service", "ControlPID": "0", "DefaultDependencies": "yes", "Delegate": "no", "Description": "NTP client/server", "DevicePolicy": "auto", "Documentation": "man:chronyd(8) man:chrony.conf(5)", "EnvironmentFile": "/etc/sysconfig/chronyd (ignore_errors=yes)", "ExecMainCode": "0", "ExecMainExitTimestampMonotonic": "0", "ExecMainPID": "20963", "ExecMainStartTimestamp": "Wed 2019-06-05 19:05:05 UTC", "ExecMainStartTimestampMonotonic": "217561771", "ExecMainStatus": "0", "ExecStart": "{ path=/usr/sbin/chronyd ; argv[]=/usr/sbin/chronyd $OPTIONS ; ignore_errors=no ; start_time=[Wed 2019-06-05 19:05:05 UTC] ; stop_time=[Wed 2019-06-05 19:05:05 UTC] ; pid=20961 ; code=exited ; status=0 }", "ExecStartPost": "{ path=/usr/libexec/chrony-helper ; argv[]=/usr/libexec/chrony-helper update-daemon ; ignore_errors=no ; start_time=[Wed 2019-06-05 19:05:05 UTC] ; stop_time=[Wed 2019-06-05 19:05:05 UTC] ; pid=20965 ; code=exited ; status=0 }", "FailureAction": "none", "FileDescriptorStoreMax": "0", "FragmentPath": "/usr/lib/systemd/system/chronyd.service", "GuessMainPID": "yes", "IOScheduling": "0", "Id": "chronyd.service", "IgnoreOnIsolate": "no", "IgnoreOnSnapshot": "no", "IgnoreSIGPIPE": "yes", "InactiveEnterTimestamp": "Wed 2019-06-05 19:05:05 UTC", "InactiveEnterTimestampMonotonic": "217538913", "InactiveExitTimestamp": "Wed 2019-06-05 19:05:05 UTC", "InactiveExitTimestampMonotonic": "217540558", "JobTimeoutAction": "none", "JobTimeoutUSec": "0", "KillMode": "control-group", "KillSignal": "15", "LimitAS": "18446744073709551615", "LimitCORE": "18446744073709551615", "LimitCPU": "18446744073709551615", "LimitDATA": "18446744073709551615", "LimitFSIZE": "18446744073709551615", "LimitLOCKS": "18446744073709551615", "LimitMEMLOCK": "65536", "LimitMSGQUEUE": "819200", "LimitNICE": "0", "LimitNOFILE": "4096", "LimitNPROC": "61816", "LimitRSS": "18446744073709551615", "LimitRTPRIO": "0", "LimitRTTIME": "18446744073709551615", "LimitSIGPENDING": "61816", "LimitSTACK": "18446744073709551615", "LoadState": "loaded", "MainPID": "20963", "MemoryAccounting": "no", "MemoryCurrent": "18446744073709551615", "MemoryLimit": "18446744073709551615", "MountFlags": "0", "Names": "chronyd.service", "NeedDaemonReload": "no", "Nice": "0", "NoNewPrivileges": "no", "NonBlocking": "no", "NotifyAccess": "none", "OOMScoreAdjust": "0", "OnFailureJobMode": "replace", "PIDFile": "/var/run/chronyd.pid", "PermissionsStartOnly": "no", "PrivateDevices": "no", "PrivateNetwork": "no", "PrivateTmp": "yes", "ProtectHome": "yes", "ProtectSystem": "full", "RefuseManualStart": "no", "RefuseManualStop": "no", "RemainAfterExit": "no", "Requires": "basic.target -.mount", "RequiresMountsFor": "/var/tmp", "Restart": "no", "RestartUSec": "100ms", "Result": "success", "RootDirectoryStartOnly": "no", "RuntimeDirectoryMode": "0755", "SameProcessGroup": "no", "SecureBits": "0", "SendSIGHUP": "no", "SendSIGKILL": "yes", "Slice": "system.slice", "StandardError": "inherit", "StandardInput": "null", "StandardOutput": "journal", "StartLimitAction": "none", "StartLimitBurst": "5", "StartLimitInterval": "10000000", "StartupBlockIOWeight": "18446744073709551615", "StartupCPUShares": "18446744073709551615", "StatusErrno": "0", "StopWhenUnneeded": "no", "SubState": "running", "SyslogLevelPrefix": "yes", "SyslogPriority": "30", "SystemCallErrorNumber": "0", "TTYReset": "no", "TTYVHangup": "no", "TTYVTDisallocate": "no", "TasksAccounting": "no", "TasksCurrent": "1", "TasksMax": "18446744073709551615", "TimeoutStartUSec": "1min 30s", "TimeoutStopUSec": "1min 30s", "TimerSlackNSec": "50000", "Transient": "no", "Type": "forking", "UMask": "0022", "UnitFilePreset": "enabled", "UnitFileState": "enabled", "WantedBy": "multi-user.target", "Wants": "system.slice", "WatchdogTimestamp": "Wed 2019-06-05 19:05:05 UTC", "WatchdogTimestampMonotonic": "217561786", "WatchdogUSec": "0"}}
2019-06-05 14:05:05,536 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:05:05,560 p=17240 u=mistral |  TASK [Ensure system is NTP time synced] ****************************************
2019-06-05 14:05:05,560 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:887
2019-06-05 14:05:05,560 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:05 -0500 (0:00:00.240)       0:01:39.329 ******** 
2019-06-05 14:05:05,591 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:15,669 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "cmd": ["chronyc", "waitsync", "20"], "delta": "0:00:10.014809", "end": "2019-06-05 19:05:15.660738", "rc": 0, "start": "2019-06-05 19:05:05.645929", "stderr": "", "stderr_lines": [], "stdout": "try: 1, refid: 00000000, correction: 0.000000000, skew: 0.000\ntry: 2, refid: 6B9B4F6C, correction: 0.000000027, skew: 7.119", "stdout_lines": ["try: 1, refid: 00000000, correction: 0.000000000, skew: 0.000", "try: 2, refid: 6B9B4F6C, correction: 0.000000027, skew: 7.119"]}
2019-06-05 14:05:15,693 p=17240 u=mistral |  TASK [Set timezone fact] *******************************************************
2019-06-05 14:05:15,693 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:889
2019-06-05 14:05:15,693 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:15 -0500 (0:00:10.133)       0:01:49.462 ******** 
2019-06-05 14:05:15,713 p=17240 u=mistral |  ok: [lab-controller-0] => {"ansible_facts": {"timezone": "UTC"}, "changed": false}
2019-06-05 14:05:15,722 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:15,746 p=17240 u=mistral |  TASK [Set timezone to UTC] *****************************************************
2019-06-05 14:05:15,746 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:892
2019-06-05 14:05:15,746 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:15 -0500 (0:00:00.052)       0:01:49.515 ******** 
2019-06-05 14:05:15,775 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:15,991 p=17240 u=mistral |  ok: [lab-controller-0] => {"changed": false}
2019-06-05 14:05:16,014 p=17240 u=mistral |  TASK [Restart services] ********************************************************
2019-06-05 14:05:16,015 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/host_prep_tasks.yaml:896
2019-06-05 14:05:16,015 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:16 -0500 (0:00:00.268)       0:01:49.784 ******** 
2019-06-05 14:05:16,035 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=rsyslog)  => {"changed": false, "item": "rsyslog", "skip_reason": "Conditional result was False"}
2019-06-05 14:05:16,037 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=crond)  => {"changed": false, "item": "crond", "skip_reason": "Conditional result was False"}
2019-06-05 14:05:16,048 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=rsyslog)  => {"changed": false, "item": "rsyslog", "skip_reason": "Conditional result was False"}
2019-06-05 14:05:16,049 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=crond)  => {"changed": false, "item": "crond", "skip_reason": "Conditional result was False"}
2019-06-05 14:05:16,073 p=17240 u=mistral |  TASK [create persistent directories] *******************************************
2019-06-05 14:05:16,073 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/host_prep_tasks.yaml:1
2019-06-05 14:05:16,073 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:16 -0500 (0:00:00.058)       0:01:49.842 ******** 
2019-06-05 14:05:16,094 p=17240 u=mistral |  skipping: [lab-controller-0] => (item={u'path': u'/var/log/containers/ceilometer', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/containers/ceilometer", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:16,095 p=17240 u=mistral |  skipping: [lab-controller-0] => (item={u'path': u'/var/log/ceilometer', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/ceilometer", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:16,188 p=17240 u=mistral |  changed: [lab-computehci-0] => (item={u'path': u'/var/log/containers/ceilometer', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/containers/ceilometer", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/containers/ceilometer", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:05:16,274 p=17240 u=mistral |  changed: [lab-computehci-0] => (item={u'path': u'/var/log/ceilometer', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/ceilometer", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/ceilometer", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:05:16,299 p=17240 u=mistral |  TASK [ceilometer logs readme] **************************************************
2019-06-05 14:05:16,299 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/host_prep_tasks.yaml:11
2019-06-05 14:05:16,299 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:16 -0500 (0:00:00.226)       0:01:50.069 ******** 
2019-06-05 14:05:16,320 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:16,599 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "checksum": "ddd9b447be4ffb7bbfc2fa4cf7f104a4e7b2a6f3", "dest": "/var/log/ceilometer/readme.txt", "gid": 0, "group": "root", "md5sum": "ee2022bdaec66717a669185c935b18d9", "mode": "0644", "owner": "root", "secontext": "system_u:object_r:var_log_t:s0", "size": 88, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559761516.33-166949532921229/source", "state": "file", "uid": 0}
2019-06-05 14:05:16,623 p=17240 u=mistral |  TASK [enable virt_sandbox_use_netlink for healthcheck] *************************
2019-06-05 14:05:16,623 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/host_prep_tasks.yaml:20
2019-06-05 14:05:16,623 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:16 -0500 (0:00:00.323)       0:01:50.392 ******** 
2019-06-05 14:05:16,643 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:17,131 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "name": "virt_sandbox_use_netlink"}
2019-06-05 14:05:17,154 p=17240 u=mistral |  TASK [set_fact] ****************************************************************
2019-06-05 14:05:17,154 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/host_prep_tasks.yaml:26
2019-06-05 14:05:17,154 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:17 -0500 (0:00:00.531)       0:01:50.924 ******** 
2019-06-05 14:05:17,174 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:17,186 p=17240 u=mistral |  ok: [lab-computehci-0] => {"ansible_facts": {"container_registry_additional_sockets": ["/var/lib/openstack/docker.sock"], "container_registry_debug": false, "container_registry_deployment_user": "", "container_registry_docker_options": "--log-driver=journald --signature-verification=false --iptables=false --live-restore", "container_registry_insecure_registries": [], "container_registry_mirror": "", "container_registry_network_options": "--bip=172.31.0.1/24", "container_registry_selinux": true, "container_registry_skip_reconfiguration": false}, "changed": false}
2019-06-05 14:05:17,210 p=17240 u=mistral |  TASK [include_role : container-registry] ***************************************
2019-06-05 14:05:17,210 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/host_prep_tasks.yaml:38
2019-06-05 14:05:17,210 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:17 -0500 (0:00:00.055)       0:01:50.980 ******** 
2019-06-05 14:05:17,230 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:17,261 p=17240 u=mistral |  META: noop
2019-06-05 14:05:17,274 p=17240 u=mistral |  TASK [container-registry : Check that the configuration mark exists in /etc/sysconfig/docker] ***
2019-06-05 14:05:17,274 p=17240 u=mistral |  task path: /usr/share/ansible/roles/container-registry/tasks/docker.yml:7
2019-06-05 14:05:17,274 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:17 -0500 (0:00:00.063)       0:01:51.043 ******** 
2019-06-05 14:05:17,380 p=17240 u=mistral |  ok: [lab-computehci-0] => {"changed": false, "cmd": ["grep", "-Fq", "# Configured by Ansible container registry role", "/etc/sysconfig/docker"], "delta": "0:00:00.002597", "end": "2019-06-05 19:05:17.371569", "failed_when_result": false, "msg": "non-zero return code", "rc": 1, "start": "2019-06-05 19:05:17.368972", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}
2019-06-05 14:05:17,381 p=17240 u=mistral |  META: noop
2019-06-05 14:05:17,395 p=17240 u=mistral |  TASK [container-registry : enable net.ipv4.ip_forward] *************************
2019-06-05 14:05:17,395 p=17240 u=mistral |  task path: /usr/share/ansible/roles/container-registry/tasks/docker.yml:20
2019-06-05 14:05:17,395 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:17 -0500 (0:00:00.120)       0:01:51.164 ******** 
2019-06-05 14:05:17,498 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true}
2019-06-05 14:05:17,499 p=17240 u=mistral |  META: noop
2019-06-05 14:05:17,513 p=17240 u=mistral |  TASK [container-registry : Check if there are XFS volumes with ftype=0] ********
2019-06-05 14:05:17,513 p=17240 u=mistral |  task path: /usr/share/ansible/roles/container-registry/tasks/docker.yml:30
2019-06-05 14:05:17,513 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:17 -0500 (0:00:00.118)       0:01:51.282 ******** 
2019-06-05 14:05:17,615 p=17240 u=mistral |  ok: [lab-computehci-0] => {"changed": false, "cmd": "for dev in $(df -h | grep '/dev/' | grep -v 'tmp' | cut -d' ' -f1)\n do\n parseftype=$(xfs_info $dev | grep ftype=0);\n if [[ ! -z \"$parseftype\" ]]; then\n ftype=\"ftype=0\";\n break;\n fi\n done\n echo $ftype;", "delta": "0:00:00.008573", "end": "2019-06-05 19:05:17.606847", "rc": 0, "start": "2019-06-05 19:05:17.598274", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}
2019-06-05 14:05:17,616 p=17240 u=mistral |  META: noop
2019-06-05 14:05:17,630 p=17240 u=mistral |  TASK [container-registry : Check ftype] ****************************************
2019-06-05 14:05:17,630 p=17240 u=mistral |  task path: /usr/share/ansible/roles/container-registry/tasks/docker.yml:44
2019-06-05 14:05:17,631 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:17 -0500 (0:00:00.117)       0:01:51.400 ******** 
2019-06-05 14:05:17,646 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:17,647 p=17240 u=mistral |  META: noop
2019-06-05 14:05:17,662 p=17240 u=mistral |  TASK [container-registry : ensure docker is installed] *************************
2019-06-05 14:05:17,662 p=17240 u=mistral |  task path: /usr/share/ansible/roles/container-registry/tasks/docker.yml:53
2019-06-05 14:05:17,662 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:17 -0500 (0:00:00.031)       0:01:51.431 ******** 
2019-06-05 14:05:17,908 p=17240 u=mistral |  ok: [lab-computehci-0] => {"changed": false, "msg": "", "rc": 0, "results": ["2:docker-1.13.1-96.gitb2f74b2.el7.centos.x86_64 providing docker is already installed"]}
2019-06-05 14:05:17,909 p=17240 u=mistral |  META: noop
2019-06-05 14:05:17,924 p=17240 u=mistral |  TASK [container-registry : manage /etc/systemd/system/docker.service.d] ********
2019-06-05 14:05:17,924 p=17240 u=mistral |  task path: /usr/share/ansible/roles/container-registry/tasks/docker.yml:58
2019-06-05 14:05:17,924 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:17 -0500 (0:00:00.262)       0:01:51.693 ******** 
2019-06-05 14:05:18,021 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "gid": 0, "group": "root", "mode": "0755", "owner": "root", "path": "/etc/systemd/system/docker.service.d", "secontext": "unconfined_u:object_r:systemd_unit_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:05:18,022 p=17240 u=mistral |  META: noop
2019-06-05 14:05:18,037 p=17240 u=mistral |  TASK [container-registry : unset mountflags] ***********************************
2019-06-05 14:05:18,037 p=17240 u=mistral |  task path: /usr/share/ansible/roles/container-registry/tasks/docker.yml:64
2019-06-05 14:05:18,037 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:18 -0500 (0:00:00.113)       0:01:51.807 ******** 
2019-06-05 14:05:18,162 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "gid": 0, "group": "root", "mode": "0644", "msg": "section and option added", "owner": "root", "path": "/etc/systemd/system/docker.service.d/99-unset-mountflags.conf", "secontext": "system_u:object_r:container_unit_file_t:s0", "size": 25, "state": "file", "uid": 0}
2019-06-05 14:05:18,163 p=17240 u=mistral |  META: noop
2019-06-05 14:05:18,177 p=17240 u=mistral |  TASK [container-registry : configure OPTIONS in /etc/sysconfig/docker] *********
2019-06-05 14:05:18,177 p=17240 u=mistral |  task path: /usr/share/ansible/roles/container-registry/tasks/docker.yml:74
2019-06-05 14:05:18,177 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:18 -0500 (0:00:00.139)       0:01:51.946 ******** 
2019-06-05 14:05:18,304 p=17240 u=mistral |  changed: [lab-computehci-0] => {"backup": "", "changed": true, "msg": "line replaced"}
2019-06-05 14:05:18,305 p=17240 u=mistral |  META: noop
2019-06-05 14:05:18,318 p=17240 u=mistral |  TASK [container-registry : configure INSECURE_REGISTRY in /etc/sysconfig/docker] ***
2019-06-05 14:05:18,318 p=17240 u=mistral |  task path: /usr/share/ansible/roles/container-registry/tasks/docker.yml:82
2019-06-05 14:05:18,318 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:18 -0500 (0:00:00.141)       0:01:52.088 ******** 
2019-06-05 14:05:18,333 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:18,334 p=17240 u=mistral |  META: noop
2019-06-05 14:05:18,348 p=17240 u=mistral |  TASK [container-registry : Create additional socket directories] ***************
2019-06-05 14:05:18,348 p=17240 u=mistral |  task path: /usr/share/ansible/roles/container-registry/tasks/docker.yml:92
2019-06-05 14:05:18,348 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:18 -0500 (0:00:00.029)       0:01:52.117 ******** 
2019-06-05 14:05:18,452 p=17240 u=mistral |  changed: [lab-computehci-0] => (item=/var/lib/openstack/docker.sock) => {"changed": true, "gid": 0, "group": "root", "item": "/var/lib/openstack/docker.sock", "mode": "0755", "owner": "root", "path": "/var/lib/openstack", "secontext": "unconfined_u:object_r:var_lib_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:05:18,485 p=17240 u=mistral |  META: noop
2019-06-05 14:05:18,499 p=17240 u=mistral |  TASK [container-registry : manage /etc/docker/daemon.json] *********************
2019-06-05 14:05:18,499 p=17240 u=mistral |  task path: /usr/share/ansible/roles/container-registry/tasks/docker.yml:100
2019-06-05 14:05:18,499 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:18 -0500 (0:00:00.151)       0:01:52.269 ******** 
2019-06-05 14:05:18,827 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "checksum": "e3daa85cf4ce54ae4bc7babe814c188ccc73a0c7", "dest": "/etc/docker/daemon.json", "gid": 0, "group": "root", "md5sum": "a3102ec9797a64d1a8262c7462c3d50d", "mode": "0644", "owner": "root", "secontext": "system_u:object_r:container_config_t:s0", "size": 21, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559761518.51-67571052610115/source", "state": "file", "uid": 0}
2019-06-05 14:05:18,828 p=17240 u=mistral |  META: noop
2019-06-05 14:05:18,842 p=17240 u=mistral |  TASK [container-registry : configure DOCKER_STORAGE_OPTIONS in /etc/sysconfig/docker-storage] ***
2019-06-05 14:05:18,842 p=17240 u=mistral |  task path: /usr/share/ansible/roles/container-registry/tasks/docker.yml:106
2019-06-05 14:05:18,842 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:18 -0500 (0:00:00.342)       0:01:52.611 ******** 
2019-06-05 14:05:18,968 p=17240 u=mistral |  changed: [lab-computehci-0] => {"backup": "", "changed": true, "msg": "line replaced"}
2019-06-05 14:05:18,969 p=17240 u=mistral |  META: noop
2019-06-05 14:05:18,982 p=17240 u=mistral |  TASK [container-registry : configure DOCKER_NETWORK_OPTIONS in /etc/sysconfig/docker-network] ***
2019-06-05 14:05:18,982 p=17240 u=mistral |  task path: /usr/share/ansible/roles/container-registry/tasks/docker.yml:115
2019-06-05 14:05:18,983 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:18 -0500 (0:00:00.140)       0:01:52.752 ******** 
2019-06-05 14:05:19,107 p=17240 u=mistral |  changed: [lab-computehci-0] => {"backup": "", "changed": true, "msg": "line replaced"}
2019-06-05 14:05:19,108 p=17240 u=mistral |  META: noop
2019-06-05 14:05:19,121 p=17240 u=mistral |  TASK [container-registry : ensure docker group exists] *************************
2019-06-05 14:05:19,121 p=17240 u=mistral |  task path: /usr/share/ansible/roles/container-registry/tasks/docker.yml:124
2019-06-05 14:05:19,122 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:19 -0500 (0:00:00.138)       0:01:52.891 ******** 
2019-06-05 14:05:19,230 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "gid": 1003, "name": "docker", "state": "present", "system": false}
2019-06-05 14:05:19,231 p=17240 u=mistral |  META: noop
2019-06-05 14:05:19,245 p=17240 u=mistral |  TASK [container-registry : add deployment user to docker group] ****************
2019-06-05 14:05:19,245 p=17240 u=mistral |  task path: /usr/share/ansible/roles/container-registry/tasks/docker.yml:129
2019-06-05 14:05:19,246 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:19 -0500 (0:00:00.123)       0:01:53.015 ******** 
2019-06-05 14:05:19,260 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:19,261 p=17240 u=mistral |  META: noop
2019-06-05 14:05:19,284 p=17240 u=mistral |  META: reset connection
2019-06-05 14:05:19,285 p=17240 u=mistral |  META: noop
2019-06-05 14:05:19,288 p=17240 u=mistral |  RUNNING HANDLER [container-registry : restart docker] **************************
2019-06-05 14:05:19,288 p=17240 u=mistral |  task path: /usr/share/ansible/roles/container-registry/handlers/main.yml:2
2019-06-05 14:05:19,288 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:19 -0500 (0:00:00.042)       0:01:53.057 ******** 
2019-06-05 14:05:19,645 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "cmd": ["/bin/true"], "delta": "0:00:00.001720", "end": "2019-06-05 19:05:19.621752", "rc": 0, "start": "2019-06-05 19:05:19.620032", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}
2019-06-05 14:05:19,647 p=17240 u=mistral |  RUNNING HANDLER [container-registry : Docker | reload systemd] *****************
2019-06-05 14:05:19,647 p=17240 u=mistral |  task path: /usr/share/ansible/roles/container-registry/handlers/main.yml:19
2019-06-05 14:05:19,647 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:19 -0500 (0:00:00.358)       0:01:53.416 ******** 
2019-06-05 14:05:19,840 p=17240 u=mistral |  ok: [lab-computehci-0] => {"changed": false, "name": null, "status": {}}
2019-06-05 14:05:19,842 p=17240 u=mistral |  RUNNING HANDLER [container-registry : Docker | reload docker] ******************
2019-06-05 14:05:19,842 p=17240 u=mistral |  task path: /usr/share/ansible/roles/container-registry/handlers/main.yml:25
2019-06-05 14:05:19,842 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:19 -0500 (0:00:00.195)       0:01:53.611 ******** 
2019-06-05 14:05:21,212 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "name": "docker", "state": "started", "status": {"ActiveEnterTimestampMonotonic": "0", "ActiveExitTimestampMonotonic": "0", "ActiveState": "inactive", "After": "basic.target network.target docker-storage-setup.service systemd-journald.socket system.slice", "AllowIsolate": "no", "AmbientCapabilities": "0", "AssertResult": "no", "AssertTimestampMonotonic": "0", "Before": "shutdown.target paunch-container-shutdown.service", "BlockIOAccounting": "no", "BlockIOWeight": "18446744073709551615", "CPUAccounting": "no", "CPUQuotaPerSecUSec": "infinity", "CPUSchedulingPolicy": "0", "CPUSchedulingPriority": "0", "CPUSchedulingResetOnFork": "no", "CPUShares": "18446744073709551615", "CanIsolate": "no", "CanReload": "yes", "CanStart": "yes", "CanStop": "yes", "CapabilityBoundingSet": "18446744073709551615", "ConditionResult": "no", "ConditionTimestampMonotonic": "0", "Conflicts": "shutdown.target", "ControlPID": "0", "DefaultDependencies": "yes", "Delegate": "no", "Description": "Docker Application Container Engine", "DevicePolicy": "auto", "Documentation": "http://docs.docker.com", "DropInPaths": "/etc/systemd/system/docker.service.d/99-unset-mountflags.conf", "Environment": "GOTRACEBACK=crash DOCKER_HTTP_HOST_COMPAT=1 PATH=/usr/libexec/docker:/usr/bin:/usr/sbin", "EnvironmentFile": "/etc/sysconfig/docker-network (ignore_errors=yes)", "ExecMainCode": "0", "ExecMainExitTimestampMonotonic": "0", "ExecMainPID": "0", "ExecMainStartTimestampMonotonic": "0", "ExecMainStatus": "0", "ExecReload": "{ path=/bin/kill ; argv[]=/bin/kill -s HUP $MAINPID ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }", "ExecStart": "{ path=/usr/bin/dockerd-current ; argv[]=/usr/bin/dockerd-current --add-runtime docker-runc=/usr/libexec/docker/docker-runc-current --default-runtime=docker-runc --exec-opt native.cgroupdriver=systemd --userland-proxy-path=/usr/libexec/docker/docker-proxy-current --init-path=/usr/libexec/docker/docker-init-current --seccomp-profile=/etc/docker/seccomp.json $OPTIONS $DOCKER_STORAGE_OPTIONS $DOCKER_NETWORK_OPTIONS $ADD_REGISTRY $BLOCK_REGISTRY $INSECURE_REGISTRY $REGISTRIES ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }", "FailureAction": "none", "FileDescriptorStoreMax": "0", "FragmentPath": "/usr/lib/systemd/system/docker.service", "GuessMainPID": "yes", "IOScheduling": "0", "Id": "docker.service", "IgnoreOnIsolate": "no", "IgnoreOnSnapshot": "no", "IgnoreSIGPIPE": "yes", "InactiveEnterTimestampMonotonic": "0", "InactiveExitTimestampMonotonic": "0", "JobTimeoutAction": "none", "JobTimeoutUSec": "0", "KillMode": "process", "KillSignal": "15", "LimitAS": "18446744073709551615", "LimitCORE": "18446744073709551615", "LimitCPU": "18446744073709551615", "LimitDATA": "18446744073709551615", "LimitFSIZE": "18446744073709551615", "LimitLOCKS": "18446744073709551615", "LimitMEMLOCK": "65536", "LimitMSGQUEUE": "819200", "LimitNICE": "0", "LimitNOFILE": "1048576", "LimitNPROC": "1048576", "LimitRSS": "18446744073709551615", "LimitRTPRIO": "0", "LimitRTTIME": "18446744073709551615", "LimitSIGPENDING": "61816", "LimitSTACK": "18446744073709551615", "LoadState": "loaded", "MainPID": "0", "MemoryAccounting": "no", "MemoryCurrent": "18446744073709551615", "MemoryLimit": "18446744073709551615", "MountFlags": "0", "Names": "docker.service", "NeedDaemonReload": "no", "Nice": "0", "NoNewPrivileges": "no", "NonBlocking": "no", "NotifyAccess": "main", "OOMScoreAdjust": "0", "OnFailureJobMode": "replace", "PermissionsStartOnly": "no", "PrivateDevices": "no", "PrivateNetwork": "no", "PrivateTmp": "no", "ProtectHome": "no", "ProtectSystem": "no", "RefuseManualStart": "no", "RefuseManualStop": "no", "RemainAfterExit": "no", "RequiredBy": "docker-cleanup.service", "Requires": "basic.target docker-cleanup.timer", "Restart": "on-abnormal", "RestartUSec": "100ms", "Result": "success", "RootDirectoryStartOnly": "no", "RuntimeDirectoryMode": "0755", "SameProcessGroup": "no", "SecureBits": "0", "SendSIGHUP": "no", "SendSIGKILL": "yes", "Slice": "system.slice", "StandardError": "inherit", "StandardInput": "null", "StandardOutput": "journal", "StartLimitAction": "none", "StartLimitBurst": "5", "StartLimitInterval": "10000000", "StartupBlockIOWeight": "18446744073709551615", "StartupCPUShares": "18446744073709551615", "StatusErrno": "0", "StopWhenUnneeded": "no", "SubState": "dead", "SyslogLevelPrefix": "yes", "SyslogPriority": "30", "SystemCallErrorNumber": "0", "TTYReset": "no", "TTYVHangup": "no", "TTYVTDisallocate": "no", "TasksAccounting": "no", "TasksCurrent": "18446744073709551615", "TasksMax": "18446744073709551615", "TimeoutStartUSec": "0", "TimeoutStopUSec": "1min 30s", "TimerSlackNSec": "50000", "Transient": "no", "Type": "notify", "UMask": "0022", "UnitFilePreset": "disabled", "UnitFileState": "disabled", "Wants": "system.slice docker-storage-setup.service", "WatchdogTimestampMonotonic": "0", "WatchdogUSec": "0"}}
2019-06-05 14:05:21,215 p=17240 u=mistral |  RUNNING HANDLER [container-registry : Docker | pause while Docker restarts] ****
2019-06-05 14:05:21,215 p=17240 u=mistral |  task path: /usr/share/ansible/roles/container-registry/handlers/main.yml:31
2019-06-05 14:05:21,215 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:21 -0500 (0:00:01.372)       0:01:54.984 ******** 
2019-06-05 14:05:21,240 p=17240 u=mistral |  Pausing for 10 seconds
2019-06-05 14:05:21,240 p=17240 u=mistral |  (ctrl+C then 'C' = continue early, ctrl+C then 'A' = abort)
2019-06-05 14:05:21,240 p=17240 u=mistral |  [container-registry : Docker | pause while Docker restarts]
Waiting for docker restart:
2019-06-05 14:05:31,242 p=17240 u=mistral |  ok: [lab-computehci-0] => {"changed": false, "delta": 10, "echo": true, "rc": 0, "start": "2019-06-05 14:05:21.239984", "stderr": "", "stdout": "Paused for 10.0 seconds", "stop": "2019-06-05 14:05:31.240123", "user_input": ""}
2019-06-05 14:05:31,244 p=17240 u=mistral |  RUNNING HANDLER [container-registry : Docker | wait for docker] ****************
2019-06-05 14:05:31,244 p=17240 u=mistral |  task path: /usr/share/ansible/roles/container-registry/handlers/main.yml:36
2019-06-05 14:05:31,244 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:31 -0500 (0:00:10.029)       0:02:05.014 ******** 
2019-06-05 14:05:31,381 p=17240 u=mistral |  changed: [lab-computehci-0] => {"attempts": 1, "changed": true, "cmd": ["/usr/bin/docker", "images"], "delta": "0:00:00.023136", "end": "2019-06-05 19:05:31.370457", "rc": 0, "start": "2019-06-05 19:05:31.347321", "stderr": "", "stderr_lines": [], "stdout": "REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE", "stdout_lines": ["REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE"]}
2019-06-05 14:05:31,381 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:05:31,382 p=17240 u=mistral |  META: noop
2019-06-05 14:05:31,397 p=17240 u=mistral |  TASK [container-registry : enable and start docker] ****************************
2019-06-05 14:05:31,397 p=17240 u=mistral |  task path: /usr/share/ansible/roles/container-registry/tasks/docker.yml:143
2019-06-05 14:05:31,397 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:31 -0500 (0:00:00.152)       0:02:05.166 ******** 
2019-06-05 14:05:31,584 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "enabled": true, "name": "docker", "state": "started", "status": {"ActiveEnterTimestamp": "Wed 2019-06-05 19:05:21 UTC", "ActiveEnterTimestampMonotonic": "233658317", "ActiveExitTimestampMonotonic": "0", "ActiveState": "active", "After": "basic.target network.target docker-storage-setup.service systemd-journald.socket system.slice", "AllowIsolate": "no", "AmbientCapabilities": "0", "AssertResult": "yes", "AssertTimestamp": "Wed 2019-06-05 19:05:20 UTC", "AssertTimestampMonotonic": "232496327", "Before": "shutdown.target paunch-container-shutdown.service", "BlockIOAccounting": "no", "BlockIOWeight": "18446744073709551615", "CPUAccounting": "no", "CPUQuotaPerSecUSec": "infinity", "CPUSchedulingPolicy": "0", "CPUSchedulingPriority": "0", "CPUSchedulingResetOnFork": "no", "CPUShares": "18446744073709551615", "CanIsolate": "no", "CanReload": "yes", "CanStart": "yes", "CanStop": "yes", "CapabilityBoundingSet": "18446744073709551615", "ConditionResult": "yes", "ConditionTimestamp": "Wed 2019-06-05 19:05:20 UTC", "ConditionTimestampMonotonic": "232496326", "Conflicts": "shutdown.target", "ControlGroup": "/system.slice/docker.service", "ControlPID": "0", "DefaultDependencies": "yes", "Delegate": "no", "Description": "Docker Application Container Engine", "DevicePolicy": "auto", "Documentation": "http://docs.docker.com", "DropInPaths": "/etc/systemd/system/docker.service.d/99-unset-mountflags.conf", "Environment": "GOTRACEBACK=crash DOCKER_HTTP_HOST_COMPAT=1 PATH=/usr/libexec/docker:/usr/bin:/usr/sbin", "EnvironmentFile": "/etc/sysconfig/docker-network (ignore_errors=yes)", "ExecMainCode": "0", "ExecMainExitTimestampMonotonic": "0", "ExecMainPID": "17108", "ExecMainStartTimestamp": "Wed 2019-06-05 19:05:20 UTC", "ExecMainStartTimestampMonotonic": "232496834", "ExecMainStatus": "0", "ExecReload": "{ path=/bin/kill ; argv[]=/bin/kill -s HUP $MAINPID ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }", "ExecStart": "{ path=/usr/bin/dockerd-current ; argv[]=/usr/bin/dockerd-current --add-runtime docker-runc=/usr/libexec/docker/docker-runc-current --default-runtime=docker-runc --exec-opt native.cgroupdriver=systemd --userland-proxy-path=/usr/libexec/docker/docker-proxy-current --init-path=/usr/libexec/docker/docker-init-current --seccomp-profile=/etc/docker/seccomp.json $OPTIONS $DOCKER_STORAGE_OPTIONS $DOCKER_NETWORK_OPTIONS $ADD_REGISTRY $BLOCK_REGISTRY $INSECURE_REGISTRY $REGISTRIES ; ignore_errors=no ; start_time=[Wed 2019-06-05 19:05:20 UTC] ; stop_time=[n/a] ; pid=17108 ; code=(null) ; status=0/0 }", "FailureAction": "none", "FileDescriptorStoreMax": "0", "FragmentPath": "/usr/lib/systemd/system/docker.service", "GuessMainPID": "yes", "IOScheduling": "0", "Id": "docker.service", "IgnoreOnIsolate": "no", "IgnoreOnSnapshot": "no", "IgnoreSIGPIPE": "yes", "InactiveEnterTimestampMonotonic": "0", "InactiveExitTimestamp": "Wed 2019-06-05 19:05:20 UTC", "InactiveExitTimestampMonotonic": "232496857", "JobTimeoutAction": "none", "JobTimeoutUSec": "0", "KillMode": "process", "KillSignal": "15", "LimitAS": "18446744073709551615", "LimitCORE": "18446744073709551615", "LimitCPU": "18446744073709551615", "LimitDATA": "18446744073709551615", "LimitFSIZE": "18446744073709551615", "LimitLOCKS": "18446744073709551615", "LimitMEMLOCK": "65536", "LimitMSGQUEUE": "819200", "LimitNICE": "0", "LimitNOFILE": "1048576", "LimitNPROC": "1048576", "LimitRSS": "18446744073709551615", "LimitRTPRIO": "0", "LimitRTTIME": "18446744073709551615", "LimitSIGPENDING": "61816", "LimitSTACK": "18446744073709551615", "LoadState": "loaded", "MainPID": "17108", "MemoryAccounting": "no", "MemoryCurrent": "18446744073709551615", "MemoryLimit": "18446744073709551615", "MountFlags": "0", "Names": "docker.service", "NeedDaemonReload": "no", "Nice": "0", "NoNewPrivileges": "no", "NonBlocking": "no", "NotifyAccess": "main", "OOMScoreAdjust": "0", "OnFailureJobMode": "replace", "PermissionsStartOnly": "no", "PrivateDevices": "no", "PrivateNetwork": "no", "PrivateTmp": "no", "ProtectHome": "no", "ProtectSystem": "no", "RefuseManualStart": "no", "RefuseManualStop": "no", "RemainAfterExit": "no", "RequiredBy": "docker-cleanup.service", "Requires": "basic.target docker-cleanup.timer", "Restart": "on-abnormal", "RestartUSec": "100ms", "Result": "success", "RootDirectoryStartOnly": "no", "RuntimeDirectoryMode": "0755", "SameProcessGroup": "no", "SecureBits": "0", "SendSIGHUP": "no", "SendSIGKILL": "yes", "Slice": "system.slice", "StandardError": "inherit", "StandardInput": "null", "StandardOutput": "journal", "StartLimitAction": "none", "StartLimitBurst": "5", "StartLimitInterval": "10000000", "StartupBlockIOWeight": "18446744073709551615", "StartupCPUShares": "18446744073709551615", "StatusErrno": "0", "StopWhenUnneeded": "no", "SubState": "running", "SyslogLevelPrefix": "yes", "SyslogPriority": "30", "SystemCallErrorNumber": "0", "TTYReset": "no", "TTYVHangup": "no", "TTYVTDisallocate": "no", "TasksAccounting": "no", "TasksCurrent": "23", "TasksMax": "18446744073709551615", "TimeoutStartUSec": "0", "TimeoutStopUSec": "1min 30s", "TimerSlackNSec": "50000", "Transient": "no", "Type": "notify", "UMask": "0022", "UnitFilePreset": "disabled", "UnitFileState": "disabled", "Wants": "system.slice docker-storage-setup.service", "WatchdogTimestamp": "Wed 2019-06-05 19:05:21 UTC", "WatchdogTimestampMonotonic": "233658219", "WatchdogUSec": "0"}}
2019-06-05 14:05:31,585 p=17240 u=mistral |  META: noop
2019-06-05 14:05:31,599 p=17240 u=mistral |  TASK [container-registry : mark docker configured] *****************************
2019-06-05 14:05:31,599 p=17240 u=mistral |  task path: /usr/share/ansible/roles/container-registry/tasks/docker.yml:150
2019-06-05 14:05:31,600 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:31 -0500 (0:00:00.202)       0:02:05.369 ******** 
2019-06-05 14:05:31,701 p=17240 u=mistral |  changed: [lab-computehci-0] => {"backup": "", "changed": true, "msg": "line added"}
2019-06-05 14:05:31,726 p=17240 u=mistral |  TASK [ensure /etc/iscsi exists] ************************************************
2019-06-05 14:05:31,726 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/host_prep_tasks.yaml:42
2019-06-05 14:05:31,726 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:31 -0500 (0:00:00.126)       0:02:05.495 ******** 
2019-06-05 14:05:31,750 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:31,838 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "gid": 0, "group": "root", "mode": "0755", "owner": "root", "path": "/etc/iscsi", "secontext": "system_u:object_r:container_file_t:s0", "size": 52, "state": "directory", "uid": 0}
2019-06-05 14:05:31,862 p=17240 u=mistral |  TASK [ensure /var/lib/iscsi exists] ********************************************
2019-06-05 14:05:31,862 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/host_prep_tasks.yaml:47
2019-06-05 14:05:31,862 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:31 -0500 (0:00:00.135)       0:02:05.631 ******** 
2019-06-05 14:05:31,881 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:31,972 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "gid": 0, "group": "root", "mode": "0755", "owner": "root", "path": "/var/lib/iscsi", "secontext": "system_u:object_r:container_file_t:s0", "size": 90, "state": "directory", "uid": 0}
2019-06-05 14:05:31,996 p=17240 u=mistral |  TASK [stat /lib/systemd/system/iscsid.socket] **********************************
2019-06-05 14:05:31,996 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/host_prep_tasks.yaml:52
2019-06-05 14:05:31,996 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:31 -0500 (0:00:00.134)       0:02:05.765 ******** 
2019-06-05 14:05:32,018 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:32,112 p=17240 u=mistral |  ok: [lab-computehci-0] => {"changed": false, "stat": {"atime": 1559761416.1568944, "attr_flags": "", "attributes": [], "block_size": 4096, "blocks": 8, "charset": "us-ascii", "checksum": "424de87cd6ae66547b285288742255731a46ab83", "ctime": 1559694316.28692, "dev": 64514, "device_type": 0, "executable": false, "exists": true, "gid": 0, "gr_name": "root", "inode": 1183379, "isblk": false, "ischr": false, "isdir": false, "isfifo": false, "isgid": false, "islnk": false, "isreg": true, "issock": false, "isuid": false, "mimetype": "text/plain", "mode": "0644", "mtime": 1540940995.0, "nlink": 1, "path": "/lib/systemd/system/iscsid.socket", "pw_name": "root", "readable": true, "rgrp": true, "roth": true, "rusr": true, "size": 175, "uid": 0, "version": "2073033812", "wgrp": false, "woth": false, "writeable": true, "wusr": true, "xgrp": false, "xoth": false, "xusr": false}}
2019-06-05 14:05:32,136 p=17240 u=mistral |  TASK [Stop and disable iscsid.socket service] **********************************
2019-06-05 14:05:32,136 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/host_prep_tasks.yaml:55
2019-06-05 14:05:32,137 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:32 -0500 (0:00:00.140)       0:02:05.906 ******** 
2019-06-05 14:05:32,156 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:32,332 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "enabled": false, "name": "iscsid.socket", "state": "stopped", "status": {"Accept": "no", "ActiveEnterTimestamp": "Wed 2019-06-05 19:01:34 UTC", "ActiveEnterTimestampMonotonic": "7246294", "ActiveExitTimestampMonotonic": "0", "ActiveState": "active", "After": "-.slice sysinit.target", "AllowIsolate": "no", "AmbientCapabilities": "0", "AssertResult": "yes", "AssertTimestamp": "Wed 2019-06-05 19:01:34 UTC", "AssertTimestampMonotonic": "7245704", "Backlog": "128", "Before": "shutdown.target iscsid.service sockets.target", "BindIPv6Only": "default", "BlockIOAccounting": "no", "BlockIOWeight": "18446744073709551615", "Broadcast": "no", "CPUAccounting": "no", "CPUQuotaPerSecUSec": "infinity", "CPUSchedulingPolicy": "0", "CPUSchedulingPriority": "0", "CPUSchedulingResetOnFork": "no", "CPUShares": "18446744073709551615", "CanIsolate": "no", "CanReload": "no", "CanStart": "yes", "CanStop": "yes", "CapabilityBoundingSet": "18446744073709551615", "ConditionResult": "yes", "ConditionTimestamp": "Wed 2019-06-05 19:01:34 UTC", "ConditionTimestampMonotonic": "7245704", "Conflicts": "shutdown.target", "ControlPID": "0", "DefaultDependencies": "yes", "DeferAcceptUSec": "0", "Delegate": "no", "Description": "Open-iSCSI iscsid Socket", "DevicePolicy": "auto", "DirectoryMode": "0755", "Documentation": "man:iscsid(8) man:iscsiadm(8)", "FragmentPath": "/usr/lib/systemd/system/iscsid.socket", "FreeBind": "no", "IOScheduling": "0", "IPTOS": "-1", "IPTTL": "-1", "Id": "iscsid.socket", "IgnoreOnIsolate": "no", "IgnoreOnSnapshot": "no", "IgnoreSIGPIPE": "yes", "InactiveEnterTimestampMonotonic": "0", "InactiveExitTimestamp": "Wed 2019-06-05 19:01:34 UTC", "InactiveExitTimestampMonotonic": "7246294", "JobTimeoutAction": "none", "JobTimeoutUSec": "0", "KeepAlive": "no", "KeepAliveIntervalUSec": "0", "KeepAliveProbes": "0", "KeepAliveTimeUSec": "0", "KillMode": "control-group", "KillSignal": "15", "LimitAS": "18446744073709551615", "LimitCORE": "18446744073709551615", "LimitCPU": "18446744073709551615", "LimitDATA": "18446744073709551615", "LimitFSIZE": "18446744073709551615", "LimitLOCKS": "18446744073709551615", "LimitMEMLOCK": "65536", "LimitMSGQUEUE": "819200", "LimitNICE": "0", "LimitNOFILE": "4096", "LimitNPROC": "61816", "LimitRSS": "18446744073709551615", "LimitRTPRIO": "0", "LimitRTTIME": "18446744073709551615", "LimitSIGPENDING": "61816", "LimitSTACK": "18446744073709551615", "ListenStream": "@ISCSIADM_ABSTRACT_NAMESPACE", "LoadState": "loaded", "Mark": "-1", "MaxConnections": "64", "MemoryAccounting": "no", "MemoryCurrent": "18446744073709551615", "MemoryLimit": "18446744073709551615", "MountFlags": "0", "NAccepted": "0", "NConnections": "0", "Names": "iscsid.socket", "NeedDaemonReload": "no", "Nice": "0", "NoDelay": "no", "NoNewPrivileges": "no", "NonBlocking": "no", "OOMScoreAdjust": "0", "OnFailureJobMode": "replace", "PassCredentials": "no", "PassSecurity": "no", "PipeSize": "0", "Priority": "-1", "PrivateDevices": "no", "PrivateNetwork": "no", "PrivateTmp": "no", "ProtectHome": "no", "ProtectSystem": "no", "ReceiveBuffer": "0", "RefuseManualStart": "no", "RefuseManualStop": "no", "RemoveOnStop": "no", "Requires": "sysinit.target", "Result": "success", "ReusePort": "no", "RuntimeDirectoryMode": "0755", "SameProcessGroup": "no", "SecureBits": "0", "SendBuffer": "0", "SendSIGHUP": "no", "SendSIGKILL": "yes", "SocketMode": "0666", "StandardError": "inherit", "StandardInput": "null", "StandardOutput": "journal", "StartupBlockIOWeight": "18446744073709551615", "StartupCPUShares": "18446744073709551615", "StopWhenUnneeded": "no", "SubState": "listening", "SyslogLevelPrefix": "yes", "SyslogPriority": "30", "SystemCallErrorNumber": "0", "TTYReset": "no", "TTYVHangup": "no", "TTYVTDisallocate": "no", "TasksAccounting": "no", "TasksCurrent": "18446744073709551615", "TasksMax": "18446744073709551615", "TimeoutUSec": "1min 30s", "TimerSlackNSec": "50000", "Transient": "no", "Transparent": "no", "Triggers": "iscsid.service", "UMask": "0022", "UnitFilePreset": "disabled", "UnitFileState": "enabled", "WantedBy": "sockets.target", "Wants": "-.slice"}}
2019-06-05 14:05:32,355 p=17240 u=mistral |  TASK [create persistent directories] *******************************************
2019-06-05 14:05:32,355 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/host_prep_tasks.yaml:58
2019-06-05 14:05:32,355 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:32 -0500 (0:00:00.218)       0:02:06.125 ******** 
2019-06-05 14:05:32,376 p=17240 u=mistral |  skipping: [lab-controller-0] => (item={u'path': u'/var/log/containers/nova', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/containers/nova", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:32,376 p=17240 u=mistral |  skipping: [lab-controller-0] => (item={u'path': u'/var/log/nova', u'setype': u'var_log_t'})  => {"changed": false, "item": {"path": "/var/log/nova", "setype": "var_log_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:32,471 p=17240 u=mistral |  changed: [lab-computehci-0] => (item={u'path': u'/var/log/containers/nova', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/containers/nova", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/containers/nova", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:05:32,557 p=17240 u=mistral |  changed: [lab-computehci-0] => (item={u'path': u'/var/log/nova', u'setype': u'var_log_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/nova", "setype": "var_log_t"}, "mode": "0755", "owner": "root", "path": "/var/log/nova", "secontext": "unconfined_u:object_r:var_log_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:05:32,581 p=17240 u=mistral |  TASK [nova logs readme] ********************************************************
2019-06-05 14:05:32,581 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/host_prep_tasks.yaml:68
2019-06-05 14:05:32,581 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:32 -0500 (0:00:00.225)       0:02:06.350 ******** 
2019-06-05 14:05:32,601 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:32,868 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "checksum": "c2216cc4edf5d3ce90f10748c3243db4e1842a85", "dest": "/var/log/nova/readme.txt", "gid": 0, "group": "root", "md5sum": "9d8ea066cd36b60e7e3fb5ff27f03339", "mode": "0644", "owner": "root", "secontext": "system_u:object_r:nova_log_t:s0", "size": 113, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559761532.61-22868465932193/source", "state": "file", "uid": 0}
2019-06-05 14:05:32,891 p=17240 u=mistral |  TASK [Mount Nova NFS Share] ****************************************************
2019-06-05 14:05:32,891 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/host_prep_tasks.yaml:77
2019-06-05 14:05:32,891 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:32 -0500 (0:00:00.309)       0:02:06.660 ******** 
2019-06-05 14:05:32,911 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:32,920 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:32,943 p=17240 u=mistral |  TASK [is Nova Resume Guests State On Host Boot enabled] ************************
2019-06-05 14:05:32,943 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/host_prep_tasks.yaml:86
2019-06-05 14:05:32,944 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:32 -0500 (0:00:00.052)       0:02:06.713 ******** 
2019-06-05 14:05:32,963 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:32,975 p=17240 u=mistral |  ok: [lab-computehci-0] => {"ansible_facts": {"resume_guests_state_on_host_boot_enabled": false}, "changed": false}
2019-06-05 14:05:32,999 p=17240 u=mistral |  TASK [libvirt-guests unit to stop nova_api container before shutdown VMs] ******
2019-06-05 14:05:32,999 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/host_prep_tasks.yaml:90
2019-06-05 14:05:32,999 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:32 -0500 (0:00:00.055)       0:02:06.768 ******** 
2019-06-05 14:05:33,018 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:33,028 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:33,050 p=17240 u=mistral |  TASK [libvirt-guests enable VM shutdown on compute reboot/shutdown] ************
2019-06-05 14:05:33,051 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/host_prep_tasks.yaml:144
2019-06-05 14:05:33,051 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:33 -0500 (0:00:00.051)       0:02:06.820 ******** 
2019-06-05 14:05:33,071 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:33,080 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:33,103 p=17240 u=mistral |  TASK [create persistent directories] *******************************************
2019-06-05 14:05:33,103 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/host_prep_tasks.yaml:151
2019-06-05 14:05:33,104 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:33 -0500 (0:00:00.052)       0:02:06.873 ******** 
2019-06-05 14:05:33,126 p=17240 u=mistral |  skipping: [lab-controller-0] => (item={u'path': u'/var/lib/nova', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/lib/nova", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:33,127 p=17240 u=mistral |  skipping: [lab-controller-0] => (item={u'path': u'/var/lib/nova/instances', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/lib/nova/instances", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:33,127 p=17240 u=mistral |  skipping: [lab-controller-0] => (item={u'path': u'/var/lib/libvirt', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/lib/libvirt", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:33,222 p=17240 u=mistral |  changed: [lab-computehci-0] => (item={u'path': u'/var/lib/nova', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/lib/nova", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/lib/nova", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:05:33,307 p=17240 u=mistral |  changed: [lab-computehci-0] => (item={u'path': u'/var/lib/nova/instances', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/lib/nova/instances", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/lib/nova/instances", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:05:33,394 p=17240 u=mistral |  changed: [lab-computehci-0] => (item={u'path': u'/var/lib/libvirt', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/lib/libvirt", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/lib/libvirt", "secontext": "system_u:object_r:container_file_t:s0", "size": 117, "state": "directory", "uid": 0}
2019-06-05 14:05:33,417 p=17240 u=mistral |  TASK [ensure ceph configurations exist] ****************************************
2019-06-05 14:05:33,417 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/host_prep_tasks.yaml:163
2019-06-05 14:05:33,418 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:33 -0500 (0:00:00.313)       0:02:07.187 ******** 
2019-06-05 14:05:33,437 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:33,526 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "gid": 0, "group": "root", "mode": "0755", "owner": "root", "path": "/etc/ceph", "secontext": "unconfined_u:object_r:etc_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:05:33,551 p=17240 u=mistral |  TASK [is Instance HA enabled] **************************************************
2019-06-05 14:05:33,551 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/host_prep_tasks.yaml:167
2019-06-05 14:05:33,551 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:33 -0500 (0:00:00.133)       0:02:07.320 ******** 
2019-06-05 14:05:33,572 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:33,581 p=17240 u=mistral |  ok: [lab-computehci-0] => {"ansible_facts": {"instance_ha_enabled": false}, "changed": false}
2019-06-05 14:05:33,605 p=17240 u=mistral |  TASK [prepare Instance HA script directory] ************************************
2019-06-05 14:05:33,606 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/host_prep_tasks.yaml:171
2019-06-05 14:05:33,606 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:33 -0500 (0:00:00.054)       0:02:07.375 ******** 
2019-06-05 14:05:33,629 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:33,639 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:33,662 p=17240 u=mistral |  TASK [install Instance HA script that runs nova-compute] ***********************
2019-06-05 14:05:33,662 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/host_prep_tasks.yaml:175
2019-06-05 14:05:33,662 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:33 -0500 (0:00:00.056)       0:02:07.432 ******** 
2019-06-05 14:05:33,682 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:33,692 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:33,715 p=17240 u=mistral |  TASK [Get list of instance HA compute nodes] ***********************************
2019-06-05 14:05:33,715 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/host_prep_tasks.yaml:287
2019-06-05 14:05:33,716 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:33 -0500 (0:00:00.053)       0:02:07.485 ******** 
2019-06-05 14:05:33,736 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:33,747 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:33,771 p=17240 u=mistral |  TASK [If instance HA is enabled on the node activate the evacuation completed check] ***
2019-06-05 14:05:33,771 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/host_prep_tasks.yaml:290
2019-06-05 14:05:33,771 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:33 -0500 (0:00:00.055)       0:02:07.541 ******** 
2019-06-05 14:05:33,793 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:33,806 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:33,833 p=17240 u=mistral |  TASK [is KSM enabled] **********************************************************
2019-06-05 14:05:33,833 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/host_prep_tasks.yaml:296
2019-06-05 14:05:33,833 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:33 -0500 (0:00:00.061)       0:02:07.603 ******** 
2019-06-05 14:05:33,889 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:33,942 p=17240 u=mistral |  ok: [lab-computehci-0] => {"ansible_facts": {"compute_ksm_enabled": false}, "changed": false}
2019-06-05 14:05:33,964 p=17240 u=mistral |  TASK [Populate service facts (ksm)] ********************************************
2019-06-05 14:05:33,964 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/host_prep_tasks.yaml:300
2019-06-05 14:05:33,965 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:33 -0500 (0:00:00.131)       0:02:07.734 ******** 
2019-06-05 14:05:33,984 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:34,120 p=17240 u=mistral |  ok: [lab-computehci-0] => {"ansible_facts": {"services": {"auditd.service": {"name": "auditd.service", "source": "systemd", "state": "running"}, "auth-rpcgss-module.service": {"name": "auth-rpcgss-module.service", "source": "systemd", "state": "stopped"}, "blk-availability.service": {"name": "blk-availability.service", "source": "systemd", "state": "stopped"}, "chronyd.service": {"name": "chronyd.service", "source": "systemd", "state": "running"}, "cloud-config.service": {"name": "cloud-config.service", "source": "systemd", "state": "stopped"}, "cloud-final.service": {"name": "cloud-final.service", "source": "systemd", "state": "stopped"}, "cloud-init-local.service": {"name": "cloud-init-local.service", "source": "systemd", "state": "stopped"}, "cloud-init.service": {"name": "cloud-init.service", "source": "systemd", "state": "stopped"}, "corosync.service": {"name": "corosync.service", "source": "systemd", "state": "stopped"}, "cpupower.service": {"name": "cpupower.service", "source": "systemd", "state": "stopped"}, "crond.service": {"name": "crond.service", "source": "systemd", "state": "running"}, "dbus.service": {"name": "dbus.service", "source": "systemd", "state": "running"}, "dhcp-interface@br-ex.service": {"name": "dhcp-interface@br-ex.service", "source": "systemd", "state": "stopped"}, "dhcp-interface@eth0.service": {"name": "dhcp-interface@eth0.service", "source": "systemd", "state": "stopped"}, "dhcp-interface@eth1.service": {"name": "dhcp-interface@eth1.service", "source": "systemd", "state": "stopped"}, "dhcp-interface@ovs-system.service": {"name": "dhcp-interface@ovs-system.service", "source": "systemd", "state": "stopped"}, "dhcp-interface@vlan20.service": {"name": "dhcp-interface@vlan20.service", "source": "systemd", "state": "stopped"}, "dhcp-interface@vlan30.service": {"name": "dhcp-interface@vlan30.service", "source": "systemd", "state": "stopped"}, "dhcp-interface@vlan40.service": {"name": "dhcp-interface@vlan40.service", "source": "systemd", "state": "stopped"}, "dhcp-interface@vlan50.service": {"name": "dhcp-interface@vlan50.service", "source": "systemd", "state": "stopped"}, "dm-event.service": {"name": "dm-event.service", "source": "systemd", "state": "stopped"}, "docker-cleanup.service": {"name": "docker-cleanup.service", "source": "systemd", "state": "stopped"}, "docker-storage-setup.service": {"name": "docker-storage-setup.service", "source": "systemd", "state": "stopped"}, "docker.service": {"name": "docker.service", "source": "systemd", "state": "running"}, "dracut-shutdown.service": {"name": "dracut-shutdown.service", "source": "systemd", "state": "stopped"}, "dynamic-login.service": {"name": "dynamic-login.service", "source": "systemd", "state": "stopped"}, "emergency.service": {"name": "emergency.service", "source": "systemd", "state": "stopped"}, "getty@tty1.service": {"name": "getty@tty1.service", "source": "systemd", "state": "running"}, "gssproxy.service": {"name": "gssproxy.service", "source": "systemd", "state": "running"}, "ip6tables.service": {"name": "ip6tables.service", "source": "systemd", "state": "stopped"}, "iptables.service": {"name": "iptables.service", "source": "systemd", "state": "stopped"}, "irqbalance.service": {"name": "irqbalance.service", "source": "systemd", "state": "running"}, "iscsi-shutdown.service": {"name": "iscsi-shutdown.service", "source": "systemd", "state": "stopped"}, "iscsi.service": {"name": "iscsi.service", "source": "systemd", "state": "stopped"}, "iscsid.service": {"name": "iscsid.service", "source": "systemd", "state": "stopped"}, "iscsiuio.service": {"name": "iscsiuio.service", "source": "systemd", "state": "stopped"}, "kdump.service": {"name": "kdump.service", "source": "systemd", "state": "stopped"}, "kmod-static-nodes.service": {"name": "kmod-static-nodes.service", "source": "systemd", "state": "stopped"}, "libvirt-guests.service": {"name": "libvirt-guests.service", "source": "systemd", "state": "stopped"}, "libvirtd.service": {"name": "libvirtd.service", "source": "systemd", "state": "running"}, "lvm2-lvmetad.service": {"name": "lvm2-lvmetad.service", "source": "systemd", "state": "running"}, "lvm2-lvmpolld.service": {"name": "lvm2-lvmpolld.service", "source": "systemd", "state": "stopped"}, "lvm2-monitor.service": {"name": "lvm2-monitor.service", "source": "systemd", "state": "stopped"}, "microcode.service": {"name": "microcode.service", "source": "systemd", "state": "stopped"}, "multipathd.service": {"name": "multipathd.service", "source": "systemd", "state": "stopped"}, "netcf-transaction.service": {"name": "netcf-transaction.service", "source": "systemd", "state": "stopped"}, "netconsole": {"name": "netconsole", "source": "sysv", "state": "stopped"}, "netns-placeholder.service": {"name": "netns-placeholder.service", "source": "systemd", "state": "stopped"}, "network": {"name": "network", "source": "sysv", "state": "running"}, "network.service": {"name": "network.service", "source": "systemd", "state": "stopped"}, "nfs-config.service": {"name": "nfs-config.service", "source": "systemd", "state": "stopped"}, "nfs-idmapd.service": {"name": "nfs-idmapd.service", "source": "systemd", "state": "stopped"}, "nfs-mountd.service": {"name": "nfs-mountd.service", "source": "systemd", "state": "stopped"}, "nfs-server.service": {"name": "nfs-server.service", "source": "systemd", "state": "stopped"}, "nfs-utils.service": {"name": "nfs-utils.service", "source": "systemd", "state": "stopped"}, "ntpd.service": {"name": "ntpd.service", "source": "systemd", "state": "stopped"}, "ntpdate.service": {"name": "ntpdate.service", "source": "systemd", "state": "stopped"}, "openvswitch.service": {"name": "openvswitch.service", "source": "systemd", "state": "stopped"}, "ovs-delete-transient-ports.service": {"name": "ovs-delete-transient-ports.service", "source": "systemd", "state": "stopped"}, "ovs-vswitchd.service": {"name": "ovs-vswitchd.service", "source": "systemd", "state": "running"}, "ovsdb-server.service": {"name": "ovsdb-server.service", "source": "systemd", "state": "running"}, "pacemaker.service": {"name": "pacemaker.service", "source": "systemd", "state": "stopped"}, "paunch-container-shutdown.service": {"name": "paunch-container-shutdown.service", "source": "systemd", "state": "stopped"}, "polkit.service": {"name": "polkit.service", "source": "systemd", "state": "running"}, "postfix.service": {"name": "postfix.service", "source": "systemd", "state": "running"}, "qemu-guest-agent.service": {"name": "qemu-guest-agent.service", "source": "systemd", "state": "running"}, "rc-local.service": {"name": "rc-local.service", "source": "systemd", "state": "stopped"}, "rescue.service": {"name": "rescue.service", "source": "systemd", "state": "stopped"}, "rhel-autorelabel.service": {"name": "rhel-autorelabel.service", "source": "systemd", "state": "stopped"}, "rhel-configure.service": {"name": "rhel-configure.service", "source": "systemd", "state": "stopped"}, "rhel-dmesg.service": {"name": "rhel-dmesg.service", "source": "systemd", "state": "stopped"}, "rhel-domainname.service": {"name": "rhel-domainname.service", "source": "systemd", "state": "stopped"}, "rhel-import-state.service": {"name": "rhel-import-state.service", "source": "systemd", "state": "stopped"}, "rhel-loadmodules.service": {"name": "rhel-loadmodules.service", "source": "systemd", "state": "stopped"}, "rhel-readonly.service": {"name": "rhel-readonly.service", "source": "systemd", "state": "stopped"}, "rpc-gssd.service": {"name": "rpc-gssd.service", "source": "systemd", "state": "stopped"}, "rpc-statd-notify.service": {"name": "rpc-statd-notify.service", "source": "systemd", "state": "stopped"}, "rpc-statd.service": {"name": "rpc-statd.service", "source": "systemd", "state": "stopped"}, "rpcbind.service": {"name": "rpcbind.service", "source": "systemd", "state": "running"}, "rsyslog.service": {"name": "rsyslog.service", "source": "systemd", "state": "running"}, "selinux-policy-migrate-local-changes@targeted.service": {"name": "selinux-policy-migrate-local-changes@targeted.service", "source": "systemd", "state": "stopped"}, "serial-getty@ttyS0.service": {"name": "serial-getty@ttyS0.service", "source": "systemd", "state": "running"}, "sshd-keygen.service": {"name": "sshd-keygen.service", "source": "systemd", "state": "stopped"}, "sshd.service": {"name": "sshd.service", "source": "systemd", "state": "running"}, "systemd-ask-password-console.service": {"name": "systemd-ask-password-console.service", "source": "systemd", "state": "stopped"}, "systemd-ask-password-wall.service": {"name": "systemd-ask-password-wall.service", "source": "systemd", "state": "stopped"}, "systemd-binfmt.service": {"name": "systemd-binfmt.service", "source": "systemd", "state": "stopped"}, "systemd-firstboot.service": {"name": "systemd-firstboot.service", "source": "systemd", "state": "stopped"}, "systemd-fsck-root.service": {"name": "systemd-fsck-root.service", "source": "systemd", "state": "stopped"}, "systemd-hwdb-update.service": {"name": "systemd-hwdb-update.service", "source": "systemd", "state": "stopped"}, "systemd-initctl.service": {"name": "systemd-initctl.service", "source": "systemd", "state": "stopped"}, "systemd-journal-catalog-update.service": {"name": "systemd-journal-catalog-update.service", "source": "systemd", "state": "stopped"}, "systemd-journal-flush.service": {"name": "systemd-journal-flush.service", "source": "systemd", "state": "stopped"}, "systemd-journald.service": {"name": "systemd-journald.service", "source": "systemd", "state": "running"}, "systemd-logind.service": {"name": "systemd-logind.service", "source": "systemd", "state": "running"}, "systemd-machine-id-commit.service": {"name": "systemd-machine-id-commit.service", "source": "systemd", "state": "stopped"}, "systemd-machined.service": {"name": "systemd-machined.service", "source": "systemd", "state": "stopped"}, "systemd-modules-load.service": {"name": "systemd-modules-load.service", "source": "systemd", "state": "stopped"}, "systemd-random-seed.service": {"name": "systemd-random-seed.service", "source": "systemd", "state": "stopped"}, "systemd-readahead-collect.service": {"name": "systemd-readahead-collect.service", "source": "systemd", "state": "stopped"}, "systemd-readahead-done.service": {"name": "systemd-readahead-done.service", "source": "systemd", "state": "stopped"}, "systemd-readahead-replay.service": {"name": "systemd-readahead-replay.service", "source": "systemd", "state": "stopped"}, "systemd-reboot.service": {"name": "systemd-reboot.service", "source": "systemd", "state": "stopped"}, "systemd-remount-fs.service": {"name": "systemd-remount-fs.service", "source": "systemd", "state": "stopped"}, "systemd-shutdownd.service": {"name": "systemd-shutdownd.service", "source": "systemd", "state": "stopped"}, "systemd-sysctl.service": {"name": "systemd-sysctl.service", "source": "systemd", "state": "stopped"}, "systemd-tmpfiles-clean.service": {"name": "systemd-tmpfiles-clean.service", "source": "systemd", "state": "stopped"}, "systemd-tmpfiles-setup-dev.service": {"name": "systemd-tmpfiles-setup-dev.service", "source": "systemd", "state": "stopped"}, "systemd-tmpfiles-setup.service": {"name": "systemd-tmpfiles-setup.service", "source": "systemd", "state": "stopped"}, "systemd-udev-settle.service": {"name": "systemd-udev-settle.service", "source": "systemd", "state": "stopped"}, "systemd-udev-trigger.service": {"name": "systemd-udev-trigger.service", "source": "systemd", "state": "stopped"}, "systemd-udevd.service": {"name": "systemd-udevd.service", "source": "systemd", "state": "running"}, "systemd-update-done.service": {"name": "systemd-update-done.service", "source": "systemd", "state": "stopped"}, "systemd-update-utmp-runlevel.service": {"name": "systemd-update-utmp-runlevel.service", "source": "systemd", "state": "stopped"}, "systemd-update-utmp.service": {"name": "systemd-update-utmp.service", "source": "systemd", "state": "stopped"}, "systemd-user-sessions.service": {"name": "systemd-user-sessions.service", "source": "systemd", "state": "stopped"}, "systemd-vconsole-setup.service": {"name": "systemd-vconsole-setup.service", "source": "systemd", "state": "stopped"}, "tripleo-ip6tables.service": {"name": "tripleo-ip6tables.service", "source": "systemd", "state": "stopped"}, "tripleo-iptables.service": {"name": "tripleo-iptables.service", "source": "systemd", "state": "stopped"}, "tuned.service": {"name": "tuned.service", "source": "systemd", "state": "running"}, "unbound-anchor.service": {"name": "unbound-anchor.service", "source": "systemd", "state": "stopped"}, "virtlockd.service": {"name": "virtlockd.service", "source": "systemd", "state": "stopped"}, "virtlogd.service": {"name": "virtlogd.service", "source": "systemd", "state": "stopped"}}}, "changed": false}
2019-06-05 14:05:34,144 p=17240 u=mistral |  TASK [disable KSM services] ****************************************************
2019-06-05 14:05:34,144 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/host_prep_tasks.yaml:302
2019-06-05 14:05:34,144 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:34 -0500 (0:00:00.179)       0:02:07.913 ******** 
2019-06-05 14:05:34,171 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=ksm.service)  => {"changed": false, "item": "ksm.service", "skip_reason": "Conditional result was False"}
2019-06-05 14:05:34,172 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=ksmtuned.service)  => {"changed": false, "item": "ksmtuned.service", "skip_reason": "Conditional result was False"}
2019-06-05 14:05:34,188 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=ksm.service)  => {"changed": false, "item": "ksm.service", "skip_reason": "Conditional result was False"}
2019-06-05 14:05:34,197 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=ksmtuned.service)  => {"changed": false, "item": "ksmtuned.service", "skip_reason": "Conditional result was False"}
2019-06-05 14:05:34,221 p=17240 u=mistral |  TASK [delete PageKSM after disable ksm on compute] *****************************
2019-06-05 14:05:34,221 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/host_prep_tasks.yaml:312
2019-06-05 14:05:34,221 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:34 -0500 (0:00:00.077)       0:02:07.991 ******** 
2019-06-05 14:05:34,248 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:34,258 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:34,281 p=17240 u=mistral |  TASK [Populate service facts (ksm)] ********************************************
2019-06-05 14:05:34,281 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/host_prep_tasks.yaml:318
2019-06-05 14:05:34,282 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:34 -0500 (0:00:00.060)       0:02:08.051 ******** 
2019-06-05 14:05:34,308 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:34,317 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:34,340 p=17240 u=mistral |  TASK [make sure package providing ksmtuned is installed (CentOS)] **************
2019-06-05 14:05:34,341 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/host_prep_tasks.yaml:320
2019-06-05 14:05:34,341 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:34 -0500 (0:00:00.059)       0:02:08.110 ******** 
2019-06-05 14:05:34,367 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:34,380 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:34,405 p=17240 u=mistral |  TASK [make sure package providing ksmtuned is installed (RHEL)] ****************
2019-06-05 14:05:34,406 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/host_prep_tasks.yaml:325
2019-06-05 14:05:34,406 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:34 -0500 (0:00:00.065)       0:02:08.175 ******** 
2019-06-05 14:05:34,432 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:34,442 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:34,465 p=17240 u=mistral |  TASK [enable ksmtunded] ********************************************************
2019-06-05 14:05:34,465 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/host_prep_tasks.yaml:330
2019-06-05 14:05:34,465 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:34 -0500 (0:00:00.059)       0:02:08.234 ******** 
2019-06-05 14:05:34,492 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=ksm.service)  => {"changed": false, "item": "ksm.service", "skip_reason": "Conditional result was False"}
2019-06-05 14:05:34,493 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=ksmtuned.service)  => {"changed": false, "item": "ksmtuned.service", "skip_reason": "Conditional result was False"}
2019-06-05 14:05:34,504 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=ksm.service)  => {"changed": false, "item": "ksm.service", "skip_reason": "Conditional result was False"}
2019-06-05 14:05:34,509 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=ksmtuned.service)  => {"changed": false, "item": "ksmtuned.service", "skip_reason": "Conditional result was False"}
2019-06-05 14:05:34,532 p=17240 u=mistral |  TASK [create libvirt persistent data directories] ******************************
2019-06-05 14:05:34,532 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/host_prep_tasks.yaml:340
2019-06-05 14:05:34,532 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:34 -0500 (0:00:00.066)       0:02:08.301 ******** 
2019-06-05 14:05:34,560 p=17240 u=mistral |  skipping: [lab-controller-0] => (item={u'path': u'/etc/libvirt', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/etc/libvirt", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:34,561 p=17240 u=mistral |  skipping: [lab-controller-0] => (item={u'path': u'/etc/libvirt/secrets', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/etc/libvirt/secrets", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:34,561 p=17240 u=mistral |  skipping: [lab-controller-0] => (item={u'path': u'/etc/libvirt/qemu', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/etc/libvirt/qemu", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:34,562 p=17240 u=mistral |  skipping: [lab-controller-0] => (item={u'path': u'/var/lib/libvirt', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/lib/libvirt", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:34,565 p=17240 u=mistral |  skipping: [lab-controller-0] => (item={u'path': u'/var/lib/nova', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/lib/nova", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:34,567 p=17240 u=mistral |  skipping: [lab-controller-0] => (item={u'path': u'/var/log/containers/libvirt', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/containers/libvirt", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:34,571 p=17240 u=mistral |  skipping: [lab-controller-0] => (item={u'path': u'/var/run/libvirt', u'setype': u'virt_var_run_t'})  => {"changed": false, "item": {"path": "/var/run/libvirt", "setype": "virt_var_run_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:34,573 p=17240 u=mistral |  skipping: [lab-controller-0] => (item={u'path': u'/var/log/libvirt', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/libvirt", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:34,578 p=17240 u=mistral |  skipping: [lab-controller-0] => (item={u'path': u'/var/log/libvirt/qemu', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/libvirt/qemu", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:34,662 p=17240 u=mistral |  changed: [lab-computehci-0] => (item={u'path': u'/etc/libvirt', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/etc/libvirt", "setype": "svirt_sandbox_file_t"}, "mode": "0700", "owner": "root", "path": "/etc/libvirt", "secontext": "system_u:object_r:container_file_t:s0", "size": 215, "state": "directory", "uid": 0}
2019-06-05 14:05:34,747 p=17240 u=mistral |  changed: [lab-computehci-0] => (item={u'path': u'/etc/libvirt/secrets', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/etc/libvirt/secrets", "setype": "svirt_sandbox_file_t"}, "mode": "0700", "owner": "root", "path": "/etc/libvirt/secrets", "secontext": "system_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:05:34,832 p=17240 u=mistral |  changed: [lab-computehci-0] => (item={u'path': u'/etc/libvirt/qemu', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/etc/libvirt/qemu", "setype": "svirt_sandbox_file_t"}, "mode": "0700", "owner": "root", "path": "/etc/libvirt/qemu", "secontext": "system_u:object_r:container_file_t:s0", "size": 22, "state": "directory", "uid": 0}
2019-06-05 14:05:34,918 p=17240 u=mistral |  changed: [lab-computehci-0] => (item={u'path': u'/var/lib/libvirt', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/lib/libvirt", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/lib/libvirt", "secontext": "system_u:object_r:container_file_t:s0", "size": 117, "state": "directory", "uid": 0}
2019-06-05 14:05:35,003 p=17240 u=mistral |  changed: [lab-computehci-0] => (item={u'path': u'/var/lib/nova', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/lib/nova", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/lib/nova", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 23, "state": "directory", "uid": 0}
2019-06-05 14:05:35,089 p=17240 u=mistral |  changed: [lab-computehci-0] => (item={u'path': u'/var/log/containers/libvirt', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/containers/libvirt", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/containers/libvirt", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:05:35,174 p=17240 u=mistral |  ok: [lab-computehci-0] => (item={u'path': u'/var/run/libvirt', u'setype': u'virt_var_run_t'}) => {"changed": false, "gid": 0, "group": "root", "item": {"path": "/var/run/libvirt", "setype": "virt_var_run_t"}, "mode": "0755", "owner": "root", "path": "/var/run/libvirt", "secontext": "system_u:object_r:virt_var_run_t:s0", "size": 260, "state": "directory", "uid": 0}
2019-06-05 14:05:35,261 p=17240 u=mistral |  changed: [lab-computehci-0] => (item={u'path': u'/var/log/libvirt', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/libvirt", "setype": "svirt_sandbox_file_t"}, "mode": "0700", "owner": "root", "path": "/var/log/libvirt", "secontext": "system_u:object_r:container_file_t:s0", "size": 29, "state": "directory", "uid": 0}
2019-06-05 14:05:35,348 p=17240 u=mistral |  changed: [lab-computehci-0] => (item={u'path': u'/var/log/libvirt/qemu', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/libvirt/qemu", "setype": "svirt_sandbox_file_t"}, "mode": "0700", "owner": "root", "path": "/var/log/libvirt/qemu", "secontext": "system_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:05:35,373 p=17240 u=mistral |  TASK [ensure qemu group is present on the host] ********************************
2019-06-05 14:05:35,373 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/host_prep_tasks.yaml:364
2019-06-05 14:05:35,373 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:35 -0500 (0:00:00.841)       0:02:09.142 ******** 
2019-06-05 14:05:35,401 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:35,491 p=17240 u=mistral |  ok: [lab-computehci-0] => {"changed": false, "gid": 107, "name": "qemu", "state": "present", "system": false}
2019-06-05 14:05:35,514 p=17240 u=mistral |  TASK [ensure qemu user is present on the host] *********************************
2019-06-05 14:05:35,514 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/host_prep_tasks.yaml:369
2019-06-05 14:05:35,515 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:35 -0500 (0:00:00.141)       0:02:09.284 ******** 
2019-06-05 14:05:35,542 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:35,743 p=17240 u=mistral |  ok: [lab-computehci-0] => {"append": false, "changed": false, "comment": "qemu user", "group": 107, "home": "/", "move_home": false, "name": "qemu", "shell": "/sbin/nologin", "state": "present", "uid": 107}
2019-06-05 14:05:35,767 p=17240 u=mistral |  TASK [create directory for vhost-user sockets with qemu ownership] *************
2019-06-05 14:05:35,767 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/host_prep_tasks.yaml:377
2019-06-05 14:05:35,767 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:35 -0500 (0:00:00.252)       0:02:09.536 ******** 
2019-06-05 14:05:35,793 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:35,883 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "gid": 107, "group": "qemu", "mode": "0755", "owner": "qemu", "path": "/var/lib/vhost_sockets", "secontext": "system_u:object_r:virt_cache_t:s0", "size": 6, "state": "directory", "uid": 107}
2019-06-05 14:05:35,907 p=17240 u=mistral |  TASK [check if libvirt is installed] *******************************************
2019-06-05 14:05:35,907 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/host_prep_tasks.yaml:385
2019-06-05 14:05:35,907 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:35 -0500 (0:00:00.140)       0:02:09.676 ******** 
2019-06-05 14:05:35,933 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:36,044 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "cmd": ["/usr/bin/rpm", "-q", "libvirt-daemon"], "delta": "0:00:00.024795", "end": "2019-06-05 19:05:36.037000", "failed_when_result": false, "rc": 0, "start": "2019-06-05 19:05:36.012205", "stderr": "", "stderr_lines": [], "stdout": "libvirt-daemon-4.5.0-10.el7_6.10.x86_64", "stdout_lines": ["libvirt-daemon-4.5.0-10.el7_6.10.x86_64"]}
2019-06-05 14:05:36,068 p=17240 u=mistral |  TASK [make sure libvirt services are disabled] *********************************
2019-06-05 14:05:36,068 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/host_prep_tasks.yaml:390
2019-06-05 14:05:36,068 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:36 -0500 (0:00:00.160)       0:02:09.837 ******** 
2019-06-05 14:05:36,095 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=libvirtd.service)  => {"changed": false, "item": "libvirtd.service", "skip_reason": "Conditional result was False"}
2019-06-05 14:05:36,095 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=virtlogd.socket)  => {"changed": false, "item": "virtlogd.socket", "skip_reason": "Conditional result was False"}
2019-06-05 14:05:36,285 p=17240 u=mistral |  changed: [lab-computehci-0] => (item=libvirtd.service) => {"changed": true, "enabled": false, "item": "libvirtd.service", "name": "libvirtd.service", "state": "stopped", "status": {"ActiveEnterTimestamp": "Wed 2019-06-05 19:01:48 UTC", "ActiveEnterTimestampMonotonic": "20973714", "ActiveExitTimestampMonotonic": "0", "ActiveState": "active", "After": "apparmor.service systemd-machined.service virtlogd.service dbus.service virtlogd.socket virtlogd-admin.socket network.target iscsid.service remote-fs.target local-fs.target virtlockd.socket system.slice basic.target systemd-journald.socket virtlockd.service virtlockd-admin.socket systemd-logind.service", "AllowIsolate": "no", "AmbientCapabilities": "0", "AssertResult": "yes", "AssertTimestamp": "Wed 2019-06-05 19:01:38 UTC", "AssertTimestampMonotonic": "10707433", "Before": "shutdown.target multi-user.target libvirt-guests.service", "BlockIOAccounting": "no", "BlockIOWeight": "18446744073709551615", "CPUAccounting": "no", "CPUQuotaPerSecUSec": "infinity", "CPUSchedulingPolicy": "0", "CPUSchedulingPriority": "0", "CPUSchedulingResetOnFork": "no", "CPUShares": "18446744073709551615", "CanIsolate": "no", "CanReload": "yes", "CanStart": "yes", "CanStop": "yes", "CapabilityBoundingSet": "18446744073709551615", "ConditionResult": "yes", "ConditionTimestamp": "Wed 2019-06-05 19:01:38 UTC", "ConditionTimestampMonotonic": "10707433", "Conflicts": "shutdown.target", "ControlGroup": "/system.slice/libvirtd.service", "ControlPID": "0", "DefaultDependencies": "yes", "Delegate": "no", "Description": "Virtualization daemon", "DevicePolicy": "auto", "Documentation": "man:libvirtd(8) https://libvirt.org", "EnvironmentFile": "/etc/sysconfig/libvirtd (ignore_errors=yes)", "ExecMainCode": "0", "ExecMainExitTimestampMonotonic": "0", "ExecMainPID": "3806", "ExecMainStartTimestamp": "Wed 2019-06-05 19:01:38 UTC", "ExecMainStartTimestampMonotonic": "10708595", "ExecMainStatus": "0", "ExecReload": "{ path=/bin/kill ; argv[]=/bin/kill -HUP $MAINPID ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }", "ExecStart": "{ path=/usr/sbin/libvirtd ; argv[]=/usr/sbin/libvirtd $LIBVIRTD_ARGS ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }", "FailureAction": "none", "FileDescriptorStoreMax": "0", "FragmentPath": "/usr/lib/systemd/system/libvirtd.service", "GuessMainPID": "yes", "IOScheduling": "0", "Id": "libvirtd.service", "IgnoreOnIsolate": "no", "IgnoreOnSnapshot": "no", "IgnoreSIGPIPE": "yes", "InactiveEnterTimestampMonotonic": "0", "InactiveExitTimestamp": "Wed 2019-06-05 19:01:38 UTC", "InactiveExitTimestampMonotonic": "10708623", "JobTimeoutAction": "none", "JobTimeoutUSec": "0", "KillMode": "process", "KillSignal": "15", "LimitAS": "18446744073709551615", "LimitCORE": "18446744073709551615", "LimitCPU": "18446744073709551615", "LimitDATA": "18446744073709551615", "LimitFSIZE": "18446744073709551615", "LimitLOCKS": "18446744073709551615", "LimitMEMLOCK": "65536", "LimitMSGQUEUE": "819200", "LimitNICE": "0", "LimitNOFILE": "8192", "LimitNPROC": "61816", "LimitRSS": "18446744073709551615", "LimitRTPRIO": "0", "LimitRTTIME": "18446744073709551615", "LimitSIGPENDING": "61816", "LimitSTACK": "18446744073709551615", "LoadState": "loaded", "MainPID": "3806", "MemoryAccounting": "no", "MemoryCurrent": "18446744073709551615", "MemoryLimit": "18446744073709551615", "MountFlags": "0", "Names": "libvirtd.service", "NeedDaemonReload": "no", "Nice": "0", "NoNewPrivileges": "no", "NonBlocking": "no", "NotifyAccess": "main", "OOMScoreAdjust": "0", "OnFailureJobMode": "replace", "PermissionsStartOnly": "no", "PrivateDevices": "no", "PrivateNetwork": "no", "PrivateTmp": "no", "ProtectHome": "no", "ProtectSystem": "no", "RefuseManualStart": "no", "RefuseManualStop": "no", "RemainAfterExit": "no", "Requires": "virtlogd.socket virtlockd.socket basic.target", "Restart": "on-failure", "RestartUSec": "100ms", "Result": "success", "RootDirectoryStartOnly": "no", "RuntimeDirectoryMode": "0755", "SameProcessGroup": "no", "SecureBits": "0", "SendSIGHUP": "no", "SendSIGKILL": "yes", "Slice": "system.slice", "StandardError": "inherit", "StandardInput": "null", "StandardOutput": "journal", "StartLimitAction": "none", "StartLimitBurst": "5", "StartLimitInterval": "10000000", "StartupBlockIOWeight": "18446744073709551615", "StartupCPUShares": "18446744073709551615", "StatusErrno": "0", "StopWhenUnneeded": "no", "SubState": "running", "SyslogLevelPrefix": "yes", "SyslogPriority": "30", "SystemCallErrorNumber": "0", "TTYReset": "no", "TTYVHangup": "no", "TTYVTDisallocate": "no", "TasksAccounting": "no", "TasksCurrent": "18446744073709551615", "TasksMax": "32768", "TimeoutStartUSec": "1min 30s", "TimeoutStopUSec": "1min 30s", "TimerSlackNSec": "50000", "Transient": "no", "Type": "notify", "UMask": "0022", "UnitFilePreset": "enabled", "UnitFileState": "enabled", "WantedBy": "multi-user.target libvirt-guests.service", "Wants": "system.slice systemd-machined.service", "WatchdogTimestamp": "Wed 2019-06-05 19:01:48 UTC", "WatchdogTimestampMonotonic": "20973682", "WatchdogUSec": "0"}}
2019-06-05 14:05:36,428 p=17240 u=mistral |  changed: [lab-computehci-0] => (item=virtlogd.socket) => {"changed": true, "enabled": false, "item": "virtlogd.socket", "name": "virtlogd.socket", "state": "stopped", "status": {"Accept": "no", "ActiveEnterTimestamp": "Wed 2019-06-05 19:01:34 UTC", "ActiveEnterTimestampMonotonic": "7244248", "ActiveExitTimestampMonotonic": "0", "ActiveState": "active", "After": "sysinit.target -.slice -.mount", "AllowIsolate": "no", "AmbientCapabilities": "0", "AssertResult": "yes", "AssertTimestamp": "Wed 2019-06-05 19:01:34 UTC", "AssertTimestampMonotonic": "7242707", "Backlog": "128", "Before": "shutdown.target virtlogd.service libvirtd.service sockets.target", "BindIPv6Only": "default", "BlockIOAccounting": "no", "BlockIOWeight": "18446744073709551615", "Broadcast": "no", "CPUAccounting": "no", "CPUQuotaPerSecUSec": "infinity", "CPUSchedulingPolicy": "0", "CPUSchedulingPriority": "0", "CPUSchedulingResetOnFork": "no", "CPUShares": "18446744073709551615", "CanIsolate": "no", "CanReload": "no", "CanStart": "yes", "CanStop": "yes", "CapabilityBoundingSet": "18446744073709551615", "ConditionResult": "yes", "ConditionTimestamp": "Wed 2019-06-05 19:01:34 UTC", "ConditionTimestampMonotonic": "7242707", "Conflicts": "shutdown.target", "ControlPID": "0", "DefaultDependencies": "yes", "DeferAcceptUSec": "0", "Delegate": "no", "Description": "Virtual machine log manager socket", "DevicePolicy": "auto", "DirectoryMode": "0755", "FragmentPath": "/usr/lib/systemd/system/virtlogd.socket", "FreeBind": "no", "IOScheduling": "0", "IPTOS": "-1", "IPTTL": "-1", "Id": "virtlogd.socket", "IgnoreOnIsolate": "no", "IgnoreOnSnapshot": "no", "IgnoreSIGPIPE": "yes", "InactiveEnterTimestampMonotonic": "0", "InactiveExitTimestamp": "Wed 2019-06-05 19:01:34 UTC", "InactiveExitTimestampMonotonic": "7244248", "JobTimeoutAction": "none", "JobTimeoutUSec": "0", "KeepAlive": "no", "KeepAliveIntervalUSec": "0", "KeepAliveProbes": "0", "KeepAliveTimeUSec": "0", "KillMode": "control-group", "KillSignal": "15", "LimitAS": "18446744073709551615", "LimitCORE": "18446744073709551615", "LimitCPU": "18446744073709551615", "LimitDATA": "18446744073709551615", "LimitFSIZE": "18446744073709551615", "LimitLOCKS": "18446744073709551615", "LimitMEMLOCK": "65536", "LimitMSGQUEUE": "819200", "LimitNICE": "0", "LimitNOFILE": "4096", "LimitNPROC": "61816", "LimitRSS": "18446744073709551615", "LimitRTPRIO": "0", "LimitRTTIME": "18446744073709551615", "LimitSIGPENDING": "61816", "LimitSTACK": "18446744073709551615", "ListenStream": "/var/run/libvirt/virtlogd-sock", "LoadState": "loaded", "Mark": "-1", "MaxConnections": "64", "MemoryAccounting": "no", "MemoryCurrent": "18446744073709551615", "MemoryLimit": "18446744073709551615", "MountFlags": "0", "NAccepted": "0", "NConnections": "0", "Names": "virtlogd.socket", "NeedDaemonReload": "no", "Nice": "0", "NoDelay": "no", "NoNewPrivileges": "no", "NonBlocking": "no", "OOMScoreAdjust": "0", "OnFailureJobMode": "replace", "PassCredentials": "no", "PassSecurity": "no", "PipeSize": "0", "Priority": "-1", "PrivateDevices": "no", "PrivateNetwork": "no", "PrivateTmp": "no", "ProtectHome": "no", "ProtectSystem": "no", "ReceiveBuffer": "0", "RefuseManualStart": "no", "RefuseManualStop": "no", "RemoveOnStop": "no", "RequiredBy": "virtlogd.service libvirtd.service", "Requires": "sysinit.target -.mount", "RequiresMountsFor": "/var/run/libvirt/virtlogd-sock", "Result": "success", "ReusePort": "no", "RuntimeDirectoryMode": "0755", "SameProcessGroup": "no", "SecureBits": "0", "SendBuffer": "0", "SendSIGHUP": "no", "SendSIGKILL": "yes", "SocketMode": "0600", "StandardError": "inherit", "StandardInput": "null", "StandardOutput": "journal", "StartupBlockIOWeight": "18446744073709551615", "StartupCPUShares": "18446744073709551615", "StopWhenUnneeded": "no", "SubState": "listening", "SyslogLevelPrefix": "yes", "SyslogPriority": "30", "SystemCallErrorNumber": "0", "TTYReset": "no", "TTYVHangup": "no", "TTYVTDisallocate": "no", "TasksAccounting": "no", "TasksCurrent": "18446744073709551615", "TasksMax": "18446744073709551615", "TimeoutUSec": "1min 30s", "TimerSlackNSec": "50000", "Transient": "no", "Transparent": "no", "Triggers": "virtlogd.service", "UMask": "0022", "UnitFilePreset": "enabled", "UnitFileState": "disabled", "Wants": "-.slice"}}
2019-06-05 14:05:36,452 p=17240 u=mistral |  TASK [ensure /var/run/libvirt is present upon reboot] **************************
2019-06-05 14:05:36,452 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/host_prep_tasks.yaml:399
2019-06-05 14:05:36,452 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:36 -0500 (0:00:00.384)       0:02:10.221 ******** 
2019-06-05 14:05:36,479 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:36,753 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "checksum": "8156d513cf9fbfe51aff187772dbc4d99ed5cc92", "dest": "/etc/tmpfiles.d/var-run-libvirt.conf", "gid": 0, "group": "root", "md5sum": "358ee138c2bb38163d1bf3cb54c5d250", "mode": "0644", "owner": "root", "secontext": "system_u:object_r:etc_t:s0", "size": 38, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559761536.49-159473908319350/source", "state": "file", "uid": 0}
2019-06-05 14:05:36,776 p=17240 u=mistral |  TASK [Populate service facts (chrony)] *****************************************
2019-06-05 14:05:36,777 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/host_prep_tasks.yaml:405
2019-06-05 14:05:36,777 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:36 -0500 (0:00:00.324)       0:02:10.546 ******** 
2019-06-05 14:05:36,804 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:36,937 p=17240 u=mistral |  ok: [lab-computehci-0] => {"ansible_facts": {"services": {"auditd.service": {"name": "auditd.service", "source": "systemd", "state": "running"}, "auth-rpcgss-module.service": {"name": "auth-rpcgss-module.service", "source": "systemd", "state": "stopped"}, "blk-availability.service": {"name": "blk-availability.service", "source": "systemd", "state": "stopped"}, "chronyd.service": {"name": "chronyd.service", "source": "systemd", "state": "running"}, "cloud-config.service": {"name": "cloud-config.service", "source": "systemd", "state": "stopped"}, "cloud-final.service": {"name": "cloud-final.service", "source": "systemd", "state": "stopped"}, "cloud-init-local.service": {"name": "cloud-init-local.service", "source": "systemd", "state": "stopped"}, "cloud-init.service": {"name": "cloud-init.service", "source": "systemd", "state": "stopped"}, "corosync.service": {"name": "corosync.service", "source": "systemd", "state": "stopped"}, "cpupower.service": {"name": "cpupower.service", "source": "systemd", "state": "stopped"}, "crond.service": {"name": "crond.service", "source": "systemd", "state": "running"}, "dbus.service": {"name": "dbus.service", "source": "systemd", "state": "running"}, "dhcp-interface@br-ex.service": {"name": "dhcp-interface@br-ex.service", "source": "systemd", "state": "stopped"}, "dhcp-interface@eth0.service": {"name": "dhcp-interface@eth0.service", "source": "systemd", "state": "stopped"}, "dhcp-interface@eth1.service": {"name": "dhcp-interface@eth1.service", "source": "systemd", "state": "stopped"}, "dhcp-interface@ovs-system.service": {"name": "dhcp-interface@ovs-system.service", "source": "systemd", "state": "stopped"}, "dhcp-interface@vlan20.service": {"name": "dhcp-interface@vlan20.service", "source": "systemd", "state": "stopped"}, "dhcp-interface@vlan30.service": {"name": "dhcp-interface@vlan30.service", "source": "systemd", "state": "stopped"}, "dhcp-interface@vlan40.service": {"name": "dhcp-interface@vlan40.service", "source": "systemd", "state": "stopped"}, "dhcp-interface@vlan50.service": {"name": "dhcp-interface@vlan50.service", "source": "systemd", "state": "stopped"}, "dm-event.service": {"name": "dm-event.service", "source": "systemd", "state": "stopped"}, "docker-cleanup.service": {"name": "docker-cleanup.service", "source": "systemd", "state": "stopped"}, "docker-storage-setup.service": {"name": "docker-storage-setup.service", "source": "systemd", "state": "stopped"}, "docker.service": {"name": "docker.service", "source": "systemd", "state": "running"}, "dracut-shutdown.service": {"name": "dracut-shutdown.service", "source": "systemd", "state": "stopped"}, "dynamic-login.service": {"name": "dynamic-login.service", "source": "systemd", "state": "stopped"}, "emergency.service": {"name": "emergency.service", "source": "systemd", "state": "stopped"}, "getty@tty1.service": {"name": "getty@tty1.service", "source": "systemd", "state": "running"}, "gssproxy.service": {"name": "gssproxy.service", "source": "systemd", "state": "running"}, "ip6tables.service": {"name": "ip6tables.service", "source": "systemd", "state": "stopped"}, "iptables.service": {"name": "iptables.service", "source": "systemd", "state": "stopped"}, "irqbalance.service": {"name": "irqbalance.service", "source": "systemd", "state": "running"}, "iscsi-shutdown.service": {"name": "iscsi-shutdown.service", "source": "systemd", "state": "stopped"}, "iscsi.service": {"name": "iscsi.service", "source": "systemd", "state": "stopped"}, "iscsid.service": {"name": "iscsid.service", "source": "systemd", "state": "stopped"}, "iscsiuio.service": {"name": "iscsiuio.service", "source": "systemd", "state": "stopped"}, "kdump.service": {"name": "kdump.service", "source": "systemd", "state": "stopped"}, "kmod-static-nodes.service": {"name": "kmod-static-nodes.service", "source": "systemd", "state": "stopped"}, "libvirt-guests.service": {"name": "libvirt-guests.service", "source": "systemd", "state": "stopped"}, "libvirtd.service": {"name": "libvirtd.service", "source": "systemd", "state": "stopped"}, "lvm2-lvmetad.service": {"name": "lvm2-lvmetad.service", "source": "systemd", "state": "running"}, "lvm2-lvmpolld.service": {"name": "lvm2-lvmpolld.service", "source": "systemd", "state": "stopped"}, "lvm2-monitor.service": {"name": "lvm2-monitor.service", "source": "systemd", "state": "stopped"}, "microcode.service": {"name": "microcode.service", "source": "systemd", "state": "stopped"}, "multipathd.service": {"name": "multipathd.service", "source": "systemd", "state": "stopped"}, "netcf-transaction.service": {"name": "netcf-transaction.service", "source": "systemd", "state": "stopped"}, "netconsole": {"name": "netconsole", "source": "sysv", "state": "stopped"}, "netns-placeholder.service": {"name": "netns-placeholder.service", "source": "systemd", "state": "stopped"}, "network": {"name": "network", "source": "sysv", "state": "running"}, "network.service": {"name": "network.service", "source": "systemd", "state": "stopped"}, "nfs-config.service": {"name": "nfs-config.service", "source": "systemd", "state": "stopped"}, "nfs-idmapd.service": {"name": "nfs-idmapd.service", "source": "systemd", "state": "stopped"}, "nfs-mountd.service": {"name": "nfs-mountd.service", "source": "systemd", "state": "stopped"}, "nfs-server.service": {"name": "nfs-server.service", "source": "systemd", "state": "stopped"}, "nfs-utils.service": {"name": "nfs-utils.service", "source": "systemd", "state": "stopped"}, "ntpd.service": {"name": "ntpd.service", "source": "systemd", "state": "stopped"}, "ntpdate.service": {"name": "ntpdate.service", "source": "systemd", "state": "stopped"}, "openvswitch.service": {"name": "openvswitch.service", "source": "systemd", "state": "stopped"}, "ovs-delete-transient-ports.service": {"name": "ovs-delete-transient-ports.service", "source": "systemd", "state": "stopped"}, "ovs-vswitchd.service": {"name": "ovs-vswitchd.service", "source": "systemd", "state": "running"}, "ovsdb-server.service": {"name": "ovsdb-server.service", "source": "systemd", "state": "running"}, "pacemaker.service": {"name": "pacemaker.service", "source": "systemd", "state": "stopped"}, "paunch-container-shutdown.service": {"name": "paunch-container-shutdown.service", "source": "systemd", "state": "stopped"}, "polkit.service": {"name": "polkit.service", "source": "systemd", "state": "running"}, "postfix.service": {"name": "postfix.service", "source": "systemd", "state": "running"}, "qemu-guest-agent.service": {"name": "qemu-guest-agent.service", "source": "systemd", "state": "running"}, "rc-local.service": {"name": "rc-local.service", "source": "systemd", "state": "stopped"}, "rescue.service": {"name": "rescue.service", "source": "systemd", "state": "stopped"}, "rhel-autorelabel.service": {"name": "rhel-autorelabel.service", "source": "systemd", "state": "stopped"}, "rhel-configure.service": {"name": "rhel-configure.service", "source": "systemd", "state": "stopped"}, "rhel-dmesg.service": {"name": "rhel-dmesg.service", "source": "systemd", "state": "stopped"}, "rhel-domainname.service": {"name": "rhel-domainname.service", "source": "systemd", "state": "stopped"}, "rhel-import-state.service": {"name": "rhel-import-state.service", "source": "systemd", "state": "stopped"}, "rhel-loadmodules.service": {"name": "rhel-loadmodules.service", "source": "systemd", "state": "stopped"}, "rhel-readonly.service": {"name": "rhel-readonly.service", "source": "systemd", "state": "stopped"}, "rpc-gssd.service": {"name": "rpc-gssd.service", "source": "systemd", "state": "stopped"}, "rpc-statd-notify.service": {"name": "rpc-statd-notify.service", "source": "systemd", "state": "stopped"}, "rpc-statd.service": {"name": "rpc-statd.service", "source": "systemd", "state": "stopped"}, "rpcbind.service": {"name": "rpcbind.service", "source": "systemd", "state": "running"}, "rsyslog.service": {"name": "rsyslog.service", "source": "systemd", "state": "running"}, "selinux-policy-migrate-local-changes@targeted.service": {"name": "selinux-policy-migrate-local-changes@targeted.service", "source": "systemd", "state": "stopped"}, "serial-getty@ttyS0.service": {"name": "serial-getty@ttyS0.service", "source": "systemd", "state": "running"}, "sshd-keygen.service": {"name": "sshd-keygen.service", "source": "systemd", "state": "stopped"}, "sshd.service": {"name": "sshd.service", "source": "systemd", "state": "running"}, "systemd-ask-password-console.service": {"name": "systemd-ask-password-console.service", "source": "systemd", "state": "stopped"}, "systemd-ask-password-wall.service": {"name": "systemd-ask-password-wall.service", "source": "systemd", "state": "stopped"}, "systemd-binfmt.service": {"name": "systemd-binfmt.service", "source": "systemd", "state": "stopped"}, "systemd-firstboot.service": {"name": "systemd-firstboot.service", "source": "systemd", "state": "stopped"}, "systemd-fsck-root.service": {"name": "systemd-fsck-root.service", "source": "systemd", "state": "stopped"}, "systemd-hwdb-update.service": {"name": "systemd-hwdb-update.service", "source": "systemd", "state": "stopped"}, "systemd-initctl.service": {"name": "systemd-initctl.service", "source": "systemd", "state": "stopped"}, "systemd-journal-catalog-update.service": {"name": "systemd-journal-catalog-update.service", "source": "systemd", "state": "stopped"}, "systemd-journal-flush.service": {"name": "systemd-journal-flush.service", "source": "systemd", "state": "stopped"}, "systemd-journald.service": {"name": "systemd-journald.service", "source": "systemd", "state": "running"}, "systemd-logind.service": {"name": "systemd-logind.service", "source": "systemd", "state": "running"}, "systemd-machine-id-commit.service": {"name": "systemd-machine-id-commit.service", "source": "systemd", "state": "stopped"}, "systemd-machined.service": {"name": "systemd-machined.service", "source": "systemd", "state": "stopped"}, "systemd-modules-load.service": {"name": "systemd-modules-load.service", "source": "systemd", "state": "stopped"}, "systemd-random-seed.service": {"name": "systemd-random-seed.service", "source": "systemd", "state": "stopped"}, "systemd-readahead-collect.service": {"name": "systemd-readahead-collect.service", "source": "systemd", "state": "stopped"}, "systemd-readahead-done.service": {"name": "systemd-readahead-done.service", "source": "systemd", "state": "stopped"}, "systemd-readahead-replay.service": {"name": "systemd-readahead-replay.service", "source": "systemd", "state": "stopped"}, "systemd-reboot.service": {"name": "systemd-reboot.service", "source": "systemd", "state": "stopped"}, "systemd-remount-fs.service": {"name": "systemd-remount-fs.service", "source": "systemd", "state": "stopped"}, "systemd-shutdownd.service": {"name": "systemd-shutdownd.service", "source": "systemd", "state": "stopped"}, "systemd-sysctl.service": {"name": "systemd-sysctl.service", "source": "systemd", "state": "stopped"}, "systemd-tmpfiles-clean.service": {"name": "systemd-tmpfiles-clean.service", "source": "systemd", "state": "stopped"}, "systemd-tmpfiles-setup-dev.service": {"name": "systemd-tmpfiles-setup-dev.service", "source": "systemd", "state": "stopped"}, "systemd-tmpfiles-setup.service": {"name": "systemd-tmpfiles-setup.service", "source": "systemd", "state": "stopped"}, "systemd-udev-settle.service": {"name": "systemd-udev-settle.service", "source": "systemd", "state": "stopped"}, "systemd-udev-trigger.service": {"name": "systemd-udev-trigger.service", "source": "systemd", "state": "stopped"}, "systemd-udevd.service": {"name": "systemd-udevd.service", "source": "systemd", "state": "running"}, "systemd-update-done.service": {"name": "systemd-update-done.service", "source": "systemd", "state": "stopped"}, "systemd-update-utmp-runlevel.service": {"name": "systemd-update-utmp-runlevel.service", "source": "systemd", "state": "stopped"}, "systemd-update-utmp.service": {"name": "systemd-update-utmp.service", "source": "systemd", "state": "stopped"}, "systemd-user-sessions.service": {"name": "systemd-user-sessions.service", "source": "systemd", "state": "stopped"}, "systemd-vconsole-setup.service": {"name": "systemd-vconsole-setup.service", "source": "systemd", "state": "stopped"}, "tripleo-ip6tables.service": {"name": "tripleo-ip6tables.service", "source": "systemd", "state": "stopped"}, "tripleo-iptables.service": {"name": "tripleo-iptables.service", "source": "systemd", "state": "stopped"}, "tuned.service": {"name": "tuned.service", "source": "systemd", "state": "running"}, "unbound-anchor.service": {"name": "unbound-anchor.service", "source": "systemd", "state": "stopped"}, "virtlockd.service": {"name": "virtlockd.service", "source": "systemd", "state": "stopped"}, "virtlogd.service": {"name": "virtlogd.service", "source": "systemd", "state": "stopped"}}}, "changed": false}
2019-06-05 14:05:36,963 p=17240 u=mistral |  TASK [Disable NTP before configuring Chrony] ***********************************
2019-06-05 14:05:36,963 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/host_prep_tasks.yaml:407
2019-06-05 14:05:36,963 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:36 -0500 (0:00:00.186)       0:02:10.732 ******** 
2019-06-05 14:05:36,990 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:37,133 p=17240 u=mistral |  ok: [lab-computehci-0] => {"changed": false, "enabled": false, "name": "ntpd", "state": "stopped", "status": {"ActiveEnterTimestampMonotonic": "0", "ActiveExitTimestampMonotonic": "0", "ActiveState": "inactive", "After": "syslog.target ntpdate.service systemd-journald.socket -.mount basic.target sntp.service tmp.mount system.slice", "AllowIsolate": "no", "AmbientCapabilities": "0", "AssertResult": "no", "AssertTimestampMonotonic": "0", "Before": "shutdown.target chronyd.service", "BlockIOAccounting": "no", "BlockIOWeight": "18446744073709551615", "CPUAccounting": "no", "CPUQuotaPerSecUSec": "infinity", "CPUSchedulingPolicy": "0", "CPUSchedulingPriority": "0", "CPUSchedulingResetOnFork": "no", "CPUShares": "18446744073709551615", "CanIsolate": "no", "CanReload": "no", "CanStart": "yes", "CanStop": "yes", "CapabilityBoundingSet": "18446744073709551615", "ConditionResult": "no", "ConditionTimestampMonotonic": "0", "ConflictedBy": "chronyd.service", "Conflicts": "shutdown.target", "ControlPID": "0", "DefaultDependencies": "yes", "Delegate": "no", "Description": "Network Time Service", "DevicePolicy": "auto", "EnvironmentFile": "/etc/sysconfig/ntpd (ignore_errors=yes)", "ExecMainCode": "0", "ExecMainExitTimestampMonotonic": "0", "ExecMainPID": "0", "ExecMainStartTimestampMonotonic": "0", "ExecMainStatus": "0", "ExecStart": "{ path=/usr/sbin/ntpd ; argv[]=/usr/sbin/ntpd -u ntp:ntp $OPTIONS ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }", "FailureAction": "none", "FileDescriptorStoreMax": "0", "FragmentPath": "/usr/lib/systemd/system/ntpd.service", "GuessMainPID": "yes", "IOScheduling": "0", "Id": "ntpd.service", "IgnoreOnIsolate": "no", "IgnoreOnSnapshot": "no", "IgnoreSIGPIPE": "yes", "InactiveEnterTimestampMonotonic": "0", "InactiveExitTimestampMonotonic": "0", "JobTimeoutAction": "none", "JobTimeoutUSec": "0", "KillMode": "control-group", "KillSignal": "15", "LimitAS": "18446744073709551615", "LimitCORE": "18446744073709551615", "LimitCPU": "18446744073709551615", "LimitDATA": "18446744073709551615", "LimitFSIZE": "18446744073709551615", "LimitLOCKS": "18446744073709551615", "LimitMEMLOCK": "65536", "LimitMSGQUEUE": "819200", "LimitNICE": "0", "LimitNOFILE": "4096", "LimitNPROC": "61816", "LimitRSS": "18446744073709551615", "LimitRTPRIO": "0", "LimitRTTIME": "18446744073709551615", "LimitSIGPENDING": "61816", "LimitSTACK": "18446744073709551615", "LoadState": "loaded", "MainPID": "0", "MemoryAccounting": "no", "MemoryCurrent": "18446744073709551615", "MemoryLimit": "18446744073709551615", "MountFlags": "0", "Names": "ntpd.service", "NeedDaemonReload": "no", "Nice": "0", "NoNewPrivileges": "no", "NonBlocking": "no", "NotifyAccess": "none", "OOMScoreAdjust": "0", "OnFailureJobMode": "replace", "PermissionsStartOnly": "no", "PrivateDevices": "no", "PrivateNetwork": "no", "PrivateTmp": "yes", "ProtectHome": "no", "ProtectSystem": "no", "RefuseManualStart": "no", "RefuseManualStop": "no", "RemainAfterExit": "no", "Requires": "basic.target -.mount", "RequiresMountsFor": "/var/tmp", "Restart": "no", "RestartUSec": "100ms", "Result": "success", "RootDirectoryStartOnly": "no", "RuntimeDirectoryMode": "0755", "SameProcessGroup": "no", "SecureBits": "0", "SendSIGHUP": "no", "SendSIGKILL": "yes", "Slice": "system.slice", "StandardError": "inherit", "StandardInput": "null", "StandardOutput": "journal", "StartLimitAction": "none", "StartLimitBurst": "5", "StartLimitInterval": "10000000", "StartupBlockIOWeight": "18446744073709551615", "StartupCPUShares": "18446744073709551615", "StatusErrno": "0", "StopWhenUnneeded": "no", "SubState": "dead", "SyslogLevelPrefix": "yes", "SyslogPriority": "30", "SystemCallErrorNumber": "0", "TTYReset": "no", "TTYVHangup": "no", "TTYVTDisallocate": "no", "TasksAccounting": "no", "TasksCurrent": "18446744073709551615", "TasksMax": "18446744073709551615", "TimeoutStartUSec": "1min 30s", "TimeoutStopUSec": "1min 30s", "TimerSlackNSec": "50000", "Transient": "no", "Type": "forking", "UMask": "0022", "UnitFilePreset": "disabled", "UnitFileState": "disabled", "Wants": "system.slice", "WatchdogTimestampMonotonic": "0", "WatchdogUSec": "0"}}
2019-06-05 14:05:37,157 p=17240 u=mistral |  TASK [Install, Configure and Run Chrony] ***************************************
2019-06-05 14:05:37,157 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/host_prep_tasks.yaml:413
2019-06-05 14:05:37,157 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:37 -0500 (0:00:00.194)       0:02:10.927 ******** 
2019-06-05 14:05:37,184 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:37,229 p=17240 u=mistral |  META: noop
2019-06-05 14:05:37,249 p=17240 u=mistral |  TASK [chrony : Load distro-specific variables] *********************************
2019-06-05 14:05:37,249 p=17240 u=mistral |  task path: /usr/share/ansible/roles/chrony/tasks/main.yml:2
2019-06-05 14:05:37,249 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:37 -0500 (0:00:00.091)       0:02:11.018 ******** 
2019-06-05 14:05:37,268 p=17240 u=mistral |  ok: [lab-computehci-0] => (item=/usr/share/ansible/roles/chrony/vars/RedHat.yml) => {"ansible_facts": {"chrony_config_file_location": "/etc/chrony.conf", "chrony_driftfile_path": "/var/lib/chrony/drift", "chrony_logdir_path": "/var/log/chrony", "chrony_makestep": "1.0 3", "chrony_package_name": "chrony", "chrony_rtc_settings": ["rtcsync"], "chrony_service_name": "chronyd"}, "ansible_included_var_files": ["/usr/share/ansible/roles/chrony/vars/RedHat.yml"], "changed": false, "item": "/usr/share/ansible/roles/chrony/vars/RedHat.yml"}
2019-06-05 14:05:37,270 p=17240 u=mistral |  META: noop
2019-06-05 14:05:37,290 p=17240 u=mistral |  TASK [chrony : Install chronyd] ************************************************
2019-06-05 14:05:37,290 p=17240 u=mistral |  task path: /usr/share/ansible/roles/chrony/tasks/main.yml:9
2019-06-05 14:05:37,291 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:37 -0500 (0:00:00.041)       0:02:11.060 ******** 
2019-06-05 14:05:37,325 p=17240 u=mistral |  included: /usr/share/ansible/roles/chrony/tasks/install.yml for lab-computehci-0
2019-06-05 14:05:37,328 p=17240 u=mistral |  META: noop
2019-06-05 14:05:37,347 p=17240 u=mistral |  TASK [chrony : Install chronyd package] ****************************************
2019-06-05 14:05:37,347 p=17240 u=mistral |  task path: /usr/share/ansible/roles/chrony/tasks/install.yml:2
2019-06-05 14:05:37,347 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:37 -0500 (0:00:00.056)       0:02:11.116 ******** 
2019-06-05 14:05:37,359 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:37,360 p=17240 u=mistral |  META: noop
2019-06-05 14:05:37,381 p=17240 u=mistral |  TASK [chrony : Upgrade chronyd] ************************************************
2019-06-05 14:05:37,381 p=17240 u=mistral |  task path: /usr/share/ansible/roles/chrony/tasks/main.yml:13
2019-06-05 14:05:37,381 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:37 -0500 (0:00:00.034)       0:02:11.151 ******** 
2019-06-05 14:05:37,394 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:37,394 p=17240 u=mistral |  META: noop
2019-06-05 14:05:37,415 p=17240 u=mistral |  TASK [chrony : Configure chronyd] **********************************************
2019-06-05 14:05:37,415 p=17240 u=mistral |  task path: /usr/share/ansible/roles/chrony/tasks/main.yml:17
2019-06-05 14:05:37,415 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:37 -0500 (0:00:00.034)       0:02:11.185 ******** 
2019-06-05 14:05:37,456 p=17240 u=mistral |  included: /usr/share/ansible/roles/chrony/tasks/config.yml for lab-computehci-0
2019-06-05 14:05:37,461 p=17240 u=mistral |  META: noop
2019-06-05 14:05:37,480 p=17240 u=mistral |  TASK [chrony : Install chrony configuration file] ******************************
2019-06-05 14:05:37,480 p=17240 u=mistral |  task path: /usr/share/ansible/roles/chrony/tasks/config.yml:2
2019-06-05 14:05:37,480 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:37 -0500 (0:00:00.064)       0:02:11.250 ******** 
2019-06-05 14:05:37,808 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "checksum": "e59a5fd99e85f19be5ec8a0e0867fff357dc3433", "dest": "/etc/chrony.conf", "gid": 0, "group": "root", "md5sum": "64319715d9b3798711b4d004c1c280d3", "mode": "0644", "owner": "root", "secontext": "system_u:object_r:etc_t:s0", "size": 398, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559761537.49-146127486645980/source", "state": "file", "uid": 0}
2019-06-05 14:05:37,809 p=17240 u=mistral |  META: noop
2019-06-05 14:05:37,829 p=17240 u=mistral |  TASK [chrony : Ensure chronyd is running] **************************************
2019-06-05 14:05:37,829 p=17240 u=mistral |  task path: /usr/share/ansible/roles/chrony/tasks/config.yml:12
2019-06-05 14:05:37,829 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:37 -0500 (0:00:00.349)       0:02:11.599 ******** 
2019-06-05 14:05:37,969 p=17240 u=mistral |  ok: [lab-computehci-0] => {"changed": false, "name": "chronyd", "state": "started", "status": {"ActiveEnterTimestamp": "Wed 2019-06-05 19:01:34 UTC", "ActiveEnterTimestampMonotonic": "7382127", "ActiveExitTimestampMonotonic": "0", "ActiveState": "active", "After": "ntpd.service -.mount basic.target sntp.service systemd-journald.socket system.slice tmp.mount ntpdate.service", "AllowIsolate": "no", "AmbientCapabilities": "0", "AssertResult": "yes", "AssertTimestamp": "Wed 2019-06-05 19:01:34 UTC", "AssertTimestampMonotonic": "7274390", "Before": "multi-user.target shutdown.target", "BlockIOAccounting": "no", "BlockIOWeight": "18446744073709551615", "CPUAccounting": "no", "CPUQuotaPerSecUSec": "infinity", "CPUSchedulingPolicy": "0", "CPUSchedulingPriority": "0", "CPUSchedulingResetOnFork": "no", "CPUShares": "18446744073709551615", "CanIsolate": "no", "CanReload": "no", "CanStart": "yes", "CanStop": "yes", "CapabilityBoundingSet": "18446744073709551615", "ConditionResult": "yes", "ConditionTimestamp": "Wed 2019-06-05 19:01:34 UTC", "ConditionTimestampMonotonic": "7274343", "Conflicts": "ntpd.service systemd-timesyncd.service shutdown.target", "ControlGroup": "/system.slice/chronyd.service", "ControlPID": "0", "DefaultDependencies": "yes", "Delegate": "no", "Description": "NTP client/server", "DevicePolicy": "auto", "Documentation": "man:chronyd(8) man:chrony.conf(5)", "EnvironmentFile": "/etc/sysconfig/chronyd (ignore_errors=yes)", "ExecMainCode": "0", "ExecMainExitTimestampMonotonic": "0", "ExecMainPID": "3269", "ExecMainStartTimestamp": "Wed 2019-06-05 19:01:34 UTC", "ExecMainStartTimestampMonotonic": "7362636", "ExecMainStatus": "0", "ExecStart": "{ path=/usr/sbin/chronyd ; argv[]=/usr/sbin/chronyd $OPTIONS ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }", "ExecStartPost": "{ path=/usr/libexec/chrony-helper ; argv[]=/usr/libexec/chrony-helper update-daemon ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }", "FailureAction": "none", "FileDescriptorStoreMax": "0", "FragmentPath": "/usr/lib/systemd/system/chronyd.service", "GuessMainPID": "yes", "IOScheduling": "0", "Id": "chronyd.service", "IgnoreOnIsolate": "no", "IgnoreOnSnapshot": "no", "IgnoreSIGPIPE": "yes", "InactiveEnterTimestampMonotonic": "0", "InactiveExitTimestamp": "Wed 2019-06-05 19:01:34 UTC", "InactiveExitTimestampMonotonic": "7275554", "JobTimeoutAction": "none", "JobTimeoutUSec": "0", "KillMode": "control-group", "KillSignal": "15", "LimitAS": "18446744073709551615", "LimitCORE": "18446744073709551615", "LimitCPU": "18446744073709551615", "LimitDATA": "18446744073709551615", "LimitFSIZE": "18446744073709551615", "LimitLOCKS": "18446744073709551615", "LimitMEMLOCK": "65536", "LimitMSGQUEUE": "819200", "LimitNICE": "0", "LimitNOFILE": "4096", "LimitNPROC": "61816", "LimitRSS": "18446744073709551615", "LimitRTPRIO": "0", "LimitRTTIME": "18446744073709551615", "LimitSIGPENDING": "61816", "LimitSTACK": "18446744073709551615", "LoadState": "loaded", "MainPID": "3269", "MemoryAccounting": "no", "MemoryCurrent": "18446744073709551615", "MemoryLimit": "18446744073709551615", "MountFlags": "0", "Names": "chronyd.service", "NeedDaemonReload": "no", "Nice": "0", "NoNewPrivileges": "no", "NonBlocking": "no", "NotifyAccess": "none", "OOMScoreAdjust": "0", "OnFailureJobMode": "replace", "PIDFile": "/var/run/chronyd.pid", "PermissionsStartOnly": "no", "PrivateDevices": "no", "PrivateNetwork": "no", "PrivateTmp": "yes", "ProtectHome": "yes", "ProtectSystem": "full", "RefuseManualStart": "no", "RefuseManualStop": "no", "RemainAfterExit": "no", "Requires": "basic.target -.mount", "RequiresMountsFor": "/var/tmp", "Restart": "no", "RestartUSec": "100ms", "Result": "success", "RootDirectoryStartOnly": "no", "RuntimeDirectoryMode": "0755", "SameProcessGroup": "no", "SecureBits": "0", "SendSIGHUP": "no", "SendSIGKILL": "yes", "Slice": "system.slice", "StandardError": "inherit", "StandardInput": "null", "StandardOutput": "journal", "StartLimitAction": "none", "StartLimitBurst": "5", "StartLimitInterval": "10000000", "StartupBlockIOWeight": "18446744073709551615", "StartupCPUShares": "18446744073709551615", "StatusErrno": "0", "StopWhenUnneeded": "no", "SubState": "running", "SyslogLevelPrefix": "yes", "SyslogPriority": "30", "SystemCallErrorNumber": "0", "TTYReset": "no", "TTYVHangup": "no", "TTYVTDisallocate": "no", "TasksAccounting": "no", "TasksCurrent": "18446744073709551615", "TasksMax": "18446744073709551615", "TimeoutStartUSec": "1min 30s", "TimeoutStopUSec": "1min 30s", "TimerSlackNSec": "50000", "Transient": "no", "Type": "forking", "UMask": "0022", "UnitFilePreset": "enabled", "UnitFileState": "enabled", "WantedBy": "multi-user.target", "Wants": "system.slice", "WatchdogTimestamp": "Wed 2019-06-05 19:01:34 UTC", "WatchdogTimestampMonotonic": "7362651", "WatchdogUSec": "0"}}
2019-06-05 14:05:37,970 p=17240 u=mistral |  META: noop
2019-06-05 14:05:37,992 p=17240 u=mistral |  TASK [chrony : Force chronyd restart] ******************************************
2019-06-05 14:05:37,992 p=17240 u=mistral |  task path: /usr/share/ansible/roles/chrony/tasks/config.yml:23
2019-06-05 14:05:37,992 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:37 -0500 (0:00:00.162)       0:02:11.761 ******** 
2019-06-05 14:05:38,194 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "name": "chronyd", "state": "started", "status": {"ActiveEnterTimestamp": "Wed 2019-06-05 19:01:34 UTC", "ActiveEnterTimestampMonotonic": "7382127", "ActiveExitTimestampMonotonic": "0", "ActiveState": "active", "After": "ntpd.service -.mount basic.target sntp.service systemd-journald.socket system.slice tmp.mount ntpdate.service", "AllowIsolate": "no", "AmbientCapabilities": "0", "AssertResult": "yes", "AssertTimestamp": "Wed 2019-06-05 19:01:34 UTC", "AssertTimestampMonotonic": "7274390", "Before": "multi-user.target shutdown.target", "BlockIOAccounting": "no", "BlockIOWeight": "18446744073709551615", "CPUAccounting": "no", "CPUQuotaPerSecUSec": "infinity", "CPUSchedulingPolicy": "0", "CPUSchedulingPriority": "0", "CPUSchedulingResetOnFork": "no", "CPUShares": "18446744073709551615", "CanIsolate": "no", "CanReload": "no", "CanStart": "yes", "CanStop": "yes", "CapabilityBoundingSet": "18446744073709551615", "ConditionResult": "yes", "ConditionTimestamp": "Wed 2019-06-05 19:01:34 UTC", "ConditionTimestampMonotonic": "7274343", "Conflicts": "ntpd.service systemd-timesyncd.service shutdown.target", "ControlGroup": "/system.slice/chronyd.service", "ControlPID": "0", "DefaultDependencies": "yes", "Delegate": "no", "Description": "NTP client/server", "DevicePolicy": "auto", "Documentation": "man:chronyd(8) man:chrony.conf(5)", "EnvironmentFile": "/etc/sysconfig/chronyd (ignore_errors=yes)", "ExecMainCode": "0", "ExecMainExitTimestampMonotonic": "0", "ExecMainPID": "3269", "ExecMainStartTimestamp": "Wed 2019-06-05 19:01:34 UTC", "ExecMainStartTimestampMonotonic": "7362636", "ExecMainStatus": "0", "ExecStart": "{ path=/usr/sbin/chronyd ; argv[]=/usr/sbin/chronyd $OPTIONS ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }", "ExecStartPost": "{ path=/usr/libexec/chrony-helper ; argv[]=/usr/libexec/chrony-helper update-daemon ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }", "FailureAction": "none", "FileDescriptorStoreMax": "0", "FragmentPath": "/usr/lib/systemd/system/chronyd.service", "GuessMainPID": "yes", "IOScheduling": "0", "Id": "chronyd.service", "IgnoreOnIsolate": "no", "IgnoreOnSnapshot": "no", "IgnoreSIGPIPE": "yes", "InactiveEnterTimestampMonotonic": "0", "InactiveExitTimestamp": "Wed 2019-06-05 19:01:34 UTC", "InactiveExitTimestampMonotonic": "7275554", "JobTimeoutAction": "none", "JobTimeoutUSec": "0", "KillMode": "control-group", "KillSignal": "15", "LimitAS": "18446744073709551615", "LimitCORE": "18446744073709551615", "LimitCPU": "18446744073709551615", "LimitDATA": "18446744073709551615", "LimitFSIZE": "18446744073709551615", "LimitLOCKS": "18446744073709551615", "LimitMEMLOCK": "65536", "LimitMSGQUEUE": "819200", "LimitNICE": "0", "LimitNOFILE": "4096", "LimitNPROC": "61816", "LimitRSS": "18446744073709551615", "LimitRTPRIO": "0", "LimitRTTIME": "18446744073709551615", "LimitSIGPENDING": "61816", "LimitSTACK": "18446744073709551615", "LoadState": "loaded", "MainPID": "3269", "MemoryAccounting": "no", "MemoryCurrent": "18446744073709551615", "MemoryLimit": "18446744073709551615", "MountFlags": "0", "Names": "chronyd.service", "NeedDaemonReload": "no", "Nice": "0", "NoNewPrivileges": "no", "NonBlocking": "no", "NotifyAccess": "none", "OOMScoreAdjust": "0", "OnFailureJobMode": "replace", "PIDFile": "/var/run/chronyd.pid", "PermissionsStartOnly": "no", "PrivateDevices": "no", "PrivateNetwork": "no", "PrivateTmp": "yes", "ProtectHome": "yes", "ProtectSystem": "full", "RefuseManualStart": "no", "RefuseManualStop": "no", "RemainAfterExit": "no", "Requires": "basic.target -.mount", "RequiresMountsFor": "/var/tmp", "Restart": "no", "RestartUSec": "100ms", "Result": "success", "RootDirectoryStartOnly": "no", "RuntimeDirectoryMode": "0755", "SameProcessGroup": "no", "SecureBits": "0", "SendSIGHUP": "no", "SendSIGKILL": "yes", "Slice": "system.slice", "StandardError": "inherit", "StandardInput": "null", "StandardOutput": "journal", "StartLimitAction": "none", "StartLimitBurst": "5", "StartLimitInterval": "10000000", "StartupBlockIOWeight": "18446744073709551615", "StartupCPUShares": "18446744073709551615", "StatusErrno": "0", "StopWhenUnneeded": "no", "SubState": "running", "SyslogLevelPrefix": "yes", "SyslogPriority": "30", "SystemCallErrorNumber": "0", "TTYReset": "no", "TTYVHangup": "no", "TTYVTDisallocate": "no", "TasksAccounting": "no", "TasksCurrent": "18446744073709551615", "TasksMax": "18446744073709551615", "TimeoutStartUSec": "1min 30s", "TimeoutStopUSec": "1min 30s", "TimerSlackNSec": "50000", "Transient": "no", "Type": "forking", "UMask": "0022", "UnitFilePreset": "enabled", "UnitFileState": "enabled", "WantedBy": "multi-user.target", "Wants": "system.slice", "WatchdogTimestamp": "Wed 2019-06-05 19:01:34 UTC", "WatchdogTimestampMonotonic": "7362651", "WatchdogUSec": "0"}}
2019-06-05 14:05:38,197 p=17240 u=mistral |  RUNNING HANDLER [chrony : Restart chronyd] *************************************
2019-06-05 14:05:38,197 p=17240 u=mistral |  task path: /usr/share/ansible/roles/chrony/handlers/main.yml:2
2019-06-05 14:05:38,197 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:38 -0500 (0:00:00.205)       0:02:11.967 ******** 
2019-06-05 14:05:38,418 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "name": "chronyd", "state": "started", "status": {"ActiveEnterTimestamp": "Wed 2019-06-05 19:05:38 UTC", "ActiveEnterTimestampMonotonic": "250641308", "ActiveExitTimestamp": "Wed 2019-06-05 19:05:38 UTC", "ActiveExitTimestampMonotonic": "250582627", "ActiveState": "active", "After": "ntpd.service -.mount basic.target sntp.service systemd-journald.socket system.slice tmp.mount ntpdate.service", "AllowIsolate": "no", "AmbientCapabilities": "0", "AssertResult": "yes", "AssertTimestamp": "Wed 2019-06-05 19:05:38 UTC", "AssertTimestampMonotonic": "250590464", "Before": "multi-user.target shutdown.target", "BlockIOAccounting": "no", "BlockIOWeight": "18446744073709551615", "CPUAccounting": "no", "CPUQuotaPerSecUSec": "infinity", "CPUSchedulingPolicy": "0", "CPUSchedulingPriority": "0", "CPUSchedulingResetOnFork": "no", "CPUShares": "18446744073709551615", "CanIsolate": "no", "CanReload": "no", "CanStart": "yes", "CanStop": "yes", "CapabilityBoundingSet": "18446744073709551615", "ConditionResult": "yes", "ConditionTimestamp": "Wed 2019-06-05 19:05:38 UTC", "ConditionTimestampMonotonic": "250590413", "Conflicts": "ntpd.service systemd-timesyncd.service shutdown.target", "ControlGroup": "/system.slice/chronyd.service", "ControlPID": "0", "DefaultDependencies": "yes", "Delegate": "no", "Description": "NTP client/server", "DevicePolicy": "auto", "Documentation": "man:chronyd(8) man:chrony.conf(5)", "EnvironmentFile": "/etc/sysconfig/chronyd (ignore_errors=yes)", "ExecMainCode": "0", "ExecMainExitTimestampMonotonic": "0", "ExecMainPID": "18018", "ExecMainStartTimestamp": "Wed 2019-06-05 19:05:38 UTC", "ExecMainStartTimestampMonotonic": "250618588", "ExecMainStatus": "0", "ExecStart": "{ path=/usr/sbin/chronyd ; argv[]=/usr/sbin/chronyd $OPTIONS ; ignore_errors=no ; start_time=[Wed 2019-06-05 19:05:38 UTC] ; stop_time=[Wed 2019-06-05 19:05:38 UTC] ; pid=18016 ; code=exited ; status=0 }", "ExecStartPost": "{ path=/usr/libexec/chrony-helper ; argv[]=/usr/libexec/chrony-helper update-daemon ; ignore_errors=no ; start_time=[Wed 2019-06-05 19:05:38 UTC] ; stop_time=[Wed 2019-06-05 19:05:38 UTC] ; pid=18020 ; code=exited ; status=0 }", "FailureAction": "none", "FileDescriptorStoreMax": "0", "FragmentPath": "/usr/lib/systemd/system/chronyd.service", "GuessMainPID": "yes", "IOScheduling": "0", "Id": "chronyd.service", "IgnoreOnIsolate": "no", "IgnoreOnSnapshot": "no", "IgnoreSIGPIPE": "yes", "InactiveEnterTimestamp": "Wed 2019-06-05 19:05:38 UTC", "InactiveEnterTimestampMonotonic": "250589924", "InactiveExitTimestamp": "Wed 2019-06-05 19:05:38 UTC", "InactiveExitTimestampMonotonic": "250591424", "JobTimeoutAction": "none", "JobTimeoutUSec": "0", "KillMode": "control-group", "KillSignal": "15", "LimitAS": "18446744073709551615", "LimitCORE": "18446744073709551615", "LimitCPU": "18446744073709551615", "LimitDATA": "18446744073709551615", "LimitFSIZE": "18446744073709551615", "LimitLOCKS": "18446744073709551615", "LimitMEMLOCK": "65536", "LimitMSGQUEUE": "819200", "LimitNICE": "0", "LimitNOFILE": "4096", "LimitNPROC": "61816", "LimitRSS": "18446744073709551615", "LimitRTPRIO": "0", "LimitRTTIME": "18446744073709551615", "LimitSIGPENDING": "61816", "LimitSTACK": "18446744073709551615", "LoadState": "loaded", "MainPID": "18018", "MemoryAccounting": "no", "MemoryCurrent": "18446744073709551615", "MemoryLimit": "18446744073709551615", "MountFlags": "0", "Names": "chronyd.service", "NeedDaemonReload": "no", "Nice": "0", "NoNewPrivileges": "no", "NonBlocking": "no", "NotifyAccess": "none", "OOMScoreAdjust": "0", "OnFailureJobMode": "replace", "PIDFile": "/var/run/chronyd.pid", "PermissionsStartOnly": "no", "PrivateDevices": "no", "PrivateNetwork": "no", "PrivateTmp": "yes", "ProtectHome": "yes", "ProtectSystem": "full", "RefuseManualStart": "no", "RefuseManualStop": "no", "RemainAfterExit": "no", "Requires": "basic.target -.mount", "RequiresMountsFor": "/var/tmp", "Restart": "no", "RestartUSec": "100ms", "Result": "success", "RootDirectoryStartOnly": "no", "RuntimeDirectoryMode": "0755", "SameProcessGroup": "no", "SecureBits": "0", "SendSIGHUP": "no", "SendSIGKILL": "yes", "Slice": "system.slice", "StandardError": "inherit", "StandardInput": "null", "StandardOutput": "journal", "StartLimitAction": "none", "StartLimitBurst": "5", "StartLimitInterval": "10000000", "StartupBlockIOWeight": "18446744073709551615", "StartupCPUShares": "18446744073709551615", "StatusErrno": "0", "StopWhenUnneeded": "no", "SubState": "running", "SyslogLevelPrefix": "yes", "SyslogPriority": "30", "SystemCallErrorNumber": "0", "TTYReset": "no", "TTYVHangup": "no", "TTYVTDisallocate": "no", "TasksAccounting": "no", "TasksCurrent": "1", "TasksMax": "18446744073709551615", "TimeoutStartUSec": "1min 30s", "TimeoutStopUSec": "1min 30s", "TimerSlackNSec": "50000", "Transient": "no", "Type": "forking", "UMask": "0022", "UnitFilePreset": "enabled", "UnitFileState": "enabled", "WantedBy": "multi-user.target", "Wants": "system.slice", "WatchdogTimestamp": "Wed 2019-06-05 19:05:38 UTC", "WatchdogTimestampMonotonic": "250618602", "WatchdogUSec": "0"}}
2019-06-05 14:05:38,418 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:05:38,441 p=17240 u=mistral |  TASK [Ensure system is NTP time synced] ****************************************
2019-06-05 14:05:38,441 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/host_prep_tasks.yaml:418
2019-06-05 14:05:38,441 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:38 -0500 (0:00:00.243)       0:02:12.210 ******** 
2019-06-05 14:05:38,468 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:48,567 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "cmd": ["chronyc", "waitsync", "20"], "delta": "0:00:10.010999", "end": "2019-06-05 19:05:48.558776", "rc": 0, "start": "2019-06-05 19:05:38.547777", "stderr": "", "stderr_lines": [], "stdout": "try: 1, refid: 00000000, correction: 0.000000000, skew: 0.000\ntry: 2, refid: C7662E4D, correction: 0.000001439, skew: 12.765", "stdout_lines": ["try: 1, refid: 00000000, correction: 0.000000000, skew: 0.000", "try: 2, refid: C7662E4D, correction: 0.000001439, skew: 12.765"]}
2019-06-05 14:05:48,593 p=17240 u=mistral |  TASK [Set timezone fact] *******************************************************
2019-06-05 14:05:48,593 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/host_prep_tasks.yaml:420
2019-06-05 14:05:48,593 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:48 -0500 (0:00:10.151)       0:02:22.362 ******** 
2019-06-05 14:05:48,620 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:48,630 p=17240 u=mistral |  ok: [lab-computehci-0] => {"ansible_facts": {"timezone": "UTC"}, "changed": false}
2019-06-05 14:05:48,654 p=17240 u=mistral |  TASK [Set timezone to UTC] *****************************************************
2019-06-05 14:05:48,654 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/host_prep_tasks.yaml:423
2019-06-05 14:05:48,654 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:48 -0500 (0:00:00.061)       0:02:22.423 ******** 
2019-06-05 14:05:48,680 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:48,833 p=17240 u=mistral |  ok: [lab-computehci-0] => {"changed": false}
2019-06-05 14:05:48,856 p=17240 u=mistral |  TASK [Restart services] ********************************************************
2019-06-05 14:05:48,857 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/host_prep_tasks.yaml:427
2019-06-05 14:05:48,857 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:48 -0500 (0:00:00.202)       0:02:22.626 ******** 
2019-06-05 14:05:48,883 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=rsyslog)  => {"changed": false, "item": "rsyslog", "skip_reason": "Conditional result was False"}
2019-06-05 14:05:48,884 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=crond)  => {"changed": false, "item": "crond", "skip_reason": "Conditional result was False"}
2019-06-05 14:05:48,895 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=rsyslog)  => {"changed": false, "item": "rsyslog", "skip_reason": "Conditional result was False"}
2019-06-05 14:05:48,899 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=crond)  => {"changed": false, "item": "crond", "skip_reason": "Conditional result was False"}
2019-06-05 14:05:48,923 p=17240 u=mistral |  TASK [create persistent directories] *******************************************
2019-06-05 14:05:48,923 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/host_prep_tasks.yaml:435
2019-06-05 14:05:48,923 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:48 -0500 (0:00:00.066)       0:02:22.692 ******** 
2019-06-05 14:05:48,952 p=17240 u=mistral |  skipping: [lab-controller-0] => (item={u'path': u'/var/log/containers/openvswitch', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/containers/openvswitch", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:48,952 p=17240 u=mistral |  skipping: [lab-controller-0] => (item={u'path': u'/var/log/openvswitch', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/openvswitch", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:49,050 p=17240 u=mistral |  changed: [lab-computehci-0] => (item={u'path': u'/var/log/containers/openvswitch', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/containers/openvswitch", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/containers/openvswitch", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:05:49,137 p=17240 u=mistral |  changed: [lab-computehci-0] => (item={u'path': u'/var/log/openvswitch', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 1000, "group": "hugetlbfs", "item": {"path": "/var/log/openvswitch", "setype": "svirt_sandbox_file_t"}, "mode": "0750", "owner": "openvswitch", "path": "/var/log/openvswitch", "secontext": "system_u:object_r:container_file_t:s0", "size": 54, "state": "directory", "uid": 992}
2019-06-05 14:05:49,162 p=17240 u=mistral |  TASK [openvswitch logs readme] *************************************************
2019-06-05 14:05:49,162 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/host_prep_tasks.yaml:445
2019-06-05 14:05:49,162 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:49 -0500 (0:00:00.238)       0:02:22.931 ******** 
2019-06-05 14:05:49,189 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:49,456 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "checksum": "a42a1d799da8bbfe9279a54cdb49379733320d91", "dest": "/var/log/openvswitch/readme.txt", "gid": 0, "group": "root", "md5sum": "de2f90ebdd31015721582bd406ba9900", "mode": "0644", "owner": "root", "secontext": "system_u:object_r:openvswitch_log_t:s0", "size": 90, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559761549.2-94110032505391/source", "state": "file", "uid": 0}
2019-06-05 14:05:49,479 p=17240 u=mistral |  TASK [create persistent directories] *******************************************
2019-06-05 14:05:49,479 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/host_prep_tasks.yaml:454
2019-06-05 14:05:49,479 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:49 -0500 (0:00:00.317)       0:02:23.248 ******** 
2019-06-05 14:05:49,506 p=17240 u=mistral |  skipping: [lab-controller-0] => (item={u'path': u'/var/log/containers/neutron', u'setype': u'svirt_sandbox_file_t'})  => {"changed": false, "item": {"path": "/var/log/containers/neutron", "setype": "svirt_sandbox_file_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:49,507 p=17240 u=mistral |  skipping: [lab-controller-0] => (item={u'path': u'/var/log/neutron', u'setype': u'var_log_t'})  => {"changed": false, "item": {"path": "/var/log/neutron", "setype": "var_log_t"}, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:49,600 p=17240 u=mistral |  changed: [lab-computehci-0] => (item={u'path': u'/var/log/containers/neutron', u'setype': u'svirt_sandbox_file_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/containers/neutron", "setype": "svirt_sandbox_file_t"}, "mode": "0755", "owner": "root", "path": "/var/log/containers/neutron", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:05:49,687 p=17240 u=mistral |  changed: [lab-computehci-0] => (item={u'path': u'/var/log/neutron', u'setype': u'var_log_t'}) => {"changed": true, "gid": 0, "group": "root", "item": {"path": "/var/log/neutron", "setype": "var_log_t"}, "mode": "0755", "owner": "root", "path": "/var/log/neutron", "secontext": "unconfined_u:object_r:var_log_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:05:49,710 p=17240 u=mistral |  TASK [neutron logs readme] *****************************************************
2019-06-05 14:05:49,710 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/host_prep_tasks.yaml:464
2019-06-05 14:05:49,710 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:49 -0500 (0:00:00.231)       0:02:23.480 ******** 
2019-06-05 14:05:49,737 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:50,005 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "checksum": "f5a95f434a4aad25a9a81a045dec39159a6e8864", "dest": "/var/log/neutron/readme.txt", "gid": 0, "group": "root", "md5sum": "5f0556f928d9bce18671eead8048ea17", "mode": "0644", "owner": "root", "secontext": "system_u:object_r:neutron_log_t:s0", "size": 124, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559761549.74-44300233157229/source", "state": "file", "uid": 0}
2019-06-05 14:05:50,028 p=17240 u=mistral |  TASK [create /run/netns with temp namespace] ***********************************
2019-06-05 14:05:50,028 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/host_prep_tasks.yaml:473
2019-06-05 14:05:50,028 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:50 -0500 (0:00:00.317)       0:02:23.797 ******** 
2019-06-05 14:05:50,054 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:50,147 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "cmd": ["ip", "netns", "add", "ns_temp"], "delta": "0:00:00.002870", "end": "2019-06-05 19:05:50.138031", "rc": 0, "start": "2019-06-05 19:05:50.135161", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}
2019-06-05 14:05:50,172 p=17240 u=mistral |  TASK [remove temp namespace] ***************************************************
2019-06-05 14:05:50,173 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/host_prep_tasks.yaml:477
2019-06-05 14:05:50,173 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:50 -0500 (0:00:00.144)       0:02:23.942 ******** 
2019-06-05 14:05:50,199 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:50,296 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "cmd": ["ip", "netns", "delete", "ns_temp"], "delta": "0:00:00.008370", "end": "2019-06-05 19:05:50.288145", "rc": 0, "start": "2019-06-05 19:05:50.279775", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}
2019-06-05 14:05:50,320 p=17240 u=mistral |  TASK [create /var/lib/neutron] *************************************************
2019-06-05 14:05:50,320 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/host_prep_tasks.yaml:481
2019-06-05 14:05:50,320 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:50 -0500 (0:00:00.147)       0:02:24.089 ******** 
2019-06-05 14:05:50,346 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:50,436 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "gid": 0, "group": "root", "mode": "0755", "owner": "root", "path": "/var/lib/neutron", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:05:50,437 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:05:50,437 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:05:50,441 p=17240 u=mistral |  PLAY [External deployment step 1] **********************************************
2019-06-05 14:05:50,446 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:05:50,459 p=17240 u=mistral |  TASK [set blacklisted_hostnames] ***********************************************
2019-06-05 14:05:50,459 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:2
2019-06-05 14:05:50,459 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:50 -0500 (0:00:00.139)       0:02:24.228 ******** 
2019-06-05 14:05:50,472 p=17240 u=mistral |  ok: [undercloud] => {"ansible_facts": {"blacklisted_hostnames": []}, "changed": false}
2019-06-05 14:05:50,486 p=17240 u=mistral |  TASK [create ceph-ansible temp dirs] *******************************************
2019-06-05 14:05:50,486 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:5
2019-06-05 14:05:50,487 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:50 -0500 (0:00:00.027)       0:02:24.256 ******** 
2019-06-05 14:05:50,615 p=17240 u=mistral |  ok: [undercloud] => (item=/var/lib/mistral/lab/ceph-ansible) => {"changed": false, "gid": 0, "group": "root", "item": "/var/lib/mistral/lab/ceph-ansible", "mode": "0755", "owner": "tripleo-admin", "path": "/var/lib/mistral/lab/ceph-ansible", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 222, "state": "directory", "uid": 1001}
2019-06-05 14:05:50,706 p=17240 u=mistral |  ok: [undercloud] => (item=/var/lib/mistral/lab/ceph-ansible/group_vars) => {"changed": false, "gid": 0, "group": "root", "item": "/var/lib/mistral/lab/ceph-ansible/group_vars", "mode": "0755", "owner": "tripleo-admin", "path": "/var/lib/mistral/lab/ceph-ansible/group_vars", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 88, "state": "directory", "uid": 1001}
2019-06-05 14:05:50,792 p=17240 u=mistral |  ok: [undercloud] => (item=/var/lib/mistral/lab/ceph-ansible/host_vars) => {"changed": false, "gid": 0, "group": "root", "item": "/var/lib/mistral/lab/ceph-ansible/host_vars", "mode": "0755", "owner": "tripleo-admin", "path": "/var/lib/mistral/lab/ceph-ansible/host_vars", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 62, "state": "directory", "uid": 1001}
2019-06-05 14:05:50,881 p=17240 u=mistral |  ok: [undercloud] => (item=/var/lib/mistral/lab/ceph-ansible/fetch_dir) => {"changed": false, "gid": 0, "group": "root", "item": "/var/lib/mistral/lab/ceph-ansible/fetch_dir", "mode": "0755", "owner": "tripleo-admin", "path": "/var/lib/mistral/lab/ceph-ansible/fetch_dir", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 50, "state": "directory", "uid": 1001}
2019-06-05 14:05:50,896 p=17240 u=mistral |  TASK [generate inventory] ******************************************************
2019-06-05 14:05:50,896 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:16
2019-06-05 14:05:50,896 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:50 -0500 (0:00:00.409)       0:02:24.665 ******** 
2019-06-05 14:05:51,390 p=17240 u=mistral |  changed: [undercloud] => {"changed": true, "checksum": "bb74dc59ad61ee12f4e8fafb779b5e70675ec236", "dest": "/var/lib/mistral/lab/ceph-ansible/inventory.yml", "gid": 1002, "group": "tripleo-admin", "md5sum": "1603c96ac5ea673eabac2e3545730514", "mode": "0664", "owner": "tripleo-admin", "secontext": "system_u:object_r:var_lib_t:s0", "size": 552, "src": "/tmp/ansible-tripleo-admin/ansible-tmp-1559761551.15-137581372969738/source", "state": "file", "uid": 1001}
2019-06-05 14:05:51,404 p=17240 u=mistral |  TASK [set ceph-ansible group vars all] *****************************************
2019-06-05 14:05:51,404 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:30
2019-06-05 14:05:51,404 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:51 -0500 (0:00:00.508)       0:02:25.173 ******** 
2019-06-05 14:05:51,419 p=17240 u=mistral |  ok: [undercloud] => {"ansible_facts": {"ceph_ansible_group_vars_all": {"ceph_conf_overrides": {"global": {"osd_pool_default_pg_num": 128, "osd_pool_default_pgp_num": 128, "osd_pool_default_size": 1, "rgw_keystone_accepted_admin_roles": "ResellerAdmin", "rgw_keystone_accepted_roles": "Member, admin", "rgw_keystone_admin_domain": "default", "rgw_keystone_admin_password": "9VxxlGgkwO6AbG4PdJXIFcf3Y", "rgw_keystone_admin_project": "service", "rgw_keystone_admin_user": "swift", "rgw_keystone_api_version": 3, "rgw_keystone_implicit_tenants": "true", "rgw_keystone_revocation_interval": "0", "rgw_keystone_url": "http://172.16.2.110:5000", "rgw_s3_auth_use_keystone": "true", "rgw_swift_versioning_enabled": "true"}}, "ceph_docker_image": "ceph/daemon", "ceph_docker_image_tag": "v4.0.0-stable-4.0-nautilus-centos-7-x86_64", "ceph_docker_registry": "docker.io", "ceph_origin": "distro", "ceph_stable": true, "cluster": "ceph", "cluster_network": "172.16.3.0/24", "containerized_deployment": true, "docker": true, "fsid": "473c3318-87c3-11e9-861d-5254009e1c0e", "generate_fsid": false, "ip_version": "ipv4", "keys": [{"caps": {"mgr": "allow *", "mon": "profile rbd", "osd": "profile rbd pool=volumes, profile rbd pool=backups, profile rbd pool=vms, profile rbd pool=images, profile rbd pool=metrics"}, "key": "AQDHD/hcAAAAABAATFjBHwsT54VTRbuXEooWHg==", "mode": "0600", "name": "client.openstack"}, {"caps": {"mds": "allow *", "mgr": "allow *", "mon": "allow r, allow command 'auth del', allow command 'auth caps', allow command 'auth get', allow command 'auth get-or-create'", "osd": "allow rw"}, "key": "AQDHD/hcAAAAABAAbE0du8YCaa7yKOuu5BfgDw==", "mode": "0600", "name": "client.manila"}, {"caps": {"mgr": "allow *", "mon": "allow rw", "osd": "allow rwx"}, "key": "AQDHD/hcAAAAABAA56/grwYCvxMn3Vf+gAtBBA==", "mode": "0600", "name": "client.radosgw"}], "monitor_address_block": "172.16.1.0/24", "ntp_service_enabled": false, "openstack_config": true, "openstack_keys": [{"caps": {"mgr": "allow *", "mon": "profile rbd", "osd": "profile rbd pool=volumes, profile rbd pool=backups, profile rbd pool=vms, profile rbd pool=images, profile rbd pool=metrics"}, "key": "AQDHD/hcAAAAABAATFjBHwsT54VTRbuXEooWHg==", "mode": "0600", "name": "client.openstack"}, {"caps": {"mds": "allow *", "mgr": "allow *", "mon": "allow r, allow command 'auth del', allow command 'auth caps', allow command 'auth get', allow command 'auth get-or-create'", "osd": "allow rw"}, "key": "AQDHD/hcAAAAABAAbE0du8YCaa7yKOuu5BfgDw==", "mode": "0600", "name": "client.manila"}, {"caps": {"mgr": "allow *", "mon": "allow rw", "osd": "allow rwx"}, "key": "AQDHD/hcAAAAABAA56/grwYCvxMn3Vf+gAtBBA==", "mode": "0600", "name": "client.radosgw"}], "openstack_pools": [{"application": "rbd", "name": "images", "pg_num": 128, "rule_name": "replicated_rule"}, {"application": "openstack_gnocchi", "name": "metrics", "pg_num": 128, "rule_name": "replicated_rule"}, {"application": "rbd", "name": "backups", "pg_num": 128, "rule_name": "replicated_rule"}, {"application": "rbd", "name": "vms", "pg_num": 128, "rule_name": "replicated_rule"}, {"application": "rbd", "name": "volumes", "pg_num": 128, "rule_name": "replicated_rule"}], "pools": [], "public_network": "172.16.1.0/24", "user_config": true}}, "changed": false}
2019-06-05 14:05:51,433 p=17240 u=mistral |  TASK [generate ceph-ansible group vars all] ************************************
2019-06-05 14:05:51,433 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:139
2019-06-05 14:05:51,433 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:51 -0500 (0:00:00.029)       0:02:25.202 ******** 
2019-06-05 14:05:51,682 p=17240 u=mistral |  changed: [undercloud] => {"changed": true, "checksum": "d256be34df50bdb31d4e4f709132f7fbea3d7328", "dest": "/var/lib/mistral/lab/ceph-ansible/group_vars/all.yml", "gid": 1002, "group": "tripleo-admin", "md5sum": "40b86d884381a6e27f047a33c246f5cf", "mode": "0664", "owner": "tripleo-admin", "secontext": "system_u:object_r:var_lib_t:s0", "size": 3223, "src": "/tmp/ansible-tripleo-admin/ansible-tmp-1559761551.45-49645840814369/source", "state": "file", "uid": 1001}
2019-06-05 14:05:51,697 p=17240 u=mistral |  TASK [set ceph-ansible extra vars] *********************************************
2019-06-05 14:05:51,697 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:143
2019-06-05 14:05:51,697 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:51 -0500 (0:00:00.263)       0:02:25.466 ******** 
2019-06-05 14:05:51,710 p=17240 u=mistral |  ok: [undercloud] => {"ansible_facts": {"ceph_ansible_extra_vars": {"container_binary": "podman", "fetch_directory": "/var/lib/mistral/lab/ceph-ansible/fetch_dir", "ireallymeanit": "yes", "is_hci": true}}, "changed": false}
2019-06-05 14:05:51,725 p=17240 u=mistral |  TASK [generate ceph-ansible extra vars] ****************************************
2019-06-05 14:05:51,725 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:150
2019-06-05 14:05:51,725 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:51 -0500 (0:00:00.028)       0:02:25.495 ******** 
2019-06-05 14:05:51,924 p=17240 u=mistral |  ok: [undercloud] => {"changed": false, "checksum": "67eefbd9680c14154b235b4417dd95dd4dc9fcf5", "dest": "/var/lib/mistral/lab/ceph-ansible/extra_vars.yml", "gid": 1002, "group": "tripleo-admin", "mode": "0664", "owner": "tripleo-admin", "path": "/var/lib/mistral/lab/ceph-ansible/extra_vars.yml", "secontext": "system_u:object_r:var_lib_t:s0", "size": 120, "state": "file", "uid": 1001}
2019-06-05 14:05:51,939 p=17240 u=mistral |  TASK [generate nodes-uuid data file] *******************************************
2019-06-05 14:05:51,939 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:154
2019-06-05 14:05:51,939 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:51 -0500 (0:00:00.213)       0:02:25.708 ******** 
2019-06-05 14:05:52,133 p=17240 u=mistral |  ok: [undercloud] => {"changed": false, "checksum": "bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f", "dest": "/var/lib/mistral/lab/ceph-ansible/nodes_uuid_data.json", "gid": 1002, "group": "tripleo-admin", "mode": "0664", "owner": "tripleo-admin", "path": "/var/lib/mistral/lab/ceph-ansible/nodes_uuid_data.json", "secontext": "system_u:object_r:var_lib_t:s0", "size": 2, "state": "file", "uid": 1001}
2019-06-05 14:05:52,148 p=17240 u=mistral |  TASK [generate nodes-uuid playbook] ********************************************
2019-06-05 14:05:52,148 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:158
2019-06-05 14:05:52,148 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:52 -0500 (0:00:00.208)       0:02:25.917 ******** 
2019-06-05 14:05:52,346 p=17240 u=mistral |  ok: [undercloud] => {"changed": false, "checksum": "0668551ccff7ac690bf02dad4407644657400daa", "dest": "/var/lib/mistral/lab/ceph-ansible/nodes_uuid_playbook.yml", "gid": 1002, "group": "tripleo-admin", "mode": "0664", "owner": "tripleo-admin", "path": "/var/lib/mistral/lab/ceph-ansible/nodes_uuid_playbook.yml", "secontext": "system_u:object_r:var_lib_t:s0", "size": 1062, "state": "file", "uid": 1001}
2019-06-05 14:05:52,361 p=17240 u=mistral |  TASK [detect private key file] *************************************************
2019-06-05 14:05:52,361 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:179
2019-06-05 14:05:52,361 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:52 -0500 (0:00:00.213)       0:02:26.130 ******** 
2019-06-05 14:05:52,372 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:52,386 p=17240 u=mistral |  TASK [set private key file] ****************************************************
2019-06-05 14:05:52,386 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:183
2019-06-05 14:05:52,386 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:52 -0500 (0:00:00.025)       0:02:26.156 ******** 
2019-06-05 14:05:52,399 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:52,413 p=17240 u=mistral |  TASK [run nodes-uuid] **********************************************************
2019-06-05 14:05:52,413 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:187
2019-06-05 14:05:52,413 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:52 -0500 (0:00:00.027)       0:02:26.183 ******** 
2019-06-05 14:05:52,426 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:52,442 p=17240 u=mistral |  TASK [set ceph-ansible params from Heat] ***************************************
2019-06-05 14:05:52,442 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:195
2019-06-05 14:05:52,442 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:52 -0500 (0:00:00.028)       0:02:26.211 ******** 
2019-06-05 14:05:52,453 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:52,468 p=17240 u=mistral |  TASK [set ceph-ansible playbooks] **********************************************
2019-06-05 14:05:52,468 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:200
2019-06-05 14:05:52,468 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:52 -0500 (0:00:00.025)       0:02:26.237 ******** 
2019-06-05 14:05:52,478 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:52,493 p=17240 u=mistral |  TASK [was path for local ceph-ansible fetch directory backups set?] ************
2019-06-05 14:05:52,493 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:205
2019-06-05 14:05:52,493 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:52 -0500 (0:00:00.025)       0:02:26.262 ******** 
2019-06-05 14:05:52,504 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:52,518 p=17240 u=mistral |  TASK [look for requested ceph-ansible fetch directory for local backup] ********
2019-06-05 14:05:52,518 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:210
2019-06-05 14:05:52,519 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:52 -0500 (0:00:00.025)       0:02:26.288 ******** 
2019-06-05 14:05:52,530 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:52,544 p=17240 u=mistral |  TASK [autocreate new directory for ceph-ansible fetch directory backup] ********
2019-06-05 14:05:52,544 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:214
2019-06-05 14:05:52,544 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:52 -0500 (0:00:00.025)       0:02:26.314 ******** 
2019-06-05 14:05:52,555 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:52,570 p=17240 u=mistral |  TASK [look for tarball of ceph-ansible fetch directory in local backup] ********
2019-06-05 14:05:52,570 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:222
2019-06-05 14:05:52,570 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:52 -0500 (0:00:00.025)       0:02:26.339 ******** 
2019-06-05 14:05:52,583 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:52,597 p=17240 u=mistral |  TASK [untar local backup of ceph-ansible fetch directory] **********************
2019-06-05 14:05:52,597 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:226
2019-06-05 14:05:52,597 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:52 -0500 (0:00:00.027)       0:02:26.367 ******** 
2019-06-05 14:05:52,609 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:52,623 p=17240 u=mistral |  TASK [set facts for swift back up of ceph-ansible fetch directory] *************
2019-06-05 14:05:52,623 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:232
2019-06-05 14:05:52,624 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:52 -0500 (0:00:00.026)       0:02:26.393 ******** 
2019-06-05 14:05:52,635 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:52,649 p=17240 u=mistral |  TASK [attempt download of fetch directory tarball from swift backup] ***********
2019-06-05 14:05:52,649 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:238
2019-06-05 14:05:52,649 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:52 -0500 (0:00:00.025)       0:02:26.418 ******** 
2019-06-05 14:05:52,660 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:52,674 p=17240 u=mistral |  TASK [ensure we create a new fetch_directory or use the old fetch_directory] ***
2019-06-05 14:05:52,674 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:243
2019-06-05 14:05:52,674 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:52 -0500 (0:00:00.024)       0:02:26.443 ******** 
2019-06-05 14:05:52,685 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:52,699 p=17240 u=mistral |  TASK [unpack downloaded ceph-ansible fetch tarball to fetch directory] *********
2019-06-05 14:05:52,699 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:251
2019-06-05 14:05:52,699 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:52 -0500 (0:00:00.025)       0:02:26.469 ******** 
2019-06-05 14:05:52,711 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:52,725 p=17240 u=mistral |  TASK [remove downloaded ceph-ansible fetch directory tarball from filesystem] ***
2019-06-05 14:05:52,725 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:257
2019-06-05 14:05:52,725 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:52 -0500 (0:00:00.025)       0:02:26.494 ******** 
2019-06-05 14:05:52,735 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:52,749 p=17240 u=mistral |  TASK [set ceph-ansible command] ************************************************
2019-06-05 14:05:52,749 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:265
2019-06-05 14:05:52,750 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:52 -0500 (0:00:00.024)       0:02:26.519 ******** 
2019-06-05 14:05:52,760 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:52,775 p=17240 u=mistral |  TASK [run ceph-ansible (immediate log at /var/lib/mistral/lab/ceph-ansible/ceph_ansible_command.log)] ***
2019-06-05 14:05:52,775 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:277
2019-06-05 14:05:52,775 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:52 -0500 (0:00:00.025)       0:02:26.545 ******** 
2019-06-05 14:05:52,785 p=17240 u=mistral |  skipping: [undercloud] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:05:52,800 p=17240 u=mistral |  TASK [print ceph-ansible output in case of failure] ****************************
2019-06-05 14:05:52,800 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:293
2019-06-05 14:05:52,800 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:52 -0500 (0:00:00.024)       0:02:26.569 ******** 
2019-06-05 14:05:52,810 p=17240 u=mistral |  skipping: [undercloud] => {}
2019-06-05 14:05:52,824 p=17240 u=mistral |  TASK [register contents of fetch_directory after ceph-ansible run] *************
2019-06-05 14:05:52,824 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:300
2019-06-05 14:05:52,824 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:52 -0500 (0:00:00.024)       0:02:26.593 ******** 
2019-06-05 14:05:52,837 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:52,852 p=17240 u=mistral |  TASK [create ceph-ansible fetch directory tarball in local backup] *************
2019-06-05 14:05:52,852 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:305
2019-06-05 14:05:52,852 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:52 -0500 (0:00:00.027)       0:02:26.621 ******** 
2019-06-05 14:05:52,868 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:52,882 p=17240 u=mistral |  TASK [create temporary ceph-ansible fetch directory tarball for swift backup] ***
2019-06-05 14:05:52,882 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:315
2019-06-05 14:05:52,882 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:52 -0500 (0:00:00.030)       0:02:26.651 ******** 
2019-06-05 14:05:52,893 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:52,907 p=17240 u=mistral |  TASK [backup temporary ceph-ansible fetch directory tarball in swift] **********
2019-06-05 14:05:52,908 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:321
2019-06-05 14:05:52,908 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:52 -0500 (0:00:00.025)       0:02:26.677 ******** 
2019-06-05 14:05:52,918 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:52,933 p=17240 u=mistral |  TASK [ensure we were able to backup temporary fetch directory to swift] ********
2019-06-05 14:05:52,933 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:325
2019-06-05 14:05:52,933 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:52 -0500 (0:00:00.025)       0:02:26.702 ******** 
2019-06-05 14:05:52,944 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:52,958 p=17240 u=mistral |  TASK [clean temporary fetch directory after swift backup] **********************
2019-06-05 14:05:52,958 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:333
2019-06-05 14:05:52,958 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:52 -0500 (0:00:00.024)       0:02:26.727 ******** 
2019-06-05 14:05:52,969 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:52,984 p=17240 u=mistral |  TASK [Remove ceph-ansible fetch directory] *************************************
2019-06-05 14:05:52,984 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:342
2019-06-05 14:05:52,984 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:52 -0500 (0:00:00.026)       0:02:26.753 ******** 
2019-06-05 14:05:52,995 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:05:53,009 p=17240 u=mistral |  TASK [set ceph-ansible group vars mgrs] ****************************************
2019-06-05 14:05:53,010 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:351
2019-06-05 14:05:53,010 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:53 -0500 (0:00:00.025)       0:02:26.779 ******** 
2019-06-05 14:05:53,022 p=17240 u=mistral |  ok: [undercloud] => {"ansible_facts": {"ceph_ansible_group_vars_mgrs": {"ceph_mgr_docker_extra_env": "-e MGR_DASHBOARD=0"}}, "changed": false}
2019-06-05 14:05:53,036 p=17240 u=mistral |  TASK [generate ceph-ansible group vars mgrs] ***********************************
2019-06-05 14:05:53,036 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:355
2019-06-05 14:05:53,036 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:53 -0500 (0:00:00.026)       0:02:26.806 ******** 
2019-06-05 14:05:53,234 p=17240 u=mistral |  ok: [undercloud] => {"changed": false, "checksum": "06d130f3471f2ac09bb0161450878cf64bafd8af", "dest": "/var/lib/mistral/lab/ceph-ansible/group_vars/mgrs.yml", "gid": 1002, "group": "tripleo-admin", "mode": "0664", "owner": "tripleo-admin", "path": "/var/lib/mistral/lab/ceph-ansible/group_vars/mgrs.yml", "secontext": "system_u:object_r:var_lib_t:s0", "size": 46, "state": "file", "uid": 1001}
2019-06-05 14:05:53,249 p=17240 u=mistral |  TASK [set ceph-ansible group vars mons] ****************************************
2019-06-05 14:05:53,249 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:363
2019-06-05 14:05:53,249 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:53 -0500 (0:00:00.212)       0:02:27.018 ******** 
2019-06-05 14:05:53,262 p=17240 u=mistral |  ok: [undercloud] => {"ansible_facts": {"ceph_ansible_group_vars_mons": {"admin_secret": "AQDHD/hcAAAAABAAC+log2GLa9wSo1vvAOB/OQ==", "monitor_secret": "AQDHD/hcAAAAABAAK4VveMIRh/HVkTzpW9bV+A=="}}, "changed": false}
2019-06-05 14:05:53,276 p=17240 u=mistral |  TASK [generate ceph-ansible group vars mons] ***********************************
2019-06-05 14:05:53,277 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:368
2019-06-05 14:05:53,277 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:53 -0500 (0:00:00.027)       0:02:27.046 ******** 
2019-06-05 14:05:53,517 p=17240 u=mistral |  changed: [undercloud] => {"changed": true, "checksum": "057d86ae735f82b314909dbe62aaa1c0f16526c8", "dest": "/var/lib/mistral/lab/ceph-ansible/group_vars/mons.yml", "gid": 1002, "group": "tripleo-admin", "md5sum": "37e1d5d0a3561853ec9e9fc3f76d178e", "mode": "0664", "owner": "tripleo-admin", "secontext": "system_u:object_r:var_lib_t:s0", "size": 112, "src": "/tmp/ansible-tripleo-admin/ansible-tmp-1559761553.29-272737071486644/source", "state": "file", "uid": 1001}
2019-06-05 14:05:53,531 p=17240 u=mistral |  TASK [set_fact] ****************************************************************
2019-06-05 14:05:53,531 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:376
2019-06-05 14:05:53,532 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:53 -0500 (0:00:00.254)       0:02:27.301 ******** 
2019-06-05 14:05:53,544 p=17240 u=mistral |  ok: [undercloud] => {"ansible_facts": {"container_image_prepare_debug": false, "log_file": "/var/log/tripleo-container-image-prepare.log"}, "changed": false}
2019-06-05 14:05:53,559 p=17240 u=mistral |  TASK [Create temp file for prepare parameter] **********************************
2019-06-05 14:05:53,559 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:379
2019-06-05 14:05:53,559 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:53 -0500 (0:00:00.027)       0:02:27.328 ******** 
2019-06-05 14:05:53,636 p=17240 u=mistral |  changed: [undercloud] => {"changed": true, "gid": 1002, "group": "tripleo-admin", "mode": "0600", "owner": "tripleo-admin", "path": "/tmp/ansible.FGKHic-prepare-param", "secontext": "unconfined_u:object_r:user_tmp_t:s0", "size": 0, "state": "file", "uid": 1001}
2019-06-05 14:05:53,650 p=17240 u=mistral |  TASK [Create temp file for role data] ******************************************
2019-06-05 14:05:53,650 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:385
2019-06-05 14:05:53,651 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:53 -0500 (0:00:00.091)       0:02:27.420 ******** 
2019-06-05 14:05:53,728 p=17240 u=mistral |  changed: [undercloud] => {"changed": true, "gid": 1002, "group": "tripleo-admin", "mode": "0600", "owner": "tripleo-admin", "path": "/tmp/ansible.44RgXW-role-data", "secontext": "unconfined_u:object_r:user_tmp_t:s0", "size": 0, "state": "file", "uid": 1001}
2019-06-05 14:05:53,742 p=17240 u=mistral |  TASK [Write ContainerImagePrepare parameter file] ******************************
2019-06-05 14:05:53,742 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:391
2019-06-05 14:05:53,742 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:53 -0500 (0:00:00.091)       0:02:27.511 ******** 
2019-06-05 14:05:53,983 p=17240 u=mistral |  changed: [undercloud] => {"changed": true, "checksum": "72d9b24b5530530070c8f9cf9275d0fd6d8fb5d9", "dest": "/tmp/ansible.FGKHic-prepare-param", "gid": 1002, "group": "tripleo-admin", "md5sum": "bd8e4532f79e0a290f21a6f7d5d1ce26", "mode": "0600", "owner": "tripleo-admin", "secontext": "unconfined_u:object_r:user_tmp_t:s0", "size": 10669, "src": "/tmp/ansible-tripleo-admin/ansible-tmp-1559761553.76-32009044229855/source", "state": "file", "uid": 1001}
2019-06-05 14:05:53,997 p=17240 u=mistral |  TASK [Write role data file] ****************************************************
2019-06-05 14:05:53,997 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:659
2019-06-05 14:05:53,997 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:53 -0500 (0:00:00.255)       0:02:27.767 ******** 
2019-06-05 14:05:54,235 p=17240 u=mistral |  changed: [undercloud] => {"changed": true, "checksum": "71ac3149507dd9b22d5e2d443f77853c327da5ca", "dest": "/tmp/ansible.44RgXW-role-data", "gid": 1002, "group": "tripleo-admin", "md5sum": "b490a08e6fe3f14e9ca1f919c453fb97", "mode": "0600", "owner": "tripleo-admin", "secontext": "unconfined_u:object_r:user_tmp_t:s0", "size": 9204, "src": "/tmp/ansible-tripleo-admin/ansible-tmp-1559761554.01-273960687257252/source", "state": "file", "uid": 1001}
2019-06-05 14:05:54,250 p=17240 u=mistral |  TASK [Run tripleo-container-image-prepare logged to /var/log/tripleo-container-image-prepare.log] ***
2019-06-05 14:05:54,250 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:905
2019-06-05 14:05:54,250 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:54 -0500 (0:00:00.252)       0:02:28.019 ******** 
2019-06-05 14:05:59,533 p=17240 u=mistral |  changed: [undercloud] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:05:59,548 p=17240 u=mistral |  TASK [Delete param file] *******************************************************
2019-06-05 14:05:59,548 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:911
2019-06-05 14:05:59,548 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:59 -0500 (0:00:05.298)       0:02:33.318 ******** 
2019-06-05 14:05:59,633 p=17240 u=mistral |  changed: [undercloud] => {"changed": true, "path": "/tmp/ansible.FGKHic-prepare-param", "state": "absent"}
2019-06-05 14:05:59,648 p=17240 u=mistral |  TASK [Delete role file] ********************************************************
2019-06-05 14:05:59,648 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:916
2019-06-05 14:05:59,648 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:59 -0500 (0:00:00.099)       0:02:33.417 ******** 
2019-06-05 14:05:59,730 p=17240 u=mistral |  changed: [undercloud] => {"changed": true, "path": "/tmp/ansible.44RgXW-role-data", "state": "absent"}
2019-06-05 14:05:59,744 p=17240 u=mistral |  TASK [set ceph-ansible group vars clients] *************************************
2019-06-05 14:05:59,744 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:925
2019-06-05 14:05:59,744 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:59 -0500 (0:00:00.096)       0:02:33.514 ******** 
2019-06-05 14:05:59,757 p=17240 u=mistral |  ok: [undercloud] => {"ansible_facts": {"ceph_ansible_group_vars_clients": {}}, "changed": false}
2019-06-05 14:05:59,771 p=17240 u=mistral |  TASK [generate ceph-ansible group vars clients] ********************************
2019-06-05 14:05:59,771 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:928
2019-06-05 14:05:59,771 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:59 -0500 (0:00:00.026)       0:02:33.541 ******** 
2019-06-05 14:05:59,972 p=17240 u=mistral |  ok: [undercloud] => {"changed": false, "checksum": "bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f", "dest": "/var/lib/mistral/lab/ceph-ansible/group_vars/clients.yml", "gid": 1002, "group": "tripleo-admin", "mode": "0664", "owner": "tripleo-admin", "path": "/var/lib/mistral/lab/ceph-ansible/group_vars/clients.yml", "secontext": "system_u:object_r:var_lib_t:s0", "size": 2, "state": "file", "uid": 1001}
2019-06-05 14:05:59,987 p=17240 u=mistral |  TASK [set ceph-ansible group vars osds] ****************************************
2019-06-05 14:05:59,987 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:936
2019-06-05 14:05:59,987 p=17240 u=mistral |  Wednesday 05 June 2019  14:05:59 -0500 (0:00:00.215)       0:02:33.756 ******** 
2019-06-05 14:06:00,002 p=17240 u=mistral |  ok: [undercloud] => {"ansible_facts": {"ceph_ansible_group_vars_osds": {"devices": ["/dev/vdb"], "journal_size": 512, "osd_scenario": "collocated"}}, "changed": false}
2019-06-05 14:06:00,016 p=17240 u=mistral |  TASK [generate ceph-ansible group vars osds] ***********************************
2019-06-05 14:06:00,016 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:943
2019-06-05 14:06:00,016 p=17240 u=mistral |  Wednesday 05 June 2019  14:06:00 -0500 (0:00:00.029)       0:02:33.786 ******** 
2019-06-05 14:06:00,216 p=17240 u=mistral |  ok: [undercloud] => {"changed": false, "checksum": "90e71abbd684de98de01c7b154201367c646f115", "dest": "/var/lib/mistral/lab/ceph-ansible/group_vars/osds.yml", "gid": 1002, "group": "tripleo-admin", "mode": "0664", "owner": "tripleo-admin", "path": "/var/lib/mistral/lab/ceph-ansible/group_vars/osds.yml", "secontext": "system_u:object_r:var_lib_t:s0", "size": 63, "state": "file", "uid": 1001}
2019-06-05 14:06:00,217 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:06:00,217 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:06:00,220 p=17240 u=mistral |  PLAY [Overcloud deploy step tasks for 1] ***************************************
2019-06-05 14:06:00,223 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:06:00,245 p=17240 u=mistral |  TASK [Write the config_step hieradata for the deploy step 1 tasks] *************
2019-06-05 14:06:00,245 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deploy_steps_playbook.yaml:154
2019-06-05 14:06:00,245 p=17240 u=mistral |  Wednesday 05 June 2019  14:06:00 -0500 (0:00:00.228)       0:02:34.014 ******** 
2019-06-05 14:06:00,530 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "checksum": "dfdcc7695edd230e7a2c06fc7b739bfa56506d8f", "dest": "/etc/puppet/hieradata/config_step.json", "gid": 0, "group": "root", "md5sum": "f0ef53dcc6eb8440334b1ebaa90bfd63", "mode": "0600", "owner": "root", "secontext": "system_u:object_r:puppet_etc_t:s0", "size": 11, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559761560.25-241127053095687/source", "state": "file", "uid": 0}
2019-06-05 14:06:00,553 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "checksum": "dfdcc7695edd230e7a2c06fc7b739bfa56506d8f", "dest": "/etc/puppet/hieradata/config_step.json", "gid": 0, "group": "root", "md5sum": "f0ef53dcc6eb8440334b1ebaa90bfd63", "mode": "0600", "owner": "root", "secontext": "system_u:object_r:puppet_etc_t:s0", "size": 11, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559761560.28-44306382992282/source", "state": "file", "uid": 0}
2019-06-05 14:06:00,577 p=17240 u=mistral |  TASK [Run puppet on the host to apply IPtables rules] **************************
2019-06-05 14:06:00,577 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/deploy_steps_tasks.yaml:2
2019-06-05 14:06:00,577 p=17240 u=mistral |  Wednesday 05 June 2019  14:06:00 -0500 (0:00:00.332)       0:02:34.346 ******** 
2019-06-05 14:06:00,613 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:06:29,987 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "cmd": "set +e\n puppet apply  --detailed-exitcodes --summarize --color=false --modulepath '/etc/puppet/modules:/opt/stack/puppet-modules:/usr/share/openstack-puppet/modules' --tags 'tripleo::firewall::rule' -e 'include ::tripleo::profile::base::haproxy'\n rc=$?\n set -e\n set +ux\n if [ $rc -eq 2 -o $rc -eq 0 ]; then\n exit 0\n fi\n exit $rc", "delta": "0:00:29.313231", "end": "2019-06-05 19:06:29.975352", "rc": 0, "start": "2019-06-05 19:06:00.662121", "stderr": "Warning: Support for ruby version 2.0.0 is deprecated and will be removed in a future release. See https://puppet.com/docs/puppet/latest/system_requirements.html for a list of supported ruby versions.\n   (location: /usr/share/ruby/vendor_ruby/puppet.rb:130:in `<module:Puppet>')\nerror: Could not connect to cluster (is it running?)\nWarning: /etc/puppet/hiera.yaml: Use of 'hiera.yaml' version 3 is deprecated. It should be converted to version 5\n   (file: /etc/puppet/hiera.yaml)\nWarning: Undefined variable '::deploy_config_name'; \\n   (file & line not available)\nWarning: ModuleLoader: module 'tripleo' has unresolved dependencies - it will only see those that are resolved. Use 'puppet module list --tree' to see information about modules\\n   (file & line not available)\nWarning: The function 'hiera' is deprecated in favor of using 'lookup'. See https://puppet.com/docs/puppet/5.5/deprecated_language.html\\n   (file & line not available)\nWarning: tag is a metaparam; this value will inherit to all contained resources in the tripleo::firewall::rule definition\nWarning: ModuleLoader: module 'concat' has unresolved dependencies - it will only see those that are resolved. Use 'puppet module list --tree' to see information about modules\\n   (file & line not available)\nWarning: Unknown variable: 'haproxy_firewall_rules'. (file: /etc/puppet/modules/tripleo/manifests/haproxy/endpoint.pp, line: 297, column: 54)\nWarning: Unknown variable: 'haproxy_firewall_rules'. (file: /etc/puppet/modules/tripleo/manifests/haproxy/endpoint.pp, line: 297, column: 54)\nWarning: Unknown variable: 'haproxy_firewall_rules'. (file: /etc/puppet/modules/tripleo/manifests/haproxy/endpoint.pp, line: 297, column: 54)\nWarning: Unknown variable: 'haproxy_firewall_rules'. (file: /etc/puppet/modules/tripleo/manifests/haproxy/endpoint.pp, line: 297, column: 54)\nWarning: Unknown variable: 'haproxy_firewall_rules'. (file: /etc/puppet/modules/tripleo/manifests/haproxy/endpoint.pp, line: 297, column: 54)\nWarning: Unknown variable: 'haproxy_firewall_rules'. (file: /etc/puppet/modules/tripleo/manifests/haproxy/endpoint.pp, line: 297, column: 54)\nWarning: Unknown variable: 'haproxy_firewall_rules'. (file: /etc/puppet/modules/tripleo/manifests/haproxy/endpoint.pp, line: 297, column: 54)\nWarning: Unknown variable: 'haproxy_firewall_rules'. (file: /etc/puppet/modules/tripleo/manifests/haproxy/endpoint.pp, line: 297, column: 54)\nWarning: Unknown variable: 'haproxy_firewall_rules'. (file: /etc/puppet/modules/tripleo/manifests/haproxy/endpoint.pp, line: 297, column: 54)\nWarning: Unknown variable: 'haproxy_firewall_rules'. (file: /etc/puppet/modules/tripleo/manifests/haproxy/endpoint.pp, line: 297, column: 54)\nWarning: Unknown variable: 'haproxy_firewall_rules'. (file: /etc/puppet/modules/tripleo/manifests/haproxy/endpoint.pp, line: 297, column: 54)\nWarning: Unknown variable: 'haproxy_firewall_rules'. (file: /etc/puppet/modules/tripleo/manifests/haproxy/endpoint.pp, line: 297, column: 54)\nWarning: Unknown variable: 'haproxy_firewall_rules'. (file: /etc/puppet/modules/tripleo/manifests/haproxy/endpoint.pp, line: 297, column: 54)\nWarning: Unknown variable: 'haproxy_firewall_rules'. (file: /etc/puppet/modules/tripleo/manifests/haproxy/endpoint.pp, line: 297, column: 54)\nWarning: This method is deprecated, please use the stdlib validate_legacy function,\n                    with Stdlib::Compat::Hash. There is further documentation for validate_legacy function in the README. at [\"/etc/puppet/modules/tripleo/manifests/firewall/rule.pp\", 148]:\n   (location: /etc/puppet/modules/stdlib/lib/puppet/functions/deprecation.rb:28:in `deprecation')\nWarning: Unknown variable: 'haproxy_firewall_rules'. (file: /etc/puppet/modules/tripleo/manifests/haproxy/endpoint.pp, line: 297, column: 54)\nWarning: Unknown variable: 'haproxy_firewall_rules'. (file: /etc/puppet/modules/tripleo/manifests/haproxy/endpoint.pp, line: 297, column: 54)\nWarning: Scope(Haproxy::Config[haproxy]): haproxy: The $merge_options parameter will default to true in the next major release. Please review the documentation regarding the implications.", "stderr_lines": ["Warning: Support for ruby version 2.0.0 is deprecated and will be removed in a future release. See https://puppet.com/docs/puppet/latest/system_requirements.html for a list of supported ruby versions.", "   (location: /usr/share/ruby/vendor_ruby/puppet.rb:130:in `<module:Puppet>')", "error: Could not connect to cluster (is it running?)", "Warning: /etc/puppet/hiera.yaml: Use of 'hiera.yaml' version 3 is deprecated. It should be converted to version 5", "   (file: /etc/puppet/hiera.yaml)", "Warning: Undefined variable '::deploy_config_name'; \\n   (file & line not available)", "Warning: ModuleLoader: module 'tripleo' has unresolved dependencies - it will only see those that are resolved. Use 'puppet module list --tree' to see information about modules\\n   (file & line not available)", "Warning: The function 'hiera' is deprecated in favor of using 'lookup'. See https://puppet.com/docs/puppet/5.5/deprecated_language.html\\n   (file & line not available)", "Warning: tag is a metaparam; this value will inherit to all contained resources in the tripleo::firewall::rule definition", "Warning: ModuleLoader: module 'concat' has unresolved dependencies - it will only see those that are resolved. Use 'puppet module list --tree' to see information about modules\\n   (file & line not available)", "Warning: Unknown variable: 'haproxy_firewall_rules'. (file: /etc/puppet/modules/tripleo/manifests/haproxy/endpoint.pp, line: 297, column: 54)", "Warning: Unknown variable: 'haproxy_firewall_rules'. (file: /etc/puppet/modules/tripleo/manifests/haproxy/endpoint.pp, line: 297, column: 54)", "Warning: Unknown variable: 'haproxy_firewall_rules'. (file: /etc/puppet/modules/tripleo/manifests/haproxy/endpoint.pp, line: 297, column: 54)", "Warning: Unknown variable: 'haproxy_firewall_rules'. (file: /etc/puppet/modules/tripleo/manifests/haproxy/endpoint.pp, line: 297, column: 54)", "Warning: Unknown variable: 'haproxy_firewall_rules'. (file: /etc/puppet/modules/tripleo/manifests/haproxy/endpoint.pp, line: 297, column: 54)", "Warning: Unknown variable: 'haproxy_firewall_rules'. (file: /etc/puppet/modules/tripleo/manifests/haproxy/endpoint.pp, line: 297, column: 54)", "Warning: Unknown variable: 'haproxy_firewall_rules'. (file: /etc/puppet/modules/tripleo/manifests/haproxy/endpoint.pp, line: 297, column: 54)", "Warning: Unknown variable: 'haproxy_firewall_rules'. (file: /etc/puppet/modules/tripleo/manifests/haproxy/endpoint.pp, line: 297, column: 54)", "Warning: Unknown variable: 'haproxy_firewall_rules'. (file: /etc/puppet/modules/tripleo/manifests/haproxy/endpoint.pp, line: 297, column: 54)", "Warning: Unknown variable: 'haproxy_firewall_rules'. (file: /etc/puppet/modules/tripleo/manifests/haproxy/endpoint.pp, line: 297, column: 54)", "Warning: Unknown variable: 'haproxy_firewall_rules'. (file: /etc/puppet/modules/tripleo/manifests/haproxy/endpoint.pp, line: 297, column: 54)", "Warning: Unknown variable: 'haproxy_firewall_rules'. (file: /etc/puppet/modules/tripleo/manifests/haproxy/endpoint.pp, line: 297, column: 54)", "Warning: Unknown variable: 'haproxy_firewall_rules'. (file: /etc/puppet/modules/tripleo/manifests/haproxy/endpoint.pp, line: 297, column: 54)", "Warning: Unknown variable: 'haproxy_firewall_rules'. (file: /etc/puppet/modules/tripleo/manifests/haproxy/endpoint.pp, line: 297, column: 54)", "Warning: This method is deprecated, please use the stdlib validate_legacy function,", "                    with Stdlib::Compat::Hash. There is further documentation for validate_legacy function in the README. at [\"/etc/puppet/modules/tripleo/manifests/firewall/rule.pp\", 148]:", "   (location: /etc/puppet/modules/stdlib/lib/puppet/functions/deprecation.rb:28:in `deprecation')", "Warning: Unknown variable: 'haproxy_firewall_rules'. (file: /etc/puppet/modules/tripleo/manifests/haproxy/endpoint.pp, line: 297, column: 54)", "Warning: Unknown variable: 'haproxy_firewall_rules'. (file: /etc/puppet/modules/tripleo/manifests/haproxy/endpoint.pp, line: 297, column: 54)", "Warning: Scope(Haproxy::Config[haproxy]): haproxy: The $merge_options parameter will default to true in the next major release. Please review the documentation regarding the implications."], "stdout": "Notice: Scope(Class[Tripleo::Firewall::Post]): At this stage, all network traffic is blocked.\nNotice: Compiled catalog for lab-controller-0.localdomain in environment production in 1.12 seconds\nNotice: /Stage[main]/Tripleo::Firewall::Pre/Tripleo::Firewall::Rule[000 accept related established rules]/Firewall[000 accept related established rules ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall::Pre/Tripleo::Firewall::Rule[000 accept related established rules]/Firewall[000 accept related established rules ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall::Pre/Tripleo::Firewall::Rule[001 accept all icmp]/Firewall[001 accept all icmp ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall::Pre/Tripleo::Firewall::Rule[001 accept all icmp]/Firewall[001 accept all icmp ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall::Pre/Tripleo::Firewall::Rule[002 accept all to lo interface]/Firewall[002 accept all to lo interface ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall::Pre/Tripleo::Firewall::Rule[002 accept all to lo interface]/Firewall[002 accept all to lo interface ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall::Pre/Tripleo::Firewall::Rule[004 accept ipv6 dhcpv6]/Firewall[004 accept ipv6 dhcpv6 ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy::Horizon_endpoint/Tripleo::Firewall::Rule[100 horizon_haproxy]/Firewall[100 horizon_haproxy ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy::Horizon_endpoint/Tripleo::Firewall::Rule[100 horizon_haproxy]/Firewall[100 horizon_haproxy ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Firewall::Rule[100 mysql_haproxy]/Firewall[100 mysql_haproxy ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Firewall::Rule[100 mysql_haproxy]/Firewall[100 mysql_haproxy ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Firewall::Rule[100 redis_haproxy]/Firewall[100 redis_haproxy ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Firewall::Rule[100 redis_haproxy]/Firewall[100 redis_haproxy ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[keystone_admin]/Tripleo::Firewall::Rule[100 keystone_admin_haproxy]/Firewall[100 keystone_admin_haproxy ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[keystone_admin]/Tripleo::Firewall::Rule[100 keystone_admin_haproxy]/Firewall[100 keystone_admin_haproxy ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[keystone_admin]/Tripleo::Firewall::Rule[100 keystone_admin_haproxy_frontend]/Firewall[100 keystone_admin_haproxy_frontend ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[keystone_admin]/Tripleo::Firewall::Rule[100 keystone_admin_haproxy_frontend]/Firewall[100 keystone_admin_haproxy_frontend ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[keystone_public]/Tripleo::Firewall::Rule[100 keystone_public_haproxy]/Firewall[100 keystone_public_haproxy ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[keystone_public]/Tripleo::Firewall::Rule[100 keystone_public_haproxy]/Firewall[100 keystone_public_haproxy ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[keystone_public]/Tripleo::Firewall::Rule[100 keystone_public_haproxy_ssl]/Firewall[100 keystone_public_haproxy_ssl ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[keystone_public]/Tripleo::Firewall::Rule[100 keystone_public_haproxy_ssl]/Firewall[100 keystone_public_haproxy_ssl ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[neutron]/Tripleo::Firewall::Rule[100 neutron_haproxy]/Firewall[100 neutron_haproxy ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[neutron]/Tripleo::Firewall::Rule[100 neutron_haproxy]/Firewall[100 neutron_haproxy ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[neutron]/Tripleo::Firewall::Rule[100 neutron_haproxy_ssl]/Firewall[100 neutron_haproxy_ssl ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[neutron]/Tripleo::Firewall::Rule[100 neutron_haproxy_ssl]/Firewall[100 neutron_haproxy_ssl ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[cinder]/Tripleo::Firewall::Rule[100 cinder_haproxy]/Firewall[100 cinder_haproxy ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[cinder]/Tripleo::Firewall::Rule[100 cinder_haproxy]/Firewall[100 cinder_haproxy ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[cinder]/Tripleo::Firewall::Rule[100 cinder_haproxy_ssl]/Firewall[100 cinder_haproxy_ssl ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[cinder]/Tripleo::Firewall::Rule[100 cinder_haproxy_ssl]/Firewall[100 cinder_haproxy_ssl ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[glance_api]/Tripleo::Firewall::Rule[100 glance_api_haproxy]/Firewall[100 glance_api_haproxy ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[glance_api]/Tripleo::Firewall::Rule[100 glance_api_haproxy]/Firewall[100 glance_api_haproxy ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[glance_api]/Tripleo::Firewall::Rule[100 glance_api_haproxy_ssl]/Firewall[100 glance_api_haproxy_ssl ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[glance_api]/Tripleo::Firewall::Rule[100 glance_api_haproxy_ssl]/Firewall[100 glance_api_haproxy_ssl ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[nova_osapi]/Tripleo::Firewall::Rule[100 nova_osapi_haproxy]/Firewall[100 nova_osapi_haproxy ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[nova_osapi]/Tripleo::Firewall::Rule[100 nova_osapi_haproxy]/Firewall[100 nova_osapi_haproxy ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[nova_osapi]/Tripleo::Firewall::Rule[100 nova_osapi_haproxy_ssl]/Firewall[100 nova_osapi_haproxy_ssl ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[nova_osapi]/Tripleo::Firewall::Rule[100 nova_osapi_haproxy_ssl]/Firewall[100 nova_osapi_haproxy_ssl ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[nova_placement]/Tripleo::Firewall::Rule[100 nova_placement_haproxy]/Firewall[100 nova_placement_haproxy ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[nova_placement]/Tripleo::Firewall::Rule[100 nova_placement_haproxy]/Firewall[100 nova_placement_haproxy ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[nova_placement]/Tripleo::Firewall::Rule[100 nova_placement_haproxy_ssl]/Firewall[100 nova_placement_haproxy_ssl ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[nova_placement]/Tripleo::Firewall::Rule[100 nova_placement_haproxy_ssl]/Firewall[100 nova_placement_haproxy_ssl ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[nova_metadata]/Tripleo::Firewall::Rule[100 nova_metadata_haproxy]/Firewall[100 nova_metadata_haproxy ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[nova_metadata]/Tripleo::Firewall::Rule[100 nova_metadata_haproxy]/Firewall[100 nova_metadata_haproxy ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[nova_novncproxy]/Tripleo::Firewall::Rule[100 nova_novncproxy_haproxy]/Firewall[100 nova_novncproxy_haproxy ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[nova_novncproxy]/Tripleo::Firewall::Rule[100 nova_novncproxy_haproxy]/Firewall[100 nova_novncproxy_haproxy ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[nova_novncproxy]/Tripleo::Firewall::Rule[100 nova_novncproxy_haproxy_ssl]/Firewall[100 nova_novncproxy_haproxy_ssl ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[nova_novncproxy]/Tripleo::Firewall::Rule[100 nova_novncproxy_haproxy_ssl]/Firewall[100 nova_novncproxy_haproxy_ssl ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[aodh]/Tripleo::Firewall::Rule[100 aodh_haproxy]/Firewall[100 aodh_haproxy ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[aodh]/Tripleo::Firewall::Rule[100 aodh_haproxy]/Firewall[100 aodh_haproxy ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[aodh]/Tripleo::Firewall::Rule[100 aodh_haproxy_ssl]/Firewall[100 aodh_haproxy_ssl ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[aodh]/Tripleo::Firewall::Rule[100 aodh_haproxy_ssl]/Firewall[100 aodh_haproxy_ssl ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[panko]/Tripleo::Firewall::Rule[100 panko_haproxy]/Firewall[100 panko_haproxy ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[panko]/Tripleo::Firewall::Rule[100 panko_haproxy]/Firewall[100 panko_haproxy ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[panko]/Tripleo::Firewall::Rule[100 panko_haproxy_ssl]/Firewall[100 panko_haproxy_ssl ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[panko]/Tripleo::Firewall::Rule[100 panko_haproxy_ssl]/Firewall[100 panko_haproxy_ssl ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[gnocchi]/Tripleo::Firewall::Rule[100 gnocchi_haproxy]/Firewall[100 gnocchi_haproxy ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[gnocchi]/Tripleo::Firewall::Rule[100 gnocchi_haproxy]/Firewall[100 gnocchi_haproxy ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[gnocchi]/Tripleo::Firewall::Rule[100 gnocchi_haproxy_ssl]/Firewall[100 gnocchi_haproxy_ssl ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[gnocchi]/Tripleo::Firewall::Rule[100 gnocchi_haproxy_ssl]/Firewall[100 gnocchi_haproxy_ssl ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[swift_proxy_server]/Tripleo::Firewall::Rule[100 swift_proxy_server_haproxy]/Firewall[100 swift_proxy_server_haproxy ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[swift_proxy_server]/Tripleo::Firewall::Rule[100 swift_proxy_server_haproxy]/Firewall[100 swift_proxy_server_haproxy ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[swift_proxy_server]/Tripleo::Firewall::Rule[100 swift_proxy_server_haproxy_ssl]/Firewall[100 swift_proxy_server_haproxy_ssl ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[swift_proxy_server]/Tripleo::Firewall::Rule[100 swift_proxy_server_haproxy_ssl]/Firewall[100 swift_proxy_server_haproxy_ssl ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[heat_api]/Tripleo::Firewall::Rule[100 heat_api_haproxy]/Firewall[100 heat_api_haproxy ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[heat_api]/Tripleo::Firewall::Rule[100 heat_api_haproxy]/Firewall[100 heat_api_haproxy ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[heat_api]/Tripleo::Firewall::Rule[100 heat_api_haproxy_ssl]/Firewall[100 heat_api_haproxy_ssl ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[heat_api]/Tripleo::Firewall::Rule[100 heat_api_haproxy_ssl]/Firewall[100 heat_api_haproxy_ssl ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[heat_cfn]/Tripleo::Firewall::Rule[100 heat_cfn_haproxy]/Firewall[100 heat_cfn_haproxy ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[heat_cfn]/Tripleo::Firewall::Rule[100 heat_cfn_haproxy]/Firewall[100 heat_cfn_haproxy ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[heat_cfn]/Tripleo::Firewall::Rule[100 heat_cfn_haproxy_ssl]/Firewall[100 heat_cfn_haproxy_ssl ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[heat_cfn]/Tripleo::Firewall::Rule[100 heat_cfn_haproxy_ssl]/Firewall[100 heat_cfn_haproxy_ssl ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[aodh_api]/Tripleo::Firewall::Rule[128 aodh-api]/Firewall[128 aodh-api ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[aodh_api]/Tripleo::Firewall::Rule[128 aodh-api]/Firewall[128 aodh-api ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[ceph_mgr]/Tripleo::Firewall::Rule[113 ceph_mgr]/Firewall[113 ceph_mgr ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[ceph_mgr]/Tripleo::Firewall::Rule[113 ceph_mgr]/Firewall[113 ceph_mgr ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[ceph_mon]/Tripleo::Firewall::Rule[110 ceph_mon]/Firewall[110 ceph_mon ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[ceph_mon]/Tripleo::Firewall::Rule[110 ceph_mon]/Firewall[110 ceph_mon ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[cinder_api]/Tripleo::Firewall::Rule[119 cinder]/Firewall[119 cinder ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[cinder_api]/Tripleo::Firewall::Rule[119 cinder]/Firewall[119 cinder ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[cinder_volume]/Tripleo::Firewall::Rule[120 iscsi initiator]/Firewall[120 iscsi initiator ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[cinder_volume]/Tripleo::Firewall::Rule[120 iscsi initiator]/Firewall[120 iscsi initiator ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[glance_api]/Tripleo::Firewall::Rule[112 glance_api]/Firewall[112 glance_api ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[glance_api]/Tripleo::Firewall::Rule[112 glance_api]/Firewall[112 glance_api ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[gnocchi_api]/Tripleo::Firewall::Rule[129 gnocchi-api]/Firewall[129 gnocchi-api ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[gnocchi_api]/Tripleo::Firewall::Rule[129 gnocchi-api]/Firewall[129 gnocchi-api ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[gnocchi_statsd]/Tripleo::Firewall::Rule[140 gnocchi-statsd]/Firewall[140 gnocchi-statsd ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[gnocchi_statsd]/Tripleo::Firewall::Rule[140 gnocchi-statsd]/Firewall[140 gnocchi-statsd ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[haproxy]/Tripleo::Firewall::Rule[107 haproxy stats]/Firewall[107 haproxy stats ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[haproxy]/Tripleo::Firewall::Rule[107 haproxy stats]/Firewall[107 haproxy stats ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[heat_api]/Tripleo::Firewall::Rule[125 heat_api]/Firewall[125 heat_api ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[heat_api]/Tripleo::Firewall::Rule[125 heat_api]/Firewall[125 heat_api ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[heat_api_cfn]/Tripleo::Firewall::Rule[125 heat_cfn]/Firewall[125 heat_cfn ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[heat_api_cfn]/Tripleo::Firewall::Rule[125 heat_cfn]/Firewall[125 heat_cfn ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[horizon]/Tripleo::Firewall::Rule[126 horizon]/Firewall[126 horizon ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[horizon]/Tripleo::Firewall::Rule[126 horizon]/Firewall[126 horizon ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[keepalived]/Tripleo::Firewall::Rule[106 keepalived vrrp]/Firewall[106 keepalived vrrp ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[keepalived]/Tripleo::Firewall::Rule[106 keepalived vrrp]/Firewall[106 keepalived vrrp ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[keystone]/Tripleo::Firewall::Rule[111 keystone]/Firewall[111 keystone ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[keystone]/Tripleo::Firewall::Rule[111 keystone]/Firewall[111 keystone ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[memcached]/Tripleo::Firewall::Rule[121 memcached 172.16.2.0/24]/Firewall[121 memcached 172.16.2.0/24 ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[mysql]/Tripleo::Firewall::Rule[104 mysql galera]/Firewall[104 mysql galera ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[mysql]/Tripleo::Firewall::Rule[104 mysql galera]/Firewall[104 mysql galera ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[neutron_api]/Tripleo::Firewall::Rule[114 neutron api]/Firewall[114 neutron api ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[neutron_api]/Tripleo::Firewall::Rule[114 neutron api]/Firewall[114 neutron api ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[nova_api]/Tripleo::Firewall::Rule[113 nova_api]/Firewall[113 nova_api ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[nova_api]/Tripleo::Firewall::Rule[113 nova_api]/Firewall[113 nova_api ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[nova_placement]/Tripleo::Firewall::Rule[138 nova_placement]/Firewall[138 nova_placement ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[nova_placement]/Tripleo::Firewall::Rule[138 nova_placement]/Firewall[138 nova_placement ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[nova_placement]/Tripleo::Firewall::Rule[139 nova_metadata]/Firewall[139 nova_metadata ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[nova_placement]/Tripleo::Firewall::Rule[139 nova_metadata]/Firewall[139 nova_metadata ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[nova_vnc_proxy]/Tripleo::Firewall::Rule[137 nova_vnc_proxy]/Firewall[137 nova_vnc_proxy ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[nova_vnc_proxy]/Tripleo::Firewall::Rule[137 nova_vnc_proxy]/Firewall[137 nova_vnc_proxy ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[ovn_dbs]/Tripleo::Firewall::Rule[121 OVN DB server ports]/Firewall[121 OVN DB server ports ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[ovn_dbs]/Tripleo::Firewall::Rule[121 OVN DB server ports]/Firewall[121 OVN DB server ports ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[ovn_controller]/Tripleo::Firewall::Rule[118 neutron vxlan networks]/Firewall[118 neutron vxlan networks ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[ovn_controller]/Tripleo::Firewall::Rule[118 neutron vxlan networks]/Firewall[118 neutron vxlan networks ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[ovn_controller]/Tripleo::Firewall::Rule[119 neutron geneve networks]/Firewall[119 neutron geneve networks ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[ovn_controller]/Tripleo::Firewall::Rule[119 neutron geneve networks]/Firewall[119 neutron geneve networks ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[panko_api]/Tripleo::Firewall::Rule[140 panko-api]/Firewall[140 panko-api ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[panko_api]/Tripleo::Firewall::Rule[140 panko-api]/Firewall[140 panko-api ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[oslo_messaging_rpc]/Tripleo::Firewall::Rule[109 rabbitmq]/Firewall[109 rabbitmq ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[oslo_messaging_rpc]/Tripleo::Firewall::Rule[109 rabbitmq]/Firewall[109 rabbitmq ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[redis]/Tripleo::Firewall::Rule[108 redis]/Firewall[108 redis ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[redis]/Tripleo::Firewall::Rule[108 redis]/Firewall[108 redis ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[snmp]/Tripleo::Firewall::Rule[124 snmp 192.168.24.0/24]/Firewall[124 snmp 192.168.24.0/24 ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[swift_proxy]/Tripleo::Firewall::Rule[122 swift proxy]/Firewall[122 swift proxy ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[swift_proxy]/Tripleo::Firewall::Rule[122 swift proxy]/Firewall[122 swift proxy ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[swift_storage]/Tripleo::Firewall::Rule[123 swift storage]/Firewall[123 swift storage ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[swift_storage]/Tripleo::Firewall::Rule[123 swift storage]/Firewall[123 swift storage ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[tripleo_firewall]/Tripleo::Firewall::Rule[003 accept ssh from controlplane]/Firewall[003 accept ssh from controlplane ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[ovn_nbdb]/Tripleo::Firewall::Rule[100 ovn_nbdb_haproxy]/Firewall[100 ovn_nbdb_haproxy ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[ovn_nbdb]/Tripleo::Firewall::Rule[100 ovn_nbdb_haproxy]/Firewall[100 ovn_nbdb_haproxy ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[ovn_nbdb]/Tripleo::Firewall::Rule[100 ovn_nbdb_haproxy_ssl]/Firewall[100 ovn_nbdb_haproxy_ssl ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[ovn_nbdb]/Tripleo::Firewall::Rule[100 ovn_nbdb_haproxy_ssl]/Firewall[100 ovn_nbdb_haproxy_ssl ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[ovn_sbdb]/Tripleo::Firewall::Rule[100 ovn_sbdb_haproxy]/Firewall[100 ovn_sbdb_haproxy ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[ovn_sbdb]/Tripleo::Firewall::Rule[100 ovn_sbdb_haproxy]/Firewall[100 ovn_sbdb_haproxy ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[ovn_sbdb]/Tripleo::Firewall::Rule[100 ovn_sbdb_haproxy_ssl]/Firewall[100 ovn_sbdb_haproxy_ssl ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[ovn_sbdb]/Tripleo::Firewall::Rule[100 ovn_sbdb_haproxy_ssl]/Firewall[100 ovn_sbdb_haproxy_ssl ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall::Post/Tripleo::Firewall::Rule[998 log all]/Firewall[998 log all ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall::Post/Tripleo::Firewall::Rule[998 log all]/Firewall[998 log all ipv6]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall::Post/Tripleo::Firewall::Rule[999 drop all]/Firewall[999 drop all ipv4]/ensure: created\nNotice: /Stage[main]/Tripleo::Firewall::Post/Tripleo::Firewall::Rule[999 drop all]/Firewall[999 drop all ipv6]/ensure: created\nNotice: Applied catalog in 24.54 seconds\nChanges:\n            Total: 142\nEvents:\n          Success: 142\n            Total: 142\nResources:\n          Changed: 142\n      Out of sync: 142\n          Skipped: 71\n            Total: 215\nTime:\n   Config retrieval: 1.43\n         Last run: 1559761589\n         Firewall: 23.96\n   Transaction evaluation: 24.52\n   Catalog application: 24.54\n            Total: 24.54\nVersion:\n           Config: 1559761563\n           Puppet: 5.5.10", "stdout_lines": ["Notice: Scope(Class[Tripleo::Firewall::Post]): At this stage, all network traffic is blocked.", "Notice: Compiled catalog for lab-controller-0.localdomain in environment production in 1.12 seconds", "Notice: /Stage[main]/Tripleo::Firewall::Pre/Tripleo::Firewall::Rule[000 accept related established rules]/Firewall[000 accept related established rules ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall::Pre/Tripleo::Firewall::Rule[000 accept related established rules]/Firewall[000 accept related established rules ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall::Pre/Tripleo::Firewall::Rule[001 accept all icmp]/Firewall[001 accept all icmp ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall::Pre/Tripleo::Firewall::Rule[001 accept all icmp]/Firewall[001 accept all icmp ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall::Pre/Tripleo::Firewall::Rule[002 accept all to lo interface]/Firewall[002 accept all to lo interface ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall::Pre/Tripleo::Firewall::Rule[002 accept all to lo interface]/Firewall[002 accept all to lo interface ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall::Pre/Tripleo::Firewall::Rule[004 accept ipv6 dhcpv6]/Firewall[004 accept ipv6 dhcpv6 ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy::Horizon_endpoint/Tripleo::Firewall::Rule[100 horizon_haproxy]/Firewall[100 horizon_haproxy ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy::Horizon_endpoint/Tripleo::Firewall::Rule[100 horizon_haproxy]/Firewall[100 horizon_haproxy ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Firewall::Rule[100 mysql_haproxy]/Firewall[100 mysql_haproxy ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Firewall::Rule[100 mysql_haproxy]/Firewall[100 mysql_haproxy ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Firewall::Rule[100 redis_haproxy]/Firewall[100 redis_haproxy ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Firewall::Rule[100 redis_haproxy]/Firewall[100 redis_haproxy ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[keystone_admin]/Tripleo::Firewall::Rule[100 keystone_admin_haproxy]/Firewall[100 keystone_admin_haproxy ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[keystone_admin]/Tripleo::Firewall::Rule[100 keystone_admin_haproxy]/Firewall[100 keystone_admin_haproxy ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[keystone_admin]/Tripleo::Firewall::Rule[100 keystone_admin_haproxy_frontend]/Firewall[100 keystone_admin_haproxy_frontend ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[keystone_admin]/Tripleo::Firewall::Rule[100 keystone_admin_haproxy_frontend]/Firewall[100 keystone_admin_haproxy_frontend ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[keystone_public]/Tripleo::Firewall::Rule[100 keystone_public_haproxy]/Firewall[100 keystone_public_haproxy ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[keystone_public]/Tripleo::Firewall::Rule[100 keystone_public_haproxy]/Firewall[100 keystone_public_haproxy ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[keystone_public]/Tripleo::Firewall::Rule[100 keystone_public_haproxy_ssl]/Firewall[100 keystone_public_haproxy_ssl ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[keystone_public]/Tripleo::Firewall::Rule[100 keystone_public_haproxy_ssl]/Firewall[100 keystone_public_haproxy_ssl ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[neutron]/Tripleo::Firewall::Rule[100 neutron_haproxy]/Firewall[100 neutron_haproxy ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[neutron]/Tripleo::Firewall::Rule[100 neutron_haproxy]/Firewall[100 neutron_haproxy ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[neutron]/Tripleo::Firewall::Rule[100 neutron_haproxy_ssl]/Firewall[100 neutron_haproxy_ssl ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[neutron]/Tripleo::Firewall::Rule[100 neutron_haproxy_ssl]/Firewall[100 neutron_haproxy_ssl ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[cinder]/Tripleo::Firewall::Rule[100 cinder_haproxy]/Firewall[100 cinder_haproxy ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[cinder]/Tripleo::Firewall::Rule[100 cinder_haproxy]/Firewall[100 cinder_haproxy ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[cinder]/Tripleo::Firewall::Rule[100 cinder_haproxy_ssl]/Firewall[100 cinder_haproxy_ssl ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[cinder]/Tripleo::Firewall::Rule[100 cinder_haproxy_ssl]/Firewall[100 cinder_haproxy_ssl ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[glance_api]/Tripleo::Firewall::Rule[100 glance_api_haproxy]/Firewall[100 glance_api_haproxy ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[glance_api]/Tripleo::Firewall::Rule[100 glance_api_haproxy]/Firewall[100 glance_api_haproxy ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[glance_api]/Tripleo::Firewall::Rule[100 glance_api_haproxy_ssl]/Firewall[100 glance_api_haproxy_ssl ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[glance_api]/Tripleo::Firewall::Rule[100 glance_api_haproxy_ssl]/Firewall[100 glance_api_haproxy_ssl ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[nova_osapi]/Tripleo::Firewall::Rule[100 nova_osapi_haproxy]/Firewall[100 nova_osapi_haproxy ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[nova_osapi]/Tripleo::Firewall::Rule[100 nova_osapi_haproxy]/Firewall[100 nova_osapi_haproxy ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[nova_osapi]/Tripleo::Firewall::Rule[100 nova_osapi_haproxy_ssl]/Firewall[100 nova_osapi_haproxy_ssl ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[nova_osapi]/Tripleo::Firewall::Rule[100 nova_osapi_haproxy_ssl]/Firewall[100 nova_osapi_haproxy_ssl ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[nova_placement]/Tripleo::Firewall::Rule[100 nova_placement_haproxy]/Firewall[100 nova_placement_haproxy ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[nova_placement]/Tripleo::Firewall::Rule[100 nova_placement_haproxy]/Firewall[100 nova_placement_haproxy ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[nova_placement]/Tripleo::Firewall::Rule[100 nova_placement_haproxy_ssl]/Firewall[100 nova_placement_haproxy_ssl ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[nova_placement]/Tripleo::Firewall::Rule[100 nova_placement_haproxy_ssl]/Firewall[100 nova_placement_haproxy_ssl ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[nova_metadata]/Tripleo::Firewall::Rule[100 nova_metadata_haproxy]/Firewall[100 nova_metadata_haproxy ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[nova_metadata]/Tripleo::Firewall::Rule[100 nova_metadata_haproxy]/Firewall[100 nova_metadata_haproxy ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[nova_novncproxy]/Tripleo::Firewall::Rule[100 nova_novncproxy_haproxy]/Firewall[100 nova_novncproxy_haproxy ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[nova_novncproxy]/Tripleo::Firewall::Rule[100 nova_novncproxy_haproxy]/Firewall[100 nova_novncproxy_haproxy ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[nova_novncproxy]/Tripleo::Firewall::Rule[100 nova_novncproxy_haproxy_ssl]/Firewall[100 nova_novncproxy_haproxy_ssl ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[nova_novncproxy]/Tripleo::Firewall::Rule[100 nova_novncproxy_haproxy_ssl]/Firewall[100 nova_novncproxy_haproxy_ssl ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[aodh]/Tripleo::Firewall::Rule[100 aodh_haproxy]/Firewall[100 aodh_haproxy ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[aodh]/Tripleo::Firewall::Rule[100 aodh_haproxy]/Firewall[100 aodh_haproxy ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[aodh]/Tripleo::Firewall::Rule[100 aodh_haproxy_ssl]/Firewall[100 aodh_haproxy_ssl ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[aodh]/Tripleo::Firewall::Rule[100 aodh_haproxy_ssl]/Firewall[100 aodh_haproxy_ssl ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[panko]/Tripleo::Firewall::Rule[100 panko_haproxy]/Firewall[100 panko_haproxy ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[panko]/Tripleo::Firewall::Rule[100 panko_haproxy]/Firewall[100 panko_haproxy ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[panko]/Tripleo::Firewall::Rule[100 panko_haproxy_ssl]/Firewall[100 panko_haproxy_ssl ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[panko]/Tripleo::Firewall::Rule[100 panko_haproxy_ssl]/Firewall[100 panko_haproxy_ssl ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[gnocchi]/Tripleo::Firewall::Rule[100 gnocchi_haproxy]/Firewall[100 gnocchi_haproxy ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[gnocchi]/Tripleo::Firewall::Rule[100 gnocchi_haproxy]/Firewall[100 gnocchi_haproxy ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[gnocchi]/Tripleo::Firewall::Rule[100 gnocchi_haproxy_ssl]/Firewall[100 gnocchi_haproxy_ssl ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[gnocchi]/Tripleo::Firewall::Rule[100 gnocchi_haproxy_ssl]/Firewall[100 gnocchi_haproxy_ssl ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[swift_proxy_server]/Tripleo::Firewall::Rule[100 swift_proxy_server_haproxy]/Firewall[100 swift_proxy_server_haproxy ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[swift_proxy_server]/Tripleo::Firewall::Rule[100 swift_proxy_server_haproxy]/Firewall[100 swift_proxy_server_haproxy ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[swift_proxy_server]/Tripleo::Firewall::Rule[100 swift_proxy_server_haproxy_ssl]/Firewall[100 swift_proxy_server_haproxy_ssl ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[swift_proxy_server]/Tripleo::Firewall::Rule[100 swift_proxy_server_haproxy_ssl]/Firewall[100 swift_proxy_server_haproxy_ssl ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[heat_api]/Tripleo::Firewall::Rule[100 heat_api_haproxy]/Firewall[100 heat_api_haproxy ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[heat_api]/Tripleo::Firewall::Rule[100 heat_api_haproxy]/Firewall[100 heat_api_haproxy ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[heat_api]/Tripleo::Firewall::Rule[100 heat_api_haproxy_ssl]/Firewall[100 heat_api_haproxy_ssl ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[heat_api]/Tripleo::Firewall::Rule[100 heat_api_haproxy_ssl]/Firewall[100 heat_api_haproxy_ssl ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[heat_cfn]/Tripleo::Firewall::Rule[100 heat_cfn_haproxy]/Firewall[100 heat_cfn_haproxy ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[heat_cfn]/Tripleo::Firewall::Rule[100 heat_cfn_haproxy]/Firewall[100 heat_cfn_haproxy ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[heat_cfn]/Tripleo::Firewall::Rule[100 heat_cfn_haproxy_ssl]/Firewall[100 heat_cfn_haproxy_ssl ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[heat_cfn]/Tripleo::Firewall::Rule[100 heat_cfn_haproxy_ssl]/Firewall[100 heat_cfn_haproxy_ssl ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[aodh_api]/Tripleo::Firewall::Rule[128 aodh-api]/Firewall[128 aodh-api ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[aodh_api]/Tripleo::Firewall::Rule[128 aodh-api]/Firewall[128 aodh-api ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[ceph_mgr]/Tripleo::Firewall::Rule[113 ceph_mgr]/Firewall[113 ceph_mgr ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[ceph_mgr]/Tripleo::Firewall::Rule[113 ceph_mgr]/Firewall[113 ceph_mgr ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[ceph_mon]/Tripleo::Firewall::Rule[110 ceph_mon]/Firewall[110 ceph_mon ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[ceph_mon]/Tripleo::Firewall::Rule[110 ceph_mon]/Firewall[110 ceph_mon ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[cinder_api]/Tripleo::Firewall::Rule[119 cinder]/Firewall[119 cinder ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[cinder_api]/Tripleo::Firewall::Rule[119 cinder]/Firewall[119 cinder ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[cinder_volume]/Tripleo::Firewall::Rule[120 iscsi initiator]/Firewall[120 iscsi initiator ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[cinder_volume]/Tripleo::Firewall::Rule[120 iscsi initiator]/Firewall[120 iscsi initiator ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[glance_api]/Tripleo::Firewall::Rule[112 glance_api]/Firewall[112 glance_api ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[glance_api]/Tripleo::Firewall::Rule[112 glance_api]/Firewall[112 glance_api ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[gnocchi_api]/Tripleo::Firewall::Rule[129 gnocchi-api]/Firewall[129 gnocchi-api ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[gnocchi_api]/Tripleo::Firewall::Rule[129 gnocchi-api]/Firewall[129 gnocchi-api ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[gnocchi_statsd]/Tripleo::Firewall::Rule[140 gnocchi-statsd]/Firewall[140 gnocchi-statsd ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[gnocchi_statsd]/Tripleo::Firewall::Rule[140 gnocchi-statsd]/Firewall[140 gnocchi-statsd ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[haproxy]/Tripleo::Firewall::Rule[107 haproxy stats]/Firewall[107 haproxy stats ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[haproxy]/Tripleo::Firewall::Rule[107 haproxy stats]/Firewall[107 haproxy stats ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[heat_api]/Tripleo::Firewall::Rule[125 heat_api]/Firewall[125 heat_api ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[heat_api]/Tripleo::Firewall::Rule[125 heat_api]/Firewall[125 heat_api ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[heat_api_cfn]/Tripleo::Firewall::Rule[125 heat_cfn]/Firewall[125 heat_cfn ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[heat_api_cfn]/Tripleo::Firewall::Rule[125 heat_cfn]/Firewall[125 heat_cfn ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[horizon]/Tripleo::Firewall::Rule[126 horizon]/Firewall[126 horizon ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[horizon]/Tripleo::Firewall::Rule[126 horizon]/Firewall[126 horizon ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[keepalived]/Tripleo::Firewall::Rule[106 keepalived vrrp]/Firewall[106 keepalived vrrp ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[keepalived]/Tripleo::Firewall::Rule[106 keepalived vrrp]/Firewall[106 keepalived vrrp ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[keystone]/Tripleo::Firewall::Rule[111 keystone]/Firewall[111 keystone ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[keystone]/Tripleo::Firewall::Rule[111 keystone]/Firewall[111 keystone ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[memcached]/Tripleo::Firewall::Rule[121 memcached 172.16.2.0/24]/Firewall[121 memcached 172.16.2.0/24 ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[mysql]/Tripleo::Firewall::Rule[104 mysql galera]/Firewall[104 mysql galera ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[mysql]/Tripleo::Firewall::Rule[104 mysql galera]/Firewall[104 mysql galera ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[neutron_api]/Tripleo::Firewall::Rule[114 neutron api]/Firewall[114 neutron api ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[neutron_api]/Tripleo::Firewall::Rule[114 neutron api]/Firewall[114 neutron api ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[nova_api]/Tripleo::Firewall::Rule[113 nova_api]/Firewall[113 nova_api ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[nova_api]/Tripleo::Firewall::Rule[113 nova_api]/Firewall[113 nova_api ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[nova_placement]/Tripleo::Firewall::Rule[138 nova_placement]/Firewall[138 nova_placement ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[nova_placement]/Tripleo::Firewall::Rule[138 nova_placement]/Firewall[138 nova_placement ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[nova_placement]/Tripleo::Firewall::Rule[139 nova_metadata]/Firewall[139 nova_metadata ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[nova_placement]/Tripleo::Firewall::Rule[139 nova_metadata]/Firewall[139 nova_metadata ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[nova_vnc_proxy]/Tripleo::Firewall::Rule[137 nova_vnc_proxy]/Firewall[137 nova_vnc_proxy ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[nova_vnc_proxy]/Tripleo::Firewall::Rule[137 nova_vnc_proxy]/Firewall[137 nova_vnc_proxy ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[ovn_dbs]/Tripleo::Firewall::Rule[121 OVN DB server ports]/Firewall[121 OVN DB server ports ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[ovn_dbs]/Tripleo::Firewall::Rule[121 OVN DB server ports]/Firewall[121 OVN DB server ports ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[ovn_controller]/Tripleo::Firewall::Rule[118 neutron vxlan networks]/Firewall[118 neutron vxlan networks ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[ovn_controller]/Tripleo::Firewall::Rule[118 neutron vxlan networks]/Firewall[118 neutron vxlan networks ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[ovn_controller]/Tripleo::Firewall::Rule[119 neutron geneve networks]/Firewall[119 neutron geneve networks ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[ovn_controller]/Tripleo::Firewall::Rule[119 neutron geneve networks]/Firewall[119 neutron geneve networks ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[panko_api]/Tripleo::Firewall::Rule[140 panko-api]/Firewall[140 panko-api ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[panko_api]/Tripleo::Firewall::Rule[140 panko-api]/Firewall[140 panko-api ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[oslo_messaging_rpc]/Tripleo::Firewall::Rule[109 rabbitmq]/Firewall[109 rabbitmq ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[oslo_messaging_rpc]/Tripleo::Firewall::Rule[109 rabbitmq]/Firewall[109 rabbitmq ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[redis]/Tripleo::Firewall::Rule[108 redis]/Firewall[108 redis ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[redis]/Tripleo::Firewall::Rule[108 redis]/Firewall[108 redis ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[snmp]/Tripleo::Firewall::Rule[124 snmp 192.168.24.0/24]/Firewall[124 snmp 192.168.24.0/24 ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[swift_proxy]/Tripleo::Firewall::Rule[122 swift proxy]/Firewall[122 swift proxy ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[swift_proxy]/Tripleo::Firewall::Rule[122 swift proxy]/Firewall[122 swift proxy ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[swift_storage]/Tripleo::Firewall::Rule[123 swift storage]/Firewall[123 swift storage ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[swift_storage]/Tripleo::Firewall::Rule[123 swift storage]/Firewall[123 swift storage ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall/Tripleo::Firewall::Service_rules[tripleo_firewall]/Tripleo::Firewall::Rule[003 accept ssh from controlplane]/Firewall[003 accept ssh from controlplane ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[ovn_nbdb]/Tripleo::Firewall::Rule[100 ovn_nbdb_haproxy]/Firewall[100 ovn_nbdb_haproxy ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[ovn_nbdb]/Tripleo::Firewall::Rule[100 ovn_nbdb_haproxy]/Firewall[100 ovn_nbdb_haproxy ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[ovn_nbdb]/Tripleo::Firewall::Rule[100 ovn_nbdb_haproxy_ssl]/Firewall[100 ovn_nbdb_haproxy_ssl ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[ovn_nbdb]/Tripleo::Firewall::Rule[100 ovn_nbdb_haproxy_ssl]/Firewall[100 ovn_nbdb_haproxy_ssl ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[ovn_sbdb]/Tripleo::Firewall::Rule[100 ovn_sbdb_haproxy]/Firewall[100 ovn_sbdb_haproxy ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[ovn_sbdb]/Tripleo::Firewall::Rule[100 ovn_sbdb_haproxy]/Firewall[100 ovn_sbdb_haproxy ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[ovn_sbdb]/Tripleo::Firewall::Rule[100 ovn_sbdb_haproxy_ssl]/Firewall[100 ovn_sbdb_haproxy_ssl ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Haproxy/Tripleo::Haproxy::Endpoint[ovn_sbdb]/Tripleo::Firewall::Rule[100 ovn_sbdb_haproxy_ssl]/Firewall[100 ovn_sbdb_haproxy_ssl ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall::Post/Tripleo::Firewall::Rule[998 log all]/Firewall[998 log all ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall::Post/Tripleo::Firewall::Rule[998 log all]/Firewall[998 log all ipv6]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall::Post/Tripleo::Firewall::Rule[999 drop all]/Firewall[999 drop all ipv4]/ensure: created", "Notice: /Stage[main]/Tripleo::Firewall::Post/Tripleo::Firewall::Rule[999 drop all]/Firewall[999 drop all ipv6]/ensure: created", "Notice: Applied catalog in 24.54 seconds", "Changes:", "            Total: 142", "Events:", "          Success: 142", "            Total: 142", "Resources:", "          Changed: 142", "      Out of sync: 142", "          Skipped: 71", "            Total: 215", "Time:", "   Config retrieval: 1.43", "         Last run: 1559761589", "         Firewall: 23.96", "   Transaction evaluation: 24.52", "   Catalog application: 24.54", "            Total: 24.54", "Version:", "           Config: 1559761563", "           Puppet: 5.5.10"]}
2019-06-05 14:06:30,011 p=17240 u=mistral |  TASK [configure tmpwatch on the host] ******************************************
2019-06-05 14:06:30,011 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/deploy_steps_tasks.yaml:13
2019-06-05 14:06:30,012 p=17240 u=mistral |  Wednesday 05 June 2019  14:06:30 -0500 (0:00:29.434)       0:03:03.781 ******** 
2019-06-05 14:06:30,039 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:06:30,047 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:06:30,070 p=17240 u=mistral |  TASK [create iptables service] *************************************************
2019-06-05 14:06:30,070 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/deploy_steps_tasks.yaml:27
2019-06-05 14:06:30,070 p=17240 u=mistral |  Wednesday 05 June 2019  14:06:30 -0500 (0:00:00.058)       0:03:03.840 ******** 
2019-06-05 14:06:30,098 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:06:30,106 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:06:30,130 p=17240 u=mistral |  TASK [enable tripleo-iptables service] *****************************************
2019-06-05 14:06:30,130 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/deploy_steps_tasks.yaml:58
2019-06-05 14:06:30,130 p=17240 u=mistral |  Wednesday 05 June 2019  14:06:30 -0500 (0:00:00.059)       0:03:03.899 ******** 
2019-06-05 14:06:30,157 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:06:30,166 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:06:30,189 p=17240 u=mistral |  TASK [create ip6tables service] ************************************************
2019-06-05 14:06:30,190 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/deploy_steps_tasks.yaml:62
2019-06-05 14:06:30,190 p=17240 u=mistral |  Wednesday 05 June 2019  14:06:30 -0500 (0:00:00.059)       0:03:03.959 ******** 
2019-06-05 14:06:30,218 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:06:30,225 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:06:30,248 p=17240 u=mistral |  TASK [enable tripleo-ip6tables service] ****************************************
2019-06-05 14:06:30,248 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/deploy_steps_tasks.yaml:93
2019-06-05 14:06:30,248 p=17240 u=mistral |  Wednesday 05 June 2019  14:06:30 -0500 (0:00:00.058)       0:03:04.017 ******** 
2019-06-05 14:06:30,274 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:06:30,281 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:06:30,305 p=17240 u=mistral |  TASK [configure tmpwatch on the host] ******************************************
2019-06-05 14:06:30,305 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/deploy_steps_tasks.yaml:2
2019-06-05 14:06:30,305 p=17240 u=mistral |  Wednesday 05 June 2019  14:06:30 -0500 (0:00:00.056)       0:03:04.074 ******** 
2019-06-05 14:06:30,337 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:06:30,347 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:06:30,370 p=17240 u=mistral |  TASK [create iptables service] *************************************************
2019-06-05 14:06:30,370 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/deploy_steps_tasks.yaml:16
2019-06-05 14:06:30,370 p=17240 u=mistral |  Wednesday 05 June 2019  14:06:30 -0500 (0:00:00.064)       0:03:04.139 ******** 
2019-06-05 14:06:30,397 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:06:30,406 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:06:30,430 p=17240 u=mistral |  TASK [enable tripleo-iptables service] *****************************************
2019-06-05 14:06:30,430 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/deploy_steps_tasks.yaml:47
2019-06-05 14:06:30,430 p=17240 u=mistral |  Wednesday 05 June 2019  14:06:30 -0500 (0:00:00.059)       0:03:04.199 ******** 
2019-06-05 14:06:30,457 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:06:30,466 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:06:30,489 p=17240 u=mistral |  TASK [create ip6tables service] ************************************************
2019-06-05 14:06:30,490 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/deploy_steps_tasks.yaml:51
2019-06-05 14:06:30,490 p=17240 u=mistral |  Wednesday 05 June 2019  14:06:30 -0500 (0:00:00.059)       0:03:04.259 ******** 
2019-06-05 14:06:30,517 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:06:30,526 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:06:30,549 p=17240 u=mistral |  TASK [enable tripleo-ip6tables service] ****************************************
2019-06-05 14:06:30,550 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/deploy_steps_tasks.yaml:82
2019-06-05 14:06:30,550 p=17240 u=mistral |  Wednesday 05 June 2019  14:06:30 -0500 (0:00:00.059)       0:03:04.319 ******** 
2019-06-05 14:06:30,577 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:06:30,585 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:06:30,586 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:06:30,586 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:06:30,590 p=17240 u=mistral |  PLAY [Overcloud common deploy step tasks 1] ************************************
2019-06-05 14:06:30,595 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:06:30,616 p=17240 u=mistral |  TASK [Check if /var/lib/tripleo-config/container-startup-config-1.json already exists] ***
2019-06-05 14:06:30,617 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deploy_steps_playbook.yaml:186
2019-06-05 14:06:30,617 p=17240 u=mistral |  Wednesday 05 June 2019  14:06:30 -0500 (0:00:00.066)       0:03:04.386 ******** 
2019-06-05 14:06:30,713 p=17240 u=mistral |  ok: [lab-controller-0] => {"changed": false, "stat": {"exists": false}}
2019-06-05 14:06:30,739 p=17240 u=mistral |  ok: [lab-computehci-0] => {"changed": false, "stat": {"exists": false}}
2019-06-05 14:06:30,797 p=17240 u=mistral |  TASK [gather facts needed by role] *********************************************
2019-06-05 14:06:30,797 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:6
2019-06-05 14:06:30,797 p=17240 u=mistral |  Wednesday 05 June 2019  14:06:30 -0500 (0:00:00.180)       0:03:04.566 ******** 
2019-06-05 14:06:30,825 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:06:30,836 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:06:30,859 p=17240 u=mistral |  TASK [set python_cmd] **********************************************************
2019-06-05 14:06:30,859 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:13
2019-06-05 14:06:30,859 p=17240 u=mistral |  Wednesday 05 June 2019  14:06:30 -0500 (0:00:00.062)       0:03:04.629 ******** 
2019-06-05 14:06:30,886 p=17240 u=mistral |  ok: [lab-controller-0] => {"ansible_facts": {"python_cmd": "python2"}, "changed": false}
2019-06-05 14:06:30,899 p=17240 u=mistral |  ok: [lab-computehci-0] => {"ansible_facts": {"python_cmd": "python2"}, "changed": false}
2019-06-05 14:06:30,922 p=17240 u=mistral |  TASK [print python facts] ******************************************************
2019-06-05 14:06:30,922 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:22
2019-06-05 14:06:30,922 p=17240 u=mistral |  Wednesday 05 June 2019  14:06:30 -0500 (0:00:00.063)       0:03:04.692 ******** 
2019-06-05 14:06:30,949 p=17240 u=mistral |  ok: [lab-controller-0] => {
    "msg": "python_cmd: python2"
}
2019-06-05 14:06:30,959 p=17240 u=mistral |  ok: [lab-computehci-0] => {
    "msg": "python_cmd: python2"
}
2019-06-05 14:06:30,983 p=17240 u=mistral |  TASK [Create and ensure setype for /var/log/containers directory] **************
2019-06-05 14:06:30,983 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:31
2019-06-05 14:06:30,983 p=17240 u=mistral |  Wednesday 05 June 2019  14:06:30 -0500 (0:00:00.060)       0:03:04.752 ******** 
2019-06-05 14:06:31,087 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "gid": 0, "group": "root", "mode": "0755", "owner": "root", "path": "/var/log/containers", "secontext": "unconfined_u:object_r:var_log_t:s0", "size": 4096, "state": "directory", "uid": 0}
2019-06-05 14:06:31,111 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "gid": 0, "group": "root", "mode": "0755", "owner": "root", "path": "/var/log/containers", "secontext": "unconfined_u:object_r:var_log_t:s0", "size": 85, "state": "directory", "uid": 0}
2019-06-05 14:06:31,134 p=17240 u=mistral |  TASK [Create ContainerLogStdoutPath directory] *********************************
2019-06-05 14:06:31,134 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:39
2019-06-05 14:06:31,134 p=17240 u=mistral |  Wednesday 05 June 2019  14:06:31 -0500 (0:00:00.151)       0:03:04.904 ******** 
2019-06-05 14:06:31,235 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "gid": 0, "group": "root", "mode": "0755", "owner": "root", "path": "/var/log/containers/stdouts", "secontext": "unconfined_u:object_r:var_log_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:06:31,260 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "gid": 0, "group": "root", "mode": "0755", "owner": "root", "path": "/var/log/containers/stdouts", "secontext": "unconfined_u:object_r:var_log_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:06:31,283 p=17240 u=mistral |  TASK [Create /var/lib/tripleo-config directory] ********************************
2019-06-05 14:06:31,283 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:46
2019-06-05 14:06:31,284 p=17240 u=mistral |  Wednesday 05 June 2019  14:06:31 -0500 (0:00:00.149)       0:03:05.053 ******** 
2019-06-05 14:06:31,387 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "gid": 0, "group": "root", "mode": "0755", "owner": "root", "path": "/var/lib/tripleo-config", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:06:31,409 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "gid": 0, "group": "root", "mode": "0755", "owner": "root", "path": "/var/lib/tripleo-config", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:06:31,433 p=17240 u=mistral |  TASK [Delete existing /var/lib/tripleo-config/check-mode directory for check mode] ***
2019-06-05 14:06:31,433 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:60
2019-06-05 14:06:31,434 p=17240 u=mistral |  Wednesday 05 June 2019  14:06:31 -0500 (0:00:00.150)       0:03:05.203 ******** 
2019-06-05 14:06:31,461 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:06:31,473 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:06:31,496 p=17240 u=mistral |  TASK [Create /var/lib/tripleo-config/check-mode directory for check mode] ******
2019-06-05 14:06:31,496 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:75
2019-06-05 14:06:31,496 p=17240 u=mistral |  Wednesday 05 June 2019  14:06:31 -0500 (0:00:00.062)       0:03:05.265 ******** 
2019-06-05 14:06:31,523 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:06:31,534 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:06:31,558 p=17240 u=mistral |  TASK [Write the puppet step_config manifest] ***********************************
2019-06-05 14:06:31,558 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:93
2019-06-05 14:06:31,558 p=17240 u=mistral |  Wednesday 05 June 2019  14:06:31 -0500 (0:00:00.061)       0:03:05.327 ******** 
2019-06-05 14:06:31,862 p=17240 u=mistral |  changed: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:31,887 p=17240 u=mistral |  changed: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:31,911 p=17240 u=mistral |  TASK [Diff puppet step_config manifest changes for check mode] *****************
2019-06-05 14:06:31,911 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:105
2019-06-05 14:06:31,911 p=17240 u=mistral |  Wednesday 05 June 2019  14:06:31 -0500 (0:00:00.352)       0:03:05.680 ******** 
2019-06-05 14:06:31,938 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:06:31,950 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:06:31,973 p=17240 u=mistral |  TASK [Diff puppet step_config manifest changes for check mode] *****************
2019-06-05 14:06:31,973 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:118
2019-06-05 14:06:31,974 p=17240 u=mistral |  Wednesday 05 June 2019  14:06:31 -0500 (0:00:00.062)       0:03:05.743 ******** 
2019-06-05 14:06:32,000 p=17240 u=mistral |  skipping: [lab-controller-0] => {}
2019-06-05 14:06:32,015 p=17240 u=mistral |  skipping: [lab-computehci-0] => {}
2019-06-05 14:06:32,040 p=17240 u=mistral |  TASK [Create /var/lib/container-puppet] ****************************************
2019-06-05 14:06:32,040 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:129
2019-06-05 14:06:32,041 p=17240 u=mistral |  Wednesday 05 June 2019  14:06:32 -0500 (0:00:00.067)       0:03:05.810 ******** 
2019-06-05 14:06:32,140 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "gid": 0, "group": "root", "mode": "0755", "owner": "root", "path": "/var/lib/container-puppet", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 33, "state": "directory", "uid": 0}
2019-06-05 14:06:32,164 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "gid": 0, "group": "root", "mode": "0755", "owner": "root", "path": "/var/lib/container-puppet", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 33, "state": "directory", "uid": 0}
2019-06-05 14:06:32,189 p=17240 u=mistral |  TASK [Create /var/lib/docker-puppet for backward compatibility] ****************
2019-06-05 14:06:32,189 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:141
2019-06-05 14:06:32,189 p=17240 u=mistral |  Wednesday 05 June 2019  14:06:32 -0500 (0:00:00.148)       0:03:05.958 ******** 
2019-06-05 14:06:32,286 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "gid": 0, "group": "root", "mode": "0755", "owner": "root", "path": "/var/lib/docker-puppet", "secontext": "unconfined_u:object_r:var_lib_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:06:32,313 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "gid": 0, "group": "root", "mode": "0755", "owner": "root", "path": "/var/lib/docker-puppet", "secontext": "unconfined_u:object_r:var_lib_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:06:32,337 p=17240 u=mistral |  TASK [Deprecation file about /var/lib/docker-puppet] ***************************
2019-06-05 14:06:32,337 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:149
2019-06-05 14:06:32,337 p=17240 u=mistral |  Wednesday 05 June 2019  14:06:32 -0500 (0:00:00.148)       0:03:06.106 ******** 
2019-06-05 14:06:32,624 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "checksum": "cd0c9cab155718ade51e9ba4ab243ab8adf1e416", "dest": "/var/lib/docker-puppet/readme.txt", "gid": 0, "group": "root", "md5sum": "b00f9d163c29fffa01193f04a6a95ad4", "mode": "0644", "owner": "root", "secontext": "system_u:object_r:var_lib_t:s0", "size": 102, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559761592.35-41097331158618/source", "state": "file", "uid": 0}
2019-06-05 14:06:32,645 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "checksum": "cd0c9cab155718ade51e9ba4ab243ab8adf1e416", "dest": "/var/lib/docker-puppet/readme.txt", "gid": 0, "group": "root", "md5sum": "b00f9d163c29fffa01193f04a6a95ad4", "mode": "0644", "owner": "root", "secontext": "system_u:object_r:var_lib_t:s0", "size": 102, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559761592.38-14600798678351/source", "state": "file", "uid": 0}
2019-06-05 14:06:32,669 p=17240 u=mistral |  TASK [Delete existing /var/lib/container-puppet/container-puppet.sh] ***********
2019-06-05 14:06:32,669 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:157
2019-06-05 14:06:32,670 p=17240 u=mistral |  Wednesday 05 June 2019  14:06:32 -0500 (0:00:00.332)       0:03:06.439 ******** 
2019-06-05 14:06:32,766 p=17240 u=mistral |  ok: [lab-controller-0] => {"changed": false, "path": "/var/lib/container-puppet/container-puppet.sh", "state": "absent"}
2019-06-05 14:06:32,790 p=17240 u=mistral |  ok: [lab-computehci-0] => {"changed": false, "path": "/var/lib/container-puppet/container-puppet.sh", "state": "absent"}
2019-06-05 14:06:32,814 p=17240 u=mistral |  TASK [Delete existing /var/lib/container-puppet/check-mode for check mode] *****
2019-06-05 14:06:32,815 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:166
2019-06-05 14:06:32,815 p=17240 u=mistral |  Wednesday 05 June 2019  14:06:32 -0500 (0:00:00.145)       0:03:06.584 ******** 
2019-06-05 14:06:32,844 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:06:32,857 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:06:32,880 p=17240 u=mistral |  TASK [Create /var/lib/container-puppet/check-mode for check mode] **************
2019-06-05 14:06:32,880 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:177
2019-06-05 14:06:32,880 p=17240 u=mistral |  Wednesday 05 June 2019  14:06:32 -0500 (0:00:00.065)       0:03:06.650 ******** 
2019-06-05 14:06:32,907 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:06:32,918 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:06:32,941 p=17240 u=mistral |  TASK [Write container-puppet.json file] ****************************************
2019-06-05 14:06:32,941 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:189
2019-06-05 14:06:32,941 p=17240 u=mistral |  Wednesday 05 June 2019  14:06:32 -0500 (0:00:00.061)       0:03:06.711 ******** 
2019-06-05 14:06:33,262 p=17240 u=mistral |  changed: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:33,269 p=17240 u=mistral |  changed: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:33,292 p=17240 u=mistral |  TASK [Diff container-puppet.json changes for check mode] ***********************
2019-06-05 14:06:33,292 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:201
2019-06-05 14:06:33,293 p=17240 u=mistral |  Wednesday 05 June 2019  14:06:33 -0500 (0:00:00.351)       0:03:07.062 ******** 
2019-06-05 14:06:33,320 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:06:33,331 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:06:33,355 p=17240 u=mistral |  TASK [Diff container-puppet.json changes for check mode] ***********************
2019-06-05 14:06:33,355 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:214
2019-06-05 14:06:33,355 p=17240 u=mistral |  Wednesday 05 June 2019  14:06:33 -0500 (0:00:00.062)       0:03:07.124 ******** 
2019-06-05 14:06:33,382 p=17240 u=mistral |  skipping: [lab-controller-0] => {}
2019-06-05 14:06:33,394 p=17240 u=mistral |  skipping: [lab-computehci-0] => {}
2019-06-05 14:06:33,416 p=17240 u=mistral |  TASK [Create /var/lib/container-config-scripts] ********************************
2019-06-05 14:06:33,417 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:224
2019-06-05 14:06:33,417 p=17240 u=mistral |  Wednesday 05 June 2019  14:06:33 -0500 (0:00:00.061)       0:03:07.186 ******** 
2019-06-05 14:06:33,518 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "gid": 0, "group": "root", "mode": "0755", "owner": "root", "path": "/var/lib/container-config-scripts", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:06:33,545 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "gid": 0, "group": "root", "mode": "0755", "owner": "root", "path": "/var/lib/container-config-scripts", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:06:33,571 p=17240 u=mistral |  TASK [Clean old /var/lib/container-startup-configs.json file] ******************
2019-06-05 14:06:33,572 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:235
2019-06-05 14:06:33,572 p=17240 u=mistral |  Wednesday 05 June 2019  14:06:33 -0500 (0:00:00.154)       0:03:07.341 ******** 
2019-06-05 14:06:33,672 p=17240 u=mistral |  ok: [lab-controller-0] => {"changed": false, "path": "/var/lib/container-startup-configs.json", "state": "absent"}
2019-06-05 14:06:33,699 p=17240 u=mistral |  ok: [lab-computehci-0] => {"changed": false, "path": "/var/lib/container-startup-configs.json", "state": "absent"}
2019-06-05 14:06:33,724 p=17240 u=mistral |  TASK [Clean old /var/lib/docker-container-startup-configs.json file] ***********
2019-06-05 14:06:33,724 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:243
2019-06-05 14:06:33,724 p=17240 u=mistral |  Wednesday 05 June 2019  14:06:33 -0500 (0:00:00.152)       0:03:07.493 ******** 
2019-06-05 14:06:33,831 p=17240 u=mistral |  ok: [lab-controller-0] => {"changed": false, "path": "/var/lib/docker-container-startup-configs.json", "state": "absent"}
2019-06-05 14:06:33,850 p=17240 u=mistral |  ok: [lab-computehci-0] => {"changed": false, "path": "/var/lib/docker-container-startup-configs.json", "state": "absent"}
2019-06-05 14:06:33,874 p=17240 u=mistral |  TASK [Write container config scripts] ******************************************
2019-06-05 14:06:33,874 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:251
2019-06-05 14:06:33,874 p=17240 u=mistral |  Wednesday 05 June 2019  14:06:33 -0500 (0:00:00.150)       0:03:07.643 ******** 
2019-06-05 14:06:34,191 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:34,246 p=17240 u=mistral |  changed: [lab-computehci-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:34,507 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:34,563 p=17240 u=mistral |  changed: [lab-computehci-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:34,809 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:34,880 p=17240 u=mistral |  changed: [lab-computehci-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:35,106 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:35,190 p=17240 u=mistral |  changed: [lab-computehci-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:35,400 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:35,401 p=17240 u=mistral |  changed: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:35,499 p=17240 u=mistral |  changed: [lab-computehci-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:35,795 p=17240 u=mistral |  changed: [lab-computehci-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:35,797 p=17240 u=mistral |  changed: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:35,819 p=17240 u=mistral |  TASK [Set container_config_default fact] ***************************************
2019-06-05 14:06:35,819 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:270
2019-06-05 14:06:35,819 p=17240 u=mistral |  Wednesday 05 June 2019  14:06:35 -0500 (0:00:01.945)       0:03:09.589 ******** 
2019-06-05 14:06:35,846 p=17240 u=mistral |  ok: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:06:35,856 p=17240 u=mistral |  ok: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:06:35,866 p=17240 u=mistral |  ok: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:06:35,869 p=17240 u=mistral |  ok: [lab-computehci-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:06:35,878 p=17240 u=mistral |  ok: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:06:35,881 p=17240 u=mistral |  ok: [lab-computehci-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:06:35,888 p=17240 u=mistral |  ok: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:06:35,898 p=17240 u=mistral |  ok: [lab-computehci-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:06:35,900 p=17240 u=mistral |  ok: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:06:35,901 p=17240 u=mistral |  ok: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:06:35,904 p=17240 u=mistral |  ok: [lab-computehci-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:06:35,916 p=17240 u=mistral |  ok: [lab-computehci-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:06:35,930 p=17240 u=mistral |  ok: [lab-computehci-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:06:35,931 p=17240 u=mistral |  ok: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:06:35,954 p=17240 u=mistral |  TASK [Set container_startup_configs_with_default fact] *************************
2019-06-05 14:06:35,954 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:278
2019-06-05 14:06:35,954 p=17240 u=mistral |  Wednesday 05 June 2019  14:06:35 -0500 (0:00:00.134)       0:03:09.723 ******** 
2019-06-05 14:06:36,053 p=17240 u=mistral |  ok: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:06:36,260 p=17240 u=mistral |  ok: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:06:36,283 p=17240 u=mistral |  TASK [Write per-step container startup configs] ********************************
2019-06-05 14:06:36,283 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:287
2019-06-05 14:06:36,283 p=17240 u=mistral |  Wednesday 05 June 2019  14:06:36 -0500 (0:00:00.328)       0:03:10.052 ******** 
2019-06-05 14:06:36,603 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:36,610 p=17240 u=mistral |  changed: [lab-computehci-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:36,889 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:36,892 p=17240 u=mistral |  changed: [lab-computehci-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:37,175 p=17240 u=mistral |  changed: [lab-computehci-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:37,176 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:37,462 p=17240 u=mistral |  changed: [lab-computehci-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:37,473 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:37,750 p=17240 u=mistral |  changed: [lab-computehci-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:37,759 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:38,035 p=17240 u=mistral |  changed: [lab-computehci-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:38,036 p=17240 u=mistral |  changed: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:38,043 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:38,045 p=17240 u=mistral |  changed: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:38,069 p=17240 u=mistral |  TASK [Create /var/lib/kolla/config_files directory] ****************************
2019-06-05 14:06:38,069 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:300
2019-06-05 14:06:38,069 p=17240 u=mistral |  Wednesday 05 June 2019  14:06:38 -0500 (0:00:01.786)       0:03:11.839 ******** 
2019-06-05 14:06:38,169 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "gid": 0, "group": "root", "mode": "0755", "owner": "root", "path": "/var/lib/kolla/config_files", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:06:38,193 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "gid": 0, "group": "root", "mode": "0755", "owner": "root", "path": "/var/lib/kolla/config_files", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:06:38,217 p=17240 u=mistral |  TASK [Create /var/lib/config-data directory] ***********************************
2019-06-05 14:06:38,217 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:310
2019-06-05 14:06:38,217 p=17240 u=mistral |  Wednesday 05 June 2019  14:06:38 -0500 (0:00:00.147)       0:03:11.987 ******** 
2019-06-05 14:06:38,316 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "gid": 0, "group": "root", "mode": "0755", "owner": "root", "path": "/var/lib/config-data", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:06:38,342 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "gid": 0, "group": "root", "mode": "0755", "owner": "root", "path": "/var/lib/config-data", "secontext": "unconfined_u:object_r:container_file_t:s0", "size": 6, "state": "directory", "uid": 0}
2019-06-05 14:06:38,365 p=17240 u=mistral |  TASK [Write kolla config json files] *******************************************
2019-06-05 14:06:38,365 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:317
2019-06-05 14:06:38,366 p=17240 u=mistral |  Wednesday 05 June 2019  14:06:38 -0500 (0:00:00.148)       0:03:12.135 ******** 
2019-06-05 14:06:38,712 p=17240 u=mistral |  changed: [lab-computehci-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:38,758 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:38,997 p=17240 u=mistral |  changed: [lab-computehci-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:39,048 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:39,279 p=17240 u=mistral |  changed: [lab-computehci-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:39,331 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:39,573 p=17240 u=mistral |  changed: [lab-computehci-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:39,618 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:39,864 p=17240 u=mistral |  changed: [lab-computehci-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:39,903 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:40,157 p=17240 u=mistral |  changed: [lab-computehci-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:40,192 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:40,441 p=17240 u=mistral |  changed: [lab-computehci-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:40,475 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:40,726 p=17240 u=mistral |  changed: [lab-computehci-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:40,760 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:41,008 p=17240 u=mistral |  changed: [lab-computehci-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:41,009 p=17240 u=mistral |  changed: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:41,043 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:41,354 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:41,626 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:41,911 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:42,182 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:42,457 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:42,735 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:43,009 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:43,283 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:43,553 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:43,824 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:44,097 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:44,369 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:44,642 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:44,926 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:45,198 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:45,469 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:45,740 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:46,010 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:46,283 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:46,555 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:46,826 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:47,096 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:47,367 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:47,643 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:47,937 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:48,211 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:48,484 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:48,754 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:49,030 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:49,302 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:49,575 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:49,862 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:50,135 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:50,409 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:50,684 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:50,954 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:51,227 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:51,499 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:51,772 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:52,042 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:52,317 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:52,586 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:52,860 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:53,131 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:53,407 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:53,688 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:53,957 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:54,228 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:54,502 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:54,774 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:55,045 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:55,315 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:55,591 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:55,874 p=17240 u=mistral |  changed: [lab-controller-0] => (item=None) => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:55,879 p=17240 u=mistral |  changed: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:06:55,903 p=17240 u=mistral |  TASK [Set host puppet debugging fact string] ***********************************
2019-06-05 14:06:55,903 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:335
2019-06-05 14:06:55,903 p=17240 u=mistral |  Wednesday 05 June 2019  14:06:55 -0500 (0:00:17.537)       0:03:29.672 ******** 
2019-06-05 14:06:55,932 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:06:55,945 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:06:55,970 p=17240 u=mistral |  TASK [Check for /etc/puppet/check-mode directory for check mode] ***************
2019-06-05 14:06:55,970 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:344
2019-06-05 14:06:55,970 p=17240 u=mistral |  Wednesday 05 June 2019  14:06:55 -0500 (0:00:00.066)       0:03:29.739 ******** 
2019-06-05 14:06:55,997 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:06:56,013 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:06:56,038 p=17240 u=mistral |  TASK [Create /etc/puppet/check-mode/hieradata directory for check mode] ********
2019-06-05 14:06:56,038 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:353
2019-06-05 14:06:56,038 p=17240 u=mistral |  Wednesday 05 June 2019  14:06:56 -0500 (0:00:00.068)       0:03:29.808 ******** 
2019-06-05 14:06:56,066 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:06:56,076 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:06:56,100 p=17240 u=mistral |  TASK [Write the config_step hieradata] *****************************************
2019-06-05 14:06:56,100 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:368
2019-06-05 14:06:56,100 p=17240 u=mistral |  Wednesday 05 June 2019  14:06:56 -0500 (0:00:00.061)       0:03:29.869 ******** 
2019-06-05 14:06:56,358 p=17240 u=mistral |  ok: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:06:56,378 p=17240 u=mistral |  ok: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:06:56,401 p=17240 u=mistral |  TASK [Create puppet check-mode files if they don't exist for check mode] *******
2019-06-05 14:06:56,402 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:379
2019-06-05 14:06:56,402 p=17240 u=mistral |  Wednesday 05 June 2019  14:06:56 -0500 (0:00:00.301)       0:03:30.171 ******** 
2019-06-05 14:06:56,429 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:06:56,440 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:06:56,465 p=17240 u=mistral |  TASK [Run puppet host configuration for step 1] ********************************
2019-06-05 14:06:56,465 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:392
2019-06-05 14:06:56,465 p=17240 u=mistral |  Wednesday 05 June 2019  14:06:56 -0500 (0:00:00.063)       0:03:30.234 ******** 
2019-06-05 14:07:30,960 p=17240 u=mistral |  changed: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:07:32,884 p=17240 u=mistral |  changed: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:07:32,908 p=17240 u=mistral |  TASK [Debug output for task: Run puppet host configuration for step 1] *********
2019-06-05 14:07:32,908 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:411
2019-06-05 14:07:32,908 p=17240 u=mistral |  Wednesday 05 June 2019  14:07:32 -0500 (0:00:36.443)       0:04:06.678 ******** 
2019-06-05 14:07:32,936 p=17240 u=mistral |  ok: [lab-controller-0] => {
    "failed_when_result": false, 
    "outputs.stdout_lines | default([]) | union(outputs.stderr_lines | default([]))": [
        "Changes:", 
        "            Total: 86", 
        "Events:", 
        "          Success: 86", 
        "Resources:", 
        "        Restarted: 4", 
        "          Changed: 85", 
        "      Out of sync: 85", 
        "            Total: 191", 
        "Time:", 
        "      Concat file: 0.00", 
        "           Anchor: 0.00", 
        "         Schedule: 0.00", 
        "             Cron: 0.00", 
        "   Package manifest: 0.00", 
        "           Augeas: 0.02", 
        "           Sysctl: 0.08", 
        "             File: 0.09", 
        "          Package: 0.11", 
        "   Sysctl runtime: 0.18", 
        "         Firewall: 0.28", 
        "          Service: 0.56", 
        "   Config retrieval: 1.21", 
        "         Last run: 1559761650", 
        "             Exec: 2.13", 
        "   Transaction evaluation: 29.65", 
        "   Catalog application: 29.69", 
        "   Concat fragment: 0.00", 
        "       Filebucket: 0.00", 
        "            Total: 29.69", 
        "Version:", 
        "           Config: 1559761619", 
        "           Puppet: 5.5.10", 
        "error: Could not connect to cluster (is it running?)"
    ]
}
2019-06-05 14:07:32,954 p=17240 u=mistral |  ok: [lab-computehci-0] => {
    "failed_when_result": false, 
    "outputs.stdout_lines | default([]) | union(outputs.stderr_lines | default([]))": [
        "Changes:", 
        "            Total: 109", 
        "Events:", 
        "          Success: 109", 
        "Resources:", 
        "          Changed: 108", 
        "      Out of sync: 108", 
        "        Restarted: 4", 
        "            Total: 144", 
        "Time:", 
        "         Schedule: 0.00", 
        "             Cron: 0.00", 
        "   Package manifest: 0.00", 
        "           Augeas: 0.02", 
        "             File: 0.05", 
        "           Sysctl: 0.06", 
        "          Package: 0.12", 
        "   Sysctl runtime: 0.20", 
        "          Service: 0.49", 
        "   Config retrieval: 0.96", 
        "         Firewall: 1.37", 
        "         Last run: 1559761652", 
        "             Exec: 3.48", 
        "       Filebucket: 0.00", 
        "   Transaction evaluation: 31.73", 
        "   Catalog application: 31.78", 
        "   Concat fragment: 0.00", 
        "      Concat file: 0.00", 
        "           Anchor: 0.00", 
        "            Total: 31.78", 
        "Version:", 
        "           Config: 1559761619", 
        "           Puppet: 5.5.10", 
        "error: Could not connect to cluster (is it running?)"
    ]
}
2019-06-05 14:07:32,978 p=17240 u=mistral |  TASK [Run container-puppet tasks (generate config) during step 1] **************
2019-06-05 14:07:32,978 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:426
2019-06-05 14:07:32,978 p=17240 u=mistral |  Wednesday 05 June 2019  14:07:32 -0500 (0:00:00.069)       0:04:06.747 ******** 
2019-06-05 14:08:50,525 p=17240 u=mistral |  ok: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:10:18,516 p=17240 u=mistral |  ok: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:10:18,542 p=17240 u=mistral |  TASK [Debug output for task: Run container-puppet tasks (generate config) during step 1] ***
2019-06-05 14:10:18,542 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:449
2019-06-05 14:10:18,542 p=17240 u=mistral |  Wednesday 05 June 2019  14:10:18 -0500 (0:02:45.563)       0:06:52.311 ******** 
2019-06-05 14:10:18,692 p=17240 u=mistral |  ok: [lab-computehci-0] => {
    "failed_when_result": false, 
    "outputs.stdout_lines | default([]) | union(outputs.stderr_lines | default([]))": [
        "2019-06-05 19:07:33,280 INFO: 36264 -- Running container-puppet", 
        "2019-06-05 19:07:33,281 INFO: 36264 -- Service compilation completed.", 
        "2019-06-05 19:07:33,281 INFO: 36264 -- Starting multiprocess configuration steps.  Using 6 processes.", 
        "2019-06-05 19:07:33,288 INFO: 36267 -- Starting configuration of ceilometer using image docker.io/tripleostein/centos-binary-ceilometer-central:current-tripleo-rdo", 
        "2019-06-05 19:07:33,289 INFO: 36269 -- Starting configuration of iscsid using image docker.io/tripleostein/centos-binary-iscsid:current-tripleo-rdo", 
        "2019-06-05 19:07:33,289 INFO: 36268 -- Starting configuration of nova_libvirt using image docker.io/tripleostein/centos-binary-nova-compute:current-tripleo-rdo", 
        "2019-06-05 19:07:33,291 INFO: 36270 -- Starting configuration of ovn_controller using image docker.io/tripleostein/centos-binary-ovn-controller:current-tripleo-rdo", 
        "2019-06-05 19:07:33,291 INFO: 36271 -- Starting configuration of crond using image docker.io/tripleostein/centos-binary-cron:current-tripleo-rdo", 
        "2019-06-05 19:07:33,291 INFO: 36272 -- Starting configuration of neutron using image docker.io/tripleostein/centos-binary-neutron-server-ovn:current-tripleo-rdo", 
        "2019-06-05 19:07:33,515 INFO: 36270 -- Removing container: container-puppet-ovn_controller", 
        "2019-06-05 19:07:33,577 INFO: 36271 -- Removing container: container-puppet-crond", 
        "2019-06-05 19:07:33,804 INFO: 36268 -- Removing container: container-puppet-nova_libvirt", 
        "2019-06-05 19:07:34,036 INFO: 36267 -- Removing container: container-puppet-ceilometer", 
        "2019-06-05 19:07:34,208 INFO: 36269 -- Removing container: container-puppet-iscsid", 
        "2019-06-05 19:07:34,546 INFO: 36272 -- Removing container: container-puppet-neutron", 
        "2019-06-05 19:07:34,666 INFO: 36270 -- Pulling image: docker.io/tripleostein/centos-binary-ovn-controller:current-tripleo-rdo", 
        "2019-06-05 19:07:34,924 INFO: 36271 -- Pulling image: docker.io/tripleostein/centos-binary-cron:current-tripleo-rdo", 
        "2019-06-05 19:07:35,088 INFO: 36268 -- Pulling image: docker.io/tripleostein/centos-binary-nova-compute:current-tripleo-rdo", 
        "2019-06-05 19:07:35,343 INFO: 36269 -- Pulling image: docker.io/tripleostein/centos-binary-iscsid:current-tripleo-rdo", 
        "2019-06-05 19:07:35,397 INFO: 36267 -- Pulling image: docker.io/tripleostein/centos-binary-ceilometer-central:current-tripleo-rdo", 
        "2019-06-05 19:07:35,532 INFO: 36272 -- Pulling image: docker.io/tripleostein/centos-binary-neutron-server-ovn:current-tripleo-rdo", 
        "2019-06-05 19:08:09,971 WARNING: 36270 -- podman pull failed: Trying to pull docker://docker.io/tripleostein/centos-binary-ovn-controller:current-tripleo-rdo...Getting image source signatures", 
        "Copying blob sha256:c0862342b9e7a81856422b95348a2d1952b46e01df6c72f74d94cac2c5815c51", 
        "Copying blob sha256:5b8f702199c16fd0d5c9c4d0028550b144acb532f4a6b8200b3f53e1cbc43aba", 
        "Copying blob sha256:31c8fa1ceee01b746a6b64c4718f5e42e867c08532b29f8d33626a8385327ede", 
        "Copying blob sha256:a35613cff6f04cbfd2f3b845d5a923d56d6f2fb718f85784e8fdcd97ae77846e", 
        "Copying blob sha256:8ba884070f611d31cb2c42eddb691319dc9facf5e0ec67672fcfa135181ab3df", 
        "Copying blob sha256:0f2be6d2e8e6e42cb3e633544d0b1aa8328bd7004a3a4b1dfc0c7a6ba14cd0c7", 
        "Copying blob sha256:0fc1fd86055457f85a0cb3f333292570aaa2803c4b556966847f55f8f3544fa8", 
        "Copying blob sha256:c80c3921174be89bdd60d2454983524a19a15b09f26f47b6822e6440d5939973", 
        "Copying blob sha256:d36b87fd0812d0e39ef92e729105260f496efbfb19ad7b6981218862502aa0f3", 
        "Copying blob sha256:2799d99efade4475ca55aad34887eabf4e9ec76e592bc0b0a80cbd8d01080ffc", 
        "Copying blob sha256:6310d6ac1536a2eb8e769d217451e2c6d420eb3c39b0fb1b9ad088a73ea67211", 
        "Copying blob sha256:46d3c6aa676de9a0ee74cfac77cced69fb7a4df7c5b9e8a7ef33922881d87c81", 
        "Copying blob sha256:fc3b29499fda939e998b0c14c6e98720e1cb7a66fd1ce884cad8d64a63669cf4", 
        "Copying blob sha256:b9846bbbebab5607bb743a5e4f50c07967ae16a461e65c862bd21028e59faf58", 
        "Copying blob sha256:2cc44a4e32219b5aad308d7d3bdc5ba18788e8830c0cf3aa9056e1d0dc647058", 
        "Copying blob sha256:89c8d96f0d37376ba1f54c92128660aaea0a802cb9d9d396a45366b02fc589cc", 
        "Copying blob sha256:ccae8e3351ac86f5c7d66e9c84321057c9f05063428851fa0f1c17946090212d", 
        "Copying blob sha256:a60799747bf1ae164a3509aefe1a60b8faf89ebeeac00f81309e984e4b351a0c", 
        "Copying blob sha256:68ff526217749f85694f4ecc42f60077a24679a69ccbe48915ca4fd575841f0b", 
        "Copying blob sha256:d7fd089bb17e5cbf93092b1825b7b49c6dac8f2341507a8a5488854b0ee5d695", 
        "Copying blob sha256:ffe31f7d08a0268aa81e6e20b0e129e9ba91d4182aac483ce2a78c9bb638da22", 
        "Copying blob sha256:cfa5b9482eec0a0eb2752118a5a5dfc3d86a14d9ff5540f3608b19e4b88b4bff", 
        "Copying blob sha256:45d804df81db3a3f58373c31a92eb2484c2b9038ec59d86fed68b6ce62565939", 
        "Copying blob sha256:f2b2206b49b6c8f792882ae9cc869619aa9806ac539f40f02be548c53ddf4cfb", 
        "Copying blob sha256:957fca782c67875fb57f10cc632f82848848485bc10effa1ea802b69f4b552b9", 
        "time=\"2019-06-05T19:08:06Z\" level=error msg=\"Error pulling image ref //tripleostein/centos-binary-ovn-controller:current-tripleo-rdo: Error reading blob sha256:d6dbd69ea530292192935158b778ccffc396ead2093138f75c6e1fa33b7a17fa: Get https://registry-1.docker.io/v2/tripleostein/centos-binary-ovn-controller/blobs/sha256:d6dbd69ea530292192935158b778ccffc396ead2093138f75c6e1fa33b7a17fa: dial tcp: lookup registry-1.docker.io on 1.0.0.1:53: read udp 192.168.122.152:55703->1.0.0.1:53: i/o timeout\" ", 
        "Failed", 
        "(0x5570b45ad420,0xc422576a20)", 
        "Error: error pulling image \"docker.io/tripleostein/centos-binary-ovn-controller:current-tripleo-rdo\": Invalid image name \"docker.io/tripleostein/centos-binary-ovn-controller:current-tripleo-rdo\", unknown transport \"docker.io/tripleostein/centos-binary-ovn-controller\"", 
        "", 
        "2019-06-05 19:08:09,971 WARNING: 36270 -- retrying pulling image: docker.io/tripleostein/centos-binary-ovn-controller:current-tripleo-rdo", 
        "2019-06-05 19:08:12,893 WARNING: 36267 -- podman pull failed: Trying to pull docker://docker.io/tripleostein/centos-binary-ceilometer-central:current-tripleo-rdo...Getting image source signatures", 
        "Copying blob sha256:d6dbd69ea530292192935158b778ccffc396ead2093138f75c6e1fa33b7a17fa", 
        "Copying blob sha256:5b89a36d5e9e14c5ac5981e8ed2304bb8ce19da7d91793f44c48ac17e7b03717", 
        "Copying blob sha256:98d5e2479617c862dcad487a2c52021bc16e516ebafe9fdab6b3eb8648b73f57", 
        "Copying blob sha256:bd6e2c36ff0e45e35121c3bc2cb54f803eb809aacb2778260d4211de2ba9fabb", 
        "Copying blob sha256:921488feccf56d8c8eb6086cd998b48f907fa44dbc5e7cf8525efd96f7c1f776", 
        "Copying blob sha256:f68d231cf9d36f0c6d1381c301b6afe0d2450100d736078b83c7891c513f6da0", 
        "Copying blob sha256:e262843cdaf24781dce31bdcdee7c4f4b4be29e4ef40215d73e2179608590dfd", 
        "Copying blob sha256:43af3b756ca1ae55bd452e50e5a8bac8b1f4791a9ca3dfa71edf28a754ab34b7", 
        "Copying blob sha256:7971653943cd097a7807d1f3e029791a226ea79c01560ae7168efea6e683f431", 
        "Copying blob sha256:343f9f42dd124dbd53b97d676c7702f6308aa52ad4e28983f1aa15f733d48213", 
        "Copying blob sha256:85874d270e7b70dfef84b9530a74bedcf7ae3d5f38c500ec033cd03b5cd15214", 
        "Copying blob sha256:e916b8a446f9ff8e13f7398ccca737459243baf513a8c1e81edbac2f653c3e6b", 
        "Copying blob sha256:7b039b08dab2afc8041191de69306123e93cfbd3064629a93a83686bd08f175e", 
        "time=\"2019-06-05T19:08:09Z\" level=error msg=\"Error pulling image ref //tripleostein/centos-binary-ceilometer-central:current-tripleo-rdo: Error reading blob sha256:8ba884070f611d31cb2c42eddb691319dc9facf5e0ec67672fcfa135181ab3df: Get https://production.cloudflare.docker.com/registry-v2/docker/registry/v2/blobs/sha256/8b/8ba884070f611d31cb2c42eddb691319dc9facf5e0ec67672fcfa135181ab3df/data?verify=1559764663-u6zxj6Ruf9erq6FQzsIE5l9U9xI%3D: dial tcp: lookup production.cloudflare.docker.com on 1.0.0.1:53: read udp 192.168.122.152:42950->1.0.0.1:53: i/o timeout\" ", 
        "(0x55ef4d847420,0xc42048b760)", 
        "Error: error pulling image \"docker.io/tripleostein/centos-binary-ceilometer-central:current-tripleo-rdo\": Invalid image name \"docker.io/tripleostein/centos-binary-ceilometer-central:current-tripleo-rdo\", unknown transport \"docker.io/tripleostein/centos-binary-ceilometer-central\"", 
        "2019-06-05 19:08:12,894 WARNING: 36267 -- retrying pulling image: docker.io/tripleostein/centos-binary-ceilometer-central:current-tripleo-rdo", 
        "2019-06-05 19:08:23,127 WARNING: 36271 -- + mkdir -p /etc/puppet", 
        "+ cp -dR /tmp/puppet-etc/auth.conf /tmp/puppet-etc/hiera.yaml /tmp/puppet-etc/hieradata /tmp/puppet-etc/modules /tmp/puppet-etc/puppet.conf /tmp/puppet-etc/ssl /etc/puppet", 
        "+ rm -Rf /etc/puppet/ssl", 
        "+ echo '{\"step\": 6}'", 
        "+ TAGS=", 
        "+ '[' -n file,file_line,concat,augeas,cron ']'", 
        "+ TAGS='--tags file,file_line,concat,augeas,cron'", 
        "+ CHECK_MODE=", 
        "+ '[' -d /tmp/puppet-check-mode ']'", 
        "+ origin_of_time=/var/lib/config-data/crond.origin_of_time", 
        "+ touch /var/lib/config-data/crond.origin_of_time", 
        "+ sync", 
        "+ export NET_HOST=true", 
        "+ NET_HOST=true", 
        "+ set +e", 
        "+ '[' true == false ']'", 
        "+ export FACTER_deployment_type=containers", 
        "+ FACTER_deployment_type=containers", 
        "++ cat /sys/class/dmi/id/product_uuid", 
        "++ tr '[:upper:]' '[:lower:]'", 
        "+ export FACTER_uuid=9071b88e-f5d7-41db-b1ab-c88aaa8c4f0c", 
        "+ FACTER_uuid=9071b88e-f5d7-41db-b1ab-c88aaa8c4f0c", 
        "+ /usr/bin/puppet apply --summarize --detailed-exitcodes --color=false --logdest syslog --logdest console --modulepath=/etc/puppet/modules:/usr/share/openstack-puppet/modules --tags file,file_line,concat,augeas,cron /etc/config.pp", 
        "+ rc=2", 
        "+ set -e", 
        "+ '[' 2 -ne 2 -a 2 -ne 0 ']'", 
        "+ '[' -z '' ']'", 
        "+ archivedirs=(\"/etc\" \"/root\" \"/opt\" \"/var/lib/ironic/tftpboot\" \"/var/lib/ironic/httpboot\" \"/var/www\" \"/var/spool/cron\" \"/var/lib/nova/.ssh\")", 
        "+ rsync_srcs=", 
        "+ for d in '\"${archivedirs[@]}\"'", 
        "+ '[' -d /etc ']'", 
        "+ rsync_srcs+=' /etc'", 
        "+ '[' -d /root ']'", 
        "+ rsync_srcs+=' /root'", 
        "+ '[' -d /opt ']'", 
        "+ rsync_srcs+=' /opt'", 
        "+ '[' -d /var/lib/ironic/tftpboot ']'", 
        "+ '[' -d /var/lib/ironic/httpboot ']'", 
        "+ '[' -d /var/www ']'", 
        "+ '[' -d /var/spool/cron ']'", 
        "+ rsync_srcs+=' /var/spool/cron'", 
        "+ '[' -d /var/lib/nova/.ssh ']'", 
        "+ password_files=/root/.my.cnf", 
        "+ exclude_files=", 
        "+ for p in '$password_files'", 
        "+ '[' -f /root/.my.cnf -a -f /var/lib/config-data/crond/root/.my.cnf ']'", 
        "+ rsync -a -R --delay-updates --delete-after /etc /root /opt /var/spool/cron /var/lib/config-data/crond", 
        "++ stat -c %y /var/lib/config-data/crond.origin_of_time", 
        "+ echo 'Gathering files modified after 2019-06-05 19:08:11.648692431 +0000'", 
        "+ mkdir -p /var/lib/config-data/puppet-generated/crond", 
        "+ rsync -a -R -0 --delay-updates --delete-after --files-from=/dev/fd/63 / /var/lib/config-data/puppet-generated/crond", 
        "++ find /etc /root /opt /var/spool/cron -newer /var/lib/config-data/crond.origin_of_time -not -path '/etc/puppet*' -print0", 
        "+ additional_checksum_files=", 
        "+ excluded_original_passwords=", 
        "+ '[' -f /root/.my.cnf ']'", 
        "+ EXCLUDE='--exclude=*/etc/swift/backups/* --exclude=*/etc/libvirt/passwd.db '", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/crond", 
        "+ tar xO", 
        "+ sed '/^#.*HEADER.*/d'", 
        "+ md5sum", 
        "+ awk '{print $1}'", 
        "tar: Removing leading `/' from member names", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/puppet-generated/crond --mtime=1970-01-01", 
        "2019-06-05 19:08:23,127 INFO: 36271 -- Removing container: container-puppet-crond", 
        "2019-06-05 19:08:23,875 INFO: 36271 -- Finished processing puppet configs for crond", 
        "2019-06-05 19:08:40,948 WARNING: 36269 -- + mkdir -p /etc/puppet", 
        "+ '[' -n file,file_line,concat,augeas,cron,iscsid_config ']'", 
        "+ TAGS='--tags file,file_line,concat,augeas,cron,iscsid_config'", 
        "+ origin_of_time=/var/lib/config-data/iscsid.origin_of_time", 
        "+ touch /var/lib/config-data/iscsid.origin_of_time", 
        "+ /usr/bin/puppet apply --summarize --detailed-exitcodes --color=false --logdest syslog --logdest console --modulepath=/etc/puppet/modules:/usr/share/openstack-puppet/modules --tags file,file_line,concat,augeas,cron,iscsid_config /etc/config.pp", 
        "+ '[' -f /root/.my.cnf -a -f /var/lib/config-data/iscsid/root/.my.cnf ']'", 
        "+ rsync -a -R --delay-updates --delete-after /etc /root /opt /var/spool/cron /var/lib/config-data/iscsid", 
        "++ stat -c %y /var/lib/config-data/iscsid.origin_of_time", 
        "+ echo 'Gathering files modified after 2019-06-05 19:08:34.516027724 +0000'", 
        "+ mkdir -p /var/lib/config-data/puppet-generated/iscsid", 
        "+ rsync -a -R -0 --delay-updates --delete-after --files-from=/dev/fd/63 / /var/lib/config-data/puppet-generated/iscsid", 
        "++ find /etc /root /opt /var/spool/cron -newer /var/lib/config-data/iscsid.origin_of_time -not -path '/etc/puppet*' -print0", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/iscsid", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/puppet-generated/iscsid --mtime=1970-01-01", 
        "2019-06-05 19:08:40,949 INFO: 36269 -- Removing container: container-puppet-iscsid", 
        "2019-06-05 19:08:41,213 INFO: 36269 -- Finished processing puppet configs for iscsid", 
        "2019-06-05 19:08:43,576 WARNING: 36272 -- + mkdir -p /etc/puppet", 
        "+ '[' -n file,file_line,concat,augeas,cron,neutron_config,ovn_metadata_agent_config ']'", 
        "+ TAGS='--tags file,file_line,concat,augeas,cron,neutron_config,ovn_metadata_agent_config'", 
        "+ origin_of_time=/var/lib/config-data/neutron.origin_of_time", 
        "+ touch /var/lib/config-data/neutron.origin_of_time", 
        "+ /usr/bin/puppet apply --summarize --detailed-exitcodes --color=false --logdest syslog --logdest console --modulepath=/etc/puppet/modules:/usr/share/openstack-puppet/modules --tags file,file_line,concat,augeas,cron,neutron_config,ovn_metadata_agent_config /etc/config.pp", 
        "net_mlx5: cannot load glue library: libibverbs.so.1: cannot open shared object file: No such file or directory", 
        "net_mlx5: cannot initialize PMD due to missing run-time dependency on rdma-core libraries (libibverbs, libmlx5)", 
        "PMD: net_mlx4: cannot load glue library: libibverbs.so.1: cannot open shared object file: No such file or directory", 
        "PMD: net_mlx4: cannot initialize PMD due to missing run-time dependency on rdma-core libraries (libibverbs, libmlx4)", 
        "+ rsync_srcs+=' /var/www'", 
        "+ '[' -f /root/.my.cnf -a -f /var/lib/config-data/neutron/root/.my.cnf ']'", 
        "+ rsync -a -R --delay-updates --delete-after /etc /root /opt /var/www /var/spool/cron /var/lib/config-data/neutron", 
        "++ stat -c %y /var/lib/config-data/neutron.origin_of_time", 
        "+ echo 'Gathering files modified after 2019-06-05 19:08:34.480027196 +0000'", 
        "+ mkdir -p /var/lib/config-data/puppet-generated/neutron", 
        "+ rsync -a -R -0 --delay-updates --delete-after --files-from=/dev/fd/63 / /var/lib/config-data/puppet-generated/neutron", 
        "++ find /etc /root /opt /var/www /var/spool/cron -newer /var/lib/config-data/neutron.origin_of_time -not -path '/etc/puppet*' -print0", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/neutron", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/puppet-generated/neutron --mtime=1970-01-01", 
        "2019-06-05 19:08:43,576 INFO: 36272 -- Removing container: container-puppet-neutron", 
        "2019-06-05 19:08:43,936 INFO: 36272 -- Finished processing puppet configs for neutron", 
        "2019-06-05 19:08:46,415 WARNING: 36270 -- + mkdir -p /etc/puppet", 
        "+ '[' -n file,file_line,concat,augeas,cron,vs_config,exec ']'", 
        "+ TAGS='--tags file,file_line,concat,augeas,cron,vs_config,exec'", 
        "+ origin_of_time=/var/lib/config-data/ovn_controller.origin_of_time", 
        "+ touch /var/lib/config-data/ovn_controller.origin_of_time", 
        "+ /usr/bin/puppet apply --summarize --detailed-exitcodes --color=false --logdest syslog --logdest console --modulepath=/etc/puppet/modules:/usr/share/openstack-puppet/modules --tags file,file_line,concat,augeas,cron,vs_config,exec /etc/config.pp", 
        "+ '[' -f /root/.my.cnf -a -f /var/lib/config-data/ovn_controller/root/.my.cnf ']'", 
        "+ rsync -a -R --delay-updates --delete-after /etc /root /opt /var/spool/cron /var/lib/config-data/ovn_controller", 
        "++ stat -c %y /var/lib/config-data/ovn_controller.origin_of_time", 
        "+ echo 'Gathering files modified after 2019-06-05 19:08:40.121109909 +0000'", 
        "+ mkdir -p /var/lib/config-data/puppet-generated/ovn_controller", 
        "+ rsync -a -R -0 --delay-updates --delete-after --files-from=/dev/fd/63 / /var/lib/config-data/puppet-generated/ovn_controller", 
        "++ find /etc /root /opt /var/spool/cron -newer /var/lib/config-data/ovn_controller.origin_of_time -not -path '/etc/puppet*' -print0", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/ovn_controller", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/puppet-generated/ovn_controller --mtime=1970-01-01", 
        "2019-06-05 19:08:46,415 INFO: 36270 -- Removing container: container-puppet-ovn_controller", 
        "2019-06-05 19:08:46,680 INFO: 36270 -- Finished processing puppet configs for ovn_controller", 
        "2019-06-05 19:08:47,195 WARNING: 36267 -- + mkdir -p /etc/puppet", 
        "+ '[' -n file,file_line,concat,augeas,cron,ceilometer_config ']'", 
        "+ TAGS='--tags file,file_line,concat,augeas,cron,ceilometer_config'", 
        "+ origin_of_time=/var/lib/config-data/ceilometer.origin_of_time", 
        "+ touch /var/lib/config-data/ceilometer.origin_of_time", 
        "+ /usr/bin/puppet apply --summarize --detailed-exitcodes --color=false --logdest syslog --logdest console --modulepath=/etc/puppet/modules:/usr/share/openstack-puppet/modules --tags file,file_line,concat,augeas,cron,ceilometer_config /etc/config.pp", 
        "+ '[' -f /root/.my.cnf -a -f /var/lib/config-data/ceilometer/root/.my.cnf ']'", 
        "+ rsync -a -R --delay-updates --delete-after /etc /root /opt /var/spool/cron /var/lib/config-data/ceilometer", 
        "++ stat -c %y /var/lib/config-data/ceilometer.origin_of_time", 
        "+ echo 'Gathering files modified after 2019-06-05 19:08:39.632102739 +0000'", 
        "+ mkdir -p /var/lib/config-data/puppet-generated/ceilometer", 
        "+ rsync -a -R -0 --delay-updates --delete-after --files-from=/dev/fd/63 / /var/lib/config-data/puppet-generated/ceilometer", 
        "++ find /etc /root /opt /var/spool/cron -newer /var/lib/config-data/ceilometer.origin_of_time -not -path '/etc/puppet*' -print0", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/ceilometer", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/puppet-generated/ceilometer --mtime=1970-01-01", 
        "2019-06-05 19:08:47,195 INFO: 36267 -- Removing container: container-puppet-ceilometer", 
        "2019-06-05 19:08:47,325 INFO: 36267 -- Finished processing puppet configs for ceilometer", 
        "2019-06-05 19:08:50,279 WARNING: 36268 -- + mkdir -p /etc/puppet", 
        "+ '[' -n file,file_line,concat,augeas,cron,nova_config,nova_paste_api_ini,libvirtd_config,nova_config,file,libvirt_tls_password ']'", 
        "+ TAGS='--tags file,file_line,concat,augeas,cron,nova_config,nova_paste_api_ini,libvirtd_config,nova_config,file,libvirt_tls_password'", 
        "+ origin_of_time=/var/lib/config-data/nova_libvirt.origin_of_time", 
        "+ touch /var/lib/config-data/nova_libvirt.origin_of_time", 
        "+ /usr/bin/puppet apply --summarize --detailed-exitcodes --color=false --logdest syslog --logdest console --modulepath=/etc/puppet/modules:/usr/share/openstack-puppet/modules --tags file,file_line,concat,augeas,cron,nova_config,nova_paste_api_ini,libvirtd_config,nova_config,file,libvirt_tls_password /etc/config.pp", 
        "ovs-vsctl: unix:/var/run/openvswitch/db.sock: database connection failed (No such file or directory)", 
        "+ rsync_srcs+=' /var/lib/nova/.ssh'", 
        "+ '[' -f /root/.my.cnf -a -f /var/lib/config-data/nova_libvirt/root/.my.cnf ']'", 
        "+ rsync -a -R --delay-updates --delete-after /etc /root /opt /var/spool/cron /var/lib/nova/.ssh /var/lib/config-data/nova_libvirt", 
        "++ stat -c %y /var/lib/config-data/nova_libvirt.origin_of_time", 
        "+ echo 'Gathering files modified after 2019-06-05 19:08:35.988049308 +0000'", 
        "+ mkdir -p /var/lib/config-data/puppet-generated/nova_libvirt", 
        "+ rsync -a -R -0 --delay-updates --delete-after --files-from=/dev/fd/63 / /var/lib/config-data/puppet-generated/nova_libvirt", 
        "++ find /etc /root /opt /var/spool/cron /var/lib/nova/.ssh -newer /var/lib/config-data/nova_libvirt.origin_of_time -not -path '/etc/puppet*' -print0", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/nova_libvirt", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/puppet-generated/nova_libvirt --mtime=1970-01-01", 
        "2019-06-05 19:08:50,280 INFO: 36268 -- Removing container: container-puppet-nova_libvirt", 
        "2019-06-05 19:08:50,465 INFO: 36268 -- Finished processing puppet configs for nova_libvirt"
    ]
}
2019-06-05 14:10:18,894 p=17240 u=mistral |  ok: [lab-controller-0] => {
    "failed_when_result": false, 
    "outputs.stdout_lines | default([]) | union(outputs.stderr_lines | default([]))": [
        "2019-06-05 19:07:33,250 INFO: 15383 -- Running container-puppet", 
        "2019-06-05 19:07:33,251 INFO: 15383 -- Service compilation completed.", 
        "2019-06-05 19:07:33,251 INFO: 15383 -- Starting multiprocess configuration steps.  Using 6 processes.", 
        "2019-06-05 19:07:33,257 INFO: 15386 -- Starting configuration of nova_placement using image docker.io/tripleostein/centos-binary-nova-placement-api:current-tripleo-rdo", 
        "2019-06-05 19:07:33,257 INFO: 15387 -- Starting configuration of heat_api using image docker.io/tripleostein/centos-binary-heat-api:current-tripleo-rdo", 
        "2019-06-05 19:07:33,259 INFO: 15388 -- Starting configuration of mysql using image docker.io/tripleostein/centos-binary-mariadb:current-tripleo-rdo", 
        "2019-06-05 19:07:33,259 INFO: 15389 -- Starting configuration of redis using image docker.io/tripleostein/centos-binary-redis:current-tripleo-rdo", 
        "2019-06-05 19:07:33,260 INFO: 15390 -- Starting configuration of nova using image docker.io/tripleostein/centos-binary-nova-api:current-tripleo-rdo", 
        "2019-06-05 19:07:33,260 INFO: 15391 -- Starting configuration of glance_api using image docker.io/tripleostein/centos-binary-glance-api:current-tripleo-rdo", 
        "2019-06-05 19:07:33,639 INFO: 15388 -- Removing container: container-puppet-mysql", 
        "2019-06-05 19:07:33,695 INFO: 15391 -- Removing container: container-puppet-glance_api", 
        "2019-06-05 19:07:33,813 INFO: 15386 -- Removing container: container-puppet-nova_placement", 
        "2019-06-05 19:07:33,874 INFO: 15387 -- Removing container: container-puppet-heat_api", 
        "2019-06-05 19:07:33,936 INFO: 15389 -- Removing container: container-puppet-redis", 
        "2019-06-05 19:07:34,214 INFO: 15390 -- Removing container: container-puppet-nova", 
        "2019-06-05 19:07:34,272 INFO: 15388 -- Pulling image: docker.io/tripleostein/centos-binary-mariadb:current-tripleo-rdo", 
        "2019-06-05 19:07:34,642 INFO: 15386 -- Pulling image: docker.io/tripleostein/centos-binary-nova-placement-api:current-tripleo-rdo", 
        "2019-06-05 19:07:34,924 INFO: 15387 -- Pulling image: docker.io/tripleostein/centos-binary-heat-api:current-tripleo-rdo", 
        "2019-06-05 19:07:35,002 INFO: 15391 -- Pulling image: docker.io/tripleostein/centos-binary-glance-api:current-tripleo-rdo", 
        "2019-06-05 19:07:35,309 INFO: 15389 -- Pulling image: docker.io/tripleostein/centos-binary-redis:current-tripleo-rdo", 
        "2019-06-05 19:07:35,443 INFO: 15390 -- Pulling image: docker.io/tripleostein/centos-binary-nova-api:current-tripleo-rdo", 
        "2019-06-05 19:08:49,792 WARNING: 15389 -- + mkdir -p /etc/puppet", 
        "+ cp -dR /tmp/puppet-etc/auth.conf /tmp/puppet-etc/hiera.yaml /tmp/puppet-etc/hieradata /tmp/puppet-etc/modules /tmp/puppet-etc/puppet.conf /tmp/puppet-etc/ssl /etc/puppet", 
        "+ rm -Rf /etc/puppet/ssl", 
        "+ echo '{\"step\": 6}'", 
        "+ TAGS=", 
        "+ '[' -n file,file_line,concat,augeas,cron,exec ']'", 
        "+ TAGS='--tags file,file_line,concat,augeas,cron,exec'", 
        "+ CHECK_MODE=", 
        "+ '[' -d /tmp/puppet-check-mode ']'", 
        "+ origin_of_time=/var/lib/config-data/redis.origin_of_time", 
        "+ touch /var/lib/config-data/redis.origin_of_time", 
        "+ sync", 
        "+ export NET_HOST=true", 
        "+ NET_HOST=true", 
        "+ set +e", 
        "+ '[' true == false ']'", 
        "+ export FACTER_deployment_type=containers", 
        "+ FACTER_deployment_type=containers", 
        "++ cat /sys/class/dmi/id/product_uuid", 
        "++ tr '[:upper:]' '[:lower:]'", 
        "+ export FACTER_uuid=ad8c85d9-6f5f-4d90-97fa-e31eefd815d6", 
        "+ FACTER_uuid=ad8c85d9-6f5f-4d90-97fa-e31eefd815d6", 
        "+ /usr/bin/puppet apply --summarize --detailed-exitcodes --color=false --logdest syslog --logdest console --modulepath=/etc/puppet/modules:/usr/share/openstack-puppet/modules --tags file,file_line,concat,augeas,cron,exec /etc/config.pp", 
        "+ rc=2", 
        "+ set -e", 
        "+ '[' 2 -ne 2 -a 2 -ne 0 ']'", 
        "+ '[' -z '' ']'", 
        "+ archivedirs=(\"/etc\" \"/root\" \"/opt\" \"/var/lib/ironic/tftpboot\" \"/var/lib/ironic/httpboot\" \"/var/www\" \"/var/spool/cron\" \"/var/lib/nova/.ssh\")", 
        "+ rsync_srcs=", 
        "+ for d in '\"${archivedirs[@]}\"'", 
        "+ '[' -d /etc ']'", 
        "+ rsync_srcs+=' /etc'", 
        "+ '[' -d /root ']'", 
        "+ rsync_srcs+=' /root'", 
        "+ '[' -d /opt ']'", 
        "+ rsync_srcs+=' /opt'", 
        "+ '[' -d /var/lib/ironic/tftpboot ']'", 
        "+ '[' -d /var/lib/ironic/httpboot ']'", 
        "+ '[' -d /var/www ']'", 
        "+ '[' -d /var/spool/cron ']'", 
        "+ rsync_srcs+=' /var/spool/cron'", 
        "+ '[' -d /var/lib/nova/.ssh ']'", 
        "+ password_files=/root/.my.cnf", 
        "+ exclude_files=", 
        "+ for p in '$password_files'", 
        "+ '[' -f /root/.my.cnf -a -f /var/lib/config-data/redis/root/.my.cnf ']'", 
        "+ rsync -a -R --delay-updates --delete-after /etc /root /opt /var/spool/cron /var/lib/config-data/redis", 
        "++ stat -c %y /var/lib/config-data/redis.origin_of_time", 
        "+ echo 'Gathering files modified after 2019-06-05 19:08:43.179668793 +0000'", 
        "+ mkdir -p /var/lib/config-data/puppet-generated/redis", 
        "+ rsync -a -R -0 --delay-updates --delete-after --files-from=/dev/fd/63 / /var/lib/config-data/puppet-generated/redis", 
        "++ find /etc /root /opt /var/spool/cron -newer /var/lib/config-data/redis.origin_of_time -not -path '/etc/puppet*' -print0", 
        "+ additional_checksum_files=", 
        "+ excluded_original_passwords=", 
        "+ '[' -f /root/.my.cnf ']'", 
        "+ EXCLUDE='--exclude=*/etc/swift/backups/* --exclude=*/etc/libvirt/passwd.db '", 
        "+ tar xO", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/redis", 
        "+ sed '/^#.*HEADER.*/d'", 
        "+ md5sum", 
        "+ awk '{print $1}'", 
        "tar: Removing leading `/' from member names", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/puppet-generated/redis --mtime=1970-01-01", 
        "", 
        "2019-06-05 19:08:49,792 INFO: 15389 -- Removing container: container-puppet-redis", 
        "2019-06-05 19:08:50,137 INFO: 15389 -- Finished processing puppet configs for redis", 
        "2019-06-05 19:08:50,138 INFO: 15389 -- Starting configuration of keepalived using image docker.io/tripleostein/centos-binary-keepalived:current-tripleo-rdo", 
        "2019-06-05 19:08:50,387 INFO: 15389 -- Removing container: container-puppet-keepalived", 
        "2019-06-05 19:08:50,899 INFO: 15389 -- Pulling image: docker.io/tripleostein/centos-binary-keepalived:current-tripleo-rdo", 
        "2019-06-05 19:08:53,172 WARNING: 15388 -- + mkdir -p /etc/puppet", 
        "+ '[' -n file,file_line,concat,augeas,cron,file ']'", 
        "+ TAGS='--tags file,file_line,concat,augeas,cron,file'", 
        "+ origin_of_time=/var/lib/config-data/mysql.origin_of_time", 
        "+ touch /var/lib/config-data/mysql.origin_of_time", 
        "+ /usr/bin/puppet apply --summarize --detailed-exitcodes --color=false --logdest syslog --logdest console --modulepath=/etc/puppet/modules:/usr/share/openstack-puppet/modules --tags file,file_line,concat,augeas,cron,file /etc/config.pp", 
        "+ '[' -f /root/.my.cnf -a -f /var/lib/config-data/mysql/root/.my.cnf ']'", 
        "+ rsync -a -R --delay-updates --delete-after /etc /root /opt /var/spool/cron /var/lib/config-data/mysql", 
        "++ stat -c %y /var/lib/config-data/mysql.origin_of_time", 
        "+ echo 'Gathering files modified after 2019-06-05 19:08:42.775662497 +0000'", 
        "+ mkdir -p /var/lib/config-data/puppet-generated/mysql", 
        "+ rsync -a -R -0 --delay-updates --delete-after --files-from=/dev/fd/63 / /var/lib/config-data/puppet-generated/mysql", 
        "++ find /etc /root /opt /var/spool/cron -newer /var/lib/config-data/mysql.origin_of_time -not -path '/etc/puppet*' -print0", 
        "+ additional_checksum_files+=' /root/.my.cnf'", 
        "+ excluded_original_passwords+=' --exclude=/var/lib/config-data/*/root/.my.cnf'", 
        "+ EXCLUDE='--exclude=*/etc/swift/backups/* --exclude=*/etc/libvirt/passwd.db  --exclude=/var/lib/config-data/*/root/.my.cnf'", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' '--exclude=/var/lib/config-data/*/root/.my.cnf' -f - /var/lib/config-data/mysql /root/.my.cnf", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' '--exclude=/var/lib/config-data/*/root/.my.cnf' -f - /var/lib/config-data/puppet-generated/mysql /root/.my.cnf --mtime=1970-01-01", 
        "2019-06-05 19:08:53,172 INFO: 15388 -- Removing container: container-puppet-mysql", 
        "2019-06-05 19:08:53,433 INFO: 15388 -- Finished processing puppet configs for mysql", 
        "2019-06-05 19:08:53,433 INFO: 15388 -- Starting configuration of gnocchi using image docker.io/tripleostein/centos-binary-gnocchi-api:current-tripleo-rdo", 
        "2019-06-05 19:08:54,689 INFO: 15388 -- Removing container: container-puppet-gnocchi", 
        "2019-06-05 19:08:55,005 WARNING: 15391 -- + mkdir -p /etc/puppet", 
        "+ '[' -n file,file_line,concat,augeas,cron,glance_api_config,glance_api_paste_ini,glance_swift_config,glance_cache_config,glance_image_import_config ']'", 
        "+ TAGS='--tags file,file_line,concat,augeas,cron,glance_api_config,glance_api_paste_ini,glance_swift_config,glance_cache_config,glance_image_import_config'", 
        "+ origin_of_time=/var/lib/config-data/glance_api.origin_of_time", 
        "+ touch /var/lib/config-data/glance_api.origin_of_time", 
        "+ /usr/bin/puppet apply --summarize --detailed-exitcodes --color=false --logdest syslog --logdest console --modulepath=/etc/puppet/modules:/usr/share/openstack-puppet/modules --tags file,file_line,concat,augeas,cron,glance_api_config,glance_api_paste_ini,glance_swift_config,glance_cache_config,glance_image_import_config /etc/config.pp", 
        "+ rsync_srcs+=' /var/www'", 
        "+ '[' -f /root/.my.cnf -a -f /var/lib/config-data/glance_api/root/.my.cnf ']'", 
        "+ rsync -a -R --delay-updates --delete-after /etc /root /opt /var/www /var/spool/cron /var/lib/config-data/glance_api", 
        "++ stat -c %y /var/lib/config-data/glance_api.origin_of_time", 
        "+ echo 'Gathering files modified after 2019-06-05 19:08:42.956665319 +0000'", 
        "+ mkdir -p /var/lib/config-data/puppet-generated/glance_api", 
        "+ rsync -a -R -0 --delay-updates --delete-after --files-from=/dev/fd/63 / /var/lib/config-data/puppet-generated/glance_api", 
        "++ find /etc /root /opt /var/www /var/spool/cron -newer /var/lib/config-data/glance_api.origin_of_time -not -path '/etc/puppet*' -print0", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/glance_api", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/puppet-generated/glance_api --mtime=1970-01-01", 
        "2019-06-05 19:08:55,005 INFO: 15391 -- Removing container: container-puppet-glance_api", 
        "2019-06-05 19:08:55,197 INFO: 15388 -- Pulling image: docker.io/tripleostein/centos-binary-gnocchi-api:current-tripleo-rdo", 
        "2019-06-05 19:08:55,404 INFO: 15391 -- Finished processing puppet configs for glance_api", 
        "2019-06-05 19:08:55,404 INFO: 15391 -- Starting configuration of keystone using image docker.io/tripleostein/centos-binary-keystone:current-tripleo-rdo", 
        "2019-06-05 19:08:55,578 WARNING: 15387 -- + mkdir -p /etc/puppet", 
        "+ '[' -n file,file_line,concat,augeas,cron,heat_config,file,concat,file_line ']'", 
        "+ TAGS='--tags file,file_line,concat,augeas,cron,heat_config,file,concat,file_line'", 
        "+ origin_of_time=/var/lib/config-data/heat_api.origin_of_time", 
        "+ touch /var/lib/config-data/heat_api.origin_of_time", 
        "+ /usr/bin/puppet apply --summarize --detailed-exitcodes --color=false --logdest syslog --logdest console --modulepath=/etc/puppet/modules:/usr/share/openstack-puppet/modules --tags file,file_line,concat,augeas,cron,heat_config,file,concat,file_line /etc/config.pp", 
        "+ '[' -f /root/.my.cnf -a -f /var/lib/config-data/heat_api/root/.my.cnf ']'", 
        "+ rsync -a -R --delay-updates --delete-after /etc /root /opt /var/www /var/spool/cron /var/lib/config-data/heat_api", 
        "++ stat -c %y /var/lib/config-data/heat_api.origin_of_time", 
        "+ echo 'Gathering files modified after 2019-06-05 19:08:43.152668372 +0000'", 
        "+ mkdir -p /var/lib/config-data/puppet-generated/heat_api", 
        "+ rsync -a -R -0 --delay-updates --delete-after --files-from=/dev/fd/63 / /var/lib/config-data/puppet-generated/heat_api", 
        "++ find /etc /root /opt /var/www /var/spool/cron -newer /var/lib/config-data/heat_api.origin_of_time -not -path '/etc/puppet*' -print0", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/heat_api", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/puppet-generated/heat_api --mtime=1970-01-01", 
        "2019-06-05 19:08:55,579 INFO: 15387 -- Removing container: container-puppet-heat_api", 
        "2019-06-05 19:08:55,605 INFO: 15391 -- Removing container: container-puppet-keystone", 
        "2019-06-05 19:08:55,800 INFO: 15387 -- Finished processing puppet configs for heat_api", 
        "2019-06-05 19:08:55,800 INFO: 15387 -- Starting configuration of swift_ringbuilder using image docker.io/tripleostein/centos-binary-swift-proxy-server:current-tripleo-rdo", 
        "2019-06-05 19:08:56,436 INFO: 15387 -- Removing container: container-puppet-swift_ringbuilder", 
        "2019-06-05 19:08:56,479 INFO: 15391 -- Pulling image: docker.io/tripleostein/centos-binary-keystone:current-tripleo-rdo", 
        "2019-06-05 19:08:57,138 INFO: 15387 -- Pulling image: docker.io/tripleostein/centos-binary-swift-proxy-server:current-tripleo-rdo", 
        "2019-06-05 19:09:01,991 WARNING: 15386 -- + mkdir -p /etc/puppet", 
        "+ '[' -n file,file_line,concat,augeas,cron,nova_config ']'", 
        "+ TAGS='--tags file,file_line,concat,augeas,cron,nova_config'", 
        "+ origin_of_time=/var/lib/config-data/nova_placement.origin_of_time", 
        "+ touch /var/lib/config-data/nova_placement.origin_of_time", 
        "+ /usr/bin/puppet apply --summarize --detailed-exitcodes --color=false --logdest syslog --logdest console --modulepath=/etc/puppet/modules:/usr/share/openstack-puppet/modules --tags file,file_line,concat,augeas,cron,nova_config /etc/config.pp", 
        "net_mlx5: cannot load glue library: libibverbs.so.1: cannot open shared object file: No such file or directory", 
        "net_mlx5: cannot initialize PMD due to missing run-time dependency on rdma-core libraries (libibverbs, libmlx5)", 
        "PMD: net_mlx4: cannot load glue library: libibverbs.so.1: cannot open shared object file: No such file or directory", 
        "PMD: net_mlx4: cannot initialize PMD due to missing run-time dependency on rdma-core libraries (libibverbs, libmlx4)", 
        "ovs-vsctl: unix:/var/run/openvswitch/db.sock: database connection failed (No such file or directory)", 
        "+ '[' -f /root/.my.cnf -a -f /var/lib/config-data/nova_placement/root/.my.cnf ']'", 
        "+ rsync -a -R --delay-updates --delete-after /etc /root /opt /var/www /var/spool/cron /var/lib/config-data/nova_placement", 
        "++ stat -c %y /var/lib/config-data/nova_placement.origin_of_time", 
        "+ echo 'Gathering files modified after 2019-06-05 19:08:41.786647094 +0000'", 
        "+ mkdir -p /var/lib/config-data/puppet-generated/nova_placement", 
        "+ rsync -a -R -0 --delay-updates --delete-after --files-from=/dev/fd/63 / /var/lib/config-data/puppet-generated/nova_placement", 
        "++ find /etc /root /opt /var/www /var/spool/cron -newer /var/lib/config-data/nova_placement.origin_of_time -not -path '/etc/puppet*' -print0", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/nova_placement", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/puppet-generated/nova_placement --mtime=1970-01-01", 
        "2019-06-05 19:09:01,991 INFO: 15386 -- Removing container: container-puppet-nova_placement", 
        "2019-06-05 19:09:03,868 INFO: 15386 -- Finished processing puppet configs for nova_placement", 
        "2019-06-05 19:09:03,868 INFO: 15386 -- Starting configuration of aodh using image docker.io/tripleostein/centos-binary-aodh-api:current-tripleo-rdo", 
        "2019-06-05 19:09:04,167 WARNING: 15390 -- + mkdir -p /etc/puppet", 
        "+ '[' -n file,file_line,concat,augeas,cron,nova_config,nova_config,nova_config,nova_config,nova_config ']'", 
        "+ TAGS='--tags file,file_line,concat,augeas,cron,nova_config,nova_config,nova_config,nova_config,nova_config'", 
        "+ origin_of_time=/var/lib/config-data/nova.origin_of_time", 
        "+ touch /var/lib/config-data/nova.origin_of_time", 
        "+ /usr/bin/puppet apply --summarize --detailed-exitcodes --color=false --logdest syslog --logdest console --modulepath=/etc/puppet/modules:/usr/share/openstack-puppet/modules --tags file,file_line,concat,augeas,cron,nova_config,nova_config,nova_config,nova_config,nova_config /etc/config.pp", 
        "+ '[' -f /root/.my.cnf -a -f /var/lib/config-data/nova/root/.my.cnf ']'", 
        "+ rsync -a -R --delay-updates --delete-after /etc /root /opt /var/www /var/spool/cron /var/lib/config-data/nova", 
        "++ stat -c %y /var/lib/config-data/nova.origin_of_time", 
        "+ echo 'Gathering files modified after 2019-06-05 19:08:43.038666596 +0000'", 
        "+ mkdir -p /var/lib/config-data/puppet-generated/nova", 
        "+ rsync -a -R -0 --delay-updates --delete-after --files-from=/dev/fd/63 / /var/lib/config-data/puppet-generated/nova", 
        "++ find /etc /root /opt /var/www /var/spool/cron -newer /var/lib/config-data/nova.origin_of_time -not -path '/etc/puppet*' -print0", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/nova", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/puppet-generated/nova --mtime=1970-01-01", 
        "2019-06-05 19:09:04,168 INFO: 15390 -- Removing container: container-puppet-nova", 
        "2019-06-05 19:09:04,430 WARNING: 15389 -- + mkdir -p /etc/puppet", 
        "+ origin_of_time=/var/lib/config-data/keepalived.origin_of_time", 
        "+ touch /var/lib/config-data/keepalived.origin_of_time", 
        "+ '[' -f /root/.my.cnf -a -f /var/lib/config-data/keepalived/root/.my.cnf ']'", 
        "+ rsync -a -R --delay-updates --delete-after /etc /root /opt /var/spool/cron /var/lib/config-data/keepalived", 
        "++ stat -c %y /var/lib/config-data/keepalived.origin_of_time", 
        "+ echo 'Gathering files modified after 2019-06-05 19:08:55.807865503 +0000'", 
        "+ mkdir -p /var/lib/config-data/puppet-generated/keepalived", 
        "+ rsync -a -R -0 --delay-updates --delete-after --files-from=/dev/fd/63 / /var/lib/config-data/puppet-generated/keepalived", 
        "++ find /etc /root /opt /var/spool/cron -newer /var/lib/config-data/keepalived.origin_of_time -not -path '/etc/puppet*' -print0", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/keepalived", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/puppet-generated/keepalived --mtime=1970-01-01", 
        "2019-06-05 19:09:04,430 INFO: 15389 -- Removing container: container-puppet-keepalived", 
        "2019-06-05 19:09:04,589 INFO: 15386 -- Removing container: container-puppet-aodh", 
        "2019-06-05 19:09:04,939 INFO: 15389 -- Finished processing puppet configs for keepalived", 
        "2019-06-05 19:09:04,940 INFO: 15389 -- Starting configuration of memcached using image docker.io/tripleostein/centos-binary-memcached:current-tripleo-rdo", 
        "2019-06-05 19:09:05,089 INFO: 15390 -- Finished processing puppet configs for nova", 
        "2019-06-05 19:09:05,089 INFO: 15390 -- Starting configuration of iscsid using image docker.io/tripleostein/centos-binary-iscsid:current-tripleo-rdo", 
        "2019-06-05 19:09:05,590 INFO: 15389 -- Removing container: container-puppet-memcached", 
        "2019-06-05 19:09:05,646 INFO: 15386 -- Pulling image: docker.io/tripleostein/centos-binary-aodh-api:current-tripleo-rdo", 
        "2019-06-05 19:09:05,704 INFO: 15390 -- Removing container: container-puppet-iscsid", 
        "2019-06-05 19:09:06,201 INFO: 15389 -- Pulling image: docker.io/tripleostein/centos-binary-memcached:current-tripleo-rdo", 
        "2019-06-05 19:09:06,968 INFO: 15390 -- Pulling image: docker.io/tripleostein/centos-binary-iscsid:current-tripleo-rdo", 
        "2019-06-05 19:09:17,584 WARNING: 15388 -- + mkdir -p /etc/puppet", 
        "+ '[' -n file,file_line,concat,augeas,cron,gnocchi_api_paste_ini,gnocchi_config,gnocchi_config,gnocchi_config ']'", 
        "+ TAGS='--tags file,file_line,concat,augeas,cron,gnocchi_api_paste_ini,gnocchi_config,gnocchi_config,gnocchi_config'", 
        "+ origin_of_time=/var/lib/config-data/gnocchi.origin_of_time", 
        "+ touch /var/lib/config-data/gnocchi.origin_of_time", 
        "+ /usr/bin/puppet apply --summarize --detailed-exitcodes --color=false --logdest syslog --logdest console --modulepath=/etc/puppet/modules:/usr/share/openstack-puppet/modules --tags file,file_line,concat,augeas,cron,gnocchi_api_paste_ini,gnocchi_config,gnocchi_config,gnocchi_config /etc/config.pp", 
        "+ '[' -f /root/.my.cnf -a -f /var/lib/config-data/gnocchi/root/.my.cnf ']'", 
        "+ rsync -a -R --delay-updates --delete-after /etc /root /opt /var/www /var/spool/cron /var/lib/config-data/gnocchi", 
        "++ stat -c %y /var/lib/config-data/gnocchi.origin_of_time", 
        "+ echo 'Gathering files modified after 2019-06-05 19:09:08.334060623 +0000'", 
        "+ mkdir -p /var/lib/config-data/puppet-generated/gnocchi", 
        "+ rsync -a -R -0 --delay-updates --delete-after --files-from=/dev/fd/63 / /var/lib/config-data/puppet-generated/gnocchi", 
        "++ find /etc /root /opt /var/www /var/spool/cron -newer /var/lib/config-data/gnocchi.origin_of_time -not -path '/etc/puppet*' -print0", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/gnocchi", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/puppet-generated/gnocchi --mtime=1970-01-01", 
        "2019-06-05 19:09:17,584 INFO: 15388 -- Removing container: container-puppet-gnocchi", 
        "2019-06-05 19:09:17,787 INFO: 15388 -- Finished processing puppet configs for gnocchi", 
        "2019-06-05 19:09:17,788 INFO: 15388 -- Starting configuration of nova_metadata using image docker.io/tripleostein/centos-binary-nova-api:current-tripleo-rdo", 
        "2019-06-05 19:09:17,983 INFO: 15388 -- Removing container: container-puppet-nova_metadata", 
        "2019-06-05 19:09:18,619 INFO: 15388 -- Image already exists: docker.io/tripleostein/centos-binary-nova-api:current-tripleo-rdo", 
        "2019-06-05 19:09:18,738 WARNING: 15391 -- + mkdir -p /etc/puppet", 
        "+ '[' -n file,file_line,concat,augeas,cron,keystone_config,keystone_domain_config ']'", 
        "+ TAGS='--tags file,file_line,concat,augeas,cron,keystone_config,keystone_domain_config'", 
        "+ origin_of_time=/var/lib/config-data/keystone.origin_of_time", 
        "+ touch /var/lib/config-data/keystone.origin_of_time", 
        "+ /usr/bin/puppet apply --summarize --detailed-exitcodes --color=false --logdest syslog --logdest console --modulepath=/etc/puppet/modules:/usr/share/openstack-puppet/modules --tags file,file_line,concat,augeas,cron,keystone_config,keystone_domain_config /etc/config.pp", 
        "+ '[' -f /root/.my.cnf -a -f /var/lib/config-data/keystone/root/.my.cnf ']'", 
        "+ rsync -a -R --delay-updates --delete-after /etc /root /opt /var/www /var/spool/cron /var/lib/config-data/keystone", 
        "++ stat -c %y /var/lib/config-data/keystone.origin_of_time", 
        "+ echo 'Gathering files modified after 2019-06-05 19:09:08.179058209 +0000'", 
        "+ mkdir -p /var/lib/config-data/puppet-generated/keystone", 
        "+ rsync -a -R -0 --delay-updates --delete-after --files-from=/dev/fd/63 / /var/lib/config-data/puppet-generated/keystone", 
        "++ find /etc /root /opt /var/www /var/spool/cron -newer /var/lib/config-data/keystone.origin_of_time -not -path '/etc/puppet*' -print0", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/keystone", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/puppet-generated/keystone --mtime=1970-01-01", 
        "2019-06-05 19:09:18,739 INFO: 15391 -- Removing container: container-puppet-keystone", 
        "2019-06-05 19:09:18,739 WARNING: 15390 -- + mkdir -p /etc/puppet", 
        "+ '[' -n file,file_line,concat,augeas,cron,iscsid_config ']'", 
        "+ TAGS='--tags file,file_line,concat,augeas,cron,iscsid_config'", 
        "+ origin_of_time=/var/lib/config-data/iscsid.origin_of_time", 
        "+ touch /var/lib/config-data/iscsid.origin_of_time", 
        "+ /usr/bin/puppet apply --summarize --detailed-exitcodes --color=false --logdest syslog --logdest console --modulepath=/etc/puppet/modules:/usr/share/openstack-puppet/modules --tags file,file_line,concat,augeas,cron,iscsid_config /etc/config.pp", 
        "+ '[' -f /root/.my.cnf -a -f /var/lib/config-data/iscsid/root/.my.cnf ']'", 
        "+ rsync -a -R --delay-updates --delete-after /etc /root /opt /var/spool/cron /var/lib/config-data/iscsid", 
        "++ stat -c %y /var/lib/config-data/iscsid.origin_of_time", 
        "+ echo 'Gathering files modified after 2019-06-05 19:09:13.508141220 +0000'", 
        "+ mkdir -p /var/lib/config-data/puppet-generated/iscsid", 
        "+ rsync -a -R -0 --delay-updates --delete-after --files-from=/dev/fd/63 / /var/lib/config-data/puppet-generated/iscsid", 
        "++ find /etc /root /opt /var/spool/cron -newer /var/lib/config-data/iscsid.origin_of_time -not -path '/etc/puppet*' -print0", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/iscsid", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/puppet-generated/iscsid --mtime=1970-01-01", 
        "2019-06-05 19:09:18,739 INFO: 15390 -- Removing container: container-puppet-iscsid", 
        "2019-06-05 19:09:18,740 WARNING: 15389 -- + mkdir -p /etc/puppet", 
        "+ origin_of_time=/var/lib/config-data/memcached.origin_of_time", 
        "+ touch /var/lib/config-data/memcached.origin_of_time", 
        "+ '[' -f /root/.my.cnf -a -f /var/lib/config-data/memcached/root/.my.cnf ']'", 
        "+ rsync -a -R --delay-updates --delete-after /etc /root /opt /var/spool/cron /var/lib/config-data/memcached", 
        "++ stat -c %y /var/lib/config-data/memcached.origin_of_time", 
        "+ echo 'Gathering files modified after 2019-06-05 19:09:12.912131936 +0000'", 
        "+ mkdir -p /var/lib/config-data/puppet-generated/memcached", 
        "+ rsync -a -R -0 --delay-updates --delete-after --files-from=/dev/fd/63 / /var/lib/config-data/puppet-generated/memcached", 
        "++ find /etc /root /opt /var/spool/cron -newer /var/lib/config-data/memcached.origin_of_time -not -path '/etc/puppet*' -print0", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/memcached", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/puppet-generated/memcached --mtime=1970-01-01", 
        "2019-06-05 19:09:18,740 INFO: 15389 -- Removing container: container-puppet-memcached", 
        "2019-06-05 19:09:19,059 INFO: 15390 -- Finished processing puppet configs for iscsid", 
        "2019-06-05 19:09:19,059 INFO: 15390 -- Starting configuration of cinder using image docker.io/tripleostein/centos-binary-cinder-api:current-tripleo-rdo", 
        "2019-06-05 19:09:19,113 INFO: 15391 -- Finished processing puppet configs for keystone", 
        "2019-06-05 19:09:19,114 INFO: 15391 -- Starting configuration of crond using image docker.io/tripleostein/centos-binary-cron:current-tripleo-rdo", 
        "2019-06-05 19:09:19,120 INFO: 15389 -- Finished processing puppet configs for memcached", 
        "2019-06-05 19:09:19,120 INFO: 15389 -- Starting configuration of panko using image docker.io/tripleostein/centos-binary-panko-api:current-tripleo-rdo", 
        "2019-06-05 19:09:19,373 INFO: 15391 -- Removing container: container-puppet-crond", 
        "2019-06-05 19:09:19,376 INFO: 15390 -- Removing container: container-puppet-cinder", 
        "2019-06-05 19:09:19,559 INFO: 15389 -- Removing container: container-puppet-panko", 
        "2019-06-05 19:09:20,210 INFO: 15390 -- Pulling image: docker.io/tripleostein/centos-binary-cinder-api:current-tripleo-rdo", 
        "2019-06-05 19:09:20,246 INFO: 15391 -- Pulling image: docker.io/tripleostein/centos-binary-cron:current-tripleo-rdo", 
        "2019-06-05 19:09:20,724 WARNING: 15387 -- + mkdir -p /etc/puppet", 
        "+ '[' -n file,file_line,concat,augeas,cron,exec,fetch_swift_ring_tarball,extract_swift_ring_tarball,ring_object_device,swift::ringbuilder::create,tripleo::profile::base::swift::add_devices,swift::ringbuilder::rebalance,create_swift_ring_tarball,upload_swift_ring_tarball ']'", 
        "+ TAGS='--tags file,file_line,concat,augeas,cron,exec,fetch_swift_ring_tarball,extract_swift_ring_tarball,ring_object_device,swift::ringbuilder::create,tripleo::profile::base::swift::add_devices,swift::ringbuilder::rebalance,create_swift_ring_tarball,upload_swift_ring_tarball'", 
        "+ origin_of_time=/var/lib/config-data/swift_ringbuilder.origin_of_time", 
        "+ touch /var/lib/config-data/swift_ringbuilder.origin_of_time", 
        "+ /usr/bin/puppet apply --summarize --detailed-exitcodes --color=false --logdest syslog --logdest console --modulepath=/etc/puppet/modules:/usr/share/openstack-puppet/modules --tags file,file_line,concat,augeas,cron,exec,fetch_swift_ring_tarball,extract_swift_ring_tarball,ring_object_device,swift::ringbuilder::create,tripleo::profile::base::swift::add_devices,swift::ringbuilder::rebalance,create_swift_ring_tarball,upload_swift_ring_tarball /etc/config.pp", 
        "+ '[' -f /root/.my.cnf -a -f /var/lib/config-data/swift_ringbuilder/root/.my.cnf ']'", 
        "+ rsync -a -R --delay-updates --delete-after /etc /root /opt /var/www /var/spool/cron /var/lib/config-data/swift_ringbuilder", 
        "++ stat -c %y /var/lib/config-data/swift_ringbuilder.origin_of_time", 
        "+ echo 'Gathering files modified after 2019-06-05 19:09:07.473047211 +0000'", 
        "+ mkdir -p /var/lib/config-data/puppet-generated/swift_ringbuilder", 
        "+ rsync -a -R -0 --delay-updates --delete-after --files-from=/dev/fd/63 / /var/lib/config-data/puppet-generated/swift_ringbuilder", 
        "++ find /etc /root /opt /var/www /var/spool/cron -newer /var/lib/config-data/swift_ringbuilder.origin_of_time -not -path '/etc/puppet*' -print0", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/swift_ringbuilder", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/puppet-generated/swift_ringbuilder --mtime=1970-01-01", 
        "2019-06-05 19:09:20,725 INFO: 15387 -- Removing container: container-puppet-swift_ringbuilder", 
        "2019-06-05 19:09:20,735 INFO: 15389 -- Pulling image: docker.io/tripleostein/centos-binary-panko-api:current-tripleo-rdo", 
        "2019-06-05 19:09:20,929 INFO: 15387 -- Finished processing puppet configs for swift_ringbuilder", 
        "2019-06-05 19:09:20,929 INFO: 15387 -- Starting configuration of ceilometer using image docker.io/tripleostein/centos-binary-ceilometer-central:current-tripleo-rdo", 
        "2019-06-05 19:09:21,057 INFO: 15387 -- Removing container: container-puppet-ceilometer", 
        "2019-06-05 19:09:21,257 INFO: 15387 -- Pulling image: docker.io/tripleostein/centos-binary-ceilometer-central:current-tripleo-rdo", 
        "2019-06-05 19:09:26,100 WARNING: 15386 -- + mkdir -p /etc/puppet", 
        "+ '[' -n file,file_line,concat,augeas,cron,aodh_api_paste_ini,aodh_config,aodh_config,aodh_config,aodh_config ']'", 
        "+ TAGS='--tags file,file_line,concat,augeas,cron,aodh_api_paste_ini,aodh_config,aodh_config,aodh_config,aodh_config'", 
        "+ origin_of_time=/var/lib/config-data/aodh.origin_of_time", 
        "+ touch /var/lib/config-data/aodh.origin_of_time", 
        "+ /usr/bin/puppet apply --summarize --detailed-exitcodes --color=false --logdest syslog --logdest console --modulepath=/etc/puppet/modules:/usr/share/openstack-puppet/modules --tags file,file_line,concat,augeas,cron,aodh_api_paste_ini,aodh_config,aodh_config,aodh_config,aodh_config /etc/config.pp", 
        "+ '[' -f /root/.my.cnf -a -f /var/lib/config-data/aodh/root/.my.cnf ']'", 
        "+ rsync -a -R --delay-updates --delete-after /etc /root /opt /var/www /var/spool/cron /var/lib/config-data/aodh", 
        "++ stat -c %y /var/lib/config-data/aodh.origin_of_time", 
        "+ echo 'Gathering files modified after 2019-06-05 19:09:13.574142248 +0000'", 
        "+ mkdir -p /var/lib/config-data/puppet-generated/aodh", 
        "+ rsync -a -R -0 --delay-updates --delete-after --files-from=/dev/fd/63 / /var/lib/config-data/puppet-generated/aodh", 
        "++ find /etc /root /opt /var/www /var/spool/cron -newer /var/lib/config-data/aodh.origin_of_time -not -path '/etc/puppet*' -print0", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/aodh", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/puppet-generated/aodh --mtime=1970-01-01", 
        "2019-06-05 19:09:26,101 INFO: 15386 -- Removing container: container-puppet-aodh", 
        "2019-06-05 19:09:26,276 INFO: 15386 -- Finished processing puppet configs for aodh", 
        "2019-06-05 19:09:26,277 INFO: 15386 -- Starting configuration of neutron using image docker.io/tripleostein/centos-binary-neutron-server-ovn:current-tripleo-rdo", 
        "2019-06-05 19:09:26,452 INFO: 15386 -- Removing container: container-puppet-neutron", 
        "2019-06-05 19:09:26,682 INFO: 15386 -- Pulling image: docker.io/tripleostein/centos-binary-neutron-server-ovn:current-tripleo-rdo", 
        "2019-06-05 19:09:35,056 WARNING: 15387 -- + mkdir -p /etc/puppet", 
        "+ '[' -n file,file_line,concat,augeas,cron,ceilometer_config,ceilometer_config ']'", 
        "+ TAGS='--tags file,file_line,concat,augeas,cron,ceilometer_config,ceilometer_config'", 
        "+ origin_of_time=/var/lib/config-data/ceilometer.origin_of_time", 
        "+ touch /var/lib/config-data/ceilometer.origin_of_time", 
        "+ /usr/bin/puppet apply --summarize --detailed-exitcodes --color=false --logdest syslog --logdest console --modulepath=/etc/puppet/modules:/usr/share/openstack-puppet/modules --tags file,file_line,concat,augeas,cron,ceilometer_config,ceilometer_config /etc/config.pp", 
        "+ '[' -f /root/.my.cnf -a -f /var/lib/config-data/ceilometer/root/.my.cnf ']'", 
        "+ rsync -a -R --delay-updates --delete-after /etc /root /opt /var/spool/cron /var/lib/config-data/ceilometer", 
        "++ stat -c %y /var/lib/config-data/ceilometer.origin_of_time", 
        "+ echo 'Gathering files modified after 2019-06-05 19:09:26.755347572 +0000'", 
        "+ mkdir -p /var/lib/config-data/puppet-generated/ceilometer", 
        "+ rsync -a -R -0 --delay-updates --delete-after --files-from=/dev/fd/63 / /var/lib/config-data/puppet-generated/ceilometer", 
        "++ find /etc /root /opt /var/spool/cron -newer /var/lib/config-data/ceilometer.origin_of_time -not -path '/etc/puppet*' -print0", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/ceilometer", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/puppet-generated/ceilometer --mtime=1970-01-01", 
        "2019-06-05 19:09:35,057 INFO: 15387 -- Removing container: container-puppet-ceilometer", 
        "2019-06-05 19:09:35,847 WARNING: 15391 -- + mkdir -p /etc/puppet", 
        "+ '[' -n file,file_line,concat,augeas,cron ']'", 
        "+ TAGS='--tags file,file_line,concat,augeas,cron'", 
        "+ origin_of_time=/var/lib/config-data/crond.origin_of_time", 
        "+ touch /var/lib/config-data/crond.origin_of_time", 
        "+ /usr/bin/puppet apply --summarize --detailed-exitcodes --color=false --logdest syslog --logdest console --modulepath=/etc/puppet/modules:/usr/share/openstack-puppet/modules --tags file,file_line,concat,augeas,cron /etc/config.pp", 
        "+ '[' -f /root/.my.cnf -a -f /var/lib/config-data/crond/root/.my.cnf ']'", 
        "+ rsync -a -R --delay-updates --delete-after /etc /root /opt /var/spool/cron /var/lib/config-data/crond", 
        "++ stat -c %y /var/lib/config-data/crond.origin_of_time", 
        "+ echo 'Gathering files modified after 2019-06-05 19:09:23.695299905 +0000'", 
        "+ mkdir -p /var/lib/config-data/puppet-generated/crond", 
        "+ rsync -a -R -0 --delay-updates --delete-after --files-from=/dev/fd/63 / /var/lib/config-data/puppet-generated/crond", 
        "++ find /etc /root /opt /var/spool/cron -newer /var/lib/config-data/crond.origin_of_time -not -path '/etc/puppet*' -print0", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/crond", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/puppet-generated/crond --mtime=1970-01-01", 
        "2019-06-05 19:09:35,847 INFO: 15391 -- Removing container: container-puppet-crond", 
        "2019-06-05 19:09:35,848 INFO: 15387 -- Finished processing puppet configs for ceilometer", 
        "2019-06-05 19:09:35,848 INFO: 15387 -- Starting configuration of rabbitmq using image docker.io/tripleostein/centos-binary-rabbitmq:current-tripleo-rdo", 
        "2019-06-05 19:09:36,295 INFO: 15391 -- Finished processing puppet configs for crond", 
        "2019-06-05 19:09:36,295 INFO: 15391 -- Starting configuration of haproxy using image docker.io/tripleostein/centos-binary-haproxy:current-tripleo-rdo", 
        "2019-06-05 19:09:36,401 WARNING: 15388 -- + mkdir -p /etc/puppet", 
        "+ origin_of_time=/var/lib/config-data/nova_metadata.origin_of_time", 
        "+ touch /var/lib/config-data/nova_metadata.origin_of_time", 
        "+ '[' -f /root/.my.cnf -a -f /var/lib/config-data/nova_metadata/root/.my.cnf ']'", 
        "+ rsync -a -R --delay-updates --delete-after /etc /root /opt /var/www /var/spool/cron /var/lib/config-data/nova_metadata", 
        "++ stat -c %y /var/lib/config-data/nova_metadata.origin_of_time", 
        "+ echo 'Gathering files modified after 2019-06-05 19:09:19.625236506 +0000'", 
        "+ mkdir -p /var/lib/config-data/puppet-generated/nova_metadata", 
        "+ rsync -a -R -0 --delay-updates --delete-after --files-from=/dev/fd/63 / /var/lib/config-data/puppet-generated/nova_metadata", 
        "++ find /etc /root /opt /var/www /var/spool/cron -newer /var/lib/config-data/nova_metadata.origin_of_time -not -path '/etc/puppet*' -print0", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/nova_metadata", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/puppet-generated/nova_metadata --mtime=1970-01-01", 
        "2019-06-05 19:09:36,401 INFO: 15388 -- Removing container: container-puppet-nova_metadata", 
        "2019-06-05 19:09:36,558 INFO: 15387 -- Removing container: container-puppet-rabbitmq", 
        "2019-06-05 19:09:36,818 INFO: 15391 -- Removing container: container-puppet-haproxy", 
        "2019-06-05 19:09:36,887 INFO: 15388 -- Finished processing puppet configs for nova_metadata", 
        "2019-06-05 19:09:36,887 INFO: 15388 -- Starting configuration of heat using image docker.io/tripleostein/centos-binary-heat-api:current-tripleo-rdo", 
        "2019-06-05 19:09:37,758 INFO: 15388 -- Removing container: container-puppet-heat", 
        "2019-06-05 19:09:37,818 INFO: 15387 -- Pulling image: docker.io/tripleostein/centos-binary-rabbitmq:current-tripleo-rdo", 
        "2019-06-05 19:09:37,876 INFO: 15391 -- Pulling image: docker.io/tripleostein/centos-binary-haproxy:current-tripleo-rdo", 
        "2019-06-05 19:09:40,252 INFO: 15388 -- Image already exists: docker.io/tripleostein/centos-binary-heat-api:current-tripleo-rdo", 
        "2019-06-05 19:09:54,807 WARNING: 15388 -- + mkdir -p /etc/puppet", 
        "+ origin_of_time=/var/lib/config-data/heat.origin_of_time", 
        "+ touch /var/lib/config-data/heat.origin_of_time", 
        "+ '[' -f /root/.my.cnf -a -f /var/lib/config-data/heat/root/.my.cnf ']'", 
        "+ rsync -a -R --delay-updates --delete-after /etc /root /opt /var/www /var/spool/cron /var/lib/config-data/heat", 
        "++ stat -c %y /var/lib/config-data/heat.origin_of_time", 
        "+ echo 'Gathering files modified after 2019-06-05 19:09:45.369671508 +0000'", 
        "+ mkdir -p /var/lib/config-data/puppet-generated/heat", 
        "+ rsync -a -R -0 --delay-updates --delete-after --files-from=/dev/fd/63 / /var/lib/config-data/puppet-generated/heat", 
        "++ find /etc /root /opt /var/www /var/spool/cron -newer /var/lib/config-data/heat.origin_of_time -not -path '/etc/puppet*' -print0", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/heat", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/puppet-generated/heat --mtime=1970-01-01", 
        "2019-06-05 19:09:54,807 INFO: 15388 -- Removing container: container-puppet-heat", 
        "2019-06-05 19:09:55,288 INFO: 15388 -- Finished processing puppet configs for heat", 
        "2019-06-05 19:09:55,289 INFO: 15388 -- Starting configuration of heat_api_cfn using image docker.io/tripleostein/centos-binary-heat-api-cfn:current-tripleo-rdo", 
        "2019-06-05 19:09:55,575 WARNING: 15391 -- + mkdir -p /etc/puppet", 
        "+ '[' -n file,file_line,concat,augeas,cron,haproxy_config ']'", 
        "+ TAGS='--tags file,file_line,concat,augeas,cron,haproxy_config'", 
        "+ origin_of_time=/var/lib/config-data/haproxy.origin_of_time", 
        "+ touch /var/lib/config-data/haproxy.origin_of_time", 
        "+ /usr/bin/puppet apply --summarize --detailed-exitcodes --color=false --logdest syslog --logdest console --modulepath=/etc/puppet/modules:/usr/share/openstack-puppet/modules --tags file,file_line,concat,augeas,cron,haproxy_config /etc/config.pp", 
        "+ '[' -f /root/.my.cnf -a -f /var/lib/config-data/haproxy/root/.my.cnf ']'", 
        "+ rsync -a -R --delay-updates --delete-after /etc /root /opt /var/spool/cron /var/lib/config-data/haproxy", 
        "++ stat -c %y /var/lib/config-data/haproxy.origin_of_time", 
        "+ echo 'Gathering files modified after 2019-06-05 19:09:48.897734796 +0000'", 
        "+ mkdir -p /var/lib/config-data/puppet-generated/haproxy", 
        "+ rsync -a -R -0 --delay-updates --delete-after --files-from=/dev/fd/63 / /var/lib/config-data/puppet-generated/haproxy", 
        "++ find /etc /root /opt /var/spool/cron -newer /var/lib/config-data/haproxy.origin_of_time -not -path '/etc/puppet*' -print0", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/haproxy", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/puppet-generated/haproxy --mtime=1970-01-01", 
        "2019-06-05 19:09:55,575 INFO: 15391 -- Removing container: container-puppet-haproxy", 
        "2019-06-05 19:09:55,578 INFO: 15388 -- Removing container: container-puppet-heat_api_cfn", 
        "2019-06-05 19:09:55,622 WARNING: 15389 -- + mkdir -p /etc/puppet", 
        "+ '[' -n file,file_line,concat,augeas,cron,panko_api_paste_ini,panko_config ']'", 
        "+ TAGS='--tags file,file_line,concat,augeas,cron,panko_api_paste_ini,panko_config'", 
        "+ origin_of_time=/var/lib/config-data/panko.origin_of_time", 
        "+ touch /var/lib/config-data/panko.origin_of_time", 
        "+ /usr/bin/puppet apply --summarize --detailed-exitcodes --color=false --logdest syslog --logdest console --modulepath=/etc/puppet/modules:/usr/share/openstack-puppet/modules --tags file,file_line,concat,augeas,cron,panko_api_paste_ini,panko_config /etc/config.pp", 
        "+ '[' -f /root/.my.cnf -a -f /var/lib/config-data/panko/root/.my.cnf ']'", 
        "+ rsync -a -R --delay-updates --delete-after /etc /root /opt /var/www /var/spool/cron /var/lib/config-data/panko", 
        "++ stat -c %y /var/lib/config-data/panko.origin_of_time", 
        "+ echo 'Gathering files modified after 2019-06-05 19:09:45.370671526 +0000'", 
        "+ mkdir -p /var/lib/config-data/puppet-generated/panko", 
        "+ rsync -a -R -0 --delay-updates --delete-after --files-from=/dev/fd/63 / /var/lib/config-data/puppet-generated/panko", 
        "++ find /etc /root /opt /var/www /var/spool/cron -newer /var/lib/config-data/panko.origin_of_time -not -path '/etc/puppet*' -print0", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/panko", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/puppet-generated/panko --mtime=1970-01-01", 
        "2019-06-05 19:09:55,622 INFO: 15389 -- Removing container: container-puppet-panko", 
        "2019-06-05 19:09:55,946 INFO: 15391 -- Finished processing puppet configs for haproxy", 
        "2019-06-05 19:09:56,106 INFO: 15389 -- Finished processing puppet configs for panko", 
        "2019-06-05 19:09:56,109 INFO: 15388 -- Pulling image: docker.io/tripleostein/centos-binary-heat-api-cfn:current-tripleo-rdo", 
        "2019-06-05 19:09:56,705 WARNING: 15390 -- + mkdir -p /etc/puppet", 
        "+ '[' -n file,file_line,concat,augeas,cron,cinder_config,cinder_type,file,concat,file_line,cinder_config,file,concat,file_line,cinder_config,file,concat,file_line ']'", 
        "+ TAGS='--tags file,file_line,concat,augeas,cron,cinder_config,cinder_type,file,concat,file_line,cinder_config,file,concat,file_line,cinder_config,file,concat,file_line'", 
        "+ origin_of_time=/var/lib/config-data/cinder.origin_of_time", 
        "+ touch /var/lib/config-data/cinder.origin_of_time", 
        "+ /usr/bin/puppet apply --summarize --detailed-exitcodes --color=false --logdest syslog --logdest console --modulepath=/etc/puppet/modules:/usr/share/openstack-puppet/modules --tags file,file_line,concat,augeas,cron,cinder_config,cinder_type,file,concat,file_line,cinder_config,file,concat,file_line,cinder_config,file,concat,file_line /etc/config.pp", 
        "+ '[' -f /root/.my.cnf -a -f /var/lib/config-data/cinder/root/.my.cnf ']'", 
        "+ rsync -a -R --delay-updates --delete-after /etc /root /opt /var/www /var/spool/cron /var/lib/config-data/cinder", 
        "++ stat -c %y /var/lib/config-data/cinder.origin_of_time", 
        "+ echo 'Gathering files modified after 2019-06-05 19:09:42.996628938 +0000'", 
        "+ mkdir -p /var/lib/config-data/puppet-generated/cinder", 
        "+ rsync -a -R -0 --delay-updates --delete-after --files-from=/dev/fd/63 / /var/lib/config-data/puppet-generated/cinder", 
        "++ find /etc /root /opt /var/www /var/spool/cron -newer /var/lib/config-data/cinder.origin_of_time -not -path '/etc/puppet*' -print0", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/cinder", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/puppet-generated/cinder --mtime=1970-01-01", 
        "2019-06-05 19:09:56,705 INFO: 15390 -- Removing container: container-puppet-cinder", 
        "2019-06-05 19:09:56,824 INFO: 15390 -- Finished processing puppet configs for cinder", 
        "2019-06-05 19:09:56,824 INFO: 15390 -- Starting configuration of swift using image docker.io/tripleostein/centos-binary-swift-proxy-server:current-tripleo-rdo", 
        "2019-06-05 19:09:56,931 INFO: 15390 -- Removing container: container-puppet-swift", 
        "2019-06-05 19:09:57,198 INFO: 15390 -- Image already exists: docker.io/tripleostein/centos-binary-swift-proxy-server:current-tripleo-rdo", 
        "2019-06-05 19:09:58,575 WARNING: 15386 -- + mkdir -p /etc/puppet", 
        "+ '[' -n file,file_line,concat,augeas,cron,neutron_config,neutron_api_config,neutron_plugin_ml2 ']'", 
        "+ TAGS='--tags file,file_line,concat,augeas,cron,neutron_config,neutron_api_config,neutron_plugin_ml2'", 
        "+ origin_of_time=/var/lib/config-data/neutron.origin_of_time", 
        "+ touch /var/lib/config-data/neutron.origin_of_time", 
        "+ /usr/bin/puppet apply --summarize --detailed-exitcodes --color=false --logdest syslog --logdest console --modulepath=/etc/puppet/modules:/usr/share/openstack-puppet/modules --tags file,file_line,concat,augeas,cron,neutron_config,neutron_api_config,neutron_plugin_ml2 /etc/config.pp", 
        "+ '[' -f /root/.my.cnf -a -f /var/lib/config-data/neutron/root/.my.cnf ']'", 
        "+ rsync -a -R --delay-updates --delete-after /etc /root /opt /var/www /var/spool/cron /var/lib/config-data/neutron", 
        "++ stat -c %y /var/lib/config-data/neutron.origin_of_time", 
        "+ echo 'Gathering files modified after 2019-06-05 19:09:48.461726975 +0000'", 
        "+ mkdir -p /var/lib/config-data/puppet-generated/neutron", 
        "+ rsync -a -R -0 --delay-updates --delete-after --files-from=/dev/fd/63 / /var/lib/config-data/puppet-generated/neutron", 
        "++ find /etc /root /opt /var/www /var/spool/cron -newer /var/lib/config-data/neutron.origin_of_time -not -path '/etc/puppet*' -print0", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/neutron", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/puppet-generated/neutron --mtime=1970-01-01", 
        "2019-06-05 19:09:58,576 INFO: 15386 -- Removing container: container-puppet-neutron", 
        "2019-06-05 19:09:58,782 INFO: 15386 -- Finished processing puppet configs for neutron", 
        "2019-06-05 19:09:58,783 INFO: 15386 -- Starting configuration of horizon using image docker.io/tripleostein/centos-binary-horizon:current-tripleo-rdo", 
        "2019-06-05 19:09:58,893 INFO: 15386 -- Removing container: container-puppet-horizon", 
        "2019-06-05 19:09:59,133 INFO: 15386 -- Pulling image: docker.io/tripleostein/centos-binary-horizon:current-tripleo-rdo", 
        "2019-06-05 19:10:02,294 WARNING: 15387 -- + mkdir -p /etc/puppet", 
        "+ origin_of_time=/var/lib/config-data/rabbitmq.origin_of_time", 
        "+ touch /var/lib/config-data/rabbitmq.origin_of_time", 
        "Error: unable to connect to node 'rabbit@lab-controller-0': nodedown", 
        "DIAGNOSTICS", 
        "===========", 
        "attempted to contact: ['rabbit@lab-controller-0']", 
        "rabbit@lab-controller-0:", 
        "  * connected to epmd (port 4369) on lab-controller-0", 
        "  * epmd reports: node 'rabbit' not running at all", 
        "                  no other nodes on lab-controller-0", 
        "  * suggestion: start the node", 
        "current node details:", 
        "- node name: 'rabbitmq-cli-08@lab-controller-0'", 
        "- home dir: /var/lib/rabbitmq", 
        "- cookie hash: cMDakQV/qBYnAFvravnu6g==", 
        "- node name: 'rabbitmq-cli-45@lab-controller-0'", 
        "+ '[' -f /root/.my.cnf -a -f /var/lib/config-data/rabbitmq/root/.my.cnf ']'", 
        "+ rsync -a -R --delay-updates --delete-after /etc /root /opt /var/spool/cron /var/lib/config-data/rabbitmq", 
        "++ stat -c %y /var/lib/config-data/rabbitmq.origin_of_time", 
        "+ echo 'Gathering files modified after 2019-06-05 19:09:49.031737200 +0000'", 
        "+ mkdir -p /var/lib/config-data/puppet-generated/rabbitmq", 
        "+ rsync -a -R -0 --delay-updates --delete-after --files-from=/dev/fd/63 / /var/lib/config-data/puppet-generated/rabbitmq", 
        "++ find /etc /root /opt /var/spool/cron -newer /var/lib/config-data/rabbitmq.origin_of_time -not -path '/etc/puppet*' -print0", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/rabbitmq", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/puppet-generated/rabbitmq --mtime=1970-01-01", 
        "2019-06-05 19:10:02,294 INFO: 15387 -- Removing container: container-puppet-rabbitmq", 
        "2019-06-05 19:10:02,448 INFO: 15387 -- Finished processing puppet configs for rabbitmq", 
        "2019-06-05 19:10:10,010 WARNING: 15390 -- + mkdir -p /etc/puppet", 
        "+ '[' -n file,file_line,concat,augeas,cron,swift_config,swift_proxy_config,swift_keymaster_config,swift_config,swift_container_config,swift_container_sync_realms_config,swift_account_config,swift_object_config,swift_object_expirer_config,rsync::server ']'", 
        "+ TAGS='--tags file,file_line,concat,augeas,cron,swift_config,swift_proxy_config,swift_keymaster_config,swift_config,swift_container_config,swift_container_sync_realms_config,swift_account_config,swift_object_config,swift_object_expirer_config,rsync::server'", 
        "+ origin_of_time=/var/lib/config-data/swift.origin_of_time", 
        "+ touch /var/lib/config-data/swift.origin_of_time", 
        "+ /usr/bin/puppet apply --summarize --detailed-exitcodes --color=false --logdest syslog --logdest console --modulepath=/etc/puppet/modules:/usr/share/openstack-puppet/modules --tags file,file_line,concat,augeas,cron,swift_config,swift_proxy_config,swift_keymaster_config,swift_config,swift_container_config,swift_container_sync_realms_config,swift_account_config,swift_object_config,swift_object_expirer_config,rsync::server /etc/config.pp", 
        "+ '[' -f /root/.my.cnf -a -f /var/lib/config-data/swift/root/.my.cnf ']'", 
        "+ rsync -a -R --delay-updates --delete-after /etc /root /opt /var/www /var/spool/cron /var/lib/config-data/swift", 
        "++ stat -c %y /var/lib/config-data/swift.origin_of_time", 
        "+ echo 'Gathering files modified after 2019-06-05 19:09:57.668892139 +0000'", 
        "+ mkdir -p /var/lib/config-data/puppet-generated/swift", 
        "+ rsync -a -R -0 --delay-updates --delete-after --files-from=/dev/fd/63 / /var/lib/config-data/puppet-generated/swift", 
        "++ find /etc /root /opt /var/www /var/spool/cron -newer /var/lib/config-data/swift.origin_of_time -not -path '/etc/puppet*' -print0", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/swift", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/puppet-generated/swift --mtime=1970-01-01", 
        "2019-06-05 19:10:10,011 INFO: 15390 -- Removing container: container-puppet-swift", 
        "2019-06-05 19:10:10,278 WARNING: 15388 -- + mkdir -p /etc/puppet", 
        "+ origin_of_time=/var/lib/config-data/heat_api_cfn.origin_of_time", 
        "+ touch /var/lib/config-data/heat_api_cfn.origin_of_time", 
        "+ '[' -f /root/.my.cnf -a -f /var/lib/config-data/heat_api_cfn/root/.my.cnf ']'", 
        "+ rsync -a -R --delay-updates --delete-after /etc /root /opt /var/www /var/spool/cron /var/lib/config-data/heat_api_cfn", 
        "++ stat -c %y /var/lib/config-data/heat_api_cfn.origin_of_time", 
        "+ echo 'Gathering files modified after 2019-06-05 19:09:59.120918187 +0000'", 
        "+ mkdir -p /var/lib/config-data/puppet-generated/heat_api_cfn", 
        "+ rsync -a -R -0 --delay-updates --delete-after --files-from=/dev/fd/63 / /var/lib/config-data/puppet-generated/heat_api_cfn", 
        "++ find /etc /root /opt /var/www /var/spool/cron -newer /var/lib/config-data/heat_api_cfn.origin_of_time -not -path '/etc/puppet*' -print0", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/heat_api_cfn", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/puppet-generated/heat_api_cfn --mtime=1970-01-01", 
        "2019-06-05 19:10:10,278 INFO: 15388 -- Removing container: container-puppet-heat_api_cfn", 
        "2019-06-05 19:10:10,394 INFO: 15390 -- Finished processing puppet configs for swift", 
        "2019-06-05 19:10:10,564 INFO: 15388 -- Finished processing puppet configs for heat_api_cfn", 
        "2019-06-05 19:10:10,565 INFO: 15388 -- Starting configuration of ovn_controller using image docker.io/tripleostein/centos-binary-ovn-controller:current-tripleo-rdo", 
        "2019-06-05 19:10:10,695 INFO: 15388 -- Removing container: container-puppet-ovn_controller", 
        "2019-06-05 19:10:10,971 INFO: 15388 -- Pulling image: docker.io/tripleostein/centos-binary-ovn-controller:current-tripleo-rdo", 
        "2019-06-05 19:10:17,745 WARNING: 15386 -- + mkdir -p /etc/puppet", 
        "+ '[' -n file,file_line,concat,augeas,cron,horizon_config ']'", 
        "+ TAGS='--tags file,file_line,concat,augeas,cron,horizon_config'", 
        "+ origin_of_time=/var/lib/config-data/horizon.origin_of_time", 
        "+ touch /var/lib/config-data/horizon.origin_of_time", 
        "+ /usr/bin/puppet apply --summarize --detailed-exitcodes --color=false --logdest syslog --logdest console --modulepath=/etc/puppet/modules:/usr/share/openstack-puppet/modules --tags file,file_line,concat,augeas,cron,horizon_config /etc/config.pp", 
        "+ '[' -f /root/.my.cnf -a -f /var/lib/config-data/horizon/root/.my.cnf ']'", 
        "+ rsync -a -R --delay-updates --delete-after /etc /root /opt /var/www /var/spool/cron /var/lib/config-data/horizon", 
        "++ stat -c %y /var/lib/config-data/horizon.origin_of_time", 
        "+ echo 'Gathering files modified after 2019-06-05 19:10:11.092132935 +0000'", 
        "+ mkdir -p /var/lib/config-data/puppet-generated/horizon", 
        "+ rsync -a -R -0 --delay-updates --delete-after --files-from=/dev/fd/63 / /var/lib/config-data/puppet-generated/horizon", 
        "++ find /etc /root /opt /var/www /var/spool/cron -newer /var/lib/config-data/horizon.origin_of_time -not -path '/etc/puppet*' -print0", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/horizon", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/puppet-generated/horizon --mtime=1970-01-01", 
        "2019-06-05 19:10:17,745 INFO: 15386 -- Removing container: container-puppet-horizon", 
        "2019-06-05 19:10:17,877 INFO: 15386 -- Finished processing puppet configs for horizon", 
        "2019-06-05 19:10:18,231 WARNING: 15388 -- + mkdir -p /etc/puppet", 
        "+ '[' -n file,file_line,concat,augeas,cron,vs_config,exec ']'", 
        "+ TAGS='--tags file,file_line,concat,augeas,cron,vs_config,exec'", 
        "+ origin_of_time=/var/lib/config-data/ovn_controller.origin_of_time", 
        "+ touch /var/lib/config-data/ovn_controller.origin_of_time", 
        "+ /usr/bin/puppet apply --summarize --detailed-exitcodes --color=false --logdest syslog --logdest console --modulepath=/etc/puppet/modules:/usr/share/openstack-puppet/modules --tags file,file_line,concat,augeas,cron,vs_config,exec /etc/config.pp", 
        "+ '[' -f /root/.my.cnf -a -f /var/lib/config-data/ovn_controller/root/.my.cnf ']'", 
        "+ rsync -a -R --delay-updates --delete-after /etc /root /opt /var/spool/cron /var/lib/config-data/ovn_controller", 
        "++ stat -c %y /var/lib/config-data/ovn_controller.origin_of_time", 
        "+ echo 'Gathering files modified after 2019-06-05 19:10:14.273189998 +0000'", 
        "+ mkdir -p /var/lib/config-data/puppet-generated/ovn_controller", 
        "+ rsync -a -R -0 --delay-updates --delete-after --files-from=/dev/fd/63 / /var/lib/config-data/puppet-generated/ovn_controller", 
        "++ find /etc /root /opt /var/spool/cron -newer /var/lib/config-data/ovn_controller.origin_of_time -not -path '/etc/puppet*' -print0", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/ovn_controller", 
        "+ tar -c --mtime=1970-01-01 '--exclude=*/etc/swift/backups/*' '--exclude=*/etc/libvirt/passwd.db' -f - /var/lib/config-data/puppet-generated/ovn_controller --mtime=1970-01-01", 
        "2019-06-05 19:10:18,231 INFO: 15388 -- Removing container: container-puppet-ovn_controller", 
        "2019-06-05 19:10:18,354 INFO: 15388 -- Finished processing puppet configs for ovn_controller"
    ]
}
2019-06-05 14:10:18,918 p=17240 u=mistral |  TASK [Diff container-puppet.py puppet-generated changes for check mode] ********
2019-06-05 14:10:18,918 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:458
2019-06-05 14:10:18,919 p=17240 u=mistral |  Wednesday 05 June 2019  14:10:18 -0500 (0:00:00.376)       0:06:52.688 ******** 
2019-06-05 14:10:18,946 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:10:18,958 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:10:18,982 p=17240 u=mistral |  TASK [Diff container-puppet.py puppet-generated changes for check mode] ********
2019-06-05 14:10:18,982 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:473
2019-06-05 14:10:18,982 p=17240 u=mistral |  Wednesday 05 June 2019  14:10:18 -0500 (0:00:00.063)       0:06:52.751 ******** 
2019-06-05 14:10:19,010 p=17240 u=mistral |  skipping: [lab-controller-0] => {}
2019-06-05 14:10:19,022 p=17240 u=mistral |  skipping: [lab-computehci-0] => {}
2019-06-05 14:10:19,046 p=17240 u=mistral |  TASK [Start containers for step 1] *********************************************
2019-06-05 14:10:19,046 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:491
2019-06-05 14:10:19,046 p=17240 u=mistral |  Wednesday 05 June 2019  14:10:19 -0500 (0:00:00.064)       0:06:52.816 ******** 
2019-06-05 14:10:19,742 p=17240 u=mistral |  ok: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:10:26,496 p=17240 u=mistral |  ok: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:10:26,522 p=17240 u=mistral |  TASK [Debug output for task: Start containers for step 1] **********************
2019-06-05 14:10:26,522 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:508
2019-06-05 14:10:26,522 p=17240 u=mistral |  Wednesday 05 June 2019  14:10:26 -0500 (0:00:07.475)       0:07:00.291 ******** 
2019-06-05 14:10:26,552 p=17240 u=mistral |  ok: [lab-controller-0] => {
    "failed_when_result": false, 
    "outputs.stdout_lines | default([]) | union(outputs.stderr_lines | default([]))": [
        "stdout: 7c8f7aed765ab1ed0821815d23e5492f0a224124be2be587579a3c0de5eca67a", 
        "", 
        "stderr: ", 
        "stdout: 3fc438eda65cd83032009c527f974cd163da409de371061fd54c28906d0b0b58", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_keepalived.service to /etc/systemd/system/tripleo_keepalived.service.", 
        "stdout: ", 
        "stdout: 4082c816fc9a0f0da0205eb45daa47788ef6570b3120d1609caee212e9d0cd06", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_memcached.service to /etc/systemd/system/tripleo_memcached.service.", 
        "Created symlink from /etc/systemd/system/timers.target.wants/tripleo_memcached_healthcheck.timer to /etc/systemd/system/tripleo_memcached_healthcheck.timer.", 
        "Created symlink from /etc/systemd/system/tripleo_memcached.service.requires/tripleo_memcached_healthcheck.timer to /etc/systemd/system/tripleo_memcached_healthcheck.timer.", 
        "stdout: 7a20729987fcd2eaf34e7df97f2d7cbc70e032371688c01cf9396d10d1612876", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_haproxy.service to /etc/systemd/system/tripleo_haproxy.service.", 
        "stdout: a6618df95d3c115f2ce44c15cb55214aebf34ea85d37e0354ab34e13498da2bd", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_redis.service to /etc/systemd/system/tripleo_redis.service.", 
        "Created symlink from /etc/systemd/system/timers.target.wants/tripleo_redis_healthcheck.timer to /etc/systemd/system/tripleo_redis_healthcheck.timer.", 
        "Created symlink from /etc/systemd/system/tripleo_redis.service.requires/tripleo_redis_healthcheck.timer to /etc/systemd/system/tripleo_redis_healthcheck.timer.", 
        "stderr: + sudo -E kolla_set_configs", 
        "INFO:__main__:Loading config file at /var/lib/kolla/config_files/config.json", 
        "INFO:__main__:Validating config file", 
        "INFO:__main__:Kolla config strategy set to: COPY_ALWAYS", 
        "INFO:__main__:Copying service configuration files", 
        "INFO:__main__:Creating directory /etc/rabbitmq/ssl", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/rabbitmq/enabled_plugins to /etc/rabbitmq/enabled_plugins", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/rabbitmq/inetrc to /etc/rabbitmq/inetrc", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/rabbitmq/rabbitmq-env.conf to /etc/rabbitmq/rabbitmq-env.conf", 
        "INFO:__main__:Deleting /etc/rabbitmq/rabbitmq.config", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/rabbitmq/rabbitmq.config to /etc/rabbitmq/rabbitmq.config", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/security/limits.d/rabbitmq-server.conf to /etc/security/limits.d/rabbitmq-server.conf", 
        "INFO:__main__:Creating directory /etc/systemd/system/rabbitmq-server.service.d", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/systemd/system/rabbitmq-server.service.d/90-limits.conf to /etc/systemd/system/rabbitmq-server.service.d/90-limits.conf", 
        "INFO:__main__:Writing out command to execute", 
        "INFO:__main__:Setting permission for /var/lib/rabbitmq", 
        "++ cat /run_command", 
        "+ CMD=/usr/lib/rabbitmq/bin/rabbitmq-server", 
        "+ ARGS=", 
        "+ [[ ! -n '' ]]", 
        "+ . kolla_extend_start", 
        "++ : /var/log/kolla/rabbitmq", 
        "++ [[ -n 0 ]]", 
        "++ [[ -e /var/lib/rabbitmq/.erlang.cookie ]]", 
        "++ echo NI698bNzqtCsfIrFTzZl", 
        "++ chmod 400 /var/lib/rabbitmq/.erlang.cookie", 
        "++ exit 0", 
        "stdout: 490315a4e06108cf2cd032a07cb10ef92d6d17985e121eb324cb5aea9642c010", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_rabbitmq.service to /etc/systemd/system/tripleo_rabbitmq.service.", 
        "Created symlink from /etc/systemd/system/timers.target.wants/tripleo_rabbitmq_healthcheck.timer to /etc/systemd/system/tripleo_rabbitmq_healthcheck.timer.", 
        "Created symlink from /etc/systemd/system/tripleo_rabbitmq.service.requires/tripleo_rabbitmq_healthcheck.timer to /etc/systemd/system/tripleo_rabbitmq_healthcheck.timer."
    ]
}
2019-06-05 14:10:26,569 p=17240 u=mistral |  ok: [lab-computehci-0] => {
    "failed_when_result": false, 
    "outputs.stdout_lines | default([]) | union(outputs.stderr_lines | default([]))": []
}
2019-06-05 14:10:26,594 p=17240 u=mistral |  TASK [Clean container_puppet_tasks for lab-controller-0 step 1] ****************
2019-06-05 14:10:26,594 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:520
2019-06-05 14:10:26,594 p=17240 u=mistral |  Wednesday 05 June 2019  14:10:26 -0500 (0:00:00.071)       0:07:00.363 ******** 
2019-06-05 14:10:26,702 p=17240 u=mistral |  ok: [lab-controller-0] => {"changed": false, "path": "/var/lib/container-puppet/container-puppet-tasks1.json", "state": "absent"}
2019-06-05 14:10:26,717 p=17240 u=mistral |  ok: [lab-computehci-0] => {"changed": false, "path": "/var/lib/container-puppet/container-puppet-tasks1.json", "state": "absent"}
2019-06-05 14:10:26,742 p=17240 u=mistral |  TASK [Calculate container_puppet_tasks for lab-controller-0 step 1] ************
2019-06-05 14:10:26,742 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:527
2019-06-05 14:10:26,742 p=17240 u=mistral |  Wednesday 05 June 2019  14:10:26 -0500 (0:00:00.148)       0:07:00.512 ******** 
2019-06-05 14:10:26,807 p=17240 u=mistral |  TASK [Write container-puppet-tasks json file for lab-controller-0 step 1] ******
2019-06-05 14:10:26,807 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:537
2019-06-05 14:10:26,807 p=17240 u=mistral |  Wednesday 05 June 2019  14:10:26 -0500 (0:00:00.064)       0:07:00.576 ******** 
2019-06-05 14:10:26,833 p=17240 u=mistral |  skipping: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:10:26,843 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:10:26,867 p=17240 u=mistral |  TASK [Run container-puppet tasks (bootstrap tasks) for step 1] *****************
2019-06-05 14:10:26,867 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:548
2019-06-05 14:10:26,867 p=17240 u=mistral |  Wednesday 05 June 2019  14:10:26 -0500 (0:00:00.060)       0:07:00.636 ******** 
2019-06-05 14:10:26,893 p=17240 u=mistral |  skipping: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:10:26,903 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:10:26,927 p=17240 u=mistral |  TASK [Debug output for task: Run container-puppet tasks (bootstrap tasks) for step 1] ***
2019-06-05 14:10:26,928 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:567
2019-06-05 14:10:26,928 p=17240 u=mistral |  Wednesday 05 June 2019  14:10:26 -0500 (0:00:00.060)       0:07:00.697 ******** 
2019-06-05 14:10:26,954 p=17240 u=mistral |  skipping: [lab-controller-0] => {}
2019-06-05 14:10:26,969 p=17240 u=mistral |  skipping: [lab-computehci-0] => {}
2019-06-05 14:10:26,970 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:10:26,970 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:10:26,977 p=17240 u=mistral |  PLAY [External deployment step 2] **********************************************
2019-06-05 14:10:26,982 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:10:26,995 p=17240 u=mistral |  TASK [set blacklisted_hostnames] ***********************************************
2019-06-05 14:10:26,995 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:2
2019-06-05 14:10:26,995 p=17240 u=mistral |  Wednesday 05 June 2019  14:10:26 -0500 (0:00:00.067)       0:07:00.764 ******** 
2019-06-05 14:10:27,006 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:10:27,021 p=17240 u=mistral |  TASK [create ceph-ansible temp dirs] *******************************************
2019-06-05 14:10:27,021 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:5
2019-06-05 14:10:27,021 p=17240 u=mistral |  Wednesday 05 June 2019  14:10:27 -0500 (0:00:00.026)       0:07:00.791 ******** 
2019-06-05 14:10:27,037 p=17240 u=mistral |  skipping: [undercloud] => (item=/var/lib/mistral/lab/ceph-ansible)  => {"changed": false, "item": "/var/lib/mistral/lab/ceph-ansible", "skip_reason": "Conditional result was False"}
2019-06-05 14:10:27,039 p=17240 u=mistral |  skipping: [undercloud] => (item=/var/lib/mistral/lab/ceph-ansible/group_vars)  => {"changed": false, "item": "/var/lib/mistral/lab/ceph-ansible/group_vars", "skip_reason": "Conditional result was False"}
2019-06-05 14:10:27,042 p=17240 u=mistral |  skipping: [undercloud] => (item=/var/lib/mistral/lab/ceph-ansible/host_vars)  => {"changed": false, "item": "/var/lib/mistral/lab/ceph-ansible/host_vars", "skip_reason": "Conditional result was False"}
2019-06-05 14:10:27,046 p=17240 u=mistral |  skipping: [undercloud] => (item=/var/lib/mistral/lab/ceph-ansible/fetch_dir)  => {"changed": false, "item": "/var/lib/mistral/lab/ceph-ansible/fetch_dir", "skip_reason": "Conditional result was False"}
2019-06-05 14:10:27,061 p=17240 u=mistral |  TASK [generate inventory] ******************************************************
2019-06-05 14:10:27,061 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:16
2019-06-05 14:10:27,061 p=17240 u=mistral |  Wednesday 05 June 2019  14:10:27 -0500 (0:00:00.039)       0:07:00.830 ******** 
2019-06-05 14:10:27,072 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:10:27,087 p=17240 u=mistral |  TASK [set ceph-ansible group vars all] *****************************************
2019-06-05 14:10:27,087 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:30
2019-06-05 14:10:27,087 p=17240 u=mistral |  Wednesday 05 June 2019  14:10:27 -0500 (0:00:00.026)       0:07:00.856 ******** 
2019-06-05 14:10:27,101 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:10:27,115 p=17240 u=mistral |  TASK [generate ceph-ansible group vars all] ************************************
2019-06-05 14:10:27,115 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:139
2019-06-05 14:10:27,115 p=17240 u=mistral |  Wednesday 05 June 2019  14:10:27 -0500 (0:00:00.028)       0:07:00.884 ******** 
2019-06-05 14:10:27,126 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:10:27,141 p=17240 u=mistral |  TASK [set ceph-ansible extra vars] *********************************************
2019-06-05 14:10:27,141 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:143
2019-06-05 14:10:27,142 p=17240 u=mistral |  Wednesday 05 June 2019  14:10:27 -0500 (0:00:00.026)       0:07:00.911 ******** 
2019-06-05 14:10:27,153 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:10:27,168 p=17240 u=mistral |  TASK [generate ceph-ansible extra vars] ****************************************
2019-06-05 14:10:27,168 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:150
2019-06-05 14:10:27,169 p=17240 u=mistral |  Wednesday 05 June 2019  14:10:27 -0500 (0:00:00.026)       0:07:00.938 ******** 
2019-06-05 14:10:27,180 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:10:27,196 p=17240 u=mistral |  TASK [generate nodes-uuid data file] *******************************************
2019-06-05 14:10:27,196 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:154
2019-06-05 14:10:27,196 p=17240 u=mistral |  Wednesday 05 June 2019  14:10:27 -0500 (0:00:00.027)       0:07:00.965 ******** 
2019-06-05 14:10:27,209 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:10:27,225 p=17240 u=mistral |  TASK [generate nodes-uuid playbook] ********************************************
2019-06-05 14:10:27,225 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:158
2019-06-05 14:10:27,225 p=17240 u=mistral |  Wednesday 05 June 2019  14:10:27 -0500 (0:00:00.029)       0:07:00.995 ******** 
2019-06-05 14:10:27,237 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:10:27,252 p=17240 u=mistral |  TASK [detect private key file] *************************************************
2019-06-05 14:10:27,252 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:179
2019-06-05 14:10:27,252 p=17240 u=mistral |  Wednesday 05 June 2019  14:10:27 -0500 (0:00:00.026)       0:07:01.021 ******** 
2019-06-05 14:10:27,345 p=17240 u=mistral |  ok: [undercloud] => {"changed": false, "stat": {"atime": 1559761409.901035, "attr_flags": "", "attributes": [], "block_size": 4096, "blocks": 8, "charset": "unknown", "ctime": 1559761405.102963, "dev": 64769, "device_type": 0, "executable": false, "exists": true, "gid": 42430, "inode": 33566831, "isblk": false, "ischr": false, "isdir": false, "isfifo": false, "isgid": false, "islnk": false, "isreg": true, "issock": false, "isuid": false, "mimetype": "unknown", "mode": "0600", "mtime": 1559761405.102963, "nlink": 1, "path": "/var/lib/mistral/lab/ssh_private_key", "readable": false, "rgrp": false, "roth": false, "rusr": true, "size": 1679, "uid": 42430, "version": null, "wgrp": false, "woth": false, "writeable": false, "wusr": true, "xgrp": false, "xoth": false, "xusr": false}}
2019-06-05 14:10:27,360 p=17240 u=mistral |  TASK [set private key file] ****************************************************
2019-06-05 14:10:27,360 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:183
2019-06-05 14:10:27,360 p=17240 u=mistral |  Wednesday 05 June 2019  14:10:27 -0500 (0:00:00.107)       0:07:01.129 ******** 
2019-06-05 14:10:27,376 p=17240 u=mistral |  ok: [undercloud] => {"ansible_facts": {"ceph_ansible_private_key_file": "/var/lib/mistral/lab/ssh_private_key"}, "changed": false}
2019-06-05 14:10:27,390 p=17240 u=mistral |  TASK [run nodes-uuid] **********************************************************
2019-06-05 14:10:27,390 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:187
2019-06-05 14:10:27,390 p=17240 u=mistral |  Wednesday 05 June 2019  14:10:27 -0500 (0:00:00.030)       0:07:01.160 ******** 
2019-06-05 14:10:28,987 p=17240 u=mistral |  changed: [undercloud] => {"changed": true, "cmd": "ANSIBLE_LOG_PATH=\"/var/lib/mistral/lab/ceph-ansible/nodes_uuid_command.log\" ANSIBLE_SSH_CONTROL_PATH_DIR=\"/var/lib/mistral/lab/ceph-ansible/\" ANSIBLE_CONFIG=\"/var/lib/mistral/lab/ansible.cfg\" ANSIBLE_REMOTE_TEMP=/tmp/nodes_uuid_tmp ansible-playbook --private-key /var/lib/mistral/lab/ssh_private_key -i /var/lib/mistral/lab/ceph-ansible/inventory.yml -e ansible_python_interpreter=/usr/bin/python2 /var/lib/mistral/lab/ceph-ansible/nodes_uuid_playbook.yml", "delta": "0:00:01.497786", "end": "2019-06-05 14:10:28.976437", "rc": 0, "start": "2019-06-05 14:10:27.478651", "stderr": "", "stderr_lines": [], "stdout": "\nPLAY [all] *********************************************************************\n\nTASK [set nodes data] **********************************************************\nok: [lab-computehci-0]\nok: [lab-controller-0]\n\nTASK [register machine id] *****************************************************\nchanged: [lab-computehci-0]\nchanged: [lab-controller-0]\n\nTASK [generate host vars from nodes data] **************************************\nok: [lab-computehci-0 -> localhost]\nok: [lab-controller-0 -> localhost]\n\nPLAY RECAP *********************************************************************\nlab-computehci-0           : ok=3    changed=1    unreachable=0    failed=0   \nlab-controller-0           : ok=3    changed=1    unreachable=0    failed=0   ", "stdout_lines": ["", "PLAY [all] *********************************************************************", "", "TASK [set nodes data] **********************************************************", "ok: [lab-computehci-0]", "ok: [lab-controller-0]", "", "TASK [register machine id] *****************************************************", "changed: [lab-computehci-0]", "changed: [lab-controller-0]", "", "TASK [generate host vars from nodes data] **************************************", "ok: [lab-computehci-0 -> localhost]", "ok: [lab-controller-0 -> localhost]", "", "PLAY RECAP *********************************************************************", "lab-computehci-0           : ok=3    changed=1    unreachable=0    failed=0   ", "lab-controller-0           : ok=3    changed=1    unreachable=0    failed=0   "]}
2019-06-05 14:10:29,002 p=17240 u=mistral |  TASK [set ceph-ansible params from Heat] ***************************************
2019-06-05 14:10:29,002 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:195
2019-06-05 14:10:29,002 p=17240 u=mistral |  Wednesday 05 June 2019  14:10:29 -0500 (0:00:01.611)       0:07:02.771 ******** 
2019-06-05 14:10:29,016 p=17240 u=mistral |  ok: [undercloud] => {"ansible_facts": {"ceph_ansible_playbook_verbosity": 1, "ceph_ansible_playbooks_param": ["default"]}, "changed": false}
2019-06-05 14:10:29,031 p=17240 u=mistral |  TASK [set ceph-ansible playbooks] **********************************************
2019-06-05 14:10:29,031 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:200
2019-06-05 14:10:29,031 p=17240 u=mistral |  Wednesday 05 June 2019  14:10:29 -0500 (0:00:00.028)       0:07:02.800 ******** 
2019-06-05 14:10:29,048 p=17240 u=mistral |  ok: [undercloud] => {"ansible_facts": {"ceph_ansible_playbooks": ["/usr/share/ceph-ansible/site-container.yml.sample"]}, "changed": false}
2019-06-05 14:10:29,062 p=17240 u=mistral |  TASK [was path for local ceph-ansible fetch directory backups set?] ************
2019-06-05 14:10:29,062 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:205
2019-06-05 14:10:29,063 p=17240 u=mistral |  Wednesday 05 June 2019  14:10:29 -0500 (0:00:00.031)       0:07:02.832 ******** 
2019-06-05 14:10:29,076 p=17240 u=mistral |  ok: [undercloud] => {"ansible_facts": {"ceph_ansible_tarball_name": "temporary_dir.tar.gz", "local_ceph_ansible_fetch_directory_backup": ""}, "changed": false}
2019-06-05 14:10:29,091 p=17240 u=mistral |  TASK [look for requested ceph-ansible fetch directory for local backup] ********
2019-06-05 14:10:29,092 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:210
2019-06-05 14:10:29,092 p=17240 u=mistral |  Wednesday 05 June 2019  14:10:29 -0500 (0:00:00.029)       0:07:02.861 ******** 
2019-06-05 14:10:29,104 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:10:29,120 p=17240 u=mistral |  TASK [autocreate new directory for ceph-ansible fetch directory backup] ********
2019-06-05 14:10:29,120 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:214
2019-06-05 14:10:29,120 p=17240 u=mistral |  Wednesday 05 June 2019  14:10:29 -0500 (0:00:00.027)       0:07:02.889 ******** 
2019-06-05 14:10:29,132 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:10:29,147 p=17240 u=mistral |  TASK [look for tarball of ceph-ansible fetch directory in local backup] ********
2019-06-05 14:10:29,147 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:222
2019-06-05 14:10:29,147 p=17240 u=mistral |  Wednesday 05 June 2019  14:10:29 -0500 (0:00:00.027)       0:07:02.917 ******** 
2019-06-05 14:10:29,160 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:10:29,175 p=17240 u=mistral |  TASK [untar local backup of ceph-ansible fetch directory] **********************
2019-06-05 14:10:29,176 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:226
2019-06-05 14:10:29,176 p=17240 u=mistral |  Wednesday 05 June 2019  14:10:29 -0500 (0:00:00.028)       0:07:02.945 ******** 
2019-06-05 14:10:29,189 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:10:29,205 p=17240 u=mistral |  TASK [set facts for swift back up of ceph-ansible fetch directory] *************
2019-06-05 14:10:29,205 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:232
2019-06-05 14:10:29,206 p=17240 u=mistral |  Wednesday 05 June 2019  14:10:29 -0500 (0:00:00.029)       0:07:02.975 ******** 
2019-06-05 14:10:29,220 p=17240 u=mistral |  ok: [undercloud] => {"ansible_facts": {"new_ceph_ansible_tarball_name": "temporary_dir_new.tar.gz", "old_ceph_ansible_tarball_name": "temporary_dir_old.tar.gz", "swift_get_url": "https://192.168.24.2:13808/v1/AUTH_1327100c0ba7410287780ba433abebed/lab_ceph_ansible_fetch_dir/temporary_dir.tar.gz?temp_url_sig=146d48d9e7da2b3e305c03718f0d4a38bf36217c&temp_url_expires=1559847279", "swift_put_url": "https://192.168.24.2:13808/v1/AUTH_1327100c0ba7410287780ba433abebed/lab_ceph_ansible_fetch_dir/temporary_dir.tar.gz?temp_url_sig=ee673cc734be0963db2282512697f7a8481f03ae&temp_url_expires=1559847279"}, "changed": false}
2019-06-05 14:10:29,236 p=17240 u=mistral |  TASK [attempt download of fetch directory tarball from swift backup] ***********
2019-06-05 14:10:29,236 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:238
2019-06-05 14:10:29,236 p=17240 u=mistral |  Wednesday 05 June 2019  14:10:29 -0500 (0:00:00.030)       0:07:03.005 ******** 
2019-06-05 14:10:29,438 p=17240 u=mistral |   [WARNING]: Consider using the get_url or uri module rather than running
'curl'.  If you need to use command because get_url or uri is insufficient you
can add 'warn: false' to this command task or set 'command_warnings=False' in
ansible.cfg to get rid of this message.

2019-06-05 14:10:29,438 p=17240 u=mistral |  changed: [undercloud] => {"changed": true, "cmd": "curl -s -o /tmp/temporary_dir_old.tar.gz -w '%{http_code}' -X GET \"https://192.168.24.2:13808/v1/AUTH_1327100c0ba7410287780ba433abebed/lab_ceph_ansible_fetch_dir/temporary_dir.tar.gz?temp_url_sig=146d48d9e7da2b3e305c03718f0d4a38bf36217c&temp_url_expires=1559847279\"", "delta": "0:00:00.115660", "end": "2019-06-05 14:10:29.428040", "rc": 0, "start": "2019-06-05 14:10:29.312380", "stderr": "", "stderr_lines": [], "stdout": "200", "stdout_lines": ["200"]}
2019-06-05 14:10:29,453 p=17240 u=mistral |  TASK [ensure we create a new fetch_directory or use the old fetch_directory] ***
2019-06-05 14:10:29,453 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:243
2019-06-05 14:10:29,453 p=17240 u=mistral |  Wednesday 05 June 2019  14:10:29 -0500 (0:00:00.217)       0:07:03.223 ******** 
2019-06-05 14:10:29,469 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:10:29,484 p=17240 u=mistral |  TASK [unpack downloaded ceph-ansible fetch tarball to fetch directory] *********
2019-06-05 14:10:29,484 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:251
2019-06-05 14:10:29,485 p=17240 u=mistral |  Wednesday 05 June 2019  14:10:29 -0500 (0:00:00.031)       0:07:03.254 ******** 
2019-06-05 14:10:29,579 p=17240 u=mistral |  changed: [undercloud] => {"changed": true, "cmd": "/usr/bin/gtar --gzip --extract --file /tmp/temporary_dir_old.tar.gz -C /var/lib/mistral/lab/ceph-ansible/fetch_dir", "delta": "0:00:00.006851", "end": "2019-06-05 14:10:29.569632", "rc": 0, "start": "2019-06-05 14:10:29.562781", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}
2019-06-05 14:10:29,594 p=17240 u=mistral |  TASK [remove downloaded ceph-ansible fetch directory tarball from filesystem] ***
2019-06-05 14:10:29,594 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:257
2019-06-05 14:10:29,594 p=17240 u=mistral |  Wednesday 05 June 2019  14:10:29 -0500 (0:00:00.109)       0:07:03.363 ******** 
2019-06-05 14:10:29,686 p=17240 u=mistral |  changed: [undercloud] => {"changed": true, "path": "/tmp/temporary_dir_old.tar.gz", "state": "absent"}
2019-06-05 14:10:29,702 p=17240 u=mistral |  TASK [set ceph-ansible command] ************************************************
2019-06-05 14:10:29,703 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:265
2019-06-05 14:10:29,703 p=17240 u=mistral |  Wednesday 05 June 2019  14:10:29 -0500 (0:00:00.108)       0:07:03.472 ******** 
2019-06-05 14:10:29,720 p=17240 u=mistral |  ok: [undercloud] => {"ansible_facts": {"ceph_ansible_command": "ANSIBLE_ACTION_PLUGINS=/usr/share/ceph-ansible/plugins/actions/ ANSIBLE_CALLBACK_PLUGINS=/usr/share/ceph-ansible/plugins/callback/ ANSIBLE_ROLES_PATH=/usr/share/ceph-ansible/roles/ ANSIBLE_LOG_PATH=\"/var/lib/mistral/lab/ceph-ansible/ceph_ansible_command.log\" ANSIBLE_LIBRARY=/usr/share/ceph-ansible/library/ ANSIBLE_CONFIG=/usr/share/ceph-ansible/ansible.cfg ANSIBLE_REMOTE_TEMP=/tmp/ceph_ansible_tmp ANSIBLE_FORKS=25 ANSIBLE_GATHER_TIMEOUT=60  ansible-playbook --private-key /var/lib/mistral/lab/ssh_private_key -e ansible_python_interpreter=/usr/bin/python2 -v --skip-tags package-install,with_pkg -i /var/lib/mistral/lab/ceph-ansible/inventory.yml --extra-vars @/var/lib/mistral/lab/ceph-ansible/extra_vars.yml"}, "changed": false}
2019-06-05 14:10:29,737 p=17240 u=mistral |  TASK [run ceph-ansible (immediate log at /var/lib/mistral/lab/ceph-ansible/ceph_ansible_command.log)] ***
2019-06-05 14:10:29,737 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:277
2019-06-05 14:10:29,737 p=17240 u=mistral |  Wednesday 05 June 2019  14:10:29 -0500 (0:00:00.034)       0:07:03.507 ******** 
2019-06-05 14:14:25,322 p=17240 u=mistral |  changed: [undercloud] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:14:25,337 p=17240 u=mistral |  TASK [print ceph-ansible output in case of failure] ****************************
2019-06-05 14:14:25,337 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:293
2019-06-05 14:14:25,337 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:25 -0500 (0:03:55.599)       0:10:59.107 ******** 
2019-06-05 14:14:25,370 p=17240 u=mistral |  skipping: [undercloud] => {}
2019-06-05 14:14:25,386 p=17240 u=mistral |  TASK [register contents of fetch_directory after ceph-ansible run] *************
2019-06-05 14:14:25,386 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:300
2019-06-05 14:14:25,387 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:25 -0500 (0:00:00.049)       0:10:59.156 ******** 
2019-06-05 14:14:25,624 p=17240 u=mistral |  ok: [undercloud] => {"changed": false, "examined": 42, "files": [{"atime": 1559761829.568343, "ctime": 1559761829.568343, "dev": 64769, "gid": 1002, "gr_name": "tripleo-admin", "inode": 46988266, "isblk": false, "ischr": false, "isdir": false, "isfifo": false, "isgid": false, "islnk": false, "isreg": true, "issock": false, "isuid": false, "mode": "0644", "mtime": 1559753464.0, "nlink": 1, "path": "/var/lib/mistral/lab/ceph-ansible/fetch_dir/4cb1bf08-87a9-11e9-861d-5254009e1c0e/etc/ceph/ceph.mgr.lab-controller-0.keyring", "pw_name": "tripleo-admin", "rgrp": true, "roth": true, "rusr": true, "size": 147, "uid": 1001, "wgrp": false, "woth": false, "wusr": true, "xgrp": false, "xoth": false, "xusr": false}, {"atime": 1559761829.568343, "ctime": 1559761829.568343, "dev": 64769, "gid": 1002, "gr_name": "tripleo-admin", "inode": 46988267, "isblk": false, "ischr": false, "isdir": false, "isfifo": false, "isgid": false, "islnk": false, "isreg": true, "issock": false, "isuid": false, "mode": "0644", "mtime": 1559753465.0, "nlink": 1, "path": "/var/lib/mistral/lab/ceph-ansible/fetch_dir/4cb1bf08-87a9-11e9-861d-5254009e1c0e/etc/ceph/ceph.client.admin.keyring", "pw_name": "tripleo-admin", "rgrp": true, "roth": true, "rusr": true, "size": 151, "uid": 1001, "wgrp": false, "woth": false, "wusr": true, "xgrp": false, "xoth": false, "xusr": false}, {"atime": 1559761829.568343, "ctime": 1559761829.568343, "dev": 64769, "gid": 1002, "gr_name": "tripleo-admin", "inode": 46988271, "isblk": false, "ischr": false, "isdir": false, "isfifo": false, "isgid": false, "islnk": false, "isreg": true, "issock": false, "isuid": false, "mode": "0644", "mtime": 1559753648.0, "nlink": 1, "path": "/var/lib/mistral/lab/ceph-ansible/fetch_dir/4cb1bf08-87a9-11e9-861d-5254009e1c0e/etc/ceph/ceph.client.openstack.keyring", "pw_name": "tripleo-admin", "rgrp": true, "roth": true, "rusr": true, "size": 253, "uid": 1001, "wgrp": false, "woth": false, "wusr": true, "xgrp": false, "xoth": false, "xusr": false}, {"atime": 1559761829.568343, "ctime": 1559761829.568343, "dev": 64769, "gid": 1002, "gr_name": "tripleo-admin", "inode": 46988272, "isblk": false, "ischr": false, "isdir": false, "isfifo": false, "isgid": false, "islnk": false, "isreg": true, "issock": false, "isuid": false, "mode": "0644", "mtime": 1559753648.0, "nlink": 1, "path": "/var/lib/mistral/lab/ceph-ansible/fetch_dir/4cb1bf08-87a9-11e9-861d-5254009e1c0e/etc/ceph/ceph.client.manila.keyring", "pw_name": "tripleo-admin", "rgrp": true, "roth": true, "rusr": true, "size": 268, "uid": 1001, "wgrp": false, "woth": false, "wusr": true, "xgrp": false, "xoth": false, "xusr": false}, {"atime": 1559761829.568343, "ctime": 1559761829.568343, "dev": 64769, "gid": 1002, "gr_name": "tripleo-admin", "inode": 46988273, "isblk": false, "ischr": false, "isdir": false, "isfifo": false, "isgid": false, "islnk": false, "isreg": true, "issock": false, "isuid": false, "mode": "0644", "mtime": 1559753648.0, "nlink": 1, "path": "/var/lib/mistral/lab/ceph-ansible/fetch_dir/4cb1bf08-87a9-11e9-861d-5254009e1c0e/etc/ceph/ceph.client.radosgw.keyring", "pw_name": "tripleo-admin", "rgrp": true, "roth": true, "rusr": true, "size": 134, "uid": 1001, "wgrp": false, "woth": false, "wusr": true, "xgrp": false, "xoth": false, "xusr": false}, {"atime": 1559761829.568343, "ctime": 1559761829.568343, "dev": 64769, "gid": 1002, "gr_name": "tripleo-admin", "inode": 59209091, "isblk": false, "ischr": false, "isdir": false, "isfifo": false, "isgid": false, "islnk": false, "isreg": true, "issock": false, "isuid": false, "mode": "0644", "mtime": 1559753464.0, "nlink": 1, "path": "/var/lib/mistral/lab/ceph-ansible/fetch_dir/4cb1bf08-87a9-11e9-861d-5254009e1c0e/var/lib/ceph/bootstrap-osd/ceph.keyring", "pw_name": "tripleo-admin", "rgrp": true, "roth": true, "rusr": true, "size": 113, "uid": 1001, "wgrp": false, "woth": false, "wusr": true, "xgrp": false, "xoth": false, "xusr": false}, {"atime": 1559761829.568343, "ctime": 1559761829.568343, "dev": 64769, "gid": 1002, "gr_name": "tripleo-admin", "inode": 63392130, "isblk": false, "ischr": false, "isdir": false, "isfifo": false, "isgid": false, "islnk": false, "isreg": true, "issock": false, "isuid": false, "mode": "0644", "mtime": 1559753464.0, "nlink": 1, "path": "/var/lib/mistral/lab/ceph-ansible/fetch_dir/4cb1bf08-87a9-11e9-861d-5254009e1c0e/var/lib/ceph/bootstrap-rgw/ceph.keyring", "pw_name": "tripleo-admin", "rgrp": true, "roth": true, "rusr": true, "size": 113, "uid": 1001, "wgrp": false, "woth": false, "wusr": true, "xgrp": false, "xoth": false, "xusr": false}, {"atime": 1559761829.568343, "ctime": 1559761829.568343, "dev": 64769, "gid": 1002, "gr_name": "tripleo-admin", "inode": 67151610, "isblk": false, "ischr": false, "isdir": false, "isfifo": false, "isgid": false, "islnk": false, "isreg": true, "issock": false, "isuid": false, "mode": "0644", "mtime": 1559753465.0, "nlink": 1, "path": "/var/lib/mistral/lab/ceph-ansible/fetch_dir/4cb1bf08-87a9-11e9-861d-5254009e1c0e/var/lib/ceph/bootstrap-mds/ceph.keyring", "pw_name": "tripleo-admin", "rgrp": true, "roth": true, "rusr": true, "size": 113, "uid": 1001, "wgrp": false, "woth": false, "wusr": true, "xgrp": false, "xoth": false, "xusr": false}, {"atime": 1559761829.568343, "ctime": 1559761829.568343, "dev": 64769, "gid": 1002, "gr_name": "tripleo-admin", "inode": 71334913, "isblk": false, "ischr": false, "isdir": false, "isfifo": false, "isgid": false, "islnk": false, "isreg": true, "issock": false, "isuid": false, "mode": "0644", "mtime": 1559753465.0, "nlink": 1, "path": "/var/lib/mistral/lab/ceph-ansible/fetch_dir/4cb1bf08-87a9-11e9-861d-5254009e1c0e/var/lib/ceph/bootstrap-rbd/ceph.keyring", "pw_name": "tripleo-admin", "rgrp": true, "roth": true, "rusr": true, "size": 113, "uid": 1001, "wgrp": false, "woth": false, "wusr": true, "xgrp": false, "xoth": false, "xusr": false}, {"atime": 1559761829.568343, "ctime": 1559761829.5693429, "dev": 64769, "gid": 1002, "gr_name": "tripleo-admin", "inode": 75549722, "isblk": false, "ischr": false, "isdir": false, "isfifo": false, "isgid": false, "islnk": false, "isreg": true, "issock": false, "isuid": false, "mode": "0644", "mtime": 1559753465.0, "nlink": 1, "path": "/var/lib/mistral/lab/ceph-ansible/fetch_dir/4cb1bf08-87a9-11e9-861d-5254009e1c0e/var/lib/ceph/bootstrap-rbd-mirror/ceph.keyring", "pw_name": "tripleo-admin", "rgrp": true, "roth": true, "rusr": true, "size": 127, "uid": 1001, "wgrp": false, "woth": false, "wusr": true, "xgrp": false, "xoth": false, "xusr": false}, {"atime": 1559761913.1705995, "ctime": 1559761895.3493316, "dev": 64769, "gid": 0, "gr_name": "root", "inode": 2018931, "isblk": false, "ischr": false, "isdir": false, "isfifo": false, "isgid": false, "islnk": false, "isreg": true, "issock": false, "isuid": false, "mode": "0644", "mtime": 1559761895.3493316, "nlink": 1, "path": "/var/lib/mistral/lab/ceph-ansible/fetch_dir/473c3318-87c3-11e9-861d-5254009e1c0e/etc/ceph/ceph.mgr.lab-controller-0.keyring", "pw_name": "root", "rgrp": true, "roth": true, "rusr": true, "size": 147, "uid": 0, "wgrp": false, "woth": false, "wusr": true, "xgrp": false, "xoth": false, "xusr": false}, {"atime": 1559761895.8983397, "ctime": 1559761895.8983397, "dev": 64769, "gid": 0, "gr_name": "root", "inode": 2018933, "isblk": false, "ischr": false, "isdir": false, "isfifo": false, "isgid": false, "islnk": false, "isreg": true, "issock": false, "isuid": false, "mode": "0644", "mtime": 1559761895.8983397, "nlink": 1, "path": "/var/lib/mistral/lab/ceph-ansible/fetch_dir/473c3318-87c3-11e9-861d-5254009e1c0e/etc/ceph/ceph.client.admin.keyring", "pw_name": "root", "rgrp": true, "roth": true, "rusr": true, "size": 151, "uid": 0, "wgrp": false, "woth": false, "wusr": true, "xgrp": false, "xoth": false, "xusr": false}, {"atime": 1559762030.8923688, "ctime": 1559762030.564364, "dev": 64769, "gid": 0, "gr_name": "root", "inode": 2018934, "isblk": false, "ischr": false, "isdir": false, "isfifo": false, "isgid": false, "islnk": false, "isreg": true, "issock": false, "isuid": false, "mode": "0644", "mtime": 1559762030.564364, "nlink": 1, "path": "/var/lib/mistral/lab/ceph-ansible/fetch_dir/473c3318-87c3-11e9-861d-5254009e1c0e/etc/ceph/ceph.client.openstack.keyring", "pw_name": "root", "rgrp": true, "roth": true, "rusr": true, "size": 253, "uid": 0, "wgrp": false, "woth": false, "wusr": true, "xgrp": false, "xoth": false, "xusr": false}, {"atime": 1559762031.116372, "ctime": 1559762030.6493652, "dev": 64769, "gid": 0, "gr_name": "root", "inode": 2018935, "isblk": false, "ischr": false, "isdir": false, "isfifo": false, "isgid": false, "islnk": false, "isreg": true, "issock": false, "isuid": false, "mode": "0644", "mtime": 1559762030.6493652, "nlink": 1, "path": "/var/lib/mistral/lab/ceph-ansible/fetch_dir/473c3318-87c3-11e9-861d-5254009e1c0e/etc/ceph/ceph.client.manila.keyring", "pw_name": "root", "rgrp": true, "roth": true, "rusr": true, "size": 268, "uid": 0, "wgrp": false, "woth": false, "wusr": true, "xgrp": false, "xoth": false, "xusr": false}, {"atime": 1559762031.3353755, "ctime": 1559762030.7323663, "dev": 64769, "gid": 0, "gr_name": "root", "inode": 2018936, "isblk": false, "ischr": false, "isdir": false, "isfifo": false, "isgid": false, "islnk": false, "isreg": true, "issock": false, "isuid": false, "mode": "0644", "mtime": 1559762030.7323663, "nlink": 1, "path": "/var/lib/mistral/lab/ceph-ansible/fetch_dir/473c3318-87c3-11e9-861d-5254009e1c0e/etc/ceph/ceph.client.radosgw.keyring", "pw_name": "root", "rgrp": true, "roth": true, "rusr": true, "size": 134, "uid": 0, "wgrp": false, "woth": false, "wusr": true, "xgrp": false, "xoth": false, "xusr": false}, {"atime": 1559761956.2722473, "ctime": 1559761895.4853337, "dev": 64769, "gid": 0, "gr_name": "root", "inode": 13741431, "isblk": false, "ischr": false, "isdir": false, "isfifo": false, "isgid": false, "islnk": false, "isreg": true, "issock": false, "isuid": false, "mode": "0644", "mtime": 1559761895.4853337, "nlink": 1, "path": "/var/lib/mistral/lab/ceph-ansible/fetch_dir/473c3318-87c3-11e9-861d-5254009e1c0e/var/lib/ceph/bootstrap-osd/ceph.keyring", "pw_name": "root", "rgrp": true, "roth": true, "rusr": true, "size": 113, "uid": 0, "wgrp": false, "woth": false, "wusr": true, "xgrp": false, "xoth": false, "xusr": false}, {"atime": 1559761895.567335, "ctime": 1559761895.567335, "dev": 64769, "gid": 0, "gr_name": "root", "inode": 16816184, "isblk": false, "ischr": false, "isdir": false, "isfifo": false, "isgid": false, "islnk": false, "isreg": true, "issock": false, "isuid": false, "mode": "0644", "mtime": 1559761895.567335, "nlink": 1, "path": "/var/lib/mistral/lab/ceph-ansible/fetch_dir/473c3318-87c3-11e9-861d-5254009e1c0e/var/lib/ceph/bootstrap-rgw/ceph.keyring", "pw_name": "root", "rgrp": true, "roth": true, "rusr": true, "size": 113, "uid": 0, "wgrp": false, "woth": false, "wusr": true, "xgrp": false, "xoth": false, "xusr": false}, {"atime": 1559761895.6513362, "ctime": 1559761895.6513362, "dev": 64769, "gid": 0, "gr_name": "root", "inode": 21396501, "isblk": false, "ischr": false, "isdir": false, "isfifo": false, "isgid": false, "islnk": false, "isreg": true, "issock": false, "isuid": false, "mode": "0644", "mtime": 1559761895.6513362, "nlink": 1, "path": "/var/lib/mistral/lab/ceph-ansible/fetch_dir/473c3318-87c3-11e9-861d-5254009e1c0e/var/lib/ceph/bootstrap-mds/ceph.keyring", "pw_name": "root", "rgrp": true, "roth": true, "rusr": true, "size": 113, "uid": 0, "wgrp": false, "woth": false, "wusr": true, "xgrp": false, "xoth": false, "xusr": false}, {"atime": 1559761895.7343373, "ctime": 1559761895.7343373, "dev": 64769, "gid": 0, "gr_name": "root", "inode": 25574558, "isblk": false, "ischr": false, "isdir": false, "isfifo": false, "isgid": false, "islnk": false, "isreg": true, "issock": false, "isuid": false, "mode": "0644", "mtime": 1559761895.7343373, "nlink": 1, "path": "/var/lib/mistral/lab/ceph-ansible/fetch_dir/473c3318-87c3-11e9-861d-5254009e1c0e/var/lib/ceph/bootstrap-rbd/ceph.keyring", "pw_name": "root", "rgrp": true, "roth": true, "rusr": true, "size": 113, "uid": 0, "wgrp": false, "woth": false, "wusr": true, "xgrp": false, "xoth": false, "xusr": false}, {"atime": 1559761895.8163385, "ctime": 1559761895.8163385, "dev": 64769, "gid": 0, "gr_name": "root", "inode": 29567691, "isblk": false, "ischr": false, "isdir": false, "isfifo": false, "isgid": false, "islnk": false, "isreg": true, "issock": false, "isuid": false, "mode": "0644", "mtime": 1559761895.8163385, "nlink": 1, "path": "/var/lib/mistral/lab/ceph-ansible/fetch_dir/473c3318-87c3-11e9-861d-5254009e1c0e/var/lib/ceph/bootstrap-rbd-mirror/ceph.keyring", "pw_name": "root", "rgrp": true, "roth": true, "rusr": true, "size": 127, "uid": 0, "wgrp": false, "woth": false, "wusr": true, "xgrp": false, "xoth": false, "xusr": false}], "matched": 20, "msg": ""}
2019-06-05 14:14:25,639 p=17240 u=mistral |  TASK [create ceph-ansible fetch directory tarball in local backup] *************
2019-06-05 14:14:25,639 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:305
2019-06-05 14:14:25,639 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:25 -0500 (0:00:00.252)       0:10:59.409 ******** 
2019-06-05 14:14:25,652 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:25,667 p=17240 u=mistral |  TASK [create temporary ceph-ansible fetch directory tarball for swift backup] ***
2019-06-05 14:14:25,667 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:315
2019-06-05 14:14:25,667 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:25 -0500 (0:00:00.028)       0:10:59.437 ******** 
2019-06-05 14:14:25,842 p=17240 u=mistral |  changed: [undercloud] => {"archived": ["/var/lib/mistral/lab/ceph-ansible/fetch_dir/4cb1bf08-87a9-11e9-861d-5254009e1c0e/etc/ceph/ceph.mgr.lab-controller-0.keyring", "/var/lib/mistral/lab/ceph-ansible/fetch_dir/4cb1bf08-87a9-11e9-861d-5254009e1c0e/etc/ceph/ceph.client.admin.keyring", "/var/lib/mistral/lab/ceph-ansible/fetch_dir/4cb1bf08-87a9-11e9-861d-5254009e1c0e/etc/ceph/ceph.client.openstack.keyring", "/var/lib/mistral/lab/ceph-ansible/fetch_dir/4cb1bf08-87a9-11e9-861d-5254009e1c0e/etc/ceph/ceph.client.manila.keyring", "/var/lib/mistral/lab/ceph-ansible/fetch_dir/4cb1bf08-87a9-11e9-861d-5254009e1c0e/etc/ceph/ceph.client.radosgw.keyring", "/var/lib/mistral/lab/ceph-ansible/fetch_dir/4cb1bf08-87a9-11e9-861d-5254009e1c0e/var/lib/ceph/bootstrap-osd/ceph.keyring", "/var/lib/mistral/lab/ceph-ansible/fetch_dir/4cb1bf08-87a9-11e9-861d-5254009e1c0e/var/lib/ceph/bootstrap-rgw/ceph.keyring", "/var/lib/mistral/lab/ceph-ansible/fetch_dir/4cb1bf08-87a9-11e9-861d-5254009e1c0e/var/lib/ceph/bootstrap-mds/ceph.keyring", "/var/lib/mistral/lab/ceph-ansible/fetch_dir/4cb1bf08-87a9-11e9-861d-5254009e1c0e/var/lib/ceph/bootstrap-rbd/ceph.keyring", "/var/lib/mistral/lab/ceph-ansible/fetch_dir/4cb1bf08-87a9-11e9-861d-5254009e1c0e/var/lib/ceph/bootstrap-rbd-mirror/ceph.keyring", "/var/lib/mistral/lab/ceph-ansible/fetch_dir/473c3318-87c3-11e9-861d-5254009e1c0e/etc/ceph/ceph.mgr.lab-controller-0.keyring", "/var/lib/mistral/lab/ceph-ansible/fetch_dir/473c3318-87c3-11e9-861d-5254009e1c0e/etc/ceph/ceph.client.admin.keyring", "/var/lib/mistral/lab/ceph-ansible/fetch_dir/473c3318-87c3-11e9-861d-5254009e1c0e/etc/ceph/ceph.client.openstack.keyring", "/var/lib/mistral/lab/ceph-ansible/fetch_dir/473c3318-87c3-11e9-861d-5254009e1c0e/etc/ceph/ceph.client.manila.keyring", "/var/lib/mistral/lab/ceph-ansible/fetch_dir/473c3318-87c3-11e9-861d-5254009e1c0e/etc/ceph/ceph.client.radosgw.keyring", "/var/lib/mistral/lab/ceph-ansible/fetch_dir/473c3318-87c3-11e9-861d-5254009e1c0e/var/lib/ceph/bootstrap-osd/ceph.keyring", "/var/lib/mistral/lab/ceph-ansible/fetch_dir/473c3318-87c3-11e9-861d-5254009e1c0e/var/lib/ceph/bootstrap-rgw/ceph.keyring", "/var/lib/mistral/lab/ceph-ansible/fetch_dir/473c3318-87c3-11e9-861d-5254009e1c0e/var/lib/ceph/bootstrap-mds/ceph.keyring", "/var/lib/mistral/lab/ceph-ansible/fetch_dir/473c3318-87c3-11e9-861d-5254009e1c0e/var/lib/ceph/bootstrap-rbd/ceph.keyring", "/var/lib/mistral/lab/ceph-ansible/fetch_dir/473c3318-87c3-11e9-861d-5254009e1c0e/var/lib/ceph/bootstrap-rbd-mirror/ceph.keyring"], "arcroot": "/var/lib/mistral/lab/ceph-ansible/fetch_dir/", "changed": true, "dest": "/tmp/temporary_dir_new.tar.gz", "expanded_exclude_paths": ["/var/lib/mistral/lab/ceph-ansible/fetch_dir/fetch_dir"], "expanded_paths": ["/var/lib/mistral/lab/ceph-ansible/fetch_dir/4cb1bf08-87a9-11e9-861d-5254009e1c0e", "/var/lib/mistral/lab/ceph-ansible/fetch_dir/473c3318-87c3-11e9-861d-5254009e1c0e"], "gid": 1002, "group": "tripleo-admin", "missing": [], "mode": "0664", "owner": "tripleo-admin", "secontext": "unconfined_u:object_r:user_tmp_t:s0", "size": 1741, "state": "file", "uid": 1001}
2019-06-05 14:14:25,856 p=17240 u=mistral |  TASK [backup temporary ceph-ansible fetch directory tarball in swift] **********
2019-06-05 14:14:25,856 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:321
2019-06-05 14:14:25,856 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:25 -0500 (0:00:00.188)       0:10:59.626 ******** 
2019-06-05 14:14:26,061 p=17240 u=mistral |  changed: [undercloud] => {"changed": true, "cmd": "curl -s -o /dev/null -w '%{http_code}' -X PUT -T /tmp/temporary_dir_new.tar.gz \"https://192.168.24.2:13808/v1/AUTH_1327100c0ba7410287780ba433abebed/lab_ceph_ansible_fetch_dir/temporary_dir.tar.gz?temp_url_sig=ee673cc734be0963db2282512697f7a8481f03ae&temp_url_expires=1559847279\"", "delta": "0:00:00.116628", "end": "2019-06-05 14:14:26.051875", "rc": 0, "start": "2019-06-05 14:14:25.935247", "stderr": "", "stderr_lines": [], "stdout": "201", "stdout_lines": ["201"]}
2019-06-05 14:14:26,076 p=17240 u=mistral |  TASK [ensure we were able to backup temporary fetch directory to swift] ********
2019-06-05 14:14:26,076 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:325
2019-06-05 14:14:26,076 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:26 -0500 (0:00:00.219)       0:10:59.845 ******** 
2019-06-05 14:14:26,097 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:26,111 p=17240 u=mistral |  TASK [clean temporary fetch directory after swift backup] **********************
2019-06-05 14:14:26,111 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:333
2019-06-05 14:14:26,111 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:26 -0500 (0:00:00.035)       0:10:59.881 ******** 
2019-06-05 14:14:26,200 p=17240 u=mistral |  changed: [undercloud] => {"changed": true, "path": "/tmp/temporary_dir_new.tar.gz", "state": "absent"}
2019-06-05 14:14:26,215 p=17240 u=mistral |  TASK [Remove ceph-ansible fetch directory] *************************************
2019-06-05 14:14:26,215 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:342
2019-06-05 14:14:26,215 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:26 -0500 (0:00:00.103)       0:10:59.984 ******** 
2019-06-05 14:14:26,314 p=17240 u=mistral |  changed: [undercloud] => {"changed": true, "path": "/var/lib/mistral/lab/ceph-ansible/fetch_dir/", "state": "absent"}
2019-06-05 14:14:26,329 p=17240 u=mistral |  TASK [set ceph-ansible group vars mgrs] ****************************************
2019-06-05 14:14:26,329 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:351
2019-06-05 14:14:26,329 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:26 -0500 (0:00:00.114)       0:11:00.099 ******** 
2019-06-05 14:14:26,340 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:26,355 p=17240 u=mistral |  TASK [generate ceph-ansible group vars mgrs] ***********************************
2019-06-05 14:14:26,355 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:355
2019-06-05 14:14:26,355 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:26 -0500 (0:00:00.025)       0:11:00.124 ******** 
2019-06-05 14:14:26,366 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:26,381 p=17240 u=mistral |  TASK [set ceph-ansible group vars mons] ****************************************
2019-06-05 14:14:26,381 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:363
2019-06-05 14:14:26,382 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:26 -0500 (0:00:00.026)       0:11:00.151 ******** 
2019-06-05 14:14:26,394 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:26,408 p=17240 u=mistral |  TASK [generate ceph-ansible group vars mons] ***********************************
2019-06-05 14:14:26,408 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:368
2019-06-05 14:14:26,409 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:26 -0500 (0:00:00.027)       0:11:00.178 ******** 
2019-06-05 14:14:26,420 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:26,434 p=17240 u=mistral |  TASK [set_fact] ****************************************************************
2019-06-05 14:14:26,434 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:376
2019-06-05 14:14:26,434 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:26 -0500 (0:00:00.025)       0:11:00.204 ******** 
2019-06-05 14:14:26,446 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:26,460 p=17240 u=mistral |  TASK [Create temp file for prepare parameter] **********************************
2019-06-05 14:14:26,460 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:379
2019-06-05 14:14:26,461 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:26 -0500 (0:00:00.026)       0:11:00.230 ******** 
2019-06-05 14:14:26,474 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:26,490 p=17240 u=mistral |  TASK [Create temp file for role data] ******************************************
2019-06-05 14:14:26,490 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:385
2019-06-05 14:14:26,490 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:26 -0500 (0:00:00.029)       0:11:00.259 ******** 
2019-06-05 14:14:26,502 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:26,516 p=17240 u=mistral |  TASK [Write ContainerImagePrepare parameter file] ******************************
2019-06-05 14:14:26,517 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:391
2019-06-05 14:14:26,517 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:26 -0500 (0:00:00.026)       0:11:00.286 ******** 
2019-06-05 14:14:26,530 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:26,544 p=17240 u=mistral |  TASK [Write role data file] ****************************************************
2019-06-05 14:14:26,544 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:659
2019-06-05 14:14:26,544 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:26 -0500 (0:00:00.027)       0:11:00.314 ******** 
2019-06-05 14:14:26,558 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:26,574 p=17240 u=mistral |  TASK [Run tripleo-container-image-prepare logged to /var/log/tripleo-container-image-prepare.log] ***
2019-06-05 14:14:26,574 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:905
2019-06-05 14:14:26,574 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:26 -0500 (0:00:00.029)       0:11:00.343 ******** 
2019-06-05 14:14:26,586 p=17240 u=mistral |  skipping: [undercloud] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:26,600 p=17240 u=mistral |  TASK [Delete param file] *******************************************************
2019-06-05 14:14:26,600 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:911
2019-06-05 14:14:26,600 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:26 -0500 (0:00:00.026)       0:11:00.370 ******** 
2019-06-05 14:14:26,614 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:26,628 p=17240 u=mistral |  TASK [Delete role file] ********************************************************
2019-06-05 14:14:26,628 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:916
2019-06-05 14:14:26,628 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:26 -0500 (0:00:00.027)       0:11:00.398 ******** 
2019-06-05 14:14:26,640 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:26,654 p=17240 u=mistral |  TASK [set ceph-ansible group vars clients] *************************************
2019-06-05 14:14:26,654 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:925
2019-06-05 14:14:26,654 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:26 -0500 (0:00:00.026)       0:11:00.424 ******** 
2019-06-05 14:14:26,665 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:26,679 p=17240 u=mistral |  TASK [generate ceph-ansible group vars clients] ********************************
2019-06-05 14:14:26,679 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:928
2019-06-05 14:14:26,679 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:26 -0500 (0:00:00.024)       0:11:00.449 ******** 
2019-06-05 14:14:26,691 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:26,705 p=17240 u=mistral |  TASK [set ceph-ansible group vars osds] ****************************************
2019-06-05 14:14:26,705 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:936
2019-06-05 14:14:26,705 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:26 -0500 (0:00:00.025)       0:11:00.475 ******** 
2019-06-05 14:14:26,717 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:26,732 p=17240 u=mistral |  TASK [generate ceph-ansible group vars osds] ***********************************
2019-06-05 14:14:26,732 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:943
2019-06-05 14:14:26,732 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:26 -0500 (0:00:00.026)       0:11:00.501 ******** 
2019-06-05 14:14:26,743 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:26,744 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:14:26,744 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:14:26,748 p=17240 u=mistral |  PLAY [Overcloud deploy step tasks for 2] ***************************************
2019-06-05 14:14:26,750 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:14:26,771 p=17240 u=mistral |  TASK [Write the config_step hieradata for the deploy step 2 tasks] *************
2019-06-05 14:14:26,771 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deploy_steps_playbook.yaml:242
2019-06-05 14:14:26,771 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:26 -0500 (0:00:00.039)       0:11:00.541 ******** 
2019-06-05 14:14:27,088 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "checksum": "f17091ee142621a3c8290c8c96b5b52d67b3a864", "dest": "/etc/puppet/hieradata/config_step.json", "gid": 0, "group": "root", "md5sum": "0c07a8d2f57375a6b7ce729be89e77fb", "mode": "0600", "owner": "root", "secontext": "system_u:object_r:puppet_etc_t:s0", "size": 11, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559762066.78-264020543659839/source", "state": "file", "uid": 0}
2019-06-05 14:14:27,110 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "checksum": "f17091ee142621a3c8290c8c96b5b52d67b3a864", "dest": "/etc/puppet/hieradata/config_step.json", "gid": 0, "group": "root", "md5sum": "0c07a8d2f57375a6b7ce729be89e77fb", "mode": "0600", "owner": "root", "secontext": "system_u:object_r:puppet_etc_t:s0", "size": 11, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559762066.81-174456626186692/source", "state": "file", "uid": 0}
2019-06-05 14:14:27,133 p=17240 u=mistral |  TASK [Run puppet on the host to apply IPtables rules] **************************
2019-06-05 14:14:27,133 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/deploy_steps_tasks.yaml:2
2019-06-05 14:14:27,133 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:27 -0500 (0:00:00.362)       0:11:00.903 ******** 
2019-06-05 14:14:27,162 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:27,171 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:27,194 p=17240 u=mistral |  TASK [configure tmpwatch on the host] ******************************************
2019-06-05 14:14:27,194 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/deploy_steps_tasks.yaml:13
2019-06-05 14:14:27,194 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:27 -0500 (0:00:00.060)       0:11:00.963 ******** 
2019-06-05 14:14:27,231 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:27,484 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "checksum": "cff12f8dcf94ad56dd4add38e048ecdf77371e29", "dest": "/etc/cron.daily/containers-tmpwatch", "gid": 0, "group": "root", "md5sum": "7647496b7335fd4a51df27ceba4cfdb5", "mode": "0755", "owner": "root", "secontext": "system_u:object_r:bin_t:s0", "size": 206, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559762067.21-94407776657061/source", "state": "file", "uid": 0}
2019-06-05 14:14:27,508 p=17240 u=mistral |  TASK [create iptables service] *************************************************
2019-06-05 14:14:27,508 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/deploy_steps_tasks.yaml:27
2019-06-05 14:14:27,508 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:27 -0500 (0:00:00.313)       0:11:01.277 ******** 
2019-06-05 14:14:27,535 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:27,542 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:27,566 p=17240 u=mistral |  TASK [enable tripleo-iptables service] *****************************************
2019-06-05 14:14:27,566 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/deploy_steps_tasks.yaml:58
2019-06-05 14:14:27,566 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:27 -0500 (0:00:00.058)       0:11:01.335 ******** 
2019-06-05 14:14:27,593 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:27,600 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:27,623 p=17240 u=mistral |  TASK [create ip6tables service] ************************************************
2019-06-05 14:14:27,623 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/deploy_steps_tasks.yaml:62
2019-06-05 14:14:27,624 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:27 -0500 (0:00:00.057)       0:11:01.393 ******** 
2019-06-05 14:14:27,651 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:27,662 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:27,688 p=17240 u=mistral |  TASK [enable tripleo-ip6tables service] ****************************************
2019-06-05 14:14:27,688 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/deploy_steps_tasks.yaml:93
2019-06-05 14:14:27,688 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:27 -0500 (0:00:00.064)       0:11:01.458 ******** 
2019-06-05 14:14:27,717 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:27,724 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:27,748 p=17240 u=mistral |  TASK [configure tmpwatch on the host] ******************************************
2019-06-05 14:14:27,748 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/deploy_steps_tasks.yaml:2
2019-06-05 14:14:27,748 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:27 -0500 (0:00:00.059)       0:11:01.517 ******** 
2019-06-05 14:14:27,775 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:28,058 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "checksum": "cff12f8dcf94ad56dd4add38e048ecdf77371e29", "dest": "/etc/cron.daily/containers-tmpwatch", "gid": 0, "group": "root", "md5sum": "7647496b7335fd4a51df27ceba4cfdb5", "mode": "0755", "owner": "root", "secontext": "system_u:object_r:bin_t:s0", "size": 206, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559762067.79-45212445932420/source", "state": "file", "uid": 0}
2019-06-05 14:14:28,082 p=17240 u=mistral |  TASK [create iptables service] *************************************************
2019-06-05 14:14:28,082 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/deploy_steps_tasks.yaml:16
2019-06-05 14:14:28,082 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:28 -0500 (0:00:00.334)       0:11:01.851 ******** 
2019-06-05 14:14:28,110 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:28,119 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:28,143 p=17240 u=mistral |  TASK [enable tripleo-iptables service] *****************************************
2019-06-05 14:14:28,143 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/deploy_steps_tasks.yaml:47
2019-06-05 14:14:28,143 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:28 -0500 (0:00:00.061)       0:11:01.912 ******** 
2019-06-05 14:14:28,171 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:28,180 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:28,203 p=17240 u=mistral |  TASK [create ip6tables service] ************************************************
2019-06-05 14:14:28,204 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/deploy_steps_tasks.yaml:51
2019-06-05 14:14:28,204 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:28 -0500 (0:00:00.060)       0:11:01.973 ******** 
2019-06-05 14:14:28,231 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:28,240 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:28,263 p=17240 u=mistral |  TASK [enable tripleo-ip6tables service] ****************************************
2019-06-05 14:14:28,263 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/deploy_steps_tasks.yaml:82
2019-06-05 14:14:28,263 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:28 -0500 (0:00:00.059)       0:11:02.033 ******** 
2019-06-05 14:14:28,294 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:28,304 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:28,305 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:14:28,305 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:14:28,309 p=17240 u=mistral |  PLAY [Overcloud common deploy step tasks 2] ************************************
2019-06-05 14:14:28,314 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:14:28,336 p=17240 u=mistral |  TASK [Check if /var/lib/tripleo-config/container-startup-config-1.json already exists] ***
2019-06-05 14:14:28,336 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deploy_steps_playbook.yaml:274
2019-06-05 14:14:28,336 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:28 -0500 (0:00:00.072)       0:11:02.105 ******** 
2019-06-05 14:14:28,430 p=17240 u=mistral |  ok: [lab-controller-0] => {"changed": false, "stat": {"exists": false}}
2019-06-05 14:14:28,454 p=17240 u=mistral |  ok: [lab-computehci-0] => {"changed": false, "stat": {"exists": false}}
2019-06-05 14:14:28,478 p=17240 u=mistral |  TASK [gather facts needed by role] *********************************************
2019-06-05 14:14:28,478 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:6
2019-06-05 14:14:28,478 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:28 -0500 (0:00:00.141)       0:11:02.247 ******** 
2019-06-05 14:14:28,506 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:28,517 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:28,540 p=17240 u=mistral |  TASK [set python_cmd] **********************************************************
2019-06-05 14:14:28,540 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:13
2019-06-05 14:14:28,541 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:28 -0500 (0:00:00.062)       0:11:02.310 ******** 
2019-06-05 14:14:28,568 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:28,578 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:28,601 p=17240 u=mistral |  TASK [print python facts] ******************************************************
2019-06-05 14:14:28,601 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:22
2019-06-05 14:14:28,601 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:28 -0500 (0:00:00.060)       0:11:02.370 ******** 
2019-06-05 14:14:28,628 p=17240 u=mistral |  ok: [lab-controller-0] => {
    "msg": "python_cmd: python2"
}
2019-06-05 14:14:28,643 p=17240 u=mistral |  ok: [lab-computehci-0] => {
    "msg": "python_cmd: python2"
}
2019-06-05 14:14:28,669 p=17240 u=mistral |  TASK [Create and ensure setype for /var/log/containers directory] **************
2019-06-05 14:14:28,669 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:31
2019-06-05 14:14:28,669 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:28 -0500 (0:00:00.068)       0:11:02.439 ******** 
2019-06-05 14:14:28,697 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:28,708 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:28,731 p=17240 u=mistral |  TASK [Create ContainerLogStdoutPath directory] *********************************
2019-06-05 14:14:28,731 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:39
2019-06-05 14:14:28,731 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:28 -0500 (0:00:00.061)       0:11:02.501 ******** 
2019-06-05 14:14:28,759 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:28,769 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:28,793 p=17240 u=mistral |  TASK [Create /var/lib/tripleo-config directory] ********************************
2019-06-05 14:14:28,793 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:46
2019-06-05 14:14:28,793 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:28 -0500 (0:00:00.061)       0:11:02.562 ******** 
2019-06-05 14:14:28,821 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:28,832 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:28,855 p=17240 u=mistral |  TASK [Delete existing /var/lib/tripleo-config/check-mode directory for check mode] ***
2019-06-05 14:14:28,855 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:60
2019-06-05 14:14:28,855 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:28 -0500 (0:00:00.062)       0:11:02.624 ******** 
2019-06-05 14:14:28,883 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:28,893 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:28,917 p=17240 u=mistral |  TASK [Create /var/lib/tripleo-config/check-mode directory for check mode] ******
2019-06-05 14:14:28,917 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:75
2019-06-05 14:14:28,917 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:28 -0500 (0:00:00.061)       0:11:02.686 ******** 
2019-06-05 14:14:28,944 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:28,954 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:28,978 p=17240 u=mistral |  TASK [Write the puppet step_config manifest] ***********************************
2019-06-05 14:14:28,978 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:93
2019-06-05 14:14:28,978 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:28 -0500 (0:00:00.060)       0:11:02.747 ******** 
2019-06-05 14:14:29,005 p=17240 u=mistral |  skipping: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:29,020 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:29,047 p=17240 u=mistral |  TASK [Diff puppet step_config manifest changes for check mode] *****************
2019-06-05 14:14:29,047 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:105
2019-06-05 14:14:29,048 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:29 -0500 (0:00:00.069)       0:11:02.817 ******** 
2019-06-05 14:14:29,075 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:29,085 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:29,108 p=17240 u=mistral |  TASK [Diff puppet step_config manifest changes for check mode] *****************
2019-06-05 14:14:29,108 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:118
2019-06-05 14:14:29,108 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:29 -0500 (0:00:00.060)       0:11:02.878 ******** 
2019-06-05 14:14:29,135 p=17240 u=mistral |  skipping: [lab-controller-0] => {}
2019-06-05 14:14:29,146 p=17240 u=mistral |  skipping: [lab-computehci-0] => {}
2019-06-05 14:14:29,169 p=17240 u=mistral |  TASK [Create /var/lib/container-puppet] ****************************************
2019-06-05 14:14:29,169 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:129
2019-06-05 14:14:29,169 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:29 -0500 (0:00:00.060)       0:11:02.939 ******** 
2019-06-05 14:14:29,196 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:29,207 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:29,230 p=17240 u=mistral |  TASK [Create /var/lib/docker-puppet for backward compatibility] ****************
2019-06-05 14:14:29,230 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:141
2019-06-05 14:14:29,230 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:29 -0500 (0:00:00.061)       0:11:03.000 ******** 
2019-06-05 14:14:29,258 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:29,267 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:29,292 p=17240 u=mistral |  TASK [Deprecation file about /var/lib/docker-puppet] ***************************
2019-06-05 14:14:29,292 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:149
2019-06-05 14:14:29,292 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:29 -0500 (0:00:00.061)       0:11:03.062 ******** 
2019-06-05 14:14:29,320 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:29,329 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:29,352 p=17240 u=mistral |  TASK [Delete existing /var/lib/container-puppet/container-puppet.sh] ***********
2019-06-05 14:14:29,352 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:157
2019-06-05 14:14:29,353 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:29 -0500 (0:00:00.060)       0:11:03.122 ******** 
2019-06-05 14:14:29,380 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:29,395 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:29,422 p=17240 u=mistral |  TASK [Delete existing /var/lib/container-puppet/check-mode for check mode] *****
2019-06-05 14:14:29,423 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:166
2019-06-05 14:14:29,423 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:29 -0500 (0:00:00.070)       0:11:03.192 ******** 
2019-06-05 14:14:29,451 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:29,461 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:29,484 p=17240 u=mistral |  TASK [Create /var/lib/container-puppet/check-mode for check mode] **************
2019-06-05 14:14:29,484 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:177
2019-06-05 14:14:29,484 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:29 -0500 (0:00:00.061)       0:11:03.253 ******** 
2019-06-05 14:14:29,511 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:29,522 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:29,545 p=17240 u=mistral |  TASK [Write container-puppet.json file] ****************************************
2019-06-05 14:14:29,545 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:189
2019-06-05 14:14:29,545 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:29 -0500 (0:00:00.061)       0:11:03.314 ******** 
2019-06-05 14:14:29,573 p=17240 u=mistral |  skipping: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:29,584 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:29,607 p=17240 u=mistral |  TASK [Diff container-puppet.json changes for check mode] ***********************
2019-06-05 14:14:29,607 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:201
2019-06-05 14:14:29,607 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:29 -0500 (0:00:00.061)       0:11:03.376 ******** 
2019-06-05 14:14:29,634 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:29,643 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:29,667 p=17240 u=mistral |  TASK [Diff container-puppet.json changes for check mode] ***********************
2019-06-05 14:14:29,667 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:214
2019-06-05 14:14:29,667 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:29 -0500 (0:00:00.060)       0:11:03.436 ******** 
2019-06-05 14:14:29,694 p=17240 u=mistral |  skipping: [lab-controller-0] => {}
2019-06-05 14:14:29,704 p=17240 u=mistral |  skipping: [lab-computehci-0] => {}
2019-06-05 14:14:29,729 p=17240 u=mistral |  TASK [Create /var/lib/container-config-scripts] ********************************
2019-06-05 14:14:29,729 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:224
2019-06-05 14:14:29,729 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:29 -0500 (0:00:00.061)       0:11:03.498 ******** 
2019-06-05 14:14:29,758 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:29,774 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:29,801 p=17240 u=mistral |  TASK [Clean old /var/lib/container-startup-configs.json file] ******************
2019-06-05 14:14:29,801 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:235
2019-06-05 14:14:29,801 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:29 -0500 (0:00:00.072)       0:11:03.570 ******** 
2019-06-05 14:14:29,830 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:29,840 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:29,864 p=17240 u=mistral |  TASK [Clean old /var/lib/docker-container-startup-configs.json file] ***********
2019-06-05 14:14:29,864 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:243
2019-06-05 14:14:29,864 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:29 -0500 (0:00:00.063)       0:11:03.633 ******** 
2019-06-05 14:14:29,892 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:29,903 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:29,926 p=17240 u=mistral |  TASK [Write container config scripts] ******************************************
2019-06-05 14:14:29,926 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:251
2019-06-05 14:14:29,927 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:29 -0500 (0:00:00.062)       0:11:03.696 ******** 
2019-06-05 14:14:29,955 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:29,960 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:29,965 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:29,971 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:29,977 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:29,977 p=17240 u=mistral |  skipping: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:29,994 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:29,999 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,004 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,010 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,015 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,021 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,021 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,044 p=17240 u=mistral |  TASK [Set container_config_default fact] ***************************************
2019-06-05 14:14:30,045 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:270
2019-06-05 14:14:30,045 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:30 -0500 (0:00:00.118)       0:11:03.814 ******** 
2019-06-05 14:14:30,073 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,073 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,075 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,084 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,089 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,095 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,095 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,096 p=17240 u=mistral |  skipping: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,099 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,104 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,110 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,115 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,120 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,121 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,144 p=17240 u=mistral |  TASK [Set container_startup_configs_with_default fact] *************************
2019-06-05 14:14:30,144 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:278
2019-06-05 14:14:30,144 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:30 -0500 (0:00:00.099)       0:11:03.913 ******** 
2019-06-05 14:14:30,172 p=17240 u=mistral |  skipping: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,188 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,215 p=17240 u=mistral |  TASK [Write per-step container startup configs] ********************************
2019-06-05 14:14:30,215 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:287
2019-06-05 14:14:30,215 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:30 -0500 (0:00:00.070)       0:11:03.984 ******** 
2019-06-05 14:14:30,253 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,258 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,261 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,265 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,266 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,272 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,276 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,279 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,280 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,284 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,289 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,289 p=17240 u=mistral |  skipping: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,291 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,291 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,315 p=17240 u=mistral |  TASK [Create /var/lib/kolla/config_files directory] ****************************
2019-06-05 14:14:30,315 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:300
2019-06-05 14:14:30,315 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:30 -0500 (0:00:00.099)       0:11:04.084 ******** 
2019-06-05 14:14:30,343 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:30,353 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:30,377 p=17240 u=mistral |  TASK [Create /var/lib/config-data directory] ***********************************
2019-06-05 14:14:30,377 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:310
2019-06-05 14:14:30,377 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:30 -0500 (0:00:00.062)       0:11:04.146 ******** 
2019-06-05 14:14:30,406 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:30,416 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:30,439 p=17240 u=mistral |  TASK [Write kolla config json files] *******************************************
2019-06-05 14:14:30,439 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:317
2019-06-05 14:14:30,439 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:30 -0500 (0:00:00.062)       0:11:04.208 ******** 
2019-06-05 14:14:30,497 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,502 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,512 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,519 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,523 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,529 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,534 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,539 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,545 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,547 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,547 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,552 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,558 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,563 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,569 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,574 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,580 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,584 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,589 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,595 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,600 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,606 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,611 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,617 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,622 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,627 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,637 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,639 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,644 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,650 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,655 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,661 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,667 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,674 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,680 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,684 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,689 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,697 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,701 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,709 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,714 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,719 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,725 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,732 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,736 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,742 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,748 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,758 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,761 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,769 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,772 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,779 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,782 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,788 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,794 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,799 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,804 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,810 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,814 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,821 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,825 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,831 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,836 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,842 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,846 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,852 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,857 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,862 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,868 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,872 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,878 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,883 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,889 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,890 p=17240 u=mistral |  skipping: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:30,913 p=17240 u=mistral |  TASK [Set host puppet debugging fact string] ***********************************
2019-06-05 14:14:30,913 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:335
2019-06-05 14:14:30,913 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:30 -0500 (0:00:00.474)       0:11:04.683 ******** 
2019-06-05 14:14:30,941 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:30,952 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:30,976 p=17240 u=mistral |  TASK [Check for /etc/puppet/check-mode directory for check mode] ***************
2019-06-05 14:14:30,976 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:344
2019-06-05 14:14:30,976 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:30 -0500 (0:00:00.062)       0:11:04.745 ******** 
2019-06-05 14:14:31,004 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:31,014 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:31,037 p=17240 u=mistral |  TASK [Create /etc/puppet/check-mode/hieradata directory for check mode] ********
2019-06-05 14:14:31,038 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:353
2019-06-05 14:14:31,038 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:31 -0500 (0:00:00.061)       0:11:04.807 ******** 
2019-06-05 14:14:31,065 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:31,076 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:31,099 p=17240 u=mistral |  TASK [Write the config_step hieradata] *****************************************
2019-06-05 14:14:31,099 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:368
2019-06-05 14:14:31,100 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:31 -0500 (0:00:00.061)       0:11:04.869 ******** 
2019-06-05 14:14:31,362 p=17240 u=mistral |  ok: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:31,382 p=17240 u=mistral |  ok: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:31,408 p=17240 u=mistral |  TASK [Create puppet check-mode files if they don't exist for check mode] *******
2019-06-05 14:14:31,408 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:379
2019-06-05 14:14:31,408 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:31 -0500 (0:00:00.308)       0:11:05.177 ******** 
2019-06-05 14:14:31,436 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:31,447 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:31,471 p=17240 u=mistral |  TASK [Run puppet host configuration for step 2] ********************************
2019-06-05 14:14:31,472 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:392
2019-06-05 14:14:31,472 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:31 -0500 (0:00:00.063)       0:11:05.241 ******** 
2019-06-05 14:14:36,900 p=17240 u=mistral |  changed: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:14:38,156 p=17240 u=mistral |  changed: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:14:38,180 p=17240 u=mistral |  TASK [Debug output for task: Run puppet host configuration for step 2] *********
2019-06-05 14:14:38,180 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:411
2019-06-05 14:14:38,180 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:38 -0500 (0:00:06.708)       0:11:11.950 ******** 
2019-06-05 14:14:38,210 p=17240 u=mistral |  ok: [lab-controller-0] => {
    "failed_when_result": false, 
    "outputs.stdout_lines | default([]) | union(outputs.stderr_lines | default([]))": [
        "Changes:", 
        "            Total: 3", 
        "Events:", 
        "          Success: 3", 
        "Resources:", 
        "          Changed: 3", 
        "      Out of sync: 3", 
        "            Total: 186", 
        "Time:", 
        "         Schedule: 0.00", 
        "   Package manifest: 0.00", 
        "   Sysctl runtime: 0.00", 
        "           Sysctl: 0.00", 
        "           Augeas: 0.01", 
        "             File: 0.05", 
        "          Service: 0.05", 
        "          Package: 0.12", 
        "             Exec: 0.21", 
        "         Firewall: 0.31", 
        "   Config retrieval: 1.17", 
        "   Transaction evaluation: 1.36", 
        "   Catalog application: 1.42", 
        "         Last run: 1559762077", 
        "   Concat fragment: 0.00", 
        "       Filebucket: 0.00", 
        "      Concat file: 0.00", 
        "           Anchor: 0.00", 
        "            Total: 1.42", 
        "Version:", 
        "           Config: 1559762075", 
        "           Puppet: 5.5.10"
    ]
}
2019-06-05 14:14:38,228 p=17240 u=mistral |  ok: [lab-computehci-0] => {
    "failed_when_result": false, 
    "outputs.stdout_lines | default([]) | union(outputs.stderr_lines | default([]))": [
        "Changes:", 
        "            Total: 3", 
        "Events:", 
        "          Success: 3", 
        "Resources:", 
        "          Changed: 3", 
        "      Out of sync: 3", 
        "            Total: 139", 
        "Time:", 
        "         Schedule: 0.00", 
        "   Package manifest: 0.00", 
        "   Sysctl runtime: 0.00", 
        "           Sysctl: 0.00", 
        "           Augeas: 0.01", 
        "             File: 0.01", 
        "         Firewall: 0.04", 
        "          Service: 0.11", 
        "          Package: 0.12", 
        "             Exec: 0.12", 
        "   Transaction evaluation: 0.67", 
        "   Catalog application: 0.70", 
        "   Config retrieval: 0.86", 
        "         Last run: 1559762076", 
        "   Concat fragment: 0.00", 
        "       Filebucket: 0.00", 
        "      Concat file: 0.00", 
        "           Anchor: 0.00", 
        "            Total: 0.70", 
        "Version:", 
        "           Config: 1559762075", 
        "           Puppet: 5.5.10", 
        "error: Could not connect to cluster (is it running?)"
    ]
}
2019-06-05 14:14:38,253 p=17240 u=mistral |  TASK [Run container-puppet tasks (generate config) during step 2] **************
2019-06-05 14:14:38,253 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:426
2019-06-05 14:14:38,253 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:38 -0500 (0:00:00.072)       0:11:12.022 ******** 
2019-06-05 14:14:38,284 p=17240 u=mistral |  skipping: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:38,295 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:14:38,319 p=17240 u=mistral |  TASK [Debug output for task: Run container-puppet tasks (generate config) during step 2] ***
2019-06-05 14:14:38,319 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:449
2019-06-05 14:14:38,320 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:38 -0500 (0:00:00.066)       0:11:12.089 ******** 
2019-06-05 14:14:38,347 p=17240 u=mistral |  skipping: [lab-controller-0] => {}
2019-06-05 14:14:38,358 p=17240 u=mistral |  skipping: [lab-computehci-0] => {}
2019-06-05 14:14:38,382 p=17240 u=mistral |  TASK [Diff container-puppet.py puppet-generated changes for check mode] ********
2019-06-05 14:14:38,382 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:458
2019-06-05 14:14:38,382 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:38 -0500 (0:00:00.062)       0:11:12.151 ******** 
2019-06-05 14:14:38,409 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:38,419 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:14:38,442 p=17240 u=mistral |  TASK [Diff container-puppet.py puppet-generated changes for check mode] ********
2019-06-05 14:14:38,442 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:473
2019-06-05 14:14:38,442 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:38 -0500 (0:00:00.060)       0:11:12.211 ******** 
2019-06-05 14:14:38,470 p=17240 u=mistral |  skipping: [lab-controller-0] => {}
2019-06-05 14:14:38,479 p=17240 u=mistral |  skipping: [lab-computehci-0] => {}
2019-06-05 14:14:38,503 p=17240 u=mistral |  TASK [Start containers for step 2] *********************************************
2019-06-05 14:14:38,503 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:491
2019-06-05 14:14:38,503 p=17240 u=mistral |  Wednesday 05 June 2019  14:14:38 -0500 (0:00:00.061)       0:11:12.272 ******** 
2019-06-05 14:14:47,164 p=17240 u=mistral |  ok: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:01,774 p=17240 u=mistral |  ok: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:01,801 p=17240 u=mistral |  TASK [Debug output for task: Start containers for step 2] **********************
2019-06-05 14:15:01,802 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:508
2019-06-05 14:15:01,802 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:01 -0500 (0:00:23.298)       0:11:35.571 ******** 
2019-06-05 14:15:01,832 p=17240 u=mistral |  ok: [lab-controller-0] => {
    "failed_when_result": false, 
    "outputs.stdout_lines | default([]) | union(outputs.stderr_lines | default([]))": [
        "stdout: cc5cbe898b2980b6ca889ad252ae65adf5d624dce7bd9d86e662456e00cca700", 
        "", 
        "stderr: Trying to pull docker://docker.io/tripleostein/centos-binary-cinder-scheduler:current-tripleo-rdo...Getting image source signatures", 
        "Copying blob sha256:a35613cff6f04cbfd2f3b845d5a923d56d6f2fb718f85784e8fdcd97ae77846e", 
        "Copying blob sha256:8ba884070f611d31cb2c42eddb691319dc9facf5e0ec67672fcfa135181ab3df", 
        "Copying blob sha256:5b8f702199c16fd0d5c9c4d0028550b144acb532f4a6b8200b3f53e1cbc43aba", 
        "Copying blob sha256:6310d6ac1536a2eb8e769d217451e2c6d420eb3c39b0fb1b9ad088a73ea67211", 
        "Copying blob sha256:31c8fa1ceee01b746a6b64c4718f5e42e867c08532b29f8d33626a8385327ede", 
        "Copying blob sha256:c0862342b9e7a81856422b95348a2d1952b46e01df6c72f74d94cac2c5815c51", 
        "Copying blob sha256:0f2be6d2e8e6e42cb3e633544d0b1aa8328bd7004a3a4b1dfc0c7a6ba14cd0c7", 
        "Copying blob sha256:c80c3921174be89bdd60d2454983524a19a15b09f26f47b6822e6440d5939973", 
        "Copying blob sha256:2799d99efade4475ca55aad34887eabf4e9ec76e592bc0b0a80cbd8d01080ffc", 
        "Copying blob sha256:d36b87fd0812d0e39ef92e729105260f496efbfb19ad7b6981218862502aa0f3", 
        "Copying blob sha256:5b89a36d5e9e14c5ac5981e8ed2304bb8ce19da7d91793f44c48ac17e7b03717", 
        "Copying blob sha256:98d5e2479617c862dcad487a2c52021bc16e516ebafe9fdab6b3eb8648b73f57", 
        "Copying blob sha256:0fc1fd86055457f85a0cb3f333292570aaa2803c4b556966847f55f8f3544fa8", 
        "Copying blob sha256:921488feccf56d8c8eb6086cd998b48f907fa44dbc5e7cf8525efd96f7c1f776", 
        "Copying blob sha256:46d3c6aa676de9a0ee74cfac77cced69fb7a4df7c5b9e8a7ef33922881d87c81", 
        "Copying blob sha256:2cc44a4e32219b5aad308d7d3bdc5ba18788e8830c0cf3aa9056e1d0dc647058", 
        "Copying blob sha256:ccae8e3351ac86f5c7d66e9c84321057c9f05063428851fa0f1c17946090212d", 
        "Copying blob sha256:fc3b29499fda939e998b0c14c6e98720e1cb7a66fd1ce884cad8d64a63669cf4", 
        "Copying blob sha256:89c8d96f0d37376ba1f54c92128660aaea0a802cb9d9d396a45366b02fc589cc", 
        "Copying blob sha256:45d804df81db3a3f58373c31a92eb2484c2b9038ec59d86fed68b6ce62565939", 
        "Copying blob sha256:343f9f42dd124dbd53b97d676c7702f6308aa52ad4e28983f1aa15f733d48213", 
        "Copying blob sha256:d6dbd69ea530292192935158b778ccffc396ead2093138f75c6e1fa33b7a17fa", 
        "Copying blob sha256:8774727e360b183320621e11466e556387ed6df1c3002f428fa4eeb6c6a9f5c9", 
        "Copying blob sha256:bd6e2c36ff0e45e35121c3bc2cb54f803eb809aacb2778260d4211de2ba9fabb", 
        "Copying blob sha256:88108b54db5387e508dfd62742e4e48c16a66398dee5f59f29ff27bbc5a427c8", 
        "Copying blob sha256:3ed6718f30b1e4f92c70e16cc00fcd5266fd54bdc22861d7f68ddb3db85cc9d4", 
        "Copying blob sha256:9a16611eef609d3db5e01b678b61c92a3e8ee7027d3ae0298abcbb42a092047b", 
        "Copying blob sha256:9fe135b100364e1a826f8dc4c3449a93849827be200c74b3bc8a3cd72fb44454", 
        "Copying blob sha256:2636b8d706ed771a94f2f0bcc727f18fb557d94b79a76ea9a1cfefbd849312f2", 
        "Copying config sha256:cc5cbe898b2980b6ca889ad252ae65adf5d624dce7bd9d86e662456e00cca700", 
        "Writing manifest to image destination", 
        "Storing signatures", 
        "stdout: 467a1c5d710aed65e2b4cf26a72ac93bbd064e234636b5e526a7bf29e54b7f0a", 
        "stderr: Trying to pull docker://docker.io/tripleostein/centos-binary-heat-engine:current-tripleo-rdo...Getting image source signatures", 
        "Copying blob sha256:ad08587940b891a92fd741bac3b62392284ec97eea349b21adebedf41b1e0466", 
        "Copying blob sha256:dfe56cbd4fa946b40b0c307329577ec361cc2dadfaf8c7c5e56eee4e6c93ebfe", 
        "Copying blob sha256:66fbf773da372cde6ca2aafe31faa921e6c03d58c7a72e0b4d510e92f997b92f", 
        "Copying blob sha256:24fd1fce0669a444529b4bca44879c23c6bbed2de49ddbe0a534b524f5918e40", 
        "Copying blob sha256:bcf3f2d1d908213d73a02675555c7337cf69dd59507b41148e27004b10b140a7", 
        "Copying blob sha256:c0bfd544ea0c5c627dd103c3fdae271e51ef52838355220c78443db7dd4948ed", 
        "Copying blob sha256:4e570f9e9f0a4b63f4bae4258ccabcbf233ec47f77fa8a9d45e585861c0e86f9", 
        "Copying config sha256:467a1c5d710aed65e2b4cf26a72ac93bbd064e234636b5e526a7bf29e54b7f0a", 
        "stdout: dbb9cffb79069d6fc6d785166baf3ec745923546317aaa405e18230d4b4d003a", 
        "stderr: Trying to pull docker://docker.io/tripleostein/centos-binary-nova-conductor:current-tripleo-rdo...Getting image source signatures", 
        "Copying blob sha256:88531674244332349666cefabdff747eacb0035c77771f43c8f4f47a52d7685f", 
        "Copying blob sha256:d75ae4cf64b29c5e27cec9a45bbf01b196dc716834c117ab6017cb74882919e0", 
        "Copying blob sha256:9869b6ce22f44304615e534ccc6c32765cd48d898b2c46ea4aa5d86c7a208c96", 
        "Copying blob sha256:f6294bc12da549b2a997050c47023556c25332e72e05c8fa2644761de96aa425", 
        "Copying blob sha256:9aef06bfe3cf0d3f0c7de9f920f09b66b2aa0caf7ba789d44f375c6e66265cbe", 
        "Copying blob sha256:594cf98c3f14159eee101d6d9bc894d91cb4719337a79ae35280bc8c8d18fe9b", 
        "Copying blob sha256:5eb702b6bb0c83c5f3a75ac505144a2f0912e23bc524466f26470f289d560849", 
        "Copying config sha256:dbb9cffb79069d6fc6d785166baf3ec745923546317aaa405e18230d4b4d003a", 
        "stdout: 901cc512490021f14140e6bb6e511f32d6d6b04c55508026774844aa87edac1d", 
        "stderr: ", 
        "stdout: 099722df15846637e3d0ff548d7a16f26ab2d31575ea4403785c23ba77f5d9f6", 
        "stdout: 908a66538a36772ca1881a904623c47ce53df1725be02f4ac54b20a538c2eac9", 
        "stdout: 379870f9a4a969ad51faad78db8aba36614f0a47ed2890db7bb1b64a19c5ae14", 
        "stdout: 6ffac67baa46262659d557631f429b20ad44a0f306e6961da152cbe87b6ea31a", 
        "stdout: 46d8b72182c69844c8165c1188297d811b76e0f9362f0107e1ca7e30277fa61c", 
        "stdout: 8c5a87c18b2fa80c03264fc18a011de35ed72a115ff0d96f7257db920f9299d8", 
        "stdout: 0dc2304996e0697388e6693ab20ca57ad1e0cd9d0954fdd5e3ba23c6290667e8", 
        "stdout: b44fdca4e0cbef2d0eea9c9b4fd63be4bd0c5122573a6163e747dedf0f84b5e3", 
        "stdout: 48d8f916a97cb8be2a4469a8ae75269192f14048c53083441ec68d15fe1a6108", 
        "stdout: 0acd1b2fdd76c5d84a32bdaf66ec6863b0e77d15dd76f6ac8c4bba7e76a377ab", 
        "stdout: 347b8d5e7320ac6ca2bc27921bb2c2d5efd562d75e73bd599fe019058e98a21d", 
        "stdout: e27d10a257051183ad5fd1aa593c6cec18ba300e4b963c7c5cea3f11a666f88d", 
        "stdout: 802bbc56167147903a04f4e9ea9fafb5f64033c798f483a288fd16159da4812d", 
        "stdout: Installing MariaDB/MySQL system tables in '/var/lib/mysql' ...", 
        "OK", 
        "To start mysqld at boot time you have to copy", 
        "support-files/mysql.server to the right place for your system", 
        "PLEASE REMEMBER TO SET A PASSWORD FOR THE MariaDB root USER !", 
        "To do so, start the server, then issue the following commands:", 
        "'/usr/bin/mysqladmin' -u root password 'new-password'", 
        "'/usr/bin/mysqladmin' -u root -h lab-controller-0 password 'new-password'", 
        "Alternatively you can run:", 
        "'/usr/bin/mysql_secure_installation'", 
        "which will also give you the option of removing the test", 
        "databases and anonymous user created by default.  This is", 
        "strongly recommended for production servers.", 
        "See the MariaDB Knowledgebase at http://mariadb.com/kb or the", 
        "MySQL manual for more instructions.", 
        "You can start the MariaDB daemon with:", 
        "cd '/usr' ; /usr/bin/mysqld_safe --datadir='/var/lib/mysql'", 
        "You can test the MariaDB daemon with mysql-test-run.pl", 
        "cd '/usr/mysql-test' ; perl mysql-test-run.pl", 
        "Please report any problems at http://mariadb.org/jira", 
        "The latest information about MariaDB is available at http://mariadb.org/.", 
        "You can find additional information about the MySQL part at:", 
        "http://dev.mysql.com", 
        "Consider joining MariaDB's strong and vibrant community:", 
        "https://mariadb.org/get-involved/", 
        "190605 19:14:56 mysqld_safe Logging to '/var/log/mariadb/mariadb.log'.", 
        "190605 19:14:56 mysqld_safe Starting mysqld daemon with databases from /var/lib/mysql", 
        "spawn mysql_secure_installation", 
        "NOTE: RUNNING ALL PARTS OF THIS SCRIPT IS RECOMMENDED FOR ALL MariaDB", 
        "      SERVERS IN PRODUCTION USE!  PLEASE READ EACH STEP CAREFULLY!", 
        "In order to log into MariaDB to secure it, we'll need the current", 
        "password for the root user.  If you've just installed MariaDB, and", 
        "you haven't set the root password yet, the password will be blank,", 
        "so you should just press enter here.", 
        "Enter current password for root (enter for none): ", 
        "OK, successfully used password, moving on...", 
        "Setting the root password ensures that nobody can log into the MariaDB", 
        "root user without the proper authorisation.", 
        "Set root password? [Y/n] y", 
        "New password: ", 
        "Re-enter new password: ", 
        "Password updated successfully!", 
        "Reloading privilege tables..", 
        " ... Success!", 
        "By default, a MariaDB installation has an anonymous user, allowing anyone", 
        "to log into MariaDB without having to have a user account created for", 
        "them.  This is intended only for testing, and to make the installation", 
        "go a bit smoother.  You should remove them before moving into a", 
        "production environment.", 
        "Remove anonymous users? [Y/n] y", 
        "Normally, root should only be allowed to connect from 'localhost'.  This", 
        "ensures that someone cannot guess at the root password from the network.", 
        "Disallow root login remotely? [Y/n] n", 
        " ... skipping.", 
        "By default, MariaDB comes with a database named 'test' that anyone can", 
        "access.  This is also intended only for testing, and should be removed", 
        "before moving into a production environment.", 
        "Remove test database and access to it? [Y/n] y", 
        " - Dropping test database...", 
        " - Removing privileges on test database...", 
        "Reloading the privilege tables will ensure that all changes made so far", 
        "will take effect immediately.", 
        "Reload privilege tables now? [Y/n] y", 
        "Cleaning up...", 
        "All done!  If you've completed all of the above steps, your MariaDB", 
        "installation should now be secure.", 
        "Thanks for using MariaDB!", 
        "190605 19:14:58 mysqld_safe Logging to '/var/log/mariadb/mariadb.log'.", 
        "190605 19:14:58 mysqld_safe Starting mysqld daemon with databases from /var/lib/mysql", 
        "mysqld is alive", 
        "stderr: INFO:__main__:Loading config file at /var/lib/kolla/config_files/config.json", 
        "INFO:__main__:Validating config file", 
        "INFO:__main__:Kolla config strategy set to: COPY_ALWAYS", 
        "INFO:__main__:Copying service configuration files", 
        "INFO:__main__:Deleting /etc/my.cnf.d/galera.cnf", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/my.cnf.d/galera.cnf to /etc/my.cnf.d/galera.cnf", 
        "INFO:__main__:Creating directory /etc/systemd/system/mariadb.service.d", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/systemd/system/mariadb.service.d/90-limits.conf to /etc/systemd/system/mariadb.service.d/90-limits.conf", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/root/.my.cnf to /root/.my.cnf", 
        "INFO:__main__:Writing out command to execute", 
        "INFO:__main__:Setting permission for /var/lib/mysql", 
        "stdout: 8ba648311de584c373da54f107d98f5af1f29d6caa1ea6c715a6347d506597c5", 
        "stdout: 014de460919aa282bb41b8db3e9b9104f7a207c03c8ccc028c102b94dd00484b", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_mysql.service to /etc/systemd/system/tripleo_mysql.service.", 
        "Created symlink from /etc/systemd/system/timers.target.wants/tripleo_mysql_healthcheck.timer to /etc/systemd/system/tripleo_mysql_healthcheck.timer.", 
        "Created symlink from /etc/systemd/system/tripleo_mysql.service.requires/tripleo_mysql_healthcheck.timer to /etc/systemd/system/tripleo_mysql_healthcheck.timer."
    ]
}
2019-06-05 14:15:01,852 p=17240 u=mistral |  ok: [lab-computehci-0] => {
    "failed_when_result": false, 
    "outputs.stdout_lines | default([]) | union(outputs.stderr_lines | default([]))": [
        "stdout: b7144c24cc153c3fbde0c83ad8ffaa280a4dcbdbbcb81c9074e39ba98318f0fc", 
        "", 
        "stderr: Trying to pull docker://docker.io/tripleostein/centos-binary-neutron-metadata-agent-ovn:current-tripleo-rdo...Getting image source signatures", 
        "Copying blob sha256:a35613cff6f04cbfd2f3b845d5a923d56d6f2fb718f85784e8fdcd97ae77846e", 
        "Copying blob sha256:8ba884070f611d31cb2c42eddb691319dc9facf5e0ec67672fcfa135181ab3df", 
        "Copying blob sha256:c0862342b9e7a81856422b95348a2d1952b46e01df6c72f74d94cac2c5815c51", 
        "Copying blob sha256:6310d6ac1536a2eb8e769d217451e2c6d420eb3c39b0fb1b9ad088a73ea67211", 
        "Copying blob sha256:c80c3921174be89bdd60d2454983524a19a15b09f26f47b6822e6440d5939973", 
        "Copying blob sha256:0f2be6d2e8e6e42cb3e633544d0b1aa8328bd7004a3a4b1dfc0c7a6ba14cd0c7", 
        "Copying blob sha256:0fc1fd86055457f85a0cb3f333292570aaa2803c4b556966847f55f8f3544fa8", 
        "Copying blob sha256:5b8f702199c16fd0d5c9c4d0028550b144acb532f4a6b8200b3f53e1cbc43aba", 
        "Copying blob sha256:31c8fa1ceee01b746a6b64c4718f5e42e867c08532b29f8d33626a8385327ede", 
        "Copying blob sha256:d36b87fd0812d0e39ef92e729105260f496efbfb19ad7b6981218862502aa0f3", 
        "Copying blob sha256:2799d99efade4475ca55aad34887eabf4e9ec76e592bc0b0a80cbd8d01080ffc", 
        "Copying blob sha256:46d3c6aa676de9a0ee74cfac77cced69fb7a4df7c5b9e8a7ef33922881d87c81", 
        "Copying blob sha256:fc3b29499fda939e998b0c14c6e98720e1cb7a66fd1ce884cad8d64a63669cf4", 
        "Copying blob sha256:921488feccf56d8c8eb6086cd998b48f907fa44dbc5e7cf8525efd96f7c1f776", 
        "Copying blob sha256:2cc44a4e32219b5aad308d7d3bdc5ba18788e8830c0cf3aa9056e1d0dc647058", 
        "Copying blob sha256:ccae8e3351ac86f5c7d66e9c84321057c9f05063428851fa0f1c17946090212d", 
        "Copying blob sha256:89c8d96f0d37376ba1f54c92128660aaea0a802cb9d9d396a45366b02fc589cc", 
        "Copying blob sha256:45d804df81db3a3f58373c31a92eb2484c2b9038ec59d86fed68b6ce62565939", 
        "Copying blob sha256:343f9f42dd124dbd53b97d676c7702f6308aa52ad4e28983f1aa15f733d48213", 
        "Copying blob sha256:d6dbd69ea530292192935158b778ccffc396ead2093138f75c6e1fa33b7a17fa", 
        "Copying blob sha256:5b89a36d5e9e14c5ac5981e8ed2304bb8ce19da7d91793f44c48ac17e7b03717", 
        "Copying blob sha256:90585b9d99de473a7d73b27da240d63f686dc233211830bd733bfffe0eeaf546", 
        "Copying blob sha256:f18f41905614cecad3420df3425e4e553621f8eb77f1df82cc39da9c703bfe4e", 
        "Copying blob sha256:98d5e2479617c862dcad487a2c52021bc16e516ebafe9fdab6b3eb8648b73f57", 
        "Copying blob sha256:bd6e2c36ff0e45e35121c3bc2cb54f803eb809aacb2778260d4211de2ba9fabb", 
        "Copying blob sha256:33d27c415956e3a5d2558c76fc95780fcbabb4ae5bfb8975b6678c32bc2896dc", 
        "Copying blob sha256:1d80d4fe1fd2062646d4d42da126c287820577d1cf63e55bb3af9b1493f2fca7", 
        "Copying blob sha256:98ba4ae196c7cc9c97f51ccad343690d2fe5d6ee2a06104c9beffacdbda1a0af", 
        "Copying blob sha256:18494e83700e33898644358ccfc3486b6bada95e06584d356a2bdf7efd7b3dd2", 
        "Copying blob sha256:e41a20fa769cae9030fa2f343c84dad9f63f9d5bb911fb4062315bd907f8a510", 
        "Copying config sha256:b7144c24cc153c3fbde0c83ad8ffaa280a4dcbdbbcb81c9074e39ba98318f0fc", 
        "Writing manifest to image destination", 
        "Storing signatures", 
        "stdout: Info: Loading facts", 
        "Info: Loading facts", 
        "Notice: Compiled catalog for lab-computehci-0.localdomain in environment production in 0.03 seconds", 
        "Info: Applying configuration version '1559762086'", 
        "Notice: /Stage[main]/Tripleo::Profile::Base::Neutron::Ovn_metadata_agent_wrappers/Tripleo::Profile::Base::Neutron::Wrappers::Haproxy[ovn_metadata_haproxy_process_wrapper]/File[/var/lib/neutron/ovn_metadata_haproxy_wrapper]/ensure: defined content as '{md5}003fa116a2207e107d290c98f58e1380'", 
        "Info: Tripleo::Profile::Base::Neutron::Wrappers::Haproxy[ovn_metadata_haproxy_process_wrapper]: Unscheduling all events on Tripleo::Profile::Base::Neutron::Wrappers::Haproxy[ovn_metadata_haproxy_process_wrapper]", 
        "Info: Creating state file /var/lib/puppet/state/state.yaml", 
        "Notice: Applied catalog in 0.01 seconds", 
        "Changes:", 
        "            Total: 1", 
        "Events:", 
        "          Success: 1", 
        "Resources:", 
        "          Changed: 1", 
        "      Out of sync: 1", 
        "          Skipped: 7", 
        "            Total: 8", 
        "Time:", 
        "             File: 0.00", 
        "   Transaction evaluation: 0.01", 
        "   Catalog application: 0.01", 
        "   Config retrieval: 0.09", 
        "         Last run: 1559762086", 
        "            Total: 0.01", 
        "Version:", 
        "           Config: 1559762086", 
        "           Puppet: 5.5.10", 
        "stderr: + STEP=4", 
        "+ TAGS=file", 
        "+ CONFIG='include ::tripleo::profile::base::neutron::ovn_metadata_agent_wrappers'", 
        "+ EXTRA_ARGS=", 
        "+ '[' -d /tmp/puppet-etc ']'", 
        "+ cp -a /tmp/puppet-etc/auth.conf /tmp/puppet-etc/hiera.yaml /tmp/puppet-etc/hieradata /tmp/puppet-etc/modules /tmp/puppet-etc/puppet.conf /tmp/puppet-etc/ssl /etc/puppet", 
        "+ echo '{\"step\": 4}'", 
        "+ export FACTER_deployment_type=containers", 
        "+ FACTER_deployment_type=containers", 
        "+ set +e", 
        "+ puppet apply --verbose --detailed-exitcodes --summarize --color=false --modulepath /etc/puppet/modules:/opt/stack/puppet-modules:/usr/share/openstack-puppet/modules --tags file -e 'noop_resource('\\''package'\\''); include ::tripleo::profile::base::neutron::ovn_metadata_agent_wrappers'", 
        "Warning: Support for ruby version 2.0.0 is deprecated and will be removed in a future release. See https://puppet.com/docs/puppet/latest/system_requirements.html for a list of supported ruby versions.", 
        "   (location: /usr/share/ruby/vendor_ruby/puppet.rb:130:in `<module:Puppet>')", 
        "net_mlx5: cannot load glue library: libibverbs.so.1: cannot open shared object file: No such file or directory", 
        "net_mlx5: cannot initialize PMD due to missing run-time dependency on rdma-core libraries (libibverbs, libmlx5)", 
        "PMD: net_mlx4: cannot load glue library: libibverbs.so.1: cannot open shared object file: No such file or directory", 
        "PMD: net_mlx4: cannot initialize PMD due to missing run-time dependency on rdma-core libraries (libibverbs, libmlx4)", 
        "Warning: ModuleLoader: module 'tripleo' has unresolved dependencies - it will only see those that are resolved. Use 'puppet module list --tree' to see information about modules\\n   (file & line not available)", 
        "Warning: /etc/puppet/hiera.yaml: Use of 'hiera.yaml' version 3 is deprecated. It should be converted to version 5", 
        "   (file: /etc/puppet/hiera.yaml)", 
        "Warning: Undefined variable '::uuid'; \\n   (file & line not available)", 
        "Warning: Undefined variable '::deploy_config_name'; \\n   (file & line not available)", 
        "Warning: The function 'hiera' is deprecated in favor of using 'lookup'. See https://puppet.com/docs/puppet/5.5/deprecated_language.html\\n   (file & line not available)", 
        "+ rc=2", 
        "+ set -e", 
        "+ set +ux"
    ]
}
2019-06-05 14:15:01,880 p=17240 u=mistral |  TASK [Clean container_puppet_tasks for lab-controller-0 step 2] ****************
2019-06-05 14:15:01,880 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:520
2019-06-05 14:15:01,880 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:01 -0500 (0:00:00.078)       0:11:35.649 ******** 
2019-06-05 14:15:01,992 p=17240 u=mistral |  ok: [lab-controller-0] => {"changed": false, "path": "/var/lib/container-puppet/container-puppet-tasks2.json", "state": "absent"}
2019-06-05 14:15:02,020 p=17240 u=mistral |  ok: [lab-computehci-0] => {"changed": false, "path": "/var/lib/container-puppet/container-puppet-tasks2.json", "state": "absent"}
2019-06-05 14:15:02,045 p=17240 u=mistral |  TASK [Calculate container_puppet_tasks for lab-controller-0 step 2] ************
2019-06-05 14:15:02,045 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:527
2019-06-05 14:15:02,045 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:02 -0500 (0:00:00.165)       0:11:35.815 ******** 
2019-06-05 14:15:02,081 p=17240 u=mistral |  ok: [lab-controller-0] => (item={'puppet_tags': u'mysql_database,mysql_grant,mysql_user', 'config_volume': u'mysql_init_tasks', 'config_image': u'docker.io/tripleostein/centos-binary-mariadb:current-tripleo-rdo', 'volumes': [u'/var/lib/mysql:/var/lib/mysql/:rw', u'/var/log/containers/mysql:/var/log/mariadb', u'/var/lib/config-data/puppet-generated/mysql/root:/root:rw'], 'service_name': u'mysql', 'step_config': u'include ::tripleo::profile::base::database::mysql'}) => {"ansible_facts": {"host_container_puppet_tasks": [{"config_image": "docker.io/tripleostein/centos-binary-mariadb:current-tripleo-rdo", "config_volume": "mysql_init_tasks", "puppet_tags": "mysql_database,mysql_grant,mysql_user", "service_name": "mysql", "step_config": "include ::tripleo::profile::base::database::mysql", "volumes": ["/var/lib/mysql:/var/lib/mysql/:rw", "/var/log/containers/mysql:/var/log/mariadb", "/var/lib/config-data/puppet-generated/mysql/root:/root:rw"]}]}, "changed": false, "item": {"config_image": "docker.io/tripleostein/centos-binary-mariadb:current-tripleo-rdo", "config_volume": "mysql_init_tasks", "puppet_tags": "mysql_database,mysql_grant,mysql_user", "service_name": "mysql", "step_config": "include ::tripleo::profile::base::database::mysql", "volumes": ["/var/lib/mysql:/var/lib/mysql/:rw", "/var/log/containers/mysql:/var/log/mariadb", "/var/lib/config-data/puppet-generated/mysql/root:/root:rw"]}}
2019-06-05 14:15:02,100 p=17240 u=mistral |  ok: [lab-controller-0] => (item={'puppet_tags': u'rabbitmq_policy,rabbitmq_user', 'config_volume': u'rabbit_init_tasks', 'config_image': u'docker.io/tripleostein/centos-binary-rabbitmq:current-tripleo-rdo', 'volumes': [u'/var/lib/config-data/rabbitmq/etc/rabbitmq/:/etc/rabbitmq/:ro', u'/var/lib/rabbitmq:/var/lib/rabbitmq:z'], 'service_name': u'oslo_messaging_rpc', 'step_config': u'include ::tripleo::profile::base::rabbitmq'}) => {"ansible_facts": {"host_container_puppet_tasks": [{"config_image": "docker.io/tripleostein/centos-binary-mariadb:current-tripleo-rdo", "config_volume": "mysql_init_tasks", "puppet_tags": "mysql_database,mysql_grant,mysql_user", "service_name": "mysql", "step_config": "include ::tripleo::profile::base::database::mysql", "volumes": ["/var/lib/mysql:/var/lib/mysql/:rw", "/var/log/containers/mysql:/var/log/mariadb", "/var/lib/config-data/puppet-generated/mysql/root:/root:rw"]}, {"config_image": "docker.io/tripleostein/centos-binary-rabbitmq:current-tripleo-rdo", "config_volume": "rabbit_init_tasks", "puppet_tags": "rabbitmq_policy,rabbitmq_user", "service_name": "oslo_messaging_rpc", "step_config": "include ::tripleo::profile::base::rabbitmq", "volumes": ["/var/lib/config-data/rabbitmq/etc/rabbitmq/:/etc/rabbitmq/:ro", "/var/lib/rabbitmq:/var/lib/rabbitmq:z"]}]}, "changed": false, "item": {"config_image": "docker.io/tripleostein/centos-binary-rabbitmq:current-tripleo-rdo", "config_volume": "rabbit_init_tasks", "puppet_tags": "rabbitmq_policy,rabbitmq_user", "service_name": "oslo_messaging_rpc", "step_config": "include ::tripleo::profile::base::rabbitmq", "volumes": ["/var/lib/config-data/rabbitmq/etc/rabbitmq/:/etc/rabbitmq/:ro", "/var/lib/rabbitmq:/var/lib/rabbitmq:z"]}}
2019-06-05 14:15:02,124 p=17240 u=mistral |  TASK [Write container-puppet-tasks json file for lab-controller-0 step 2] ******
2019-06-05 14:15:02,124 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:537
2019-06-05 14:15:02,125 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:02 -0500 (0:00:00.079)       0:11:35.894 ******** 
2019-06-05 14:15:02,164 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:02,421 p=17240 u=mistral |  changed: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:15:02,446 p=17240 u=mistral |  TASK [Run container-puppet tasks (bootstrap tasks) for step 2] *****************
2019-06-05 14:15:02,446 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:548
2019-06-05 14:15:02,446 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:02 -0500 (0:00:00.321)       0:11:36.216 ******** 
2019-06-05 14:15:02,494 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:11,672 p=17240 u=mistral |  ok: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:11,696 p=17240 u=mistral |  TASK [Debug output for task: Run container-puppet tasks (bootstrap tasks) for step 2] ***
2019-06-05 14:15:11,696 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:567
2019-06-05 14:15:11,696 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:11 -0500 (0:00:09.249)       0:11:45.465 ******** 
2019-06-05 14:15:11,726 p=17240 u=mistral |  ok: [lab-controller-0] => {
    "failed_when_result": false, 
    "outputs.stdout_lines | default([]) | union(outputs.stderr_lines | default([]))": [
        "2019-06-05 19:15:02,707 INFO: 49626 -- Running container-puppet", 
        "2019-06-05 19:15:02,707 INFO: 49626 -- Service compilation completed.", 
        "2019-06-05 19:15:02,707 INFO: 49626 -- Starting multiprocess configuration steps.  Using 4 processes.", 
        "2019-06-05 19:15:02,713 INFO: 49629 -- Starting configuration of mysql_init_tasks using image docker.io/tripleostein/centos-binary-mariadb:current-tripleo-rdo", 
        "2019-06-05 19:15:02,714 INFO: 49630 -- Starting configuration of rabbit_init_tasks using image docker.io/tripleostein/centos-binary-rabbitmq:current-tripleo-rdo", 
        "2019-06-05 19:15:02,886 INFO: 49630 -- Removing container: container-puppet-rabbit_init_tasks", 
        "2019-06-05 19:15:02,891 INFO: 49629 -- Removing container: container-puppet-mysql_init_tasks", 
        "2019-06-05 19:15:03,195 INFO: 49630 -- Image already exists: docker.io/tripleostein/centos-binary-rabbitmq:current-tripleo-rdo", 
        "2019-06-05 19:15:03,198 INFO: 49629 -- Image already exists: docker.io/tripleostein/centos-binary-mariadb:current-tripleo-rdo", 
        "2019-06-05 19:15:11,327 WARNING: 49630 -- + mkdir -p /etc/puppet", 
        "+ cp -dR /tmp/puppet-etc/auth.conf /tmp/puppet-etc/hiera.yaml /tmp/puppet-etc/hieradata /tmp/puppet-etc/modules /tmp/puppet-etc/puppet.conf /tmp/puppet-etc/ssl /etc/puppet", 
        "+ rm -Rf /etc/puppet/ssl", 
        "+ echo '{\"step\": 2}'", 
        "+ TAGS=", 
        "+ '[' -n file,file_line,concat,augeas,cron,rabbitmq_policy,rabbitmq_user ']'", 
        "+ TAGS='--tags file,file_line,concat,augeas,cron,rabbitmq_policy,rabbitmq_user'", 
        "+ CHECK_MODE=", 
        "+ '[' -d /tmp/puppet-check-mode ']'", 
        "+ origin_of_time=/var/lib/config-data/rabbit_init_tasks.origin_of_time", 
        "+ touch /var/lib/config-data/rabbit_init_tasks.origin_of_time", 
        "+ sync", 
        "+ export NET_HOST=true", 
        "+ NET_HOST=true", 
        "+ set +e", 
        "+ '[' true == false ']'", 
        "+ export FACTER_deployment_type=containers", 
        "+ FACTER_deployment_type=containers", 
        "++ cat /sys/class/dmi/id/product_uuid", 
        "++ tr '[:upper:]' '[:lower:]'", 
        "+ export FACTER_uuid=ad8c85d9-6f5f-4d90-97fa-e31eefd815d6", 
        "+ FACTER_uuid=ad8c85d9-6f5f-4d90-97fa-e31eefd815d6", 
        "+ /usr/bin/puppet apply --summarize --detailed-exitcodes --color=false --logdest syslog --logdest console --modulepath=/etc/puppet/modules:/usr/share/openstack-puppet/modules --tags file,file_line,concat,augeas,cron,rabbitmq_policy,rabbitmq_user /etc/config.pp", 
        "+ rc=2", 
        "+ set -e", 
        "+ '[' 2 -ne 2 -a 2 -ne 0 ']'", 
        "+ '[' -z true ']'", 
        "", 
        "2019-06-05 19:15:11,327 INFO: 49630 -- Removing container: container-puppet-rabbit_init_tasks", 
        "2019-06-05 19:15:11,501 INFO: 49630 -- Finished processing puppet configs for rabbit_init_tasks", 
        "2019-06-05 19:15:11,530 WARNING: 49629 -- + mkdir -p /etc/puppet", 
        "+ '[' -n file,file_line,concat,augeas,cron,mysql_database,mysql_grant,mysql_user ']'", 
        "+ TAGS='--tags file,file_line,concat,augeas,cron,mysql_database,mysql_grant,mysql_user'", 
        "+ origin_of_time=/var/lib/config-data/mysql_init_tasks.origin_of_time", 
        "+ touch /var/lib/config-data/mysql_init_tasks.origin_of_time", 
        "+ /usr/bin/puppet apply --summarize --detailed-exitcodes --color=false --logdest syslog --logdest console --modulepath=/etc/puppet/modules:/usr/share/openstack-puppet/modules --tags file,file_line,concat,augeas,cron,mysql_database,mysql_grant,mysql_user /etc/config.pp", 
        "2019-06-05 19:15:11,530 INFO: 49629 -- Removing container: container-puppet-mysql_init_tasks", 
        "2019-06-05 19:15:11,638 INFO: 49629 -- Finished processing puppet configs for mysql_init_tasks"
    ]
}
2019-06-05 14:15:11,735 p=17240 u=mistral |  skipping: [lab-computehci-0] => {}
2019-06-05 14:15:11,736 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:15:11,737 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:15:11,740 p=17240 u=mistral |  PLAY [External deployment step 3] **********************************************
2019-06-05 14:15:11,745 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:15:11,759 p=17240 u=mistral |  TASK [set blacklisted_hostnames] ***********************************************
2019-06-05 14:15:11,759 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:2
2019-06-05 14:15:11,759 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:11 -0500 (0:00:00.062)       0:11:45.528 ******** 
2019-06-05 14:15:11,771 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:11,785 p=17240 u=mistral |  TASK [create ceph-ansible temp dirs] *******************************************
2019-06-05 14:15:11,785 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:5
2019-06-05 14:15:11,785 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:11 -0500 (0:00:00.026)       0:11:45.555 ******** 
2019-06-05 14:15:11,803 p=17240 u=mistral |  skipping: [undercloud] => (item=/var/lib/mistral/lab/ceph-ansible)  => {"changed": false, "item": "/var/lib/mistral/lab/ceph-ansible", "skip_reason": "Conditional result was False"}
2019-06-05 14:15:11,805 p=17240 u=mistral |  skipping: [undercloud] => (item=/var/lib/mistral/lab/ceph-ansible/group_vars)  => {"changed": false, "item": "/var/lib/mistral/lab/ceph-ansible/group_vars", "skip_reason": "Conditional result was False"}
2019-06-05 14:15:11,809 p=17240 u=mistral |  skipping: [undercloud] => (item=/var/lib/mistral/lab/ceph-ansible/host_vars)  => {"changed": false, "item": "/var/lib/mistral/lab/ceph-ansible/host_vars", "skip_reason": "Conditional result was False"}
2019-06-05 14:15:11,811 p=17240 u=mistral |  skipping: [undercloud] => (item=/var/lib/mistral/lab/ceph-ansible/fetch_dir)  => {"changed": false, "item": "/var/lib/mistral/lab/ceph-ansible/fetch_dir", "skip_reason": "Conditional result was False"}
2019-06-05 14:15:11,827 p=17240 u=mistral |  TASK [generate inventory] ******************************************************
2019-06-05 14:15:11,827 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:16
2019-06-05 14:15:11,827 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:11 -0500 (0:00:00.041)       0:11:45.596 ******** 
2019-06-05 14:15:11,838 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:11,854 p=17240 u=mistral |  TASK [set ceph-ansible group vars all] *****************************************
2019-06-05 14:15:11,854 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:30
2019-06-05 14:15:11,854 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:11 -0500 (0:00:00.026)       0:11:45.623 ******** 
2019-06-05 14:15:11,867 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:11,881 p=17240 u=mistral |  TASK [generate ceph-ansible group vars all] ************************************
2019-06-05 14:15:11,881 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:139
2019-06-05 14:15:11,881 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:11 -0500 (0:00:00.027)       0:11:45.650 ******** 
2019-06-05 14:15:11,893 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:11,908 p=17240 u=mistral |  TASK [set ceph-ansible extra vars] *********************************************
2019-06-05 14:15:11,908 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:143
2019-06-05 14:15:11,908 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:11 -0500 (0:00:00.026)       0:11:45.677 ******** 
2019-06-05 14:15:11,920 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:11,935 p=17240 u=mistral |  TASK [generate ceph-ansible extra vars] ****************************************
2019-06-05 14:15:11,935 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:150
2019-06-05 14:15:11,935 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:11 -0500 (0:00:00.026)       0:11:45.704 ******** 
2019-06-05 14:15:11,948 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:11,962 p=17240 u=mistral |  TASK [generate nodes-uuid data file] *******************************************
2019-06-05 14:15:11,962 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:154
2019-06-05 14:15:11,963 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:11 -0500 (0:00:00.027)       0:11:45.732 ******** 
2019-06-05 14:15:11,974 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:11,989 p=17240 u=mistral |  TASK [generate nodes-uuid playbook] ********************************************
2019-06-05 14:15:11,989 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:158
2019-06-05 14:15:11,989 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:11 -0500 (0:00:00.026)       0:11:45.758 ******** 
2019-06-05 14:15:12,001 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:12,015 p=17240 u=mistral |  TASK [detect private key file] *************************************************
2019-06-05 14:15:12,015 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:179
2019-06-05 14:15:12,015 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:12 -0500 (0:00:00.026)       0:11:45.785 ******** 
2019-06-05 14:15:12,028 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:12,044 p=17240 u=mistral |  TASK [set private key file] ****************************************************
2019-06-05 14:15:12,044 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:183
2019-06-05 14:15:12,044 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:12 -0500 (0:00:00.028)       0:11:45.813 ******** 
2019-06-05 14:15:12,055 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:12,070 p=17240 u=mistral |  TASK [run nodes-uuid] **********************************************************
2019-06-05 14:15:12,070 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:187
2019-06-05 14:15:12,071 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:12 -0500 (0:00:00.026)       0:11:45.840 ******** 
2019-06-05 14:15:12,085 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:12,100 p=17240 u=mistral |  TASK [set ceph-ansible params from Heat] ***************************************
2019-06-05 14:15:12,100 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:195
2019-06-05 14:15:12,100 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:12 -0500 (0:00:00.029)       0:11:45.869 ******** 
2019-06-05 14:15:12,114 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:12,130 p=17240 u=mistral |  TASK [set ceph-ansible playbooks] **********************************************
2019-06-05 14:15:12,130 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:200
2019-06-05 14:15:12,131 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:12 -0500 (0:00:00.030)       0:11:45.900 ******** 
2019-06-05 14:15:12,142 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:12,157 p=17240 u=mistral |  TASK [was path for local ceph-ansible fetch directory backups set?] ************
2019-06-05 14:15:12,157 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:205
2019-06-05 14:15:12,157 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:12 -0500 (0:00:00.026)       0:11:45.926 ******** 
2019-06-05 14:15:12,168 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:12,183 p=17240 u=mistral |  TASK [look for requested ceph-ansible fetch directory for local backup] ********
2019-06-05 14:15:12,183 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:210
2019-06-05 14:15:12,183 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:12 -0500 (0:00:00.026)       0:11:45.952 ******** 
2019-06-05 14:15:12,195 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:12,210 p=17240 u=mistral |  TASK [autocreate new directory for ceph-ansible fetch directory backup] ********
2019-06-05 14:15:12,210 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:214
2019-06-05 14:15:12,210 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:12 -0500 (0:00:00.027)       0:11:45.980 ******** 
2019-06-05 14:15:12,221 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:12,236 p=17240 u=mistral |  TASK [look for tarball of ceph-ansible fetch directory in local backup] ********
2019-06-05 14:15:12,236 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:222
2019-06-05 14:15:12,236 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:12 -0500 (0:00:00.026)       0:11:46.006 ******** 
2019-06-05 14:15:12,247 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:12,262 p=17240 u=mistral |  TASK [untar local backup of ceph-ansible fetch directory] **********************
2019-06-05 14:15:12,262 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:226
2019-06-05 14:15:12,262 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:12 -0500 (0:00:00.025)       0:11:46.032 ******** 
2019-06-05 14:15:12,274 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:12,288 p=17240 u=mistral |  TASK [set facts for swift back up of ceph-ansible fetch directory] *************
2019-06-05 14:15:12,289 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:232
2019-06-05 14:15:12,289 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:12 -0500 (0:00:00.026)       0:11:46.058 ******** 
2019-06-05 14:15:12,300 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:12,315 p=17240 u=mistral |  TASK [attempt download of fetch directory tarball from swift backup] ***********
2019-06-05 14:15:12,315 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:238
2019-06-05 14:15:12,315 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:12 -0500 (0:00:00.026)       0:11:46.084 ******** 
2019-06-05 14:15:12,327 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:12,342 p=17240 u=mistral |  TASK [ensure we create a new fetch_directory or use the old fetch_directory] ***
2019-06-05 14:15:12,342 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:243
2019-06-05 14:15:12,342 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:12 -0500 (0:00:00.026)       0:11:46.111 ******** 
2019-06-05 14:15:12,354 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:12,369 p=17240 u=mistral |  TASK [unpack downloaded ceph-ansible fetch tarball to fetch directory] *********
2019-06-05 14:15:12,369 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:251
2019-06-05 14:15:12,369 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:12 -0500 (0:00:00.027)       0:11:46.139 ******** 
2019-06-05 14:15:12,383 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:12,398 p=17240 u=mistral |  TASK [remove downloaded ceph-ansible fetch directory tarball from filesystem] ***
2019-06-05 14:15:12,398 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:257
2019-06-05 14:15:12,398 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:12 -0500 (0:00:00.028)       0:11:46.168 ******** 
2019-06-05 14:15:12,410 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:12,426 p=17240 u=mistral |  TASK [set ceph-ansible command] ************************************************
2019-06-05 14:15:12,426 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:265
2019-06-05 14:15:12,426 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:12 -0500 (0:00:00.027)       0:11:46.195 ******** 
2019-06-05 14:15:12,437 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:12,453 p=17240 u=mistral |  TASK [run ceph-ansible (immediate log at /var/lib/mistral/lab/ceph-ansible/ceph_ansible_command.log)] ***
2019-06-05 14:15:12,453 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:277
2019-06-05 14:15:12,453 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:12 -0500 (0:00:00.027)       0:11:46.223 ******** 
2019-06-05 14:15:12,465 p=17240 u=mistral |  skipping: [undercloud] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:12,479 p=17240 u=mistral |  TASK [print ceph-ansible output in case of failure] ****************************
2019-06-05 14:15:12,479 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:293
2019-06-05 14:15:12,479 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:12 -0500 (0:00:00.025)       0:11:46.248 ******** 
2019-06-05 14:15:12,491 p=17240 u=mistral |  skipping: [undercloud] => {}
2019-06-05 14:15:12,506 p=17240 u=mistral |  TASK [register contents of fetch_directory after ceph-ansible run] *************
2019-06-05 14:15:12,506 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:300
2019-06-05 14:15:12,506 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:12 -0500 (0:00:00.026)       0:11:46.275 ******** 
2019-06-05 14:15:12,516 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:12,531 p=17240 u=mistral |  TASK [create ceph-ansible fetch directory tarball in local backup] *************
2019-06-05 14:15:12,531 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:305
2019-06-05 14:15:12,531 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:12 -0500 (0:00:00.025)       0:11:46.300 ******** 
2019-06-05 14:15:12,546 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:12,560 p=17240 u=mistral |  TASK [create temporary ceph-ansible fetch directory tarball for swift backup] ***
2019-06-05 14:15:12,560 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:315
2019-06-05 14:15:12,560 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:12 -0500 (0:00:00.029)       0:11:46.330 ******** 
2019-06-05 14:15:12,575 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:12,592 p=17240 u=mistral |  TASK [backup temporary ceph-ansible fetch directory tarball in swift] **********
2019-06-05 14:15:12,592 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:321
2019-06-05 14:15:12,592 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:12 -0500 (0:00:00.031)       0:11:46.361 ******** 
2019-06-05 14:15:12,603 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:12,618 p=17240 u=mistral |  TASK [ensure we were able to backup temporary fetch directory to swift] ********
2019-06-05 14:15:12,618 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:325
2019-06-05 14:15:12,618 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:12 -0500 (0:00:00.026)       0:11:46.388 ******** 
2019-06-05 14:15:12,630 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:12,644 p=17240 u=mistral |  TASK [clean temporary fetch directory after swift backup] **********************
2019-06-05 14:15:12,644 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:333
2019-06-05 14:15:12,644 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:12 -0500 (0:00:00.025)       0:11:46.413 ******** 
2019-06-05 14:15:12,656 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:12,670 p=17240 u=mistral |  TASK [Remove ceph-ansible fetch directory] *************************************
2019-06-05 14:15:12,670 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:342
2019-06-05 14:15:12,670 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:12 -0500 (0:00:00.026)       0:11:46.439 ******** 
2019-06-05 14:15:12,681 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:12,696 p=17240 u=mistral |  TASK [set ceph-ansible group vars mgrs] ****************************************
2019-06-05 14:15:12,696 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:351
2019-06-05 14:15:12,696 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:12 -0500 (0:00:00.026)       0:11:46.466 ******** 
2019-06-05 14:15:12,708 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:12,722 p=17240 u=mistral |  TASK [generate ceph-ansible group vars mgrs] ***********************************
2019-06-05 14:15:12,722 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:355
2019-06-05 14:15:12,722 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:12 -0500 (0:00:00.025)       0:11:46.492 ******** 
2019-06-05 14:15:12,734 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:12,748 p=17240 u=mistral |  TASK [set ceph-ansible group vars mons] ****************************************
2019-06-05 14:15:12,748 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:363
2019-06-05 14:15:12,748 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:12 -0500 (0:00:00.026)       0:11:46.518 ******** 
2019-06-05 14:15:12,760 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:12,775 p=17240 u=mistral |  TASK [generate ceph-ansible group vars mons] ***********************************
2019-06-05 14:15:12,775 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:368
2019-06-05 14:15:12,776 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:12 -0500 (0:00:00.027)       0:11:46.545 ******** 
2019-06-05 14:15:12,788 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:12,802 p=17240 u=mistral |  TASK [set_fact] ****************************************************************
2019-06-05 14:15:12,802 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:376
2019-06-05 14:15:12,802 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:12 -0500 (0:00:00.026)       0:11:46.572 ******** 
2019-06-05 14:15:12,814 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:12,828 p=17240 u=mistral |  TASK [Create temp file for prepare parameter] **********************************
2019-06-05 14:15:12,828 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:379
2019-06-05 14:15:12,829 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:12 -0500 (0:00:00.026)       0:11:46.598 ******** 
2019-06-05 14:15:12,840 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:12,855 p=17240 u=mistral |  TASK [Create temp file for role data] ******************************************
2019-06-05 14:15:12,855 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:385
2019-06-05 14:15:12,855 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:12 -0500 (0:00:00.026)       0:11:46.624 ******** 
2019-06-05 14:15:12,868 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:12,882 p=17240 u=mistral |  TASK [Write ContainerImagePrepare parameter file] ******************************
2019-06-05 14:15:12,883 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:391
2019-06-05 14:15:12,883 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:12 -0500 (0:00:00.027)       0:11:46.652 ******** 
2019-06-05 14:15:12,896 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:12,910 p=17240 u=mistral |  TASK [Write role data file] ****************************************************
2019-06-05 14:15:12,910 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:659
2019-06-05 14:15:12,910 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:12 -0500 (0:00:00.027)       0:11:46.679 ******** 
2019-06-05 14:15:12,925 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:12,940 p=17240 u=mistral |  TASK [Run tripleo-container-image-prepare logged to /var/log/tripleo-container-image-prepare.log] ***
2019-06-05 14:15:12,940 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:905
2019-06-05 14:15:12,940 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:12 -0500 (0:00:00.030)       0:11:46.710 ******** 
2019-06-05 14:15:12,952 p=17240 u=mistral |  skipping: [undercloud] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:12,967 p=17240 u=mistral |  TASK [Delete param file] *******************************************************
2019-06-05 14:15:12,967 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:911
2019-06-05 14:15:12,967 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:12 -0500 (0:00:00.026)       0:11:46.736 ******** 
2019-06-05 14:15:12,979 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:12,993 p=17240 u=mistral |  TASK [Delete role file] ********************************************************
2019-06-05 14:15:12,993 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:916
2019-06-05 14:15:12,993 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:12 -0500 (0:00:00.026)       0:11:46.762 ******** 
2019-06-05 14:15:13,008 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:13,025 p=17240 u=mistral |  TASK [set ceph-ansible group vars clients] *************************************
2019-06-05 14:15:13,025 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:925
2019-06-05 14:15:13,025 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:13 -0500 (0:00:00.031)       0:11:46.794 ******** 
2019-06-05 14:15:13,036 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:13,051 p=17240 u=mistral |  TASK [generate ceph-ansible group vars clients] ********************************
2019-06-05 14:15:13,052 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:928
2019-06-05 14:15:13,052 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:13 -0500 (0:00:00.026)       0:11:46.821 ******** 
2019-06-05 14:15:13,072 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:13,087 p=17240 u=mistral |  TASK [set ceph-ansible group vars osds] ****************************************
2019-06-05 14:15:13,087 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:936
2019-06-05 14:15:13,087 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:13 -0500 (0:00:00.035)       0:11:46.857 ******** 
2019-06-05 14:15:13,099 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:13,114 p=17240 u=mistral |  TASK [generate ceph-ansible group vars osds] ***********************************
2019-06-05 14:15:13,114 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:943
2019-06-05 14:15:13,114 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:13 -0500 (0:00:00.026)       0:11:46.884 ******** 
2019-06-05 14:15:13,126 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:13,127 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:15:13,127 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:15:13,131 p=17240 u=mistral |  PLAY [Overcloud deploy step tasks for 3] ***************************************
2019-06-05 14:15:13,133 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:15:13,155 p=17240 u=mistral |  TASK [Write the config_step hieradata for the deploy step 3 tasks] *************
2019-06-05 14:15:13,155 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deploy_steps_playbook.yaml:330
2019-06-05 14:15:13,156 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:13 -0500 (0:00:00.041)       0:11:46.925 ******** 
2019-06-05 14:15:13,658 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "checksum": "62439dd24dde40c90e7a39f6a1b31cc6061fe59b", "dest": "/etc/puppet/hieradata/config_step.json", "gid": 0, "group": "root", "md5sum": "d1a4fc06e2525150450e67007bfcc8f3", "mode": "0600", "owner": "root", "secontext": "system_u:object_r:puppet_etc_t:s0", "size": 11, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559762113.17-212680755219348/source", "state": "file", "uid": 0}
2019-06-05 14:15:13,660 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "checksum": "62439dd24dde40c90e7a39f6a1b31cc6061fe59b", "dest": "/etc/puppet/hieradata/config_step.json", "gid": 0, "group": "root", "md5sum": "d1a4fc06e2525150450e67007bfcc8f3", "mode": "0600", "owner": "root", "secontext": "system_u:object_r:puppet_etc_t:s0", "size": 11, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559762113.19-234494873033624/source", "state": "file", "uid": 0}
2019-06-05 14:15:13,684 p=17240 u=mistral |  TASK [Run puppet on the host to apply IPtables rules] **************************
2019-06-05 14:15:13,684 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/deploy_steps_tasks.yaml:2
2019-06-05 14:15:13,684 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:13 -0500 (0:00:00.528)       0:11:47.453 ******** 
2019-06-05 14:15:13,712 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:13,720 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:13,744 p=17240 u=mistral |  TASK [configure tmpwatch on the host] ******************************************
2019-06-05 14:15:13,744 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/deploy_steps_tasks.yaml:13
2019-06-05 14:15:13,744 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:13 -0500 (0:00:00.059)       0:11:47.513 ******** 
2019-06-05 14:15:13,774 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:13,782 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:13,805 p=17240 u=mistral |  TASK [create iptables service] *************************************************
2019-06-05 14:15:13,805 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/deploy_steps_tasks.yaml:27
2019-06-05 14:15:13,805 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:13 -0500 (0:00:00.060)       0:11:47.574 ******** 
2019-06-05 14:15:13,833 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:13,841 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:13,865 p=17240 u=mistral |  TASK [enable tripleo-iptables service] *****************************************
2019-06-05 14:15:13,865 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/deploy_steps_tasks.yaml:58
2019-06-05 14:15:13,865 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:13 -0500 (0:00:00.060)       0:11:47.635 ******** 
2019-06-05 14:15:13,893 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:13,900 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:13,924 p=17240 u=mistral |  TASK [create ip6tables service] ************************************************
2019-06-05 14:15:13,924 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/deploy_steps_tasks.yaml:62
2019-06-05 14:15:13,925 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:13 -0500 (0:00:00.059)       0:11:47.694 ******** 
2019-06-05 14:15:13,952 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:13,960 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:13,984 p=17240 u=mistral |  TASK [enable tripleo-ip6tables service] ****************************************
2019-06-05 14:15:13,984 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/deploy_steps_tasks.yaml:93
2019-06-05 14:15:13,984 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:13 -0500 (0:00:00.059)       0:11:47.753 ******** 
2019-06-05 14:15:14,011 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:14,019 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:14,042 p=17240 u=mistral |  TASK [configure tmpwatch on the host] ******************************************
2019-06-05 14:15:14,042 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/deploy_steps_tasks.yaml:2
2019-06-05 14:15:14,042 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:14 -0500 (0:00:00.058)       0:11:47.812 ******** 
2019-06-05 14:15:14,070 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:14,079 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:14,102 p=17240 u=mistral |  TASK [create iptables service] *************************************************
2019-06-05 14:15:14,102 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/deploy_steps_tasks.yaml:16
2019-06-05 14:15:14,102 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:14 -0500 (0:00:00.059)       0:11:47.871 ******** 
2019-06-05 14:15:14,134 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:14,200 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:14,266 p=17240 u=mistral |  TASK [enable tripleo-iptables service] *****************************************
2019-06-05 14:15:14,266 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/deploy_steps_tasks.yaml:47
2019-06-05 14:15:14,266 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:14 -0500 (0:00:00.164)       0:11:48.036 ******** 
2019-06-05 14:15:14,294 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:14,303 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:14,326 p=17240 u=mistral |  TASK [create ip6tables service] ************************************************
2019-06-05 14:15:14,327 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/deploy_steps_tasks.yaml:51
2019-06-05 14:15:14,327 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:14 -0500 (0:00:00.060)       0:11:48.096 ******** 
2019-06-05 14:15:14,354 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:14,363 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:14,386 p=17240 u=mistral |  TASK [enable tripleo-ip6tables service] ****************************************
2019-06-05 14:15:14,386 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/deploy_steps_tasks.yaml:82
2019-06-05 14:15:14,386 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:14 -0500 (0:00:00.059)       0:11:48.156 ******** 
2019-06-05 14:15:14,419 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:14,428 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:14,428 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:15:14,429 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:15:14,433 p=17240 u=mistral |  PLAY [Overcloud common deploy step tasks 3] ************************************
2019-06-05 14:15:14,437 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:15:14,459 p=17240 u=mistral |  TASK [Check if /var/lib/tripleo-config/container-startup-config-1.json already exists] ***
2019-06-05 14:15:14,459 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deploy_steps_playbook.yaml:362
2019-06-05 14:15:14,459 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:14 -0500 (0:00:00.072)       0:11:48.228 ******** 
2019-06-05 14:15:14,554 p=17240 u=mistral |  ok: [lab-controller-0] => {"changed": false, "stat": {"exists": false}}
2019-06-05 14:15:14,578 p=17240 u=mistral |  ok: [lab-computehci-0] => {"changed": false, "stat": {"exists": false}}
2019-06-05 14:15:14,602 p=17240 u=mistral |  TASK [gather facts needed by role] *********************************************
2019-06-05 14:15:14,602 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:6
2019-06-05 14:15:14,602 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:14 -0500 (0:00:00.142)       0:11:48.371 ******** 
2019-06-05 14:15:14,629 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:14,643 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:14,669 p=17240 u=mistral |  TASK [set python_cmd] **********************************************************
2019-06-05 14:15:14,669 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:13
2019-06-05 14:15:14,669 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:14 -0500 (0:00:00.067)       0:11:48.439 ******** 
2019-06-05 14:15:14,697 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:14,708 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:14,733 p=17240 u=mistral |  TASK [print python facts] ******************************************************
2019-06-05 14:15:14,733 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:22
2019-06-05 14:15:14,733 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:14 -0500 (0:00:00.063)       0:11:48.502 ******** 
2019-06-05 14:15:14,760 p=17240 u=mistral |  ok: [lab-controller-0] => {
    "msg": "python_cmd: python2"
}
2019-06-05 14:15:14,772 p=17240 u=mistral |  ok: [lab-computehci-0] => {
    "msg": "python_cmd: python2"
}
2019-06-05 14:15:14,795 p=17240 u=mistral |  TASK [Create and ensure setype for /var/log/containers directory] **************
2019-06-05 14:15:14,795 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:31
2019-06-05 14:15:14,795 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:14 -0500 (0:00:00.062)       0:11:48.565 ******** 
2019-06-05 14:15:14,823 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:14,833 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:14,856 p=17240 u=mistral |  TASK [Create ContainerLogStdoutPath directory] *********************************
2019-06-05 14:15:14,857 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:39
2019-06-05 14:15:14,857 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:14 -0500 (0:00:00.061)       0:11:48.626 ******** 
2019-06-05 14:15:14,883 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:14,893 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:14,916 p=17240 u=mistral |  TASK [Create /var/lib/tripleo-config directory] ********************************
2019-06-05 14:15:14,916 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:46
2019-06-05 14:15:14,916 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:14 -0500 (0:00:00.059)       0:11:48.685 ******** 
2019-06-05 14:15:14,943 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:14,953 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:14,975 p=17240 u=mistral |  TASK [Delete existing /var/lib/tripleo-config/check-mode directory for check mode] ***
2019-06-05 14:15:14,975 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:60
2019-06-05 14:15:14,976 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:14 -0500 (0:00:00.059)       0:11:48.745 ******** 
2019-06-05 14:15:15,002 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:15,016 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:15,042 p=17240 u=mistral |  TASK [Create /var/lib/tripleo-config/check-mode directory for check mode] ******
2019-06-05 14:15:15,042 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:75
2019-06-05 14:15:15,043 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:15 -0500 (0:00:00.066)       0:11:48.812 ******** 
2019-06-05 14:15:15,070 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:15,081 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:15,104 p=17240 u=mistral |  TASK [Write the puppet step_config manifest] ***********************************
2019-06-05 14:15:15,104 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:93
2019-06-05 14:15:15,104 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:15 -0500 (0:00:00.061)       0:11:48.873 ******** 
2019-06-05 14:15:15,131 p=17240 u=mistral |  skipping: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:15,141 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:15,164 p=17240 u=mistral |  TASK [Diff puppet step_config manifest changes for check mode] *****************
2019-06-05 14:15:15,164 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:105
2019-06-05 14:15:15,165 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:15 -0500 (0:00:00.060)       0:11:48.934 ******** 
2019-06-05 14:15:15,193 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:15,202 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:15,226 p=17240 u=mistral |  TASK [Diff puppet step_config manifest changes for check mode] *****************
2019-06-05 14:15:15,226 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:118
2019-06-05 14:15:15,226 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:15 -0500 (0:00:00.061)       0:11:48.995 ******** 
2019-06-05 14:15:15,254 p=17240 u=mistral |  skipping: [lab-controller-0] => {}
2019-06-05 14:15:15,264 p=17240 u=mistral |  skipping: [lab-computehci-0] => {}
2019-06-05 14:15:15,287 p=17240 u=mistral |  TASK [Create /var/lib/container-puppet] ****************************************
2019-06-05 14:15:15,287 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:129
2019-06-05 14:15:15,288 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:15 -0500 (0:00:00.061)       0:11:49.057 ******** 
2019-06-05 14:15:15,315 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:15,325 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:15,348 p=17240 u=mistral |  TASK [Create /var/lib/docker-puppet for backward compatibility] ****************
2019-06-05 14:15:15,348 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:141
2019-06-05 14:15:15,348 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:15 -0500 (0:00:00.060)       0:11:49.117 ******** 
2019-06-05 14:15:15,374 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:15,390 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:15,416 p=17240 u=mistral |  TASK [Deprecation file about /var/lib/docker-puppet] ***************************
2019-06-05 14:15:15,416 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:149
2019-06-05 14:15:15,416 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:15 -0500 (0:00:00.067)       0:11:49.185 ******** 
2019-06-05 14:15:15,443 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:15,454 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:15,477 p=17240 u=mistral |  TASK [Delete existing /var/lib/container-puppet/container-puppet.sh] ***********
2019-06-05 14:15:15,477 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:157
2019-06-05 14:15:15,477 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:15 -0500 (0:00:00.061)       0:11:49.246 ******** 
2019-06-05 14:15:15,505 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:15,515 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:15,538 p=17240 u=mistral |  TASK [Delete existing /var/lib/container-puppet/check-mode for check mode] *****
2019-06-05 14:15:15,538 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:166
2019-06-05 14:15:15,538 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:15 -0500 (0:00:00.060)       0:11:49.307 ******** 
2019-06-05 14:15:15,566 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:15,576 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:15,599 p=17240 u=mistral |  TASK [Create /var/lib/container-puppet/check-mode for check mode] **************
2019-06-05 14:15:15,599 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:177
2019-06-05 14:15:15,599 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:15 -0500 (0:00:00.061)       0:11:49.369 ******** 
2019-06-05 14:15:15,626 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:15,636 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:15,659 p=17240 u=mistral |  TASK [Write container-puppet.json file] ****************************************
2019-06-05 14:15:15,659 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:189
2019-06-05 14:15:15,659 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:15 -0500 (0:00:00.059)       0:11:49.428 ******** 
2019-06-05 14:15:15,685 p=17240 u=mistral |  skipping: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:15,695 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:15,717 p=17240 u=mistral |  TASK [Diff container-puppet.json changes for check mode] ***********************
2019-06-05 14:15:15,718 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:201
2019-06-05 14:15:15,718 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:15 -0500 (0:00:00.058)       0:11:49.487 ******** 
2019-06-05 14:15:15,744 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:15,758 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:15,784 p=17240 u=mistral |  TASK [Diff container-puppet.json changes for check mode] ***********************
2019-06-05 14:15:15,784 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:214
2019-06-05 14:15:15,784 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:15 -0500 (0:00:00.066)       0:11:49.554 ******** 
2019-06-05 14:15:15,812 p=17240 u=mistral |  skipping: [lab-controller-0] => {}
2019-06-05 14:15:15,822 p=17240 u=mistral |  skipping: [lab-computehci-0] => {}
2019-06-05 14:15:15,845 p=17240 u=mistral |  TASK [Create /var/lib/container-config-scripts] ********************************
2019-06-05 14:15:15,845 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:224
2019-06-05 14:15:15,846 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:15 -0500 (0:00:00.061)       0:11:49.615 ******** 
2019-06-05 14:15:15,872 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:15,885 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:15,909 p=17240 u=mistral |  TASK [Clean old /var/lib/container-startup-configs.json file] ******************
2019-06-05 14:15:15,910 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:235
2019-06-05 14:15:15,910 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:15 -0500 (0:00:00.064)       0:11:49.679 ******** 
2019-06-05 14:15:15,940 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:15,951 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:15,976 p=17240 u=mistral |  TASK [Clean old /var/lib/docker-container-startup-configs.json file] ***********
2019-06-05 14:15:15,976 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:243
2019-06-05 14:15:15,976 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:15 -0500 (0:00:00.066)       0:11:49.745 ******** 
2019-06-05 14:15:16,005 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:16,016 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:16,039 p=17240 u=mistral |  TASK [Write container config scripts] ******************************************
2019-06-05 14:15:16,040 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:251
2019-06-05 14:15:16,040 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:16 -0500 (0:00:00.063)       0:11:49.809 ******** 
2019-06-05 14:15:16,068 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,076 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,078 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,084 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,092 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,093 p=17240 u=mistral |  skipping: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,106 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,111 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,120 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,127 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,131 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,136 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,138 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,161 p=17240 u=mistral |  TASK [Set container_config_default fact] ***************************************
2019-06-05 14:15:16,161 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:270
2019-06-05 14:15:16,161 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:16 -0500 (0:00:00.121)       0:11:49.930 ******** 
2019-06-05 14:15:16,193 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,193 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,196 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,202 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,206 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,211 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,212 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,212 p=17240 u=mistral |  skipping: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,215 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,220 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,226 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,231 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,236 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,237 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,261 p=17240 u=mistral |  TASK [Set container_startup_configs_with_default fact] *************************
2019-06-05 14:15:16,261 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:278
2019-06-05 14:15:16,262 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:16 -0500 (0:00:00.100)       0:11:50.031 ******** 
2019-06-05 14:15:16,289 p=17240 u=mistral |  skipping: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,299 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,323 p=17240 u=mistral |  TASK [Write per-step container startup configs] ********************************
2019-06-05 14:15:16,323 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:287
2019-06-05 14:15:16,323 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:16 -0500 (0:00:00.061)       0:11:50.092 ******** 
2019-06-05 14:15:16,361 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,367 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,369 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,375 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,375 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,381 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,385 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,387 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,388 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,392 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,394 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,395 p=17240 u=mistral |  skipping: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,398 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,399 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,422 p=17240 u=mistral |  TASK [Create /var/lib/kolla/config_files directory] ****************************
2019-06-05 14:15:16,422 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:300
2019-06-05 14:15:16,422 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:16 -0500 (0:00:00.099)       0:11:50.192 ******** 
2019-06-05 14:15:16,449 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:16,459 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:16,482 p=17240 u=mistral |  TASK [Create /var/lib/config-data directory] ***********************************
2019-06-05 14:15:16,483 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:310
2019-06-05 14:15:16,483 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:16 -0500 (0:00:00.060)       0:11:50.252 ******** 
2019-06-05 14:15:16,509 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:16,519 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:16,542 p=17240 u=mistral |  TASK [Write kolla config json files] *******************************************
2019-06-05 14:15:16,542 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:317
2019-06-05 14:15:16,543 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:16 -0500 (0:00:00.059)       0:11:50.312 ******** 
2019-06-05 14:15:16,602 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,607 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,613 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,619 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,625 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,631 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,640 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,648 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,655 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,655 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,661 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,661 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,665 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,673 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,679 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,682 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,689 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,706 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,706 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,712 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,715 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,721 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,731 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,734 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,738 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,744 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,750 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,755 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,760 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,766 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,771 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,777 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,782 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,788 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,792 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,798 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,803 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,809 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,814 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,820 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,825 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,830 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,836 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,842 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,847 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,852 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,859 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,864 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,868 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,874 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,879 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,884 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,890 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,895 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,901 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,906 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,912 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,916 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,922 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,927 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,932 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,938 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,943 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,949 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,953 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,959 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,964 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,970 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,976 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,981 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,987 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,992 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,997 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:16,999 p=17240 u=mistral |  skipping: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:17,021 p=17240 u=mistral |  TASK [Set host puppet debugging fact string] ***********************************
2019-06-05 14:15:17,021 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:335
2019-06-05 14:15:17,021 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:17 -0500 (0:00:00.478)       0:11:50.790 ******** 
2019-06-05 14:15:17,049 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:17,061 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:17,084 p=17240 u=mistral |  TASK [Check for /etc/puppet/check-mode directory for check mode] ***************
2019-06-05 14:15:17,084 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:344
2019-06-05 14:15:17,084 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:17 -0500 (0:00:00.063)       0:11:50.854 ******** 
2019-06-05 14:15:17,111 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:17,122 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:17,146 p=17240 u=mistral |  TASK [Create /etc/puppet/check-mode/hieradata directory for check mode] ********
2019-06-05 14:15:17,146 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:353
2019-06-05 14:15:17,146 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:17 -0500 (0:00:00.061)       0:11:50.915 ******** 
2019-06-05 14:15:17,173 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:17,186 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:17,211 p=17240 u=mistral |  TASK [Write the config_step hieradata] *****************************************
2019-06-05 14:15:17,211 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:368
2019-06-05 14:15:17,211 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:17 -0500 (0:00:00.065)       0:11:50.980 ******** 
2019-06-05 14:15:17,477 p=17240 u=mistral |  ok: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:17,495 p=17240 u=mistral |  ok: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:17,518 p=17240 u=mistral |  TASK [Create puppet check-mode files if they don't exist for check mode] *******
2019-06-05 14:15:17,519 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:379
2019-06-05 14:15:17,519 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:17 -0500 (0:00:00.307)       0:11:51.288 ******** 
2019-06-05 14:15:17,547 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:17,557 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:17,582 p=17240 u=mistral |  TASK [Run puppet host configuration for step 3] ********************************
2019-06-05 14:15:17,582 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:392
2019-06-05 14:15:17,582 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:17 -0500 (0:00:00.063)       0:11:51.351 ******** 
2019-06-05 14:15:22,617 p=17240 u=mistral |  changed: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:15:23,670 p=17240 u=mistral |  changed: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:15:23,693 p=17240 u=mistral |  TASK [Debug output for task: Run puppet host configuration for step 3] *********
2019-06-05 14:15:23,694 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:411
2019-06-05 14:15:23,694 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:23 -0500 (0:00:06.111)       0:11:57.463 ******** 
2019-06-05 14:15:23,722 p=17240 u=mistral |  ok: [lab-controller-0] => {
    "failed_when_result": false, 
    "outputs.stdout_lines | default([]) | union(outputs.stderr_lines | default([]))": [
        "Changes:", 
        "            Total: 3", 
        "Events:", 
        "          Success: 3", 
        "Resources:", 
        "          Changed: 3", 
        "      Out of sync: 3", 
        "            Total: 186", 
        "Time:", 
        "           Anchor: 0.00", 
        "      Concat file: 0.00", 
        "         Schedule: 0.00", 
        "   Package manifest: 0.00", 
        "   Sysctl runtime: 0.00", 
        "           Sysctl: 0.00", 
        "           Augeas: 0.01", 
        "          Service: 0.05", 
        "             File: 0.09", 
        "          Package: 0.11", 
        "             Exec: 0.11", 
        "         Firewall: 0.32", 
        "   Config retrieval: 1.16", 
        "   Transaction evaluation: 1.30", 
        "   Catalog application: 1.36", 
        "         Last run: 1559762123", 
        "   Concat fragment: 0.00", 
        "       Filebucket: 0.00", 
        "            Total: 1.36", 
        "Version:", 
        "           Config: 1559762120", 
        "           Puppet: 5.5.10"
    ]
}
2019-06-05 14:15:23,739 p=17240 u=mistral |  ok: [lab-computehci-0] => {
    "failed_when_result": false, 
    "outputs.stdout_lines | default([]) | union(outputs.stderr_lines | default([]))": [
        "Changes:", 
        "            Total: 3", 
        "Events:", 
        "          Success: 3", 
        "Resources:", 
        "          Changed: 3", 
        "      Out of sync: 3", 
        "            Total: 139", 
        "Time:", 
        "           Anchor: 0.00", 
        "         Schedule: 0.00", 
        "   Sysctl runtime: 0.00", 
        "           Sysctl: 0.00", 
        "   Package manifest: 0.00", 
        "           Augeas: 0.01", 
        "             File: 0.01", 
        "         Firewall: 0.04", 
        "          Service: 0.06", 
        "          Package: 0.11", 
        "             Exec: 0.12", 
        "   Transaction evaluation: 0.63", 
        "   Catalog application: 0.81", 
        "   Config retrieval: 0.84", 
        "         Last run: 1559762122", 
        "   Concat fragment: 0.00", 
        "       Filebucket: 0.00", 
        "      Concat file: 0.00", 
        "            Total: 0.81", 
        "Version:", 
        "           Config: 1559762120", 
        "           Puppet: 5.5.10", 
        "error: Could not connect to cluster (is it running?)"
    ]
}
2019-06-05 14:15:23,763 p=17240 u=mistral |  TASK [Run container-puppet tasks (generate config) during step 3] **************
2019-06-05 14:15:23,764 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:426
2019-06-05 14:15:23,764 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:23 -0500 (0:00:00.069)       0:11:57.533 ******** 
2019-06-05 14:15:23,791 p=17240 u=mistral |  skipping: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:23,801 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:15:23,826 p=17240 u=mistral |  TASK [Debug output for task: Run container-puppet tasks (generate config) during step 3] ***
2019-06-05 14:15:23,826 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:449
2019-06-05 14:15:23,826 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:23 -0500 (0:00:00.062)       0:11:57.595 ******** 
2019-06-05 14:15:23,853 p=17240 u=mistral |  skipping: [lab-controller-0] => {}
2019-06-05 14:15:23,862 p=17240 u=mistral |  skipping: [lab-computehci-0] => {}
2019-06-05 14:15:23,886 p=17240 u=mistral |  TASK [Diff container-puppet.py puppet-generated changes for check mode] ********
2019-06-05 14:15:23,886 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:458
2019-06-05 14:15:23,886 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:23 -0500 (0:00:00.060)       0:11:57.655 ******** 
2019-06-05 14:15:23,913 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:23,923 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:15:23,946 p=17240 u=mistral |  TASK [Diff container-puppet.py puppet-generated changes for check mode] ********
2019-06-05 14:15:23,946 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:473
2019-06-05 14:15:23,946 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:23 -0500 (0:00:00.060)       0:11:57.715 ******** 
2019-06-05 14:15:23,973 p=17240 u=mistral |  skipping: [lab-controller-0] => {}
2019-06-05 14:15:23,987 p=17240 u=mistral |  skipping: [lab-computehci-0] => {}
2019-06-05 14:15:24,014 p=17240 u=mistral |  TASK [Start containers for step 3] *********************************************
2019-06-05 14:15:24,014 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:491
2019-06-05 14:15:24,014 p=17240 u=mistral |  Wednesday 05 June 2019  14:15:24 -0500 (0:00:00.068)       0:11:57.784 ******** 
2019-06-05 14:15:46,169 p=17240 u=mistral |  ok: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:16:47,466 p=17240 u=mistral |  ok: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:16:47,493 p=17240 u=mistral |  TASK [Debug output for task: Start containers for step 3] **********************
2019-06-05 14:16:47,493 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:508
2019-06-05 14:16:47,493 p=17240 u=mistral |  Wednesday 05 June 2019  14:16:47 -0500 (0:01:23.479)       0:13:21.263 ******** 
2019-06-05 14:16:47,553 p=17240 u=mistral |  ok: [lab-controller-0] => {
    "failed_when_result": false, 
    "outputs.stdout_lines | default([]) | union(outputs.stderr_lines | default([]))": [
        "stdout: 0ad1f0c28db54b361d3bdef22fdf5be4d86381fcd18fd140d740b1f49fa13037", 
        "", 
        "stderr: Trying to pull docker://docker.io/tripleostein/centos-binary-ceilometer-notification:current-tripleo-rdo...Getting image source signatures", 
        "Copying blob sha256:a35613cff6f04cbfd2f3b845d5a923d56d6f2fb718f85784e8fdcd97ae77846e", 
        "Copying blob sha256:8ba884070f611d31cb2c42eddb691319dc9facf5e0ec67672fcfa135181ab3df", 
        "Copying blob sha256:0f2be6d2e8e6e42cb3e633544d0b1aa8328bd7004a3a4b1dfc0c7a6ba14cd0c7", 
        "Copying blob sha256:5b8f702199c16fd0d5c9c4d0028550b144acb532f4a6b8200b3f53e1cbc43aba", 
        "Copying blob sha256:c0862342b9e7a81856422b95348a2d1952b46e01df6c72f74d94cac2c5815c51", 
        "Copying blob sha256:31c8fa1ceee01b746a6b64c4718f5e42e867c08532b29f8d33626a8385327ede", 
        "Copying blob sha256:6310d6ac1536a2eb8e769d217451e2c6d420eb3c39b0fb1b9ad088a73ea67211", 
        "Copying blob sha256:c80c3921174be89bdd60d2454983524a19a15b09f26f47b6822e6440d5939973", 
        "Copying blob sha256:2799d99efade4475ca55aad34887eabf4e9ec76e592bc0b0a80cbd8d01080ffc", 
        "Copying blob sha256:d36b87fd0812d0e39ef92e729105260f496efbfb19ad7b6981218862502aa0f3", 
        "Copying blob sha256:0fc1fd86055457f85a0cb3f333292570aaa2803c4b556966847f55f8f3544fa8", 
        "Copying blob sha256:46d3c6aa676de9a0ee74cfac77cced69fb7a4df7c5b9e8a7ef33922881d87c81", 
        "Copying blob sha256:fc3b29499fda939e998b0c14c6e98720e1cb7a66fd1ce884cad8d64a63669cf4", 
        "Copying blob sha256:d6dbd69ea530292192935158b778ccffc396ead2093138f75c6e1fa33b7a17fa", 
        "Copying blob sha256:921488feccf56d8c8eb6086cd998b48f907fa44dbc5e7cf8525efd96f7c1f776", 
        "Copying blob sha256:ccae8e3351ac86f5c7d66e9c84321057c9f05063428851fa0f1c17946090212d", 
        "Copying blob sha256:89c8d96f0d37376ba1f54c92128660aaea0a802cb9d9d396a45366b02fc589cc", 
        "Copying blob sha256:45d804df81db3a3f58373c31a92eb2484c2b9038ec59d86fed68b6ce62565939", 
        "Copying blob sha256:5b89a36d5e9e14c5ac5981e8ed2304bb8ce19da7d91793f44c48ac17e7b03717", 
        "Copying blob sha256:98d5e2479617c862dcad487a2c52021bc16e516ebafe9fdab6b3eb8648b73f57", 
        "Copying blob sha256:bd6e2c36ff0e45e35121c3bc2cb54f803eb809aacb2778260d4211de2ba9fabb", 
        "Copying blob sha256:2cc44a4e32219b5aad308d7d3bdc5ba18788e8830c0cf3aa9056e1d0dc647058", 
        "Copying blob sha256:343f9f42dd124dbd53b97d676c7702f6308aa52ad4e28983f1aa15f733d48213", 
        "Copying blob sha256:f68d231cf9d36f0c6d1381c301b6afe0d2450100d736078b83c7891c513f6da0", 
        "Copying blob sha256:e262843cdaf24781dce31bdcdee7c4f4b4be29e4ef40215d73e2179608590dfd", 
        "Copying blob sha256:7971653943cd097a7807d1f3e029791a226ea79c01560ae7168efea6e683f431", 
        "Copying blob sha256:43af3b756ca1ae55bd452e50e5a8bac8b1f4791a9ca3dfa71edf28a754ab34b7", 
        "Copying blob sha256:e916b8a446f9ff8e13f7398ccca737459243baf513a8c1e81edbac2f653c3e6b", 
        "Copying blob sha256:cc88780057d2bbb373a47c58c6b33cb88b8a58bed0251bfc480450f74068d877", 
        "Copying blob sha256:4ebe4153c0591d7b806e5b4fb3d6cfb91877a137c510b66cd3510bb14a635939", 
        "Copying blob sha256:759afea44a271a93f8731a7ce653f7ece1a63af14b73bf9d64cffb116a85f270", 
        "Copying blob sha256:5da976e30b61aa8e8f3e2e060e1f2b13d69d9a9107cd1de70aafc38f7ef86c8b", 
        "Copying config sha256:0ad1f0c28db54b361d3bdef22fdf5be4d86381fcd18fd140d740b1f49fa13037", 
        "Writing manifest to image destination", 
        "Storing signatures", 
        "stdout: 78eec2da959af67fa3c1a543eeabb756b5987d67f7b520184d88be5c14c90b75", 
        "stderr: Trying to pull docker://docker.io/tripleostein/centos-binary-cinder-volume:current-tripleo-rdo...Getting image source signatures", 
        "Copying blob sha256:8774727e360b183320621e11466e556387ed6df1c3002f428fa4eeb6c6a9f5c9", 
        "Copying blob sha256:88108b54db5387e508dfd62742e4e48c16a66398dee5f59f29ff27bbc5a427c8", 
        "Copying blob sha256:3ed6718f30b1e4f92c70e16cc00fcd5266fd54bdc22861d7f68ddb3db85cc9d4", 
        "Copying blob sha256:9a16611eef609d3db5e01b678b61c92a3e8ee7027d3ae0298abcbb42a092047b", 
        "Copying blob sha256:9fe135b100364e1a826f8dc4c3449a93849827be200c74b3bc8a3cd72fb44454", 
        "Copying blob sha256:116f39a3a71446b1535dcb4bdfeb7ec9ee89a9bfc58ed69df7937cbd4e5708bb", 
        "Copying blob sha256:78d7360acc6809884dbae8ea505619204fd0d09a94e9f2158646abef2db29fda", 
        "Copying blob sha256:c359345d7e76adf13184678badd8d3aa5376666e0b639264a9748ba2bed5cb42", 
        "Copying blob sha256:812d3b7e35f9f9626740cd81c8f406452353362695e323fa91b039ade591942a", 
        "Copying blob sha256:5d33d53e29164b3f90a0b231691545d64d39deb51065592acd1cfffcd4646014", 
        "Copying config sha256:78eec2da959af67fa3c1a543eeabb756b5987d67f7b520184d88be5c14c90b75", 
        "stdout: 1db7339b4ec168038a9106b8eedb408e61f95de36adcd00d9c837dd6047b0630", 
        "stderr: Trying to pull docker://docker.io/tripleostein/centos-binary-swift-account:current-tripleo-rdo...Getting image source signatures", 
        "Copying blob sha256:be817afa7b98add2661bfaab95d450fb41ca56adb06301a2c8c33d13a3278109", 
        "Copying blob sha256:6a8b329e2234e1a19a3aa91ccb586e3540a4c5464ad263ee76de34bc05f78212", 
        "Copying blob sha256:7f211c86201e29de65858d380694fda728af7cf140b00d611111a1dc9e8c899e", 
        "Copying blob sha256:778b5f306cfd7e6af23d58d8addd34f3d50b4b441a09628c766987b2bfbf0212", 
        "Copying blob sha256:fc38390f14e8ae1bd7c72e4136f0004dc655f4df400d4bfdb6f6075484c97966", 
        "Copying blob sha256:c79f73bc1d26b481cc8d4e8d14e599dfb2fe5668b8ae974b9a90d4dfe402caeb", 
        "Copying blob sha256:3d7a9d30e477df33af307b11ef3526c0c51177f7e7cca9c95164f53f55ae9e83", 
        "Copying blob sha256:aeb586d58c1087f5fd81f233c4913c68455f778bf00ed31315d74f66ac24171b", 
        "Copying config sha256:1db7339b4ec168038a9106b8eedb408e61f95de36adcd00d9c837dd6047b0630", 
        "stdout: ee69fc0cca0ad866737e41fa032028ec4a698e3461490e7f3a1d533dbf87d55e", 
        "stderr: Trying to pull docker://docker.io/tripleostein/centos-binary-swift-object:current-tripleo-rdo...Getting image source signatures", 
        "Copying blob sha256:5cade17d0a4f522234cccef167917f196c0d7381a45e36b6343a01011e8aa0d8", 
        "Copying blob sha256:b3af7fc7fad1a9df9583e2ae6588e6037adbff2a0d4af152f51e611e73029c92", 
        "Copying config sha256:ee69fc0cca0ad866737e41fa032028ec4a698e3461490e7f3a1d533dbf87d55e", 
        "stdout: ", 
        "stderr: ", 
        "stdout: 84a4c0ea40baa775e41abc8b0cda447a88fdfcfb8ddc9587409268a70e84f15e", 
        "stdout: 2019-06-05 19:15:43.523 13 INFO migrate.versioning.api [-] 70 -> 71... \u001b[00m", 
        "2019-06-05 19:15:43.812 13 INFO migrate.versioning.api [-] done\u001b[00m", 
        "2019-06-05 19:15:43.812 13 INFO migrate.versioning.api [-] 71 -> 72... \u001b[00m", 
        "2019-06-05 19:15:43.869 13 INFO migrate.versioning.api [-] done\u001b[00m", 
        "2019-06-05 19:15:43.869 13 INFO migrate.versioning.api [-] 72 -> 73... \u001b[00m", 
        "2019-06-05 19:15:43.929 13 INFO migrate.versioning.api [-] done\u001b[00m", 
        "2019-06-05 19:15:43.930 13 INFO migrate.versioning.api [-] 73 -> 74... \u001b[00m", 
        "2019-06-05 19:15:43.935 13 INFO migrate.versioning.api [-] done\u001b[00m", 
        "2019-06-05 19:15:43.935 13 INFO migrate.versioning.api [-] 74 -> 75... \u001b[00m", 
        "2019-06-05 19:15:43.941 13 INFO migrate.versioning.api [-] done\u001b[00m", 
        "2019-06-05 19:15:43.941 13 INFO migrate.versioning.api [-] 75 -> 76... \u001b[00m", 
        "2019-06-05 19:15:43.946 13 INFO migrate.versioning.api [-] done\u001b[00m", 
        "2019-06-05 19:15:43.946 13 INFO migrate.versioning.api [-] 76 -> 77... \u001b[00m", 
        "2019-06-05 19:15:43.951 13 INFO migrate.versioning.api [-] done\u001b[00m", 
        "2019-06-05 19:15:43.951 13 INFO migrate.versioning.api [-] 77 -> 78... \u001b[00m", 
        "2019-06-05 19:15:43.957 13 INFO migrate.versioning.api [-] done\u001b[00m", 
        "2019-06-05 19:15:43.957 13 INFO migrate.versioning.api [-] 78 -> 79... \u001b[00m", 
        "2019-06-05 19:15:44.082 13 INFO migrate.versioning.api [-] done\u001b[00m", 
        "2019-06-05 19:15:44.082 13 INFO migrate.versioning.api [-] 79 -> 80... \u001b[00m", 
        "2019-06-05 19:15:44.138 13 INFO migrate.versioning.api [-] done\u001b[00m", 
        "2019-06-05 19:15:44.138 13 INFO migrate.versioning.api [-] 80 -> 81... \u001b[00m", 
        "2019-06-05 19:15:44.143 13 INFO migrate.versioning.api [-] done\u001b[00m", 
        "2019-06-05 19:15:44.143 13 INFO migrate.versioning.api [-] 81 -> 82... \u001b[00m", 
        "2019-06-05 19:15:44.149 13 INFO migrate.versioning.api [-] done\u001b[00m", 
        "2019-06-05 19:15:44.149 13 INFO migrate.versioning.api [-] 82 -> 83... \u001b[00m", 
        "2019-06-05 19:15:44.155 13 INFO migrate.versioning.api [-] done\u001b[00m", 
        "2019-06-05 19:15:44.155 13 INFO migrate.versioning.api [-] 83 -> 84... \u001b[00m", 
        "2019-06-05 19:15:44.160 13 INFO migrate.versioning.api [-] done\u001b[00m", 
        "2019-06-05 19:15:44.160 13 INFO migrate.versioning.api [-] 84 -> 85... \u001b[00m", 
        "2019-06-05 19:15:44.166 13 INFO migrate.versioning.api [-] done\u001b[00m", 
        "2019-06-05 19:15:44.166 13 INFO migrate.versioning.api [-] 85 -> 86... \u001b[00m", 
        "2019-06-05 19:15:44.222 13 INFO migrate.versioning.api [-] done\u001b[00m", 
        "stderr: Deprecated: Option \"logdir\" from group \"DEFAULT\" is deprecated. Use option \"log-dir\" from group \"DEFAULT\".", 
        "stdout: Upgraded database to: rocky_expand02, current revision(s): rocky_expand02", 
        "Database migration is up to date. No migration needed.", 
        "Upgraded database to: rocky_contract02, current revision(s): rocky_contract02", 
        "Database is synced successfully.", 
        "stderr: + sudo -E kolla_set_configs", 
        "INFO:__main__:Loading config file at /var/lib/kolla/config_files/config.json", 
        "INFO:__main__:Validating config file", 
        "INFO:__main__:Kolla config strategy set to: COPY_ALWAYS", 
        "INFO:__main__:Copying service configuration files", 
        "INFO:__main__:Deleting /etc/glance/glance-api.conf", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/glance/glance-api.conf to /etc/glance/glance-api.conf", 
        "INFO:__main__:Deleting /etc/glance/glance-cache.conf", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/glance/glance-cache.conf to /etc/glance/glance-cache.conf", 
        "INFO:__main__:Deleting /etc/glance/glance-image-import.conf", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/glance/glance-image-import.conf to /etc/glance/glance-image-import.conf", 
        "INFO:__main__:Creating directory /etc/my.cnf.d", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/my.cnf.d/tripleo.cnf to /etc/my.cnf.d/tripleo.cnf", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src-ceph/ceph.conf to /etc/ceph/ceph.conf", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src-ceph/ceph.mon.keyring to /etc/ceph/ceph.mon.keyring", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src-ceph/ceph.client.admin.keyring to /etc/ceph/ceph.client.admin.keyring", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src-ceph/ceph.mgr.lab-controller-0.keyring to /etc/ceph/ceph.mgr.lab-controller-0.keyring", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src-ceph/ceph.client.openstack.keyring to /etc/ceph/ceph.client.openstack.keyring", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src-ceph/ceph.client.manila.keyring to /etc/ceph/ceph.client.manila.keyring", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src-ceph/ceph.client.radosgw.keyring to /etc/ceph/ceph.client.radosgw.keyring", 
        "INFO:__main__:Writing out command to execute", 
        "INFO:__main__:Setting permission for /var/lib/glance", 
        "INFO:__main__:Setting permission for /etc/ceph/ceph.client.openstack.keyring", 
        "++ cat /run_command", 
        "+ CMD='/usr/bin/glance-api --config-file /usr/share/glance/glance-api-dist.conf --config-file /etc/glance/glance-api.conf --config-file /etc/glance/glance-image-import.conf'", 
        "+ ARGS=", 
        "+ [[ ! -n '' ]]", 
        "+ . kolla_extend_start", 
        "++ [[ ! -d /var/log/kolla/glance ]]", 
        "++ mkdir -p /var/log/kolla/glance", 
        "+++ stat -c %a /var/log/kolla/glance", 
        "++ [[ 2755 != \\7\\5\\5 ]]", 
        "++ chmod 755 /var/log/kolla/glance", 
        "++ . /usr/local/bin/kolla_glance_extend_start", 
        "+++ [[ -n 0 ]]", 
        "+++ glance-manage db_sync", 
        "/usr/lib/python2.7/site-packages/oslo_db/sqlalchemy/enginefacade.py:1371: OsloDBDeprecationWarning: EngineFacade is deprecated; please use oslo_db.sqlalchemy.enginefacade", 
        "  expire_on_commit=expire_on_commit, _conf=conf)", 
        "INFO  [alembic.runtime.migration] Context impl MySQLImpl.", 
        "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.", 
        "INFO  [alembic.runtime.migration] Running upgrade  -> liberty, liberty initial", 
        "INFO  [alembic.runtime.migration] Running upgrade liberty -> mitaka01, add index on created_at and updated_at columns of 'images' table", 
        "INFO  [alembic.runtime.migration] Running upgrade mitaka01 -> mitaka02, update metadef os_nova_server", 
        "INFO  [alembic.runtime.migration] Running upgrade mitaka02 -> ocata_expand01, add visibility to images", 
        "INFO  [alembic.runtime.migration] Running upgrade ocata_expand01 -> pike_expand01, empty expand for symmetry with pike_contract01", 
        "INFO  [alembic.runtime.migration] Running upgrade pike_expand01 -> queens_expand01", 
        "INFO  [alembic.runtime.migration] Running upgrade queens_expand01 -> rocky_expand01, add os_hidden column to images table", 
        "INFO  [alembic.runtime.migration] Running upgrade rocky_expand01 -> rocky_expand02, add os_hash_algo and os_hash_value columns to images table", 
        "INFO  [alembic.runtime.migration] Running upgrade mitaka02 -> ocata_contract01, remove is_public from images", 
        "INFO  [alembic.runtime.migration] Running upgrade ocata_contract01 -> pike_contract01, drop glare artifacts tables", 
        "INFO  [alembic.runtime.migration] Running upgrade pike_contract01 -> queens_contract01", 
        "INFO  [alembic.runtime.migration] Running upgrade queens_contract01 -> rocky_contract01", 
        "INFO  [alembic.runtime.migration] Running upgrade rocky_contract01 -> rocky_contract02", 
        "+++ glance-manage db_load_metadefs", 
        "+++ exit 0", 
        "stdout: '/swift_ringbuilder/etc/swift/account.ring.gz' -> '/etc/swift/account.ring.gz'", 
        "'/swift_ringbuilder/etc/swift/container.ring.gz' -> '/etc/swift/container.ring.gz'", 
        "'/swift_ringbuilder/etc/swift/object.ring.gz' -> '/etc/swift/object.ring.gz'", 
        "'/swift_ringbuilder/etc/swift/account.builder' -> '/etc/swift/account.builder'", 
        "'/swift_ringbuilder/etc/swift/container.builder' -> '/etc/swift/container.builder'", 
        "'/swift_ringbuilder/etc/swift/object.builder' -> '/etc/swift/object.builder'", 
        "'/swift_ringbuilder/etc/swift/backups' -> '/etc/swift/backups'", 
        "'/swift_ringbuilder/etc/swift/backups/1559761753.object.builder' -> '/etc/swift/backups/1559761753.object.builder'", 
        "'/swift_ringbuilder/etc/swift/backups/1559761754.account.builder' -> '/etc/swift/backups/1559761754.account.builder'", 
        "'/swift_ringbuilder/etc/swift/backups/1559761754.container.builder' -> '/etc/swift/backups/1559761754.container.builder'", 
        "'/swift_ringbuilder/etc/swift/backups/1559761756.object.builder' -> '/etc/swift/backups/1559761756.object.builder'", 
        "'/swift_ringbuilder/etc/swift/backups/1559761756.object.ring.gz' -> '/etc/swift/backups/1559761756.object.ring.gz'", 
        "'/swift_ringbuilder/etc/swift/backups/1559761757.account.builder' -> '/etc/swift/backups/1559761757.account.builder'", 
        "'/swift_ringbuilder/etc/swift/backups/1559761757.account.ring.gz' -> '/etc/swift/backups/1559761757.account.ring.gz'", 
        "'/swift_ringbuilder/etc/swift/backups/1559761757.container.builder' -> '/etc/swift/backups/1559761757.container.builder'", 
        "'/swift_ringbuilder/etc/swift/backups/1559761757.container.ring.gz' -> '/etc/swift/backups/1559761757.container.ring.gz'", 
        "INFO:__main__:Creating directory /etc/keystone/fernet-keys", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/keystone/fernet-keys/0 to /etc/keystone/fernet-keys/0", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/keystone/fernet-keys/1 to /etc/keystone/fernet-keys/1", 
        "INFO:__main__:Deleting /etc/httpd/conf.d", 
        "INFO:__main__:Creating directory /etc/httpd/conf.d", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.d/10-keystone_wsgi.conf to /etc/httpd/conf.d/10-keystone_wsgi.conf", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.d/ssl.conf to /etc/httpd/conf.d/ssl.conf", 
        "INFO:__main__:Deleting /etc/httpd/conf.d/10-keystone_wsgi.conf", 
        "INFO:__main__:Deleting /etc/httpd/conf.d/ssl.conf", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/access_compat.load to /etc/httpd/conf.modules.d/access_compat.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/actions.load to /etc/httpd/conf.modules.d/actions.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/alias.conf to /etc/httpd/conf.modules.d/alias.conf", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/alias.load to /etc/httpd/conf.modules.d/alias.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/auth_basic.load to /etc/httpd/conf.modules.d/auth_basic.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/auth_digest.load to /etc/httpd/conf.modules.d/auth_digest.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/authn_anon.load to /etc/httpd/conf.modules.d/authn_anon.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/authn_core.load to /etc/httpd/conf.modules.d/authn_core.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/authn_dbm.load to /etc/httpd/conf.modules.d/authn_dbm.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/authn_file.load to /etc/httpd/conf.modules.d/authn_file.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/authz_core.load to /etc/httpd/conf.modules.d/authz_core.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/authz_dbm.load to /etc/httpd/conf.modules.d/authz_dbm.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/authz_groupfile.load to /etc/httpd/conf.modules.d/authz_groupfile.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/authz_host.load to /etc/httpd/conf.modules.d/authz_host.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/authz_owner.load to /etc/httpd/conf.modules.d/authz_owner.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/authz_user.load to /etc/httpd/conf.modules.d/authz_user.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/autoindex.conf to /etc/httpd/conf.modules.d/autoindex.conf", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/autoindex.load to /etc/httpd/conf.modules.d/autoindex.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/cache.load to /etc/httpd/conf.modules.d/cache.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/cgi.load to /etc/httpd/conf.modules.d/cgi.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/dav.load to /etc/httpd/conf.modules.d/dav.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/dav_fs.conf to /etc/httpd/conf.modules.d/dav_fs.conf", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/dav_fs.load to /etc/httpd/conf.modules.d/dav_fs.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/deflate.conf to /etc/httpd/conf.modules.d/deflate.conf", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/deflate.load to /etc/httpd/conf.modules.d/deflate.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/dir.conf to /etc/httpd/conf.modules.d/dir.conf", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/dir.load to /etc/httpd/conf.modules.d/dir.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/env.load to /etc/httpd/conf.modules.d/env.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/expires.load to /etc/httpd/conf.modules.d/expires.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/ext_filter.load to /etc/httpd/conf.modules.d/ext_filter.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/filter.load to /etc/httpd/conf.modules.d/filter.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/include.load to /etc/httpd/conf.modules.d/include.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/log_config.load to /etc/httpd/conf.modules.d/log_config.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/logio.load to /etc/httpd/conf.modules.d/logio.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/mime.conf to /etc/httpd/conf.modules.d/mime.conf", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/mime.load to /etc/httpd/conf.modules.d/mime.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/mime_magic.conf to /etc/httpd/conf.modules.d/mime_magic.conf", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/mime_magic.load to /etc/httpd/conf.modules.d/mime_magic.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/negotiation.conf to /etc/httpd/conf.modules.d/negotiation.conf", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/negotiation.load to /etc/httpd/conf.modules.d/negotiation.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/prefork.conf to /etc/httpd/conf.modules.d/prefork.conf", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/prefork.load to /etc/httpd/conf.modules.d/prefork.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/rewrite.load to /etc/httpd/conf.modules.d/rewrite.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/setenvif.conf to /etc/httpd/conf.modules.d/setenvif.conf", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/setenvif.load to /etc/httpd/conf.modules.d/setenvif.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/socache_shmcb.load to /etc/httpd/conf.modules.d/socache_shmcb.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/speling.load to /etc/httpd/conf.modules.d/speling.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/ssl.load to /etc/httpd/conf.modules.d/ssl.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/status.conf to /etc/httpd/conf.modules.d/status.conf", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/status.load to /etc/httpd/conf.modules.d/status.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/substitute.load to /etc/httpd/conf.modules.d/substitute.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/suexec.load to /etc/httpd/conf.modules.d/suexec.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/systemd.load to /etc/httpd/conf.modules.d/systemd.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/unixd.load to /etc/httpd/conf.modules.d/unixd.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/usertrack.load to /etc/httpd/conf.modules.d/usertrack.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/version.load to /etc/httpd/conf.modules.d/version.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/vhost_alias.load to /etc/httpd/conf.modules.d/vhost_alias.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/wsgi.conf to /etc/httpd/conf.modules.d/wsgi.conf", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/wsgi.load to /etc/httpd/conf.modules.d/wsgi.load", 
        "INFO:__main__:Deleting /etc/httpd/conf/httpd.conf", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf/httpd.conf to /etc/httpd/conf/httpd.conf", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf/ports.conf to /etc/httpd/conf/ports.conf", 
        "INFO:__main__:Creating directory /etc/keystone/credential-keys", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/keystone/credential-keys/0 to /etc/keystone/credential-keys/0", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/keystone/credential-keys/1 to /etc/keystone/credential-keys/1", 
        "INFO:__main__:Deleting /etc/keystone/fernet-keys/0", 
        "INFO:__main__:Deleting /etc/keystone/fernet-keys/1", 
        "INFO:__main__:Deleting /etc/keystone/keystone.conf", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/keystone/keystone.conf to /etc/keystone/keystone.conf", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/var/spool/cron/keystone to /var/spool/cron/keystone", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/var/www/cgi-bin/keystone/keystone to /var/www/cgi-bin/keystone/keystone", 
        "+ CMD='/usr/sbin/httpd -DFOREGROUND'", 
        "++ [[ centos =~ debian|ubuntu ]]", 
        "++ rm -rf /var/run/httpd/htcacheclean /run/httpd/htcacheclean '/tmp/httpd*'", 
        "++ KEYSTONE_LOG_DIR=/var/log/kolla/keystone", 
        "++ [[ ! -d /var/log/kolla/keystone ]]", 
        "++ mkdir -p /var/log/kolla/keystone", 
        "+++ stat -c %U:%G /var/log/kolla/keystone", 
        "++ [[ root:kolla != \\k\\e\\y\\s\\t\\o\\n\\e\\:\\k\\o\\l\\l\\a ]]", 
        "++ chown keystone:kolla /var/log/kolla/keystone", 
        "++ '[' '!' -f /var/log/kolla/keystone/keystone.log ']'", 
        "++ touch /var/log/kolla/keystone/keystone.log", 
        "+++ stat -c %U:%G /var/log/kolla/keystone/keystone.log", 
        "++ [[ root:kolla != \\k\\e\\y\\s\\t\\o\\n\\e\\:\\k\\e\\y\\s\\t\\o\\n\\e ]]", 
        "++ chown keystone:keystone /var/log/kolla/keystone/keystone.log", 
        "+++ stat -c %a /var/log/kolla/keystone", 
        "++ chmod 755 /var/log/kolla/keystone", 
        "++ EXTRA_KEYSTONE_MANAGE_ARGS=", 
        "++ [[ -n '' ]]", 
        "++ [[ -n 0 ]]", 
        "++ sudo -H -u keystone keystone-manage db_sync", 
        "++ exit 0", 
        "stdout: d8ca065e3006aa7602e3bafd23d649e3c2f9e280799e7143a4e3bb795e7867aa", 
        "stdout: Running upgrade for neutron ...", 
        "OK", 
        "Running upgrade for networking-l2gw ...", 
        "Running upgrade for networking-ovn ...", 
        "Running upgrade for networking-sfc ...", 
        "Running upgrade for neutron-dynamic-routing ...", 
        "Running upgrade for neutron-fwaas ...", 
        "Running upgrade for neutron-lbaas ...", 
        "Running upgrade for neutron-vpnaas ...", 
        "Running upgrade for vmware-nsx ...", 
        "stderr: INFO  [alembic.runtime.migration] Context impl MySQLImpl.", 
        "INFO  [alembic.runtime.migration] Running upgrade  -> kilo", 
        "INFO  [alembic.runtime.migration] Running upgrade kilo -> 354db87e3225", 
        "INFO  [alembic.runtime.migration] Running upgrade 354db87e3225 -> 599c6a226151", 
        "INFO  [alembic.runtime.migration] Running upgrade 599c6a226151 -> 52c5312f6baf", 
        "INFO  [alembic.runtime.migration] Running upgrade 52c5312f6baf -> 313373c0ffee", 
        "INFO  [alembic.runtime.migration] Running upgrade 313373c0ffee -> 8675309a5c4f", 
        "INFO  [alembic.runtime.migration] Running upgrade 8675309a5c4f -> 45f955889773", 
        "INFO  [alembic.runtime.migration] Running upgrade 45f955889773 -> 26c371498592", 
        "INFO  [alembic.runtime.migration] Running upgrade 26c371498592 -> 1c844d1677f7", 
        "INFO  [alembic.runtime.migration] Running upgrade 1c844d1677f7 -> 1b4c6e320f79", 
        "INFO  [alembic.runtime.migration] Running upgrade 1b4c6e320f79 -> 48153cb5f051", 
        "INFO  [alembic.runtime.migration] Running upgrade 48153cb5f051 -> 9859ac9c136", 
        "INFO  [alembic.runtime.migration] Running upgrade 9859ac9c136 -> 34af2b5c5a59", 
        "INFO  [alembic.runtime.migration] Running upgrade 34af2b5c5a59 -> 59cb5b6cf4d", 
        "INFO  [alembic.runtime.migration] Running upgrade 59cb5b6cf4d -> 13cfb89f881a", 
        "INFO  [alembic.runtime.migration] Running upgrade 13cfb89f881a -> 32e5974ada25", 
        "INFO  [alembic.runtime.migration] Running upgrade 32e5974ada25 -> ec7fcfbf72ee", 
        "INFO  [alembic.runtime.migration] Running upgrade ec7fcfbf72ee -> dce3ec7a25c9", 
        "INFO  [alembic.runtime.migration] Running upgrade dce3ec7a25c9 -> c3a73f615e4", 
        "INFO  [alembic.runtime.migration] Running upgrade c3a73f615e4 -> 659bf3d90664", 
        "INFO  [alembic.runtime.migration] Running upgrade 659bf3d90664 -> 1df244e556f5", 
        "INFO  [alembic.runtime.migration] Running upgrade 1df244e556f5 -> 19f26505c74f", 
        "INFO  [alembic.runtime.migration] Running upgrade 19f26505c74f -> 15be73214821", 
        "INFO  [alembic.runtime.migration] Running upgrade 15be73214821 -> b4caf27aae4", 
        "INFO  [alembic.runtime.migration] Running upgrade b4caf27aae4 -> 15e43b934f81", 
        "INFO  [alembic.runtime.migration] Running upgrade 15e43b934f81 -> 31ed664953e6", 
        "INFO  [alembic.runtime.migration] Running upgrade 31ed664953e6 -> 2f9e956e7532", 
        "INFO  [alembic.runtime.migration] Running upgrade 2f9e956e7532 -> 3894bccad37f", 
        "INFO  [alembic.runtime.migration] Running upgrade 3894bccad37f -> 0e66c5227a8a", 
        "INFO  [alembic.runtime.migration] Running upgrade 0e66c5227a8a -> 45f8dd33480b", 
        "INFO  [alembic.runtime.migration] Running upgrade 45f8dd33480b -> 5abc0278ca73", 
        "INFO  [alembic.runtime.migration] Running upgrade 5abc0278ca73 -> d3435b514502", 
        "INFO  [alembic.runtime.migration] Running upgrade d3435b514502 -> 30107ab6a3ee", 
        "INFO  [alembic.runtime.migration] Running upgrade 30107ab6a3ee -> c415aab1c048", 
        "INFO  [alembic.runtime.migration] Running upgrade c415aab1c048 -> a963b38d82f4", 
        "INFO  [alembic.runtime.migration] Running upgrade kilo -> 30018084ec99", 
        "INFO  [alembic.runtime.migration] Running upgrade 30018084ec99 -> 4ffceebfada", 
        "INFO  [alembic.runtime.migration] Running upgrade 4ffceebfada -> 5498d17be016", 
        "INFO  [alembic.runtime.migration] Running upgrade 5498d17be016 -> 2a16083502f3", 
        "INFO  [alembic.runtime.migration] Running upgrade 2a16083502f3 -> 2e5352a0ad4d", 
        "INFO  [alembic.runtime.migration] Running upgrade 2e5352a0ad4d -> 11926bcfe72d", 
        "INFO  [alembic.runtime.migration] Running upgrade 11926bcfe72d -> 4af11ca47297", 
        "INFO  [alembic.runtime.migration] Running upgrade 4af11ca47297 -> 1b294093239c", 
        "INFO  [alembic.runtime.migration] Running upgrade 1b294093239c -> 8a6d8bdae39", 
        "INFO  [alembic.runtime.migration] Running upgrade 8a6d8bdae39 -> 2b4c2465d44b", 
        "INFO  [alembic.runtime.migration] Running upgrade 2b4c2465d44b -> e3278ee65050", 
        "INFO  [alembic.runtime.migration] Running upgrade e3278ee65050 -> c6c112992c9", 
        "INFO  [alembic.runtime.migration] Running upgrade c6c112992c9 -> 5ffceebfada", 
        "INFO  [alembic.runtime.migration] Running upgrade 5ffceebfada -> 4ffceebfcdc", 
        "INFO  [alembic.runtime.migration] Running upgrade 4ffceebfcdc -> 7bbb25278f53", 
        "INFO  [alembic.runtime.migration] Running upgrade 7bbb25278f53 -> 89ab9a816d70", 
        "INFO  [alembic.runtime.migration] Running upgrade 89ab9a816d70 -> c879c5e1ee90", 
        "INFO  [alembic.runtime.migration] Running upgrade c879c5e1ee90 -> 8fd3918ef6f4", 
        "INFO  [alembic.runtime.migration] Running upgrade 8fd3918ef6f4 -> 4bcd4df1f426", 
        "INFO  [alembic.runtime.migration] Running upgrade 4bcd4df1f426 -> b67e765a3524", 
        "INFO  [alembic.runtime.migration] Running upgrade a963b38d82f4 -> 3d0e74aa7d37", 
        "INFO  [alembic.runtime.migration] Running upgrade 3d0e74aa7d37 -> 030a959ceafa", 
        "INFO  [alembic.runtime.migration] Running upgrade 030a959ceafa -> a5648cfeeadf", 
        "INFO  [alembic.runtime.migration] Running upgrade a5648cfeeadf -> 0f5bef0f87d4", 
        "INFO  [alembic.runtime.migration] Running upgrade 0f5bef0f87d4 -> 67daae611b6e", 
        "INFO  [alembic.runtime.migration] Running upgrade 67daae611b6e -> 6b461a21bcfc", 
        "INFO  [alembic.runtime.migration] Running upgrade 6b461a21bcfc -> 5cd92597d11d", 
        "INFO  [alembic.runtime.migration] Running upgrade 5cd92597d11d -> 929c968efe70", 
        "INFO  [alembic.runtime.migration] Running upgrade 929c968efe70 -> a9c43481023c", 
        "INFO  [alembic.runtime.migration] Running upgrade a9c43481023c -> 804a3c76314c", 
        "INFO  [alembic.runtime.migration] Running upgrade 804a3c76314c -> 2b42d90729da", 
        "INFO  [alembic.runtime.migration] Running upgrade 2b42d90729da -> 62c781cb6192", 
        "INFO  [alembic.runtime.migration] Running upgrade 62c781cb6192 -> c8c222d42aa9", 
        "INFO  [alembic.runtime.migration] Running upgrade c8c222d42aa9 -> 349b6fd605a6", 
        "INFO  [alembic.runtime.migration] Running upgrade 349b6fd605a6 -> 7d32f979895f", 
        "INFO  [alembic.runtime.migration] Running upgrade 7d32f979895f -> 594422d373ee", 
        "INFO  [alembic.runtime.migration] Running upgrade 594422d373ee -> 61663558142c", 
        "INFO  [alembic.runtime.migration] Running upgrade 61663558142c -> 867d39095bf4, port forwarding", 
        "INFO  [alembic.runtime.migration] Running upgrade 867d39095bf4 -> d72db3e25539, modify uniq port forwarding", 
        "INFO  [alembic.runtime.migration] Running upgrade d72db3e25539 -> cada2437bf41", 
        "INFO  [alembic.runtime.migration] Running upgrade cada2437bf41 -> 195176fb410d, router gateway IP QoS", 
        "INFO  [alembic.runtime.migration] Running upgrade 195176fb410d -> fb0167bd9639", 
        "INFO  [alembic.runtime.migration] Running upgrade fb0167bd9639 -> 0ff9e3881597", 
        "INFO  [alembic.runtime.migration] Running upgrade 0ff9e3881597 -> 9bfad3f1e780", 
        "INFO  [alembic.runtime.migration] Running upgrade b67e765a3524 -> a84ccf28f06a", 
        "INFO  [alembic.runtime.migration] Running upgrade a84ccf28f06a -> 7d9d8eeec6ad", 
        "INFO  [alembic.runtime.migration] Running upgrade 7d9d8eeec6ad -> a8b517cff8ab", 
        "INFO  [alembic.runtime.migration] Running upgrade a8b517cff8ab -> 3b935b28e7a0", 
        "INFO  [alembic.runtime.migration] Running upgrade 3b935b28e7a0 -> b12a3ef66e62", 
        "INFO  [alembic.runtime.migration] Running upgrade b12a3ef66e62 -> 97c25b0d2353", 
        "INFO  [alembic.runtime.migration] Running upgrade 97c25b0d2353 -> 2e0d7a8a1586", 
        "INFO  [alembic.runtime.migration] Running upgrade 2e0d7a8a1586 -> 5c85685d616d", 
        "INFO  [alembic.runtime.migration] Running upgrade  -> start_networking_l2gw, start networking-l2gw chain", 
        "INFO  [alembic.runtime.migration] Running upgrade start_networking_l2gw -> 54c9c8fe22bf, DB_Models_for_OVSDB_Hardware_VTEP_Schema", 
        "INFO  [alembic.runtime.migration] Running upgrade 54c9c8fe22bf -> 42438454c556, l2gateway_models", 
        "INFO  [alembic.runtime.migration] Running upgrade 42438454c556 -> kilo, kilo", 
        "INFO  [alembic.runtime.migration] Running upgrade kilo -> 60019185aa99, Initial no-op Liberty expand rule.", 
        "INFO  [alembic.runtime.migration] Running upgrade 60019185aa99 -> 49ce408ac349, add indexes to tenant_id", 
        "INFO  [alembic.runtime.migration] Running upgrade 49ce408ac349 -> 8d7d772eafcf, add standard_attribute_id for l2gw", 
        "INFO  [alembic.runtime.migration] Running upgrade kilo -> 79919185aa99, Initial no-op Liberty contract rule.", 
        "INFO  [alembic.runtime.migration] Running upgrade 79919185aa99 -> 2f533f7705dd, rename tenant to project", 
        "INFO  [alembic.runtime.migration] Running upgrade 2f533f7705dd -> 0fb45e525aa9, add standard_attribute_id for l2gw", 
        "INFO  [alembic.runtime.migration] Running upgrade  -> initial_branchpoint, initial branchpoint", 
        "INFO  [alembic.runtime.migration] Running upgrade initial_branchpoint -> ac094507b7f4, initial networking-ovn contract branch", 
        "INFO  [alembic.runtime.migration] Running upgrade ac094507b7f4 -> e229b8aad9f2, add ovn_journal and ovn_maintenance tables", 
        "INFO  [alembic.runtime.migration] Running upgrade e229b8aad9f2 -> bc9e24bb9da2, Drop journaling related tables", 
        "INFO  [alembic.runtime.migration] Running upgrade bc9e24bb9da2 -> f48286668608, add_ovn_revision_numbers_table", 
        "INFO  [alembic.runtime.migration] Running upgrade f48286668608 -> 5c198d2723b6, add_ovn_revision_resource_type_as_pk", 
        "INFO  [alembic.runtime.migration] Running upgrade initial_branchpoint -> 1d271ead4eb6, initial networking-ovn contract branch", 
        "INFO  [alembic.runtime.migration] Running upgrade  -> start_networking_sfc, start networking-sfc chain", 
        "INFO  [alembic.runtime.migration] Running upgrade start_networking_sfc -> 24fc7241aa5, Initial Mitaka no-op script.", 
        "INFO  [alembic.runtime.migration] Running upgrade 24fc7241aa5 -> 9768e6a66c9, Defining flow-classifier data-model", 
        "INFO  [alembic.runtime.migration] Running upgrade 9768e6a66c9 -> c3e178d4a985, Defining Port Chain data-model.", 
        "INFO  [alembic.runtime.migration] Running upgrade c3e178d4a985 -> 5a475fc853e6, Defining OVS data-model", 
        "INFO  [alembic.runtime.migration] Running upgrade 5a475fc853e6 -> d1002a1f97f6, update flow classifier", 
        "INFO  [alembic.runtime.migration] Running upgrade d1002a1f97f6 -> fa75d46a7f11, add_port_pair_group_params", 
        "INFO  [alembic.runtime.migration] Running upgrade fa75d46a7f11 -> b3adaf631bab, _add_fwd_path_and_in_mac_column", 
        "INFO  [alembic.runtime.migration] Running upgrade b3adaf631bab -> 6185f1633a3d, description of revision", 
        "INFO  [alembic.runtime.migration] Running upgrade 6185f1633a3d -> 61832141fb82, add_ppg_n_tuple_mapping_column", 
        "INFO  [alembic.runtime.migration] Running upgrade 61832141fb82 -> 8329e9be2d8a, modify_value_column_size_in_port_pair_group_params", 
        "INFO  [alembic.runtime.migration] Running upgrade 8329e9be2d8a -> 53ed5bec6cff, Add Service Graph API resource", 
        "INFO  [alembic.runtime.migration] Running upgrade 53ed5bec6cff -> d6fb381b65f2", 
        "INFO  [alembic.runtime.migration] Running upgrade d6fb381b65f2 -> a3ad63aa834f, extra attributes for pathnode", 
        "INFO  [alembic.runtime.migration] Running upgrade start_networking_sfc -> 48072cb59133, Initial Mitaka no-op script.", 
        "INFO  [alembic.runtime.migration] Running upgrade 48072cb59133 -> 010308b06b49, rename tenant to project", 
        "INFO  [alembic.runtime.migration] Running upgrade 010308b06b49 -> 06382790fb2c, fix foreign constraints", 
        "INFO  [alembic.runtime.migration] Running upgrade  -> start_neutron_dynamic_routing, start neutron-dynamic-routing chain", 
        "INFO  [alembic.runtime.migration] Running upgrade start_neutron_dynamic_routing -> 61cc795e43e8, initial", 
        "INFO  [alembic.runtime.migration] Running upgrade 61cc795e43e8 -> 4cf8bc3edb66, rename tenant to project", 
        "INFO  [alembic.runtime.migration] Running upgrade 4cf8bc3edb66 -> a589fdb5724c, change size of as number", 
        "INFO  [alembic.runtime.migration] Running upgrade start_neutron_dynamic_routing -> f399fa0f5f25, initial", 
        "INFO  [alembic.runtime.migration] Running upgrade  -> start_neutron_fwaas, start neutron-fwaas chain", 
        "INFO  [alembic.runtime.migration] Running upgrade start_neutron_fwaas -> 4202e3047e47, add_index_tenant_id", 
        "INFO  [alembic.runtime.migration] Running upgrade 4202e3047e47 -> 540142f314f4, FWaaS router insertion", 
        "INFO  [alembic.runtime.migration] Running upgrade 540142f314f4 -> 796c68dffbb, cisco_csr_fwaas", 
        "INFO  [alembic.runtime.migration] Running upgrade 796c68dffbb -> kilo, kilo", 
        "INFO  [alembic.runtime.migration] Running upgrade kilo -> c40fbb377ad, Initial Liberty no-op script.", 
        "INFO  [alembic.runtime.migration] Running upgrade c40fbb377ad -> 4b47ea298795, add reject rule", 
        "INFO  [alembic.runtime.migration] Running upgrade 4b47ea298795 -> d6a12e637e28, neutron-fwaas v2.0", 
        "INFO  [alembic.runtime.migration] Running upgrade d6a12e637e28 -> 876782258a43, create_default_firewall_groups_table", 
        "INFO  [alembic.runtime.migration] Running upgrade 876782258a43 -> f24e0d5e5bff, uniq_firewallgroupportassociation0port", 
        "INFO  [alembic.runtime.migration] Running upgrade kilo -> 67c8e8d61d5, Initial Liberty no-op script.", 
        "INFO  [alembic.runtime.migration] Running upgrade 67c8e8d61d5 -> 458aa42b14b, fw_table_alter script to make <name> column case sensitive", 
        "INFO  [alembic.runtime.migration] Running upgrade 458aa42b14b -> f83a0b2964d0, rename tenant to project", 
        "INFO  [alembic.runtime.migration] Running upgrade f83a0b2964d0 -> fd38cd995cc0, change shared attribute for firewall resource", 
        "INFO  [alembic.runtime.migration] Running upgrade  -> start_neutron_lbaas, start neutron-lbaas chain", 
        "INFO  [alembic.runtime.migration] Running upgrade start_neutron_lbaas -> lbaasv2, lbaas version 2 api", 
        "INFO  [alembic.runtime.migration] Running upgrade lbaasv2 -> 4deef6d81931, add provisioning and operating statuses", 
        "INFO  [alembic.runtime.migration] Running upgrade 4deef6d81931 -> 4b6d8d5310b8, add_index_tenant_id", 
        "INFO  [alembic.runtime.migration] Running upgrade 4b6d8d5310b8 -> 364f9b6064f0, agentv2", 
        "INFO  [alembic.runtime.migration] Running upgrade 364f9b6064f0 -> lbaasv2_tls, lbaasv2 TLS", 
        "INFO  [alembic.runtime.migration] Running upgrade lbaasv2_tls -> 4ba00375f715, edge_driver", 
        "INFO  [alembic.runtime.migration] Running upgrade 4ba00375f715 -> kilo, kilo", 
        "INFO  [alembic.runtime.migration] Running upgrade kilo -> 3345facd0452, Initial Liberty no-op expand script.", 
        "INFO  [alembic.runtime.migration] Running upgrade 3345facd0452 -> 4a408dd491c2, Addition of Name column to lbaas_members and lbaas_healthmonitors table", 
        "INFO  [alembic.runtime.migration] Running upgrade 4a408dd491c2 -> 3426acbc12de, Add flavor id", 
        "INFO  [alembic.runtime.migration] Running upgrade 3426acbc12de -> 6aee0434f911, independent pools", 
        "INFO  [alembic.runtime.migration] Running upgrade 6aee0434f911 -> 3543deab1547, add_l7_tables", 
        "INFO  [alembic.runtime.migration] Running upgrade 3543deab1547 -> 62deca5010cd, Add tenant-id index for L7 tables", 
        "INFO  [alembic.runtime.migration] Running upgrade kilo -> 130ebfdef43, Initial Liberty no-op contract revision.", 
        "INFO  [alembic.runtime.migration] Running upgrade 130ebfdef43 -> 4b4dc6d5d843, rename tenant to project", 
        "INFO  [alembic.runtime.migration] Running upgrade 4b4dc6d5d843 -> e6417a8b114d, Drop v1 tables", 
        "INFO  [alembic.runtime.migration] Running upgrade 62deca5010cd -> 844352f9fe6f, Add healthmonitor max retries down", 
        "INFO  [alembic.runtime.migration] Running upgrade  -> start_neutron_vpnaas, start neutron-vpnaas chain", 
        "INFO  [alembic.runtime.migration] Running upgrade start_neutron_vpnaas -> 3ea02b2a773e, add_index_tenant_id", 
        "INFO  [alembic.runtime.migration] Running upgrade 3ea02b2a773e -> kilo, kilo", 
        "INFO  [alembic.runtime.migration] Running upgrade kilo -> 30018084ed99, Initial no-op Liberty expand rule.", 
        "INFO  [alembic.runtime.migration] Running upgrade 30018084ed99 -> 24f28869838b, Add fields to VPN service table", 
        "INFO  [alembic.runtime.migration] Running upgrade 24f28869838b -> 41b509d10b5e, VPNaaS endpoint groups", 
        "INFO  [alembic.runtime.migration] Running upgrade 41b509d10b5e -> 28ee739a7e4b, Multiple local subnets", 
        "INFO  [alembic.runtime.migration] Running upgrade kilo -> 56893333aa52, fix identifier map fk", 
        "INFO  [alembic.runtime.migration] Running upgrade 56893333aa52 -> 333dfd6afaa2, Populate VPN service table fields", 
        "INFO  [alembic.runtime.migration] Running upgrade 333dfd6afaa2 -> 2c82e782d734, drop_tenant_id_in_cisco_csr_identifier_map", 
        "INFO  [alembic.runtime.migration] Running upgrade 2c82e782d734 -> 2cb4ee992b41, Multiple local subnets", 
        "INFO  [alembic.runtime.migration] Running upgrade 2cb4ee992b41 -> b6a2519ab7dc, rename tenant to project", 
        "INFO  [alembic.runtime.migration] Running upgrade b6a2519ab7dc -> e50641731f1a, drop cisco_csr_identifier_map table", 
        "INFO  [alembic.runtime.migration] Running upgrade 28ee739a7e4b -> fe637dc3f042, support sha256", 
        "INFO  [alembic.runtime.migration] Running upgrade fe637dc3f042 -> 52783a36bd67, support local id", 
        "INFO  [alembic.runtime.migration] Running upgrade 52783a36bd67 -> 38893903cbde, add_auth_algorithm_sha384_and_sha512", 
        "INFO  [alembic.runtime.migration] Running upgrade 38893903cbde -> 95601446dbcc, add flavor id to vpnservices", 
        "INFO  [alembic.runtime.migration] Running upgrade  -> kilo, kilo", 
        "INFO  [alembic.runtime.migration] Running upgrade kilo -> 53a3254aa95e, Initial Liberty no-op expand script.", 
        "INFO  [alembic.runtime.migration] Running upgrade 53a3254aa95e -> 28430956782d, nsxv3_security_groups", 
        "INFO  [alembic.runtime.migration] Running upgrade 28430956782d -> 279b70ac3ae8, NSXv3 Add l2gwconnection table", 
        "INFO  [alembic.runtime.migration] Running upgrade 279b70ac3ae8 -> 312211a5725f, nsxv_lbv2", 
        "INFO  [alembic.runtime.migration] Running upgrade 312211a5725f -> 2af850eb3970, update nsxv tz binding type", 
        "INFO  [alembic.runtime.migration] Running upgrade 2af850eb3970 -> 69fb78b33d41, NSXv add dns search domain to subnets", 
        "INFO  [alembic.runtime.migration] Running upgrade 69fb78b33d41 -> 20483029f1ff, update nsx_v3 tz_network_bindings_binding_type", 
        "INFO  [alembic.runtime.migration] Running upgrade 20483029f1ff -> 4c45bcadccf9, extend_secgroup_rule", 
        "INFO  [alembic.runtime.migration] Running upgrade 4c45bcadccf9 -> 2c87aedb206f, nsxv_security_group_logging", 
        "INFO  [alembic.runtime.migration] Running upgrade 2c87aedb206f -> 3e4dccfe6fb4, NSXv add dns search domain to subnets", 
        "INFO  [alembic.runtime.migration] Running upgrade 3e4dccfe6fb4 -> 967462f585e1, add dvs_id column to neutron_nsx_network_mappings", 
        "INFO  [alembic.runtime.migration] Running upgrade 967462f585e1 -> b7f41687cbad, nsxv3_qos_policy_mapping", 
        "INFO  [alembic.runtime.migration] Running upgrade b7f41687cbad -> c288bb6a7252, NSXv add resource pool to the router bindings table", 
        "INFO  [alembic.runtime.migration] Running upgrade c288bb6a7252 -> c644ec62c585, NSXv3 add nsx_service_bindings and nsx_dhcp_bindings tables", 
        "INFO  [alembic.runtime.migration] Running upgrade c644ec62c585 -> 5e564e781d77, add nsx binding type", 
        "INFO  [alembic.runtime.migration] Running upgrade 5e564e781d77 -> aede17d51d0f, add timestamp", 
        "INFO  [alembic.runtime.migration] Running upgrade aede17d51d0f -> 7e46906f8997, lbaas foreignkeys", 
        "INFO  [alembic.runtime.migration] Running upgrade 7e46906f8997 -> 86a55205337c, NSXv add availability zone to the router bindings table instead of", 
        "the resource pool column", 
        "INFO  [alembic.runtime.migration] Running upgrade 86a55205337c -> 633514d94b93, Add support for TaaS", 
        "INFO  [alembic.runtime.migration] Running upgrade 633514d94b93 -> 1b4eaffe4f31, NSX Adds a 'provider' attribute to security-group", 
        "INFO  [alembic.runtime.migration] Running upgrade 1b4eaffe4f31 -> 6e6da8296c0e, Add support for IPAM in NSXv", 
        "INFO  [alembic.runtime.migration] Running upgrade kilo -> 393bf843b96, Initial Liberty no-op contract script.", 
        "INFO  [alembic.runtime.migration] Running upgrade 393bf843b96 -> 3c88bdea3054, nsxv_vdr_dhcp_binding.py", 
        "INFO  [alembic.runtime.migration] Running upgrade 3c88bdea3054 -> 5ed1ffbc0d2a, nsxv_security_group_logging", 
        "INFO  [alembic.runtime.migration] Running upgrade 5ed1ffbc0d2a -> 081af0e396d7, nsxv3_secgroup_local_ip_prefix", 
        "INFO  [alembic.runtime.migration] Running upgrade 081af0e396d7 -> dbe29d208ac6, NSXv add DHCP MTU to subnets", 
        "INFO  [alembic.runtime.migration] Running upgrade dbe29d208ac6 -> d49ac91b560e, Support shared pools with NSXv LBaaSv2 driver", 
        "INFO  [alembic.runtime.migration] Running upgrade d49ac91b560e -> 5c8f451290b7, nsxv_subnet_ipam rename to nsx_subnet_ipam", 
        "INFO  [alembic.runtime.migration] Running upgrade 5c8f451290b7 -> 14a89ddf96e2, NSX Adds a 'availability_zone' attribute to internal-networks table", 
        "INFO  [alembic.runtime.migration] Running upgrade 14a89ddf96e2 -> 8c0a81a07691, Update the primary key constraint of nsx_subnet_ipam", 
        "INFO  [alembic.runtime.migration] Running upgrade 8c0a81a07691 -> 84ceffa27115, remove the foreign key constrain from nsxv3_qos_policy_mapping", 
        "INFO  [alembic.runtime.migration] Running upgrade 84ceffa27115 -> a1be06050b41, update nsx binding types", 
        "INFO  [alembic.runtime.migration] Running upgrade a1be06050b41 -> 717f7f63a219, nsxv3_lbaas_l7policy", 
        "INFO  [alembic.runtime.migration] Running upgrade 6e6da8296c0e -> 7b5ec3caa9a4, Fix the availability zones default value in the router bindings table", 
        "INFO  [alembic.runtime.migration] Running upgrade 7b5ec3caa9a4 -> e816d4fe9d4f, NSX Adds a 'policy' attribute to security-group", 
        "INFO  [alembic.runtime.migration] Running upgrade e816d4fe9d4f -> dd9fe5a3a526, NSX Adds certificate table for client certificate management", 
        "INFO  [alembic.runtime.migration] Running upgrade dd9fe5a3a526 -> 01a33f93f5fd, nsxv_lbv2_l7policy", 
        "INFO  [alembic.runtime.migration] Running upgrade 01a33f93f5fd -> e4c503f4133f, Port vnic_type support", 
        "INFO  [alembic.runtime.migration] Running upgrade e4c503f4133f -> 7c4704ad37df, Fix NSX Lbaas L7 policy table creation", 
        "INFO  [alembic.runtime.migration] Running upgrade 7c4704ad37df -> 8699700cd95c, nsxv_bgp_speaker_mapping", 
        "INFO  [alembic.runtime.migration] Running upgrade 8699700cd95c -> 53eb497903a4, Drop VDR DHCP bindings table", 
        "INFO  [alembic.runtime.migration] Running upgrade 53eb497903a4 -> ea7a72ab9643", 
        "INFO  [alembic.runtime.migration] Running upgrade ea7a72ab9643 -> 9799427fc0e1, nsx map project to plugin", 
        "INFO  [alembic.runtime.migration] Running upgrade 9799427fc0e1 -> 0dbeda408e41, nsxv3_vpn_mapping", 
        "INFO  [alembic.runtime.migration] Running upgrade 0dbeda408e41 -> fc6308289aca, lbaas_no_foreign_key", 
        "INFO  [alembic.runtime.migration] Running upgrade fc6308289aca -> 99bfcb6003c6, lbaas_error_no_member", 
        "stdout: d60380b4807d81685ec57d2daa0aac170470618495a2123238bc971561ee0ac1", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_horizon.service to /etc/systemd/system/tripleo_horizon.service.", 
        "stdout: 85c4439ab29d98304fac38cc3e2b3d138dbaaca6c5ef08f26a0866e80834f683", 
        "stdout: (cellv2) Creating default cell_v2 cell", 
        "stdout: 0fa342f71199bbf458f458c0383d488b32d689f56a97db4dea6a7e17b96a621c", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_iscsid.service to /etc/systemd/system/tripleo_iscsid.service.", 
        "Created symlink from /etc/systemd/system/timers.target.wants/tripleo_iscsid_healthcheck.timer to /etc/systemd/system/tripleo_iscsid_healthcheck.timer.", 
        "Created symlink from /etc/systemd/system/tripleo_iscsid.service.requires/tripleo_iscsid_healthcheck.timer to /etc/systemd/system/tripleo_iscsid_healthcheck.timer.", 
        "stdout: baa4c48e93a4607a74cec7b5de3e76efee539517f4b6e568cc8ca5eb8ce330cb", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_keystone.service to /etc/systemd/system/tripleo_keystone.service.", 
        "Created symlink from /etc/systemd/system/timers.target.wants/tripleo_keystone_healthcheck.timer to /etc/systemd/system/tripleo_keystone_healthcheck.timer.", 
        "Created symlink from /etc/systemd/system/tripleo_keystone.service.requires/tripleo_keystone_healthcheck.timer to /etc/systemd/system/tripleo_keystone_healthcheck.timer.", 
        "stderr: /usr/lib/python2.7/site-packages/pymysql/cursors.py:170: Warning: (1831, u'Duplicate index `block_device_mapping_instance_uuid_virtual_name_device_name_idx`. This is deprecated and will be disallowed in a future release')", 
        "  result = self._query(query)", 
        "/usr/lib/python2.7/site-packages/pymysql/cursors.py:170: Warning: (1831, u'Duplicate index `uniq_instances0uuid`. This is deprecated and will be disallowed in a future release')", 
        "stdout: c34cca1fe8a6ee05adf938ef5baa6fa8eb2a5b3e607e372a2e63be68c85e6ec3", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_keystone_cron.service to /etc/systemd/system/tripleo_keystone_cron.service.", 
        "Created symlink from /etc/systemd/system/timers.target.wants/tripleo_keystone_cron_healthcheck.timer to /etc/systemd/system/tripleo_keystone_cron_healthcheck.timer.", 
        "Created symlink from /etc/systemd/system/tripleo_keystone_cron.service.requires/tripleo_keystone_cron_healthcheck.timer to /etc/systemd/system/tripleo_keystone_cron_healthcheck.timer."
    ]
}
2019-06-05 14:16:47,601 p=17240 u=mistral |  ok: [lab-computehci-0] => {
    "failed_when_result": false, 
    "outputs.stdout_lines | default([]) | union(outputs.stderr_lines | default([]))": [
        "stdout: ca0598d5a1b1cc99b7f92f4aea9b1140cea6b5f20203823b7208595e70251316", 
        "", 
        "stderr: Trying to pull docker://docker.io/tripleostein/centos-binary-nova-libvirt:current-tripleo-rdo...Getting image source signatures", 
        "Copying blob sha256:a35613cff6f04cbfd2f3b845d5a923d56d6f2fb718f85784e8fdcd97ae77846e", 
        "Copying blob sha256:0f2be6d2e8e6e42cb3e633544d0b1aa8328bd7004a3a4b1dfc0c7a6ba14cd0c7", 
        "Copying blob sha256:8ba884070f611d31cb2c42eddb691319dc9facf5e0ec67672fcfa135181ab3df", 
        "Copying blob sha256:c0862342b9e7a81856422b95348a2d1952b46e01df6c72f74d94cac2c5815c51", 
        "Copying blob sha256:5b8f702199c16fd0d5c9c4d0028550b144acb532f4a6b8200b3f53e1cbc43aba", 
        "Copying blob sha256:31c8fa1ceee01b746a6b64c4718f5e42e867c08532b29f8d33626a8385327ede", 
        "Copying blob sha256:6310d6ac1536a2eb8e769d217451e2c6d420eb3c39b0fb1b9ad088a73ea67211", 
        "Copying blob sha256:c80c3921174be89bdd60d2454983524a19a15b09f26f47b6822e6440d5939973", 
        "Copying blob sha256:fc3b29499fda939e998b0c14c6e98720e1cb7a66fd1ce884cad8d64a63669cf4", 
        "Copying blob sha256:2799d99efade4475ca55aad34887eabf4e9ec76e592bc0b0a80cbd8d01080ffc", 
        "Copying blob sha256:d6dbd69ea530292192935158b778ccffc396ead2093138f75c6e1fa33b7a17fa", 
        "Copying blob sha256:5b89a36d5e9e14c5ac5981e8ed2304bb8ce19da7d91793f44c48ac17e7b03717", 
        "Copying blob sha256:d36b87fd0812d0e39ef92e729105260f496efbfb19ad7b6981218862502aa0f3", 
        "Copying blob sha256:98d5e2479617c862dcad487a2c52021bc16e516ebafe9fdab6b3eb8648b73f57", 
        "Copying blob sha256:bd6e2c36ff0e45e35121c3bc2cb54f803eb809aacb2778260d4211de2ba9fabb", 
        "Copying blob sha256:921488feccf56d8c8eb6086cd998b48f907fa44dbc5e7cf8525efd96f7c1f776", 
        "Copying blob sha256:0fc1fd86055457f85a0cb3f333292570aaa2803c4b556966847f55f8f3544fa8", 
        "Copying blob sha256:2cc44a4e32219b5aad308d7d3bdc5ba18788e8830c0cf3aa9056e1d0dc647058", 
        "Copying blob sha256:ccae8e3351ac86f5c7d66e9c84321057c9f05063428851fa0f1c17946090212d", 
        "Copying blob sha256:89c8d96f0d37376ba1f54c92128660aaea0a802cb9d9d396a45366b02fc589cc", 
        "Copying blob sha256:45d804df81db3a3f58373c31a92eb2484c2b9038ec59d86fed68b6ce62565939", 
        "Copying blob sha256:46d3c6aa676de9a0ee74cfac77cced69fb7a4df7c5b9e8a7ef33922881d87c81", 
        "Copying blob sha256:fe4a57b69254f1ea281cfe85c93a25adb5e1ea981da8a42aa8aa85183c171c6c", 
        "Copying blob sha256:4fc630ada1f7b1efc1ab3023e9be4083bc04c11d25e0ed5a11bbee99f34cfe8e", 
        "Copying blob sha256:57c9a5b644b0ea031c43d8a67b4bdf21aa29ed3b1a5c16f4ad1abb1671220fd8", 
        "Copying blob sha256:ba14efeb73c8c9882178c925f727ce332fd809265e356539edb6004c204ac64a", 
        "Copying blob sha256:ca8fc29a92a889e8ec718e289600ee719c581af50e8718cac54477ce5cc41ab8", 
        "Copying config sha256:ca0598d5a1b1cc99b7f92f4aea9b1140cea6b5f20203823b7208595e70251316", 
        "Writing manifest to image destination", 
        "Storing signatures", 
        "stdout: INFO:nova_statedir:Applying nova statedir ownership", 
        "INFO:nova_statedir:Target ownership for /var/lib/nova: 42436:42436", 
        "INFO:nova_statedir:Checking uid: 0 gid: 0 path: /var/lib/nova/", 
        "INFO:nova_statedir:Changing ownership of /var/lib/nova from 0:0 to 42436:42436", 
        "INFO:nova_statedir:Checking uid: 0 gid: 0 path: /var/lib/nova/instances/", 
        "INFO:nova_statedir:Changing ownership of /var/lib/nova/instances from 0:0 to 42436:42436", 
        "INFO:nova_statedir:Nova statedir ownership complete", 
        "stderr: + command -v python3", 
        "+ command -v python2", 
        "+ python2 /container-config-scripts/nova_statedir_ownership.py", 
        "stdout: 112ae894036b5e2a38dcda3aab8fdfa1324e3ce4cb4f813ab20c1a2ca7ea5048", 
        "stderr: WARNING: The same type, major and minor should not be used for multiple devices.", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_nova_virtlogd.service to /etc/systemd/system/tripleo_nova_virtlogd.service.", 
        "stdout: 555adcbdb5c1c8893faafd9ab29eb8d0fcc9e660022d5e069d875cf95942b802", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_nova_libvirt.service to /etc/systemd/system/tripleo_nova_libvirt.service.", 
        "Created symlink from /etc/systemd/system/timers.target.wants/tripleo_nova_libvirt_healthcheck.timer to /etc/systemd/system/tripleo_nova_libvirt_healthcheck.timer.", 
        "Created symlink from /etc/systemd/system/tripleo_nova_libvirt.service.requires/tripleo_nova_libvirt_healthcheck.timer to /etc/systemd/system/tripleo_nova_libvirt_healthcheck.timer.", 
        "stdout: 2a6c58bb7002fa41d9f299042f616484c38ae35a8ef09447eea1256689fbe477", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_iscsid.service to /etc/systemd/system/tripleo_iscsid.service.", 
        "Created symlink from /etc/systemd/system/timers.target.wants/tripleo_iscsid_healthcheck.timer to /etc/systemd/system/tripleo_iscsid_healthcheck.timer.", 
        "Created symlink from /etc/systemd/system/tripleo_iscsid.service.requires/tripleo_iscsid_healthcheck.timer to /etc/systemd/system/tripleo_iscsid_healthcheck.timer."
    ]
}
2019-06-05 14:16:47,626 p=17240 u=mistral |  TASK [Clean container_puppet_tasks for lab-controller-0 step 3] ****************
2019-06-05 14:16:47,626 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:520
2019-06-05 14:16:47,627 p=17240 u=mistral |  Wednesday 05 June 2019  14:16:47 -0500 (0:00:00.133)       0:13:21.396 ******** 
2019-06-05 14:16:47,794 p=17240 u=mistral |  ok: [lab-controller-0] => {"changed": false, "path": "/var/lib/container-puppet/container-puppet-tasks3.json", "state": "absent"}
2019-06-05 14:16:47,809 p=17240 u=mistral |  ok: [lab-computehci-0] => {"changed": false, "path": "/var/lib/container-puppet/container-puppet-tasks3.json", "state": "absent"}
2019-06-05 14:16:47,837 p=17240 u=mistral |  TASK [Calculate container_puppet_tasks for lab-controller-0 step 3] ************
2019-06-05 14:16:47,837 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:527
2019-06-05 14:16:47,837 p=17240 u=mistral |  Wednesday 05 June 2019  14:16:47 -0500 (0:00:00.210)       0:13:21.606 ******** 
2019-06-05 14:16:47,880 p=17240 u=mistral |  ok: [lab-controller-0] => (item={'puppet_tags': u'keystone_config,keystone_domain_config,keystone_endpoint,keystone_identity_provider,keystone_paste_ini,keystone_role,keystone_service,keystone_tenant,keystone_user,keystone_user_role,keystone_domain', 'config_volume': u'keystone_init_tasks', 'step_config': u'include ::tripleo::profile::base::keystone', 'config_image': u'docker.io/tripleostein/centos-binary-keystone:current-tripleo-rdo', 'service_name': u'keystone'}) => {"ansible_facts": {"host_container_puppet_tasks": [{"config_image": "docker.io/tripleostein/centos-binary-mariadb:current-tripleo-rdo", "config_volume": "mysql_init_tasks", "puppet_tags": "mysql_database,mysql_grant,mysql_user", "service_name": "mysql", "step_config": "include ::tripleo::profile::base::database::mysql", "volumes": ["/var/lib/mysql:/var/lib/mysql/:rw", "/var/log/containers/mysql:/var/log/mariadb", "/var/lib/config-data/puppet-generated/mysql/root:/root:rw"]}, {"config_image": "docker.io/tripleostein/centos-binary-rabbitmq:current-tripleo-rdo", "config_volume": "rabbit_init_tasks", "puppet_tags": "rabbitmq_policy,rabbitmq_user", "service_name": "oslo_messaging_rpc", "step_config": "include ::tripleo::profile::base::rabbitmq", "volumes": ["/var/lib/config-data/rabbitmq/etc/rabbitmq/:/etc/rabbitmq/:ro", "/var/lib/rabbitmq:/var/lib/rabbitmq:z"]}, {"config_image": "docker.io/tripleostein/centos-binary-keystone:current-tripleo-rdo", "config_volume": "keystone_init_tasks", "puppet_tags": "keystone_config,keystone_domain_config,keystone_endpoint,keystone_identity_provider,keystone_paste_ini,keystone_role,keystone_service,keystone_tenant,keystone_user,keystone_user_role,keystone_domain", "service_name": "keystone", "step_config": "include ::tripleo::profile::base::keystone"}]}, "changed": false, "item": {"config_image": "docker.io/tripleostein/centos-binary-keystone:current-tripleo-rdo", "config_volume": "keystone_init_tasks", "puppet_tags": "keystone_config,keystone_domain_config,keystone_endpoint,keystone_identity_provider,keystone_paste_ini,keystone_role,keystone_service,keystone_tenant,keystone_user,keystone_user_role,keystone_domain", "service_name": "keystone", "step_config": "include ::tripleo::profile::base::keystone"}}
2019-06-05 14:16:47,911 p=17240 u=mistral |  TASK [Write container-puppet-tasks json file for lab-controller-0 step 3] ******
2019-06-05 14:16:47,911 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:537
2019-06-05 14:16:47,912 p=17240 u=mistral |  Wednesday 05 June 2019  14:16:47 -0500 (0:00:00.074)       0:13:21.681 ******** 
2019-06-05 14:16:47,958 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:16:48,269 p=17240 u=mistral |  changed: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:16:48,294 p=17240 u=mistral |  TASK [Run container-puppet tasks (bootstrap tasks) for step 3] *****************
2019-06-05 14:16:48,294 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:548
2019-06-05 14:16:48,295 p=17240 u=mistral |  Wednesday 05 June 2019  14:16:48 -0500 (0:00:00.382)       0:13:22.064 ******** 
2019-06-05 14:16:48,341 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:39,266 p=17240 u=mistral |  ok: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:39,291 p=17240 u=mistral |  TASK [Debug output for task: Run container-puppet tasks (bootstrap tasks) for step 3] ***
2019-06-05 14:18:39,291 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:567
2019-06-05 14:18:39,291 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:39 -0500 (0:01:50.996)       0:15:13.060 ******** 
2019-06-05 14:18:39,321 p=17240 u=mistral |  ok: [lab-controller-0] => {
    "failed_when_result": false, 
    "outputs.stdout_lines | default([]) | union(outputs.stderr_lines | default([]))": [
        "2019-06-05 19:16:48,574 INFO: 56984 -- Running container-puppet", 
        "2019-06-05 19:16:48,574 INFO: 56984 -- Service compilation completed.", 
        "2019-06-05 19:16:48,575 INFO: 56984 -- Starting multiprocess configuration steps.  Using 4 processes.", 
        "2019-06-05 19:16:48,581 INFO: 56987 -- Starting configuration of mysql_init_tasks using image docker.io/tripleostein/centos-binary-mariadb:current-tripleo-rdo", 
        "2019-06-05 19:16:48,581 INFO: 56990 -- Starting configuration of rabbit_init_tasks using image docker.io/tripleostein/centos-binary-rabbitmq:current-tripleo-rdo", 
        "2019-06-05 19:16:48,584 INFO: 56988 -- Starting configuration of keystone_init_tasks using image docker.io/tripleostein/centos-binary-keystone:current-tripleo-rdo", 
        "2019-06-05 19:16:48,830 INFO: 56988 -- Removing container: container-puppet-keystone_init_tasks", 
        "2019-06-05 19:16:48,970 INFO: 56987 -- Removing container: container-puppet-mysql_init_tasks", 
        "2019-06-05 19:16:48,972 INFO: 56990 -- Removing container: container-puppet-rabbit_init_tasks", 
        "2019-06-05 19:16:49,226 INFO: 56988 -- Image already exists: docker.io/tripleostein/centos-binary-keystone:current-tripleo-rdo", 
        "2019-06-05 19:16:49,448 INFO: 56990 -- Image already exists: docker.io/tripleostein/centos-binary-rabbitmq:current-tripleo-rdo", 
        "2019-06-05 19:16:49,493 INFO: 56987 -- Image already exists: docker.io/tripleostein/centos-binary-mariadb:current-tripleo-rdo", 
        "2019-06-05 19:16:59,385 WARNING: 56987 -- + mkdir -p /etc/puppet", 
        "+ cp -dR /tmp/puppet-etc/auth.conf /tmp/puppet-etc/hiera.yaml /tmp/puppet-etc/hieradata /tmp/puppet-etc/modules /tmp/puppet-etc/puppet.conf /tmp/puppet-etc/ssl /etc/puppet", 
        "+ rm -Rf /etc/puppet/ssl", 
        "+ echo '{\"step\": 3}'", 
        "+ TAGS=", 
        "+ '[' -n file,file_line,concat,augeas,cron,mysql_database,mysql_grant,mysql_user ']'", 
        "+ TAGS='--tags file,file_line,concat,augeas,cron,mysql_database,mysql_grant,mysql_user'", 
        "+ CHECK_MODE=", 
        "+ '[' -d /tmp/puppet-check-mode ']'", 
        "+ origin_of_time=/var/lib/config-data/mysql_init_tasks.origin_of_time", 
        "+ touch /var/lib/config-data/mysql_init_tasks.origin_of_time", 
        "+ sync", 
        "+ export NET_HOST=true", 
        "+ NET_HOST=true", 
        "+ set +e", 
        "+ '[' true == false ']'", 
        "+ export FACTER_deployment_type=containers", 
        "+ FACTER_deployment_type=containers", 
        "++ cat /sys/class/dmi/id/product_uuid", 
        "++ tr '[:upper:]' '[:lower:]'", 
        "+ export FACTER_uuid=ad8c85d9-6f5f-4d90-97fa-e31eefd815d6", 
        "+ FACTER_uuid=ad8c85d9-6f5f-4d90-97fa-e31eefd815d6", 
        "+ /usr/bin/puppet apply --summarize --detailed-exitcodes --color=false --logdest syslog --logdest console --modulepath=/etc/puppet/modules:/usr/share/openstack-puppet/modules --tags file,file_line,concat,augeas,cron,mysql_database,mysql_grant,mysql_user /etc/config.pp", 
        "+ rc=2", 
        "+ set -e", 
        "+ '[' 2 -ne 2 -a 2 -ne 0 ']'", 
        "+ '[' -z true ']'", 
        "", 
        "2019-06-05 19:16:59,386 INFO: 56987 -- Removing container: container-puppet-mysql_init_tasks", 
        "2019-06-05 19:16:59,561 INFO: 56987 -- Finished processing puppet configs for mysql_init_tasks", 
        "2019-06-05 19:16:59,825 WARNING: 56990 -- + mkdir -p /etc/puppet", 
        "+ '[' -n file,file_line,concat,augeas,cron,rabbitmq_policy,rabbitmq_user ']'", 
        "+ TAGS='--tags file,file_line,concat,augeas,cron,rabbitmq_policy,rabbitmq_user'", 
        "+ origin_of_time=/var/lib/config-data/rabbit_init_tasks.origin_of_time", 
        "+ touch /var/lib/config-data/rabbit_init_tasks.origin_of_time", 
        "+ /usr/bin/puppet apply --summarize --detailed-exitcodes --color=false --logdest syslog --logdest console --modulepath=/etc/puppet/modules:/usr/share/openstack-puppet/modules --tags file,file_line,concat,augeas,cron,rabbitmq_policy,rabbitmq_user /etc/config.pp", 
        "2019-06-05 19:16:59,826 INFO: 56990 -- Removing container: container-puppet-rabbit_init_tasks", 
        "2019-06-05 19:16:59,978 INFO: 56990 -- Finished processing puppet configs for rabbit_init_tasks", 
        "2019-06-05 19:18:39,039 WARNING: 56988 -- + mkdir -p /etc/puppet", 
        "+ '[' -n file,file_line,concat,augeas,cron,keystone_config,keystone_domain_config,keystone_endpoint,keystone_identity_provider,keystone_paste_ini,keystone_role,keystone_service,keystone_tenant,keystone_user,keystone_user_role,keystone_domain ']'", 
        "+ TAGS='--tags file,file_line,concat,augeas,cron,keystone_config,keystone_domain_config,keystone_endpoint,keystone_identity_provider,keystone_paste_ini,keystone_role,keystone_service,keystone_tenant,keystone_user,keystone_user_role,keystone_domain'", 
        "+ origin_of_time=/var/lib/config-data/keystone_init_tasks.origin_of_time", 
        "+ touch /var/lib/config-data/keystone_init_tasks.origin_of_time", 
        "+ /usr/bin/puppet apply --summarize --detailed-exitcodes --color=false --logdest syslog --logdest console --modulepath=/etc/puppet/modules:/usr/share/openstack-puppet/modules --tags file,file_line,concat,augeas,cron,keystone_config,keystone_domain_config,keystone_endpoint,keystone_identity_provider,keystone_paste_ini,keystone_role,keystone_service,keystone_tenant,keystone_user,keystone_user_role,keystone_domain /etc/config.pp", 
        "2019-06-05 19:18:39,039 INFO: 56988 -- Removing container: container-puppet-keystone_init_tasks", 
        "2019-06-05 19:18:39,173 INFO: 56988 -- Finished processing puppet configs for keystone_init_tasks"
    ]
}
2019-06-05 14:18:39,333 p=17240 u=mistral |  skipping: [lab-computehci-0] => {}
2019-06-05 14:18:39,334 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:18:39,334 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:18:39,340 p=17240 u=mistral |  PLAY [External deployment step 4] **********************************************
2019-06-05 14:18:39,345 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:18:39,359 p=17240 u=mistral |  TASK [set blacklisted_hostnames] ***********************************************
2019-06-05 14:18:39,360 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:2
2019-06-05 14:18:39,360 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:39 -0500 (0:00:00.068)       0:15:13.129 ******** 
2019-06-05 14:18:39,374 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:39,391 p=17240 u=mistral |  TASK [create ceph-ansible temp dirs] *******************************************
2019-06-05 14:18:39,391 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:5
2019-06-05 14:18:39,391 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:39 -0500 (0:00:00.031)       0:15:13.160 ******** 
2019-06-05 14:18:39,413 p=17240 u=mistral |  skipping: [undercloud] => (item=/var/lib/mistral/lab/ceph-ansible)  => {"changed": false, "item": "/var/lib/mistral/lab/ceph-ansible", "skip_reason": "Conditional result was False"}
2019-06-05 14:18:39,413 p=17240 u=mistral |  skipping: [undercloud] => (item=/var/lib/mistral/lab/ceph-ansible/group_vars)  => {"changed": false, "item": "/var/lib/mistral/lab/ceph-ansible/group_vars", "skip_reason": "Conditional result was False"}
2019-06-05 14:18:39,416 p=17240 u=mistral |  skipping: [undercloud] => (item=/var/lib/mistral/lab/ceph-ansible/host_vars)  => {"changed": false, "item": "/var/lib/mistral/lab/ceph-ansible/host_vars", "skip_reason": "Conditional result was False"}
2019-06-05 14:18:39,422 p=17240 u=mistral |  skipping: [undercloud] => (item=/var/lib/mistral/lab/ceph-ansible/fetch_dir)  => {"changed": false, "item": "/var/lib/mistral/lab/ceph-ansible/fetch_dir", "skip_reason": "Conditional result was False"}
2019-06-05 14:18:39,437 p=17240 u=mistral |  TASK [generate inventory] ******************************************************
2019-06-05 14:18:39,437 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:16
2019-06-05 14:18:39,437 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:39 -0500 (0:00:00.046)       0:15:13.206 ******** 
2019-06-05 14:18:39,449 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:39,464 p=17240 u=mistral |  TASK [set ceph-ansible group vars all] *****************************************
2019-06-05 14:18:39,464 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:30
2019-06-05 14:18:39,464 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:39 -0500 (0:00:00.027)       0:15:13.234 ******** 
2019-06-05 14:18:39,477 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:39,492 p=17240 u=mistral |  TASK [generate ceph-ansible group vars all] ************************************
2019-06-05 14:18:39,492 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:139
2019-06-05 14:18:39,492 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:39 -0500 (0:00:00.028)       0:15:13.262 ******** 
2019-06-05 14:18:39,504 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:39,519 p=17240 u=mistral |  TASK [set ceph-ansible extra vars] *********************************************
2019-06-05 14:18:39,519 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:143
2019-06-05 14:18:39,520 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:39 -0500 (0:00:00.027)       0:15:13.289 ******** 
2019-06-05 14:18:39,531 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:39,546 p=17240 u=mistral |  TASK [generate ceph-ansible extra vars] ****************************************
2019-06-05 14:18:39,546 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:150
2019-06-05 14:18:39,546 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:39 -0500 (0:00:00.026)       0:15:13.316 ******** 
2019-06-05 14:18:39,558 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:39,575 p=17240 u=mistral |  TASK [generate nodes-uuid data file] *******************************************
2019-06-05 14:18:39,576 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:154
2019-06-05 14:18:39,576 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:39 -0500 (0:00:00.029)       0:15:13.345 ******** 
2019-06-05 14:18:39,589 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:39,605 p=17240 u=mistral |  TASK [generate nodes-uuid playbook] ********************************************
2019-06-05 14:18:39,605 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:158
2019-06-05 14:18:39,605 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:39 -0500 (0:00:00.029)       0:15:13.375 ******** 
2019-06-05 14:18:39,622 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:39,637 p=17240 u=mistral |  TASK [detect private key file] *************************************************
2019-06-05 14:18:39,637 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:179
2019-06-05 14:18:39,637 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:39 -0500 (0:00:00.031)       0:15:13.406 ******** 
2019-06-05 14:18:39,648 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:39,663 p=17240 u=mistral |  TASK [set private key file] ****************************************************
2019-06-05 14:18:39,663 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:183
2019-06-05 14:18:39,663 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:39 -0500 (0:00:00.026)       0:15:13.433 ******** 
2019-06-05 14:18:39,674 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:39,689 p=17240 u=mistral |  TASK [run nodes-uuid] **********************************************************
2019-06-05 14:18:39,689 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:187
2019-06-05 14:18:39,689 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:39 -0500 (0:00:00.025)       0:15:13.458 ******** 
2019-06-05 14:18:39,701 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:39,715 p=17240 u=mistral |  TASK [set ceph-ansible params from Heat] ***************************************
2019-06-05 14:18:39,715 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:195
2019-06-05 14:18:39,715 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:39 -0500 (0:00:00.025)       0:15:13.484 ******** 
2019-06-05 14:18:39,726 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:39,741 p=17240 u=mistral |  TASK [set ceph-ansible playbooks] **********************************************
2019-06-05 14:18:39,741 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:200
2019-06-05 14:18:39,741 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:39 -0500 (0:00:00.026)       0:15:13.510 ******** 
2019-06-05 14:18:39,754 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:39,769 p=17240 u=mistral |  TASK [was path for local ceph-ansible fetch directory backups set?] ************
2019-06-05 14:18:39,769 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:205
2019-06-05 14:18:39,769 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:39 -0500 (0:00:00.028)       0:15:13.538 ******** 
2019-06-05 14:18:39,783 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:39,797 p=17240 u=mistral |  TASK [look for requested ceph-ansible fetch directory for local backup] ********
2019-06-05 14:18:39,797 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:210
2019-06-05 14:18:39,797 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:39 -0500 (0:00:00.027)       0:15:13.566 ******** 
2019-06-05 14:18:39,808 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:39,824 p=17240 u=mistral |  TASK [autocreate new directory for ceph-ansible fetch directory backup] ********
2019-06-05 14:18:39,824 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:214
2019-06-05 14:18:39,824 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:39 -0500 (0:00:00.026)       0:15:13.593 ******** 
2019-06-05 14:18:39,836 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:39,851 p=17240 u=mistral |  TASK [look for tarball of ceph-ansible fetch directory in local backup] ********
2019-06-05 14:18:39,851 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:222
2019-06-05 14:18:39,851 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:39 -0500 (0:00:00.027)       0:15:13.620 ******** 
2019-06-05 14:18:39,862 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:39,877 p=17240 u=mistral |  TASK [untar local backup of ceph-ansible fetch directory] **********************
2019-06-05 14:18:39,877 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:226
2019-06-05 14:18:39,877 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:39 -0500 (0:00:00.025)       0:15:13.646 ******** 
2019-06-05 14:18:39,888 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:39,903 p=17240 u=mistral |  TASK [set facts for swift back up of ceph-ansible fetch directory] *************
2019-06-05 14:18:39,903 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:232
2019-06-05 14:18:39,903 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:39 -0500 (0:00:00.026)       0:15:13.672 ******** 
2019-06-05 14:18:39,914 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:39,929 p=17240 u=mistral |  TASK [attempt download of fetch directory tarball from swift backup] ***********
2019-06-05 14:18:39,929 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:238
2019-06-05 14:18:39,929 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:39 -0500 (0:00:00.026)       0:15:13.699 ******** 
2019-06-05 14:18:39,940 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:39,954 p=17240 u=mistral |  TASK [ensure we create a new fetch_directory or use the old fetch_directory] ***
2019-06-05 14:18:39,954 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:243
2019-06-05 14:18:39,954 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:39 -0500 (0:00:00.025)       0:15:13.724 ******** 
2019-06-05 14:18:39,966 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:39,980 p=17240 u=mistral |  TASK [unpack downloaded ceph-ansible fetch tarball to fetch directory] *********
2019-06-05 14:18:39,981 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:251
2019-06-05 14:18:39,981 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:39 -0500 (0:00:00.026)       0:15:13.750 ******** 
2019-06-05 14:18:39,991 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:40,006 p=17240 u=mistral |  TASK [remove downloaded ceph-ansible fetch directory tarball from filesystem] ***
2019-06-05 14:18:40,006 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:257
2019-06-05 14:18:40,006 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:40 -0500 (0:00:00.025)       0:15:13.776 ******** 
2019-06-05 14:18:40,017 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:40,031 p=17240 u=mistral |  TASK [set ceph-ansible command] ************************************************
2019-06-05 14:18:40,031 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:265
2019-06-05 14:18:40,032 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:40 -0500 (0:00:00.025)       0:15:13.801 ******** 
2019-06-05 14:18:40,043 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:40,059 p=17240 u=mistral |  TASK [run ceph-ansible (immediate log at /var/lib/mistral/lab/ceph-ansible/ceph_ansible_command.log)] ***
2019-06-05 14:18:40,059 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:277
2019-06-05 14:18:40,059 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:40 -0500 (0:00:00.027)       0:15:13.828 ******** 
2019-06-05 14:18:40,070 p=17240 u=mistral |  skipping: [undercloud] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:40,085 p=17240 u=mistral |  TASK [print ceph-ansible output in case of failure] ****************************
2019-06-05 14:18:40,085 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:293
2019-06-05 14:18:40,085 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:40 -0500 (0:00:00.026)       0:15:13.854 ******** 
2019-06-05 14:18:40,096 p=17240 u=mistral |  skipping: [undercloud] => {}
2019-06-05 14:18:40,111 p=17240 u=mistral |  TASK [register contents of fetch_directory after ceph-ansible run] *************
2019-06-05 14:18:40,111 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:300
2019-06-05 14:18:40,111 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:40 -0500 (0:00:00.026)       0:15:13.880 ******** 
2019-06-05 14:18:40,121 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:40,139 p=17240 u=mistral |  TASK [create ceph-ansible fetch directory tarball in local backup] *************
2019-06-05 14:18:40,139 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:305
2019-06-05 14:18:40,139 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:40 -0500 (0:00:00.027)       0:15:13.908 ******** 
2019-06-05 14:18:40,151 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:40,166 p=17240 u=mistral |  TASK [create temporary ceph-ansible fetch directory tarball for swift backup] ***
2019-06-05 14:18:40,166 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:315
2019-06-05 14:18:40,166 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:40 -0500 (0:00:00.027)       0:15:13.935 ******** 
2019-06-05 14:18:40,178 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:40,193 p=17240 u=mistral |  TASK [backup temporary ceph-ansible fetch directory tarball in swift] **********
2019-06-05 14:18:40,193 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:321
2019-06-05 14:18:40,193 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:40 -0500 (0:00:00.026)       0:15:13.962 ******** 
2019-06-05 14:18:40,208 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:40,225 p=17240 u=mistral |  TASK [ensure we were able to backup temporary fetch directory to swift] ********
2019-06-05 14:18:40,225 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:325
2019-06-05 14:18:40,225 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:40 -0500 (0:00:00.032)       0:15:13.994 ******** 
2019-06-05 14:18:40,236 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:40,251 p=17240 u=mistral |  TASK [clean temporary fetch directory after swift backup] **********************
2019-06-05 14:18:40,251 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:333
2019-06-05 14:18:40,251 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:40 -0500 (0:00:00.026)       0:15:14.021 ******** 
2019-06-05 14:18:40,262 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:40,277 p=17240 u=mistral |  TASK [Remove ceph-ansible fetch directory] *************************************
2019-06-05 14:18:40,277 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:342
2019-06-05 14:18:40,277 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:40 -0500 (0:00:00.026)       0:15:14.047 ******** 
2019-06-05 14:18:40,289 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:40,304 p=17240 u=mistral |  TASK [set ceph-ansible group vars mgrs] ****************************************
2019-06-05 14:18:40,304 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:351
2019-06-05 14:18:40,304 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:40 -0500 (0:00:00.026)       0:15:14.074 ******** 
2019-06-05 14:18:40,315 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:40,329 p=17240 u=mistral |  TASK [generate ceph-ansible group vars mgrs] ***********************************
2019-06-05 14:18:40,329 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:355
2019-06-05 14:18:40,330 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:40 -0500 (0:00:00.025)       0:15:14.099 ******** 
2019-06-05 14:18:40,342 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:40,356 p=17240 u=mistral |  TASK [set ceph-ansible group vars mons] ****************************************
2019-06-05 14:18:40,356 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:363
2019-06-05 14:18:40,356 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:40 -0500 (0:00:00.026)       0:15:14.126 ******** 
2019-06-05 14:18:40,368 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:40,383 p=17240 u=mistral |  TASK [generate ceph-ansible group vars mons] ***********************************
2019-06-05 14:18:40,383 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:368
2019-06-05 14:18:40,384 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:40 -0500 (0:00:00.027)       0:15:14.153 ******** 
2019-06-05 14:18:40,395 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:40,409 p=17240 u=mistral |  TASK [set_fact] ****************************************************************
2019-06-05 14:18:40,409 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:376
2019-06-05 14:18:40,410 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:40 -0500 (0:00:00.026)       0:15:14.179 ******** 
2019-06-05 14:18:40,421 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:40,435 p=17240 u=mistral |  TASK [Create temp file for prepare parameter] **********************************
2019-06-05 14:18:40,435 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:379
2019-06-05 14:18:40,435 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:40 -0500 (0:00:00.025)       0:15:14.204 ******** 
2019-06-05 14:18:40,446 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:40,461 p=17240 u=mistral |  TASK [Create temp file for role data] ******************************************
2019-06-05 14:18:40,461 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:385
2019-06-05 14:18:40,462 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:40 -0500 (0:00:00.026)       0:15:14.231 ******** 
2019-06-05 14:18:40,473 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:40,488 p=17240 u=mistral |  TASK [Write ContainerImagePrepare parameter file] ******************************
2019-06-05 14:18:40,488 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:391
2019-06-05 14:18:40,488 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:40 -0500 (0:00:00.026)       0:15:14.257 ******** 
2019-06-05 14:18:40,501 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:40,516 p=17240 u=mistral |  TASK [Write role data file] ****************************************************
2019-06-05 14:18:40,516 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:659
2019-06-05 14:18:40,516 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:40 -0500 (0:00:00.027)       0:15:14.285 ******** 
2019-06-05 14:18:40,529 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:40,544 p=17240 u=mistral |  TASK [Run tripleo-container-image-prepare logged to /var/log/tripleo-container-image-prepare.log] ***
2019-06-05 14:18:40,544 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:905
2019-06-05 14:18:40,544 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:40 -0500 (0:00:00.028)       0:15:14.314 ******** 
2019-06-05 14:18:40,556 p=17240 u=mistral |  skipping: [undercloud] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:40,570 p=17240 u=mistral |  TASK [Delete param file] *******************************************************
2019-06-05 14:18:40,570 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:911
2019-06-05 14:18:40,570 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:40 -0500 (0:00:00.026)       0:15:14.340 ******** 
2019-06-05 14:18:40,582 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:40,597 p=17240 u=mistral |  TASK [Delete role file] ********************************************************
2019-06-05 14:18:40,597 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:916
2019-06-05 14:18:40,597 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:40 -0500 (0:00:00.026)       0:15:14.366 ******** 
2019-06-05 14:18:40,608 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:40,623 p=17240 u=mistral |  TASK [set ceph-ansible group vars clients] *************************************
2019-06-05 14:18:40,623 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:925
2019-06-05 14:18:40,623 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:40 -0500 (0:00:00.026)       0:15:14.393 ******** 
2019-06-05 14:18:40,638 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:40,653 p=17240 u=mistral |  TASK [generate ceph-ansible group vars clients] ********************************
2019-06-05 14:18:40,654 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:928
2019-06-05 14:18:40,654 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:40 -0500 (0:00:00.030)       0:15:14.423 ******** 
2019-06-05 14:18:40,670 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:40,684 p=17240 u=mistral |  TASK [set ceph-ansible group vars osds] ****************************************
2019-06-05 14:18:40,684 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:936
2019-06-05 14:18:40,684 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:40 -0500 (0:00:00.030)       0:15:14.453 ******** 
2019-06-05 14:18:40,696 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:40,711 p=17240 u=mistral |  TASK [generate ceph-ansible group vars osds] ***********************************
2019-06-05 14:18:40,711 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:943
2019-06-05 14:18:40,711 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:40 -0500 (0:00:00.026)       0:15:14.480 ******** 
2019-06-05 14:18:40,723 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:40,723 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:18:40,723 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:18:40,727 p=17240 u=mistral |  PLAY [Overcloud deploy step tasks for 4] ***************************************
2019-06-05 14:18:40,729 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:18:40,752 p=17240 u=mistral |  TASK [Write the config_step hieradata for the deploy step 4 tasks] *************
2019-06-05 14:18:40,752 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deploy_steps_playbook.yaml:418
2019-06-05 14:18:40,752 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:40 -0500 (0:00:00.040)       0:15:14.521 ******** 
2019-06-05 14:18:41,078 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "checksum": "ee48fb03297eb703b1954c8852d0f67fab51dac1", "dest": "/etc/puppet/hieradata/config_step.json", "gid": 0, "group": "root", "md5sum": "e66511bcb9efc937174b88035d019e7b", "mode": "0600", "owner": "root", "secontext": "system_u:object_r:puppet_etc_t:s0", "size": 11, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559762320.76-156429329886059/source", "state": "file", "uid": 0}
2019-06-05 14:18:41,089 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "checksum": "ee48fb03297eb703b1954c8852d0f67fab51dac1", "dest": "/etc/puppet/hieradata/config_step.json", "gid": 0, "group": "root", "md5sum": "e66511bcb9efc937174b88035d019e7b", "mode": "0600", "owner": "root", "secontext": "system_u:object_r:puppet_etc_t:s0", "size": 11, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559762320.79-128999921978990/source", "state": "file", "uid": 0}
2019-06-05 14:18:41,113 p=17240 u=mistral |  TASK [Run puppet on the host to apply IPtables rules] **************************
2019-06-05 14:18:41,113 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/deploy_steps_tasks.yaml:2
2019-06-05 14:18:41,113 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:41 -0500 (0:00:00.361)       0:15:14.882 ******** 
2019-06-05 14:18:41,140 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:41,147 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:41,171 p=17240 u=mistral |  TASK [configure tmpwatch on the host] ******************************************
2019-06-05 14:18:41,171 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/deploy_steps_tasks.yaml:13
2019-06-05 14:18:41,171 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:41 -0500 (0:00:00.058)       0:15:14.940 ******** 
2019-06-05 14:18:41,198 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:41,205 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:41,229 p=17240 u=mistral |  TASK [create iptables service] *************************************************
2019-06-05 14:18:41,229 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/deploy_steps_tasks.yaml:27
2019-06-05 14:18:41,229 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:41 -0500 (0:00:00.057)       0:15:14.998 ******** 
2019-06-05 14:18:41,259 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:41,266 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:41,290 p=17240 u=mistral |  TASK [enable tripleo-iptables service] *****************************************
2019-06-05 14:18:41,290 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/deploy_steps_tasks.yaml:58
2019-06-05 14:18:41,290 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:41 -0500 (0:00:00.060)       0:15:15.059 ******** 
2019-06-05 14:18:41,316 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:41,325 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:41,348 p=17240 u=mistral |  TASK [create ip6tables service] ************************************************
2019-06-05 14:18:41,348 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/deploy_steps_tasks.yaml:62
2019-06-05 14:18:41,348 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:41 -0500 (0:00:00.058)       0:15:15.117 ******** 
2019-06-05 14:18:41,376 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:41,385 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:41,409 p=17240 u=mistral |  TASK [enable tripleo-ip6tables service] ****************************************
2019-06-05 14:18:41,409 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/deploy_steps_tasks.yaml:93
2019-06-05 14:18:41,409 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:41 -0500 (0:00:00.061)       0:15:15.179 ******** 
2019-06-05 14:18:41,437 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:41,446 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:41,470 p=17240 u=mistral |  TASK [configure tmpwatch on the host] ******************************************
2019-06-05 14:18:41,470 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/deploy_steps_tasks.yaml:2
2019-06-05 14:18:41,470 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:41 -0500 (0:00:00.060)       0:15:15.240 ******** 
2019-06-05 14:18:41,499 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:41,508 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:41,531 p=17240 u=mistral |  TASK [create iptables service] *************************************************
2019-06-05 14:18:41,531 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/deploy_steps_tasks.yaml:16
2019-06-05 14:18:41,531 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:41 -0500 (0:00:00.060)       0:15:15.300 ******** 
2019-06-05 14:18:41,557 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:41,566 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:41,589 p=17240 u=mistral |  TASK [enable tripleo-iptables service] *****************************************
2019-06-05 14:18:41,589 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/deploy_steps_tasks.yaml:47
2019-06-05 14:18:41,590 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:41 -0500 (0:00:00.058)       0:15:15.359 ******** 
2019-06-05 14:18:41,619 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:41,672 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:41,730 p=17240 u=mistral |  TASK [create ip6tables service] ************************************************
2019-06-05 14:18:41,730 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/deploy_steps_tasks.yaml:51
2019-06-05 14:18:41,730 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:41 -0500 (0:00:00.140)       0:15:15.499 ******** 
2019-06-05 14:18:41,757 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:41,767 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:41,790 p=17240 u=mistral |  TASK [enable tripleo-ip6tables service] ****************************************
2019-06-05 14:18:41,790 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/deploy_steps_tasks.yaml:82
2019-06-05 14:18:41,790 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:41 -0500 (0:00:00.060)       0:15:15.560 ******** 
2019-06-05 14:18:41,817 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:41,826 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:41,827 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:18:41,827 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:18:41,832 p=17240 u=mistral |  PLAY [Overcloud common deploy step tasks 4] ************************************
2019-06-05 14:18:41,837 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:18:41,858 p=17240 u=mistral |  TASK [Check if /var/lib/tripleo-config/container-startup-config-1.json already exists] ***
2019-06-05 14:18:41,858 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deploy_steps_playbook.yaml:450
2019-06-05 14:18:41,858 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:41 -0500 (0:00:00.067)       0:15:15.628 ******** 
2019-06-05 14:18:41,961 p=17240 u=mistral |  ok: [lab-controller-0] => {"changed": false, "stat": {"exists": false}}
2019-06-05 14:18:41,992 p=17240 u=mistral |  ok: [lab-computehci-0] => {"changed": false, "stat": {"exists": false}}
2019-06-05 14:18:42,017 p=17240 u=mistral |  TASK [gather facts needed by role] *********************************************
2019-06-05 14:18:42,017 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:6
2019-06-05 14:18:42,017 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:42 -0500 (0:00:00.159)       0:15:15.787 ******** 
2019-06-05 14:18:42,046 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:42,057 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:42,081 p=17240 u=mistral |  TASK [set python_cmd] **********************************************************
2019-06-05 14:18:42,082 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:13
2019-06-05 14:18:42,082 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:42 -0500 (0:00:00.064)       0:15:15.851 ******** 
2019-06-05 14:18:42,109 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:42,123 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:42,149 p=17240 u=mistral |  TASK [print python facts] ******************************************************
2019-06-05 14:18:42,149 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:22
2019-06-05 14:18:42,149 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:42 -0500 (0:00:00.067)       0:15:15.919 ******** 
2019-06-05 14:18:42,177 p=17240 u=mistral |  ok: [lab-controller-0] => {
    "msg": "python_cmd: python2"
}
2019-06-05 14:18:42,188 p=17240 u=mistral |  ok: [lab-computehci-0] => {
    "msg": "python_cmd: python2"
}
2019-06-05 14:18:42,211 p=17240 u=mistral |  TASK [Create and ensure setype for /var/log/containers directory] **************
2019-06-05 14:18:42,211 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:31
2019-06-05 14:18:42,211 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:42 -0500 (0:00:00.061)       0:15:15.980 ******** 
2019-06-05 14:18:42,238 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:42,247 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:42,271 p=17240 u=mistral |  TASK [Create ContainerLogStdoutPath directory] *********************************
2019-06-05 14:18:42,271 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:39
2019-06-05 14:18:42,271 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:42 -0500 (0:00:00.059)       0:15:16.040 ******** 
2019-06-05 14:18:42,299 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:42,308 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:42,332 p=17240 u=mistral |  TASK [Create /var/lib/tripleo-config directory] ********************************
2019-06-05 14:18:42,332 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:46
2019-06-05 14:18:42,332 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:42 -0500 (0:00:00.060)       0:15:16.101 ******** 
2019-06-05 14:18:42,359 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:42,368 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:42,393 p=17240 u=mistral |  TASK [Delete existing /var/lib/tripleo-config/check-mode directory for check mode] ***
2019-06-05 14:18:42,393 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:60
2019-06-05 14:18:42,393 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:42 -0500 (0:00:00.061)       0:15:16.162 ******** 
2019-06-05 14:18:42,420 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:42,429 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:42,453 p=17240 u=mistral |  TASK [Create /var/lib/tripleo-config/check-mode directory for check mode] ******
2019-06-05 14:18:42,453 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:75
2019-06-05 14:18:42,453 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:42 -0500 (0:00:00.059)       0:15:16.222 ******** 
2019-06-05 14:18:42,479 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:42,494 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:42,520 p=17240 u=mistral |  TASK [Write the puppet step_config manifest] ***********************************
2019-06-05 14:18:42,521 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:93
2019-06-05 14:18:42,521 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:42 -0500 (0:00:00.067)       0:15:16.290 ******** 
2019-06-05 14:18:42,548 p=17240 u=mistral |  skipping: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:42,559 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:42,582 p=17240 u=mistral |  TASK [Diff puppet step_config manifest changes for check mode] *****************
2019-06-05 14:18:42,582 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:105
2019-06-05 14:18:42,582 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:42 -0500 (0:00:00.061)       0:15:16.352 ******** 
2019-06-05 14:18:42,609 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:42,620 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:42,646 p=17240 u=mistral |  TASK [Diff puppet step_config manifest changes for check mode] *****************
2019-06-05 14:18:42,646 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:118
2019-06-05 14:18:42,646 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:42 -0500 (0:00:00.064)       0:15:16.416 ******** 
2019-06-05 14:18:42,676 p=17240 u=mistral |  skipping: [lab-controller-0] => {}
2019-06-05 14:18:42,690 p=17240 u=mistral |  skipping: [lab-computehci-0] => {}
2019-06-05 14:18:42,714 p=17240 u=mistral |  TASK [Create /var/lib/container-puppet] ****************************************
2019-06-05 14:18:42,714 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:129
2019-06-05 14:18:42,714 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:42 -0500 (0:00:00.068)       0:15:16.484 ******** 
2019-06-05 14:18:42,750 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:42,763 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:42,788 p=17240 u=mistral |  TASK [Create /var/lib/docker-puppet for backward compatibility] ****************
2019-06-05 14:18:42,788 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:141
2019-06-05 14:18:42,788 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:42 -0500 (0:00:00.073)       0:15:16.557 ******** 
2019-06-05 14:18:42,822 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:42,832 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:42,856 p=17240 u=mistral |  TASK [Deprecation file about /var/lib/docker-puppet] ***************************
2019-06-05 14:18:42,856 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:149
2019-06-05 14:18:42,856 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:42 -0500 (0:00:00.068)       0:15:16.625 ******** 
2019-06-05 14:18:42,884 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:42,899 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:42,926 p=17240 u=mistral |  TASK [Delete existing /var/lib/container-puppet/container-puppet.sh] ***********
2019-06-05 14:18:42,926 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:157
2019-06-05 14:18:42,926 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:42 -0500 (0:00:00.069)       0:15:16.695 ******** 
2019-06-05 14:18:42,954 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:42,964 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:42,987 p=17240 u=mistral |  TASK [Delete existing /var/lib/container-puppet/check-mode for check mode] *****
2019-06-05 14:18:42,987 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:166
2019-06-05 14:18:42,987 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:42 -0500 (0:00:00.061)       0:15:16.757 ******** 
2019-06-05 14:18:43,014 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:43,025 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:43,049 p=17240 u=mistral |  TASK [Create /var/lib/container-puppet/check-mode for check mode] **************
2019-06-05 14:18:43,049 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:177
2019-06-05 14:18:43,049 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:43 -0500 (0:00:00.061)       0:15:16.818 ******** 
2019-06-05 14:18:43,077 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:43,087 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:43,111 p=17240 u=mistral |  TASK [Write container-puppet.json file] ****************************************
2019-06-05 14:18:43,111 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:189
2019-06-05 14:18:43,111 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:43 -0500 (0:00:00.061)       0:15:16.880 ******** 
2019-06-05 14:18:43,138 p=17240 u=mistral |  skipping: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:43,148 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:43,171 p=17240 u=mistral |  TASK [Diff container-puppet.json changes for check mode] ***********************
2019-06-05 14:18:43,171 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:201
2019-06-05 14:18:43,172 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:43 -0500 (0:00:00.060)       0:15:16.941 ******** 
2019-06-05 14:18:43,199 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:43,208 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:43,231 p=17240 u=mistral |  TASK [Diff container-puppet.json changes for check mode] ***********************
2019-06-05 14:18:43,231 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:214
2019-06-05 14:18:43,232 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:43 -0500 (0:00:00.059)       0:15:17.001 ******** 
2019-06-05 14:18:43,259 p=17240 u=mistral |  skipping: [lab-controller-0] => {}
2019-06-05 14:18:43,275 p=17240 u=mistral |  skipping: [lab-computehci-0] => {}
2019-06-05 14:18:43,302 p=17240 u=mistral |  TASK [Create /var/lib/container-config-scripts] ********************************
2019-06-05 14:18:43,303 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:224
2019-06-05 14:18:43,303 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:43 -0500 (0:00:00.071)       0:15:17.072 ******** 
2019-06-05 14:18:43,333 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:43,343 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:43,367 p=17240 u=mistral |  TASK [Clean old /var/lib/container-startup-configs.json file] ******************
2019-06-05 14:18:43,367 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:235
2019-06-05 14:18:43,368 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:43 -0500 (0:00:00.064)       0:15:17.137 ******** 
2019-06-05 14:18:43,397 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:43,408 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:43,431 p=17240 u=mistral |  TASK [Clean old /var/lib/docker-container-startup-configs.json file] ***********
2019-06-05 14:18:43,431 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:243
2019-06-05 14:18:43,431 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:43 -0500 (0:00:00.063)       0:15:17.200 ******** 
2019-06-05 14:18:43,459 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:43,470 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:43,493 p=17240 u=mistral |  TASK [Write container config scripts] ******************************************
2019-06-05 14:18:43,493 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:251
2019-06-05 14:18:43,493 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:43 -0500 (0:00:00.062)       0:15:17.263 ******** 
2019-06-05 14:18:43,525 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:43,531 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:43,536 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:43,540 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:43,545 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:43,546 p=17240 u=mistral |  skipping: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:43,561 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:43,567 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:43,572 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:43,581 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:43,585 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:43,591 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:43,592 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:43,615 p=17240 u=mistral |  TASK [Set container_config_default fact] ***************************************
2019-06-05 14:18:43,615 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:270
2019-06-05 14:18:43,615 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:43 -0500 (0:00:00.121)       0:15:17.384 ******** 
2019-06-05 14:18:43,644 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:43,645 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:43,647 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:43,652 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:43,658 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:43,664 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:43,664 p=17240 u=mistral |  skipping: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:43,671 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:43,672 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:43,681 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:43,684 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:43,689 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:43,694 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:43,694 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:43,720 p=17240 u=mistral |  TASK [Set container_startup_configs_with_default fact] *************************
2019-06-05 14:18:43,720 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:278
2019-06-05 14:18:43,720 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:43 -0500 (0:00:00.104)       0:15:17.489 ******** 
2019-06-05 14:18:43,748 p=17240 u=mistral |  skipping: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:43,759 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:43,782 p=17240 u=mistral |  TASK [Write per-step container startup configs] ********************************
2019-06-05 14:18:43,782 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:287
2019-06-05 14:18:43,782 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:43 -0500 (0:00:00.061)       0:15:17.551 ******** 
2019-06-05 14:18:43,821 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:43,827 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:43,830 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:43,832 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:43,835 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:43,841 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:43,843 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:43,846 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:43,849 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:43,854 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:43,854 p=17240 u=mistral |  skipping: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:43,855 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:43,860 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:43,860 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:43,885 p=17240 u=mistral |  TASK [Create /var/lib/kolla/config_files directory] ****************************
2019-06-05 14:18:43,885 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:300
2019-06-05 14:18:43,885 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:43 -0500 (0:00:00.102)       0:15:17.654 ******** 
2019-06-05 14:18:43,913 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:43,923 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:43,947 p=17240 u=mistral |  TASK [Create /var/lib/config-data directory] ***********************************
2019-06-05 14:18:43,947 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:310
2019-06-05 14:18:43,947 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:43 -0500 (0:00:00.061)       0:15:17.716 ******** 
2019-06-05 14:18:43,974 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:43,983 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:44,007 p=17240 u=mistral |  TASK [Write kolla config json files] *******************************************
2019-06-05 14:18:44,007 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:317
2019-06-05 14:18:44,007 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:44 -0500 (0:00:00.060)       0:15:17.776 ******** 
2019-06-05 14:18:44,066 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,071 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,077 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,082 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,088 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,099 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,101 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,106 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,112 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,112 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,116 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,121 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,126 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,132 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,137 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,142 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,148 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,158 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,158 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,163 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,169 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,177 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,180 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,184 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,190 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,195 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,200 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,205 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,211 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,216 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,222 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,226 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,232 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,237 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,242 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,248 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,252 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,259 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,264 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,269 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,274 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,280 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,285 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,291 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,297 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,303 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,308 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,314 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,319 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,323 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,329 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,335 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,340 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,345 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,350 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,356 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,360 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,365 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,371 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,376 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,382 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,388 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,393 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,399 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,403 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,409 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,414 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,420 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,425 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,431 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,435 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,440 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,446 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,448 p=17240 u=mistral |  skipping: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,471 p=17240 u=mistral |  TASK [Set host puppet debugging fact string] ***********************************
2019-06-05 14:18:44,472 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:335
2019-06-05 14:18:44,472 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:44 -0500 (0:00:00.464)       0:15:18.241 ******** 
2019-06-05 14:18:44,499 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:44,510 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:44,534 p=17240 u=mistral |  TASK [Check for /etc/puppet/check-mode directory for check mode] ***************
2019-06-05 14:18:44,534 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:344
2019-06-05 14:18:44,534 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:44 -0500 (0:00:00.062)       0:15:18.303 ******** 
2019-06-05 14:18:44,562 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:44,572 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:44,596 p=17240 u=mistral |  TASK [Create /etc/puppet/check-mode/hieradata directory for check mode] ********
2019-06-05 14:18:44,596 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:353
2019-06-05 14:18:44,596 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:44 -0500 (0:00:00.061)       0:15:18.365 ******** 
2019-06-05 14:18:44,623 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:44,633 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:44,658 p=17240 u=mistral |  TASK [Write the config_step hieradata] *****************************************
2019-06-05 14:18:44,658 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:368
2019-06-05 14:18:44,658 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:44 -0500 (0:00:00.061)       0:15:18.427 ******** 
2019-06-05 14:18:44,952 p=17240 u=mistral |  ok: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,967 p=17240 u=mistral |  ok: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:44,991 p=17240 u=mistral |  TASK [Create puppet check-mode files if they don't exist for check mode] *******
2019-06-05 14:18:44,991 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:379
2019-06-05 14:18:44,991 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:44 -0500 (0:00:00.333)       0:15:18.761 ******** 
2019-06-05 14:18:45,019 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:45,030 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:45,055 p=17240 u=mistral |  TASK [Run puppet host configuration for step 4] ********************************
2019-06-05 14:18:45,055 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:392
2019-06-05 14:18:45,055 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:45 -0500 (0:00:00.063)       0:15:18.824 ******** 
2019-06-05 14:18:56,171 p=17240 u=mistral |  changed: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:18:57,228 p=17240 u=mistral |  changed: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:18:57,252 p=17240 u=mistral |  TASK [Debug output for task: Run puppet host configuration for step 4] *********
2019-06-05 14:18:57,252 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:411
2019-06-05 14:18:57,252 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:57 -0500 (0:00:12.197)       0:15:31.021 ******** 
2019-06-05 14:18:57,281 p=17240 u=mistral |  ok: [lab-controller-0] => {
    "failed_when_result": false, 
    "outputs.stdout_lines | default([]) | union(outputs.stderr_lines | default([]))": [
        "Changes:", 
        "            Total: 10", 
        "Events:", 
        "          Success: 10", 
        "Resources:", 
        "        Restarted: 1", 
        "          Changed: 10", 
        "      Out of sync: 10", 
        "            Total: 195", 
        "Time:", 
        "           Anchor: 0.00", 
        "         Schedule: 0.00", 
        "   Package manifest: 0.00", 
        "   Sysctl runtime: 0.00", 
        "           Sysctl: 0.00", 
        "           Augeas: 0.01", 
        "          Package: 0.13", 
        "         Firewall: 0.24", 
        "             File: 0.30", 
        "          Service: 0.39", 
        "   Config retrieval: 1.42", 
        "         Last run: 1559762336", 
        "   Concat fragment: 0.00", 
        "             Exec: 5.14", 
        "       Filebucket: 0.00", 
        "   Transaction evaluation: 6.85", 
        "   Catalog application: 6.89", 
        "      Concat file: 0.00", 
        "            Total: 6.89", 
        "Version:", 
        "           Config: 1559762328", 
        "           Puppet: 5.5.10"
    ]
}
2019-06-05 14:18:57,299 p=17240 u=mistral |  ok: [lab-computehci-0] => {
    "failed_when_result": false, 
    "outputs.stdout_lines | default([]) | union(outputs.stderr_lines | default([]))": [
        "Changes:", 
        "            Total: 18", 
        "Events:", 
        "          Success: 18", 
        "Resources:", 
        "          Changed: 18", 
        "      Out of sync: 18", 
        "        Restarted: 4", 
        "            Total: 173", 
        "Time:", 
        "      Concat file: 0.00", 
        "         Schedule: 0.00", 
        "           Anchor: 0.00", 
        "   Package manifest: 0.00", 
        "        File line: 0.00", 
        "   Sysctl runtime: 0.00", 
        "           Sysctl: 0.00", 
        "           Augeas: 0.01", 
        "         Firewall: 0.04", 
        "             File: 0.15", 
        "          Package: 0.18", 
        "          Service: 0.35", 
        "   Config retrieval: 1.28", 
        "         Last run: 1559762335", 
        "   Concat fragment: 0.00", 
        "             Exec: 5.24", 
        "       Filebucket: 0.00", 
        "   Transaction evaluation: 6.32", 
        "   Catalog application: 6.34", 
        "            Total: 6.34", 
        "Version:", 
        "           Config: 1559762328", 
        "           Puppet: 5.5.10"
    ]
}
2019-06-05 14:18:57,324 p=17240 u=mistral |  TASK [Run container-puppet tasks (generate config) during step 4] **************
2019-06-05 14:18:57,324 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:426
2019-06-05 14:18:57,324 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:57 -0500 (0:00:00.071)       0:15:31.093 ******** 
2019-06-05 14:18:57,352 p=17240 u=mistral |  skipping: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:57,362 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:18:57,387 p=17240 u=mistral |  TASK [Debug output for task: Run container-puppet tasks (generate config) during step 4] ***
2019-06-05 14:18:57,387 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:449
2019-06-05 14:18:57,387 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:57 -0500 (0:00:00.063)       0:15:31.157 ******** 
2019-06-05 14:18:57,417 p=17240 u=mistral |  skipping: [lab-controller-0] => {}
2019-06-05 14:18:57,427 p=17240 u=mistral |  skipping: [lab-computehci-0] => {}
2019-06-05 14:18:57,451 p=17240 u=mistral |  TASK [Diff container-puppet.py puppet-generated changes for check mode] ********
2019-06-05 14:18:57,451 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:458
2019-06-05 14:18:57,451 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:57 -0500 (0:00:00.063)       0:15:31.220 ******** 
2019-06-05 14:18:57,478 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:57,488 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:18:57,511 p=17240 u=mistral |  TASK [Diff container-puppet.py puppet-generated changes for check mode] ********
2019-06-05 14:18:57,511 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:473
2019-06-05 14:18:57,511 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:57 -0500 (0:00:00.060)       0:15:31.280 ******** 
2019-06-05 14:18:57,538 p=17240 u=mistral |  skipping: [lab-controller-0] => {}
2019-06-05 14:18:57,547 p=17240 u=mistral |  skipping: [lab-computehci-0] => {}
2019-06-05 14:18:57,571 p=17240 u=mistral |  TASK [Start containers for step 4] *********************************************
2019-06-05 14:18:57,572 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:491
2019-06-05 14:18:57,572 p=17240 u=mistral |  Wednesday 05 June 2019  14:18:57 -0500 (0:00:00.060)       0:15:31.341 ******** 
2019-06-05 14:20:14,233 p=17240 u=mistral |  ok: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:27,368 p=17240 u=mistral |  ok: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:27,392 p=17240 u=mistral |  TASK [Debug output for task: Start containers for step 4] **********************
2019-06-05 14:20:27,392 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:508
2019-06-05 14:20:27,392 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:27 -0500 (0:01:29.820)       0:17:01.162 ******** 
2019-06-05 14:20:27,425 p=17240 u=mistral |  ok: [lab-controller-0] => {
    "failed_when_result": false, 
    "outputs.stdout_lines | default([]) | union(outputs.stderr_lines | default([]))": [
        "stdout: 7c05e47406299152f9c136773d45b3ba861f5485530bb4859849ad9dd41538a9", 
        "", 
        "stderr: Trying to pull docker://docker.io/tripleostein/centos-binary-aodh-evaluator:current-tripleo-rdo...Getting image source signatures", 
        "Copying blob sha256:a35613cff6f04cbfd2f3b845d5a923d56d6f2fb718f85784e8fdcd97ae77846e", 
        "Copying blob sha256:0f2be6d2e8e6e42cb3e633544d0b1aa8328bd7004a3a4b1dfc0c7a6ba14cd0c7", 
        "Copying blob sha256:31c8fa1ceee01b746a6b64c4718f5e42e867c08532b29f8d33626a8385327ede", 
        "Copying blob sha256:c80c3921174be89bdd60d2454983524a19a15b09f26f47b6822e6440d5939973", 
        "Copying blob sha256:c0862342b9e7a81856422b95348a2d1952b46e01df6c72f74d94cac2c5815c51", 
        "Copying blob sha256:5b8f702199c16fd0d5c9c4d0028550b144acb532f4a6b8200b3f53e1cbc43aba", 
        "Copying blob sha256:8ba884070f611d31cb2c42eddb691319dc9facf5e0ec67672fcfa135181ab3df", 
        "Copying blob sha256:6310d6ac1536a2eb8e769d217451e2c6d420eb3c39b0fb1b9ad088a73ea67211", 
        "Copying blob sha256:2799d99efade4475ca55aad34887eabf4e9ec76e592bc0b0a80cbd8d01080ffc", 
        "Copying blob sha256:d36b87fd0812d0e39ef92e729105260f496efbfb19ad7b6981218862502aa0f3", 
        "Copying blob sha256:0fc1fd86055457f85a0cb3f333292570aaa2803c4b556966847f55f8f3544fa8", 
        "Copying blob sha256:46d3c6aa676de9a0ee74cfac77cced69fb7a4df7c5b9e8a7ef33922881d87c81", 
        "Copying blob sha256:fc3b29499fda939e998b0c14c6e98720e1cb7a66fd1ce884cad8d64a63669cf4", 
        "Copying blob sha256:d6dbd69ea530292192935158b778ccffc396ead2093138f75c6e1fa33b7a17fa", 
        "Copying blob sha256:5b89a36d5e9e14c5ac5981e8ed2304bb8ce19da7d91793f44c48ac17e7b03717", 
        "Copying blob sha256:98d5e2479617c862dcad487a2c52021bc16e516ebafe9fdab6b3eb8648b73f57", 
        "Copying blob sha256:bd6e2c36ff0e45e35121c3bc2cb54f803eb809aacb2778260d4211de2ba9fabb", 
        "Copying blob sha256:921488feccf56d8c8eb6086cd998b48f907fa44dbc5e7cf8525efd96f7c1f776", 
        "Copying blob sha256:2cc44a4e32219b5aad308d7d3bdc5ba18788e8830c0cf3aa9056e1d0dc647058", 
        "Copying blob sha256:ccae8e3351ac86f5c7d66e9c84321057c9f05063428851fa0f1c17946090212d", 
        "Copying blob sha256:89c8d96f0d37376ba1f54c92128660aaea0a802cb9d9d396a45366b02fc589cc", 
        "Copying blob sha256:45d804df81db3a3f58373c31a92eb2484c2b9038ec59d86fed68b6ce62565939", 
        "Copying blob sha256:4eec291ae3a6360772d13ef90deb53c7a7a43dcc53cf884977f36d0da6c579df", 
        "Copying blob sha256:13a398bd1117935860905e8f3ed0b6fcf669f781d7b6a74688d46969351ec787", 
        "Copying blob sha256:343f9f42dd124dbd53b97d676c7702f6308aa52ad4e28983f1aa15f733d48213", 
        "Copying blob sha256:f71e002ed44a355a6f642d0ff4e51176086dc892cbf21317b5acdec93ed666d7", 
        "Copying blob sha256:f2cf5031ad64e4da2ee6c05ce500f2fe922ce7a17fc7f46f63d609f1a33f9180", 
        "Copying blob sha256:1d0ecf9cae7683248bdbf99e2da593d61b86aca383e4bc386fcafc5574afedcd", 
        "Copying blob sha256:0c92a773231f3e3ad97e13399196c70a9a8f5c228ccc9f423731c0b3eb49b685", 
        "Copying blob sha256:d9bf901c7f2ae7bc130eb989f125f2e2d4410df9451fb9aaa3bd795d8166e534", 
        "Copying blob sha256:941a386b4bee3438a71a5743cf94e273a91af9245c733aa70e778e984536c02c", 
        "Copying config sha256:7c05e47406299152f9c136773d45b3ba861f5485530bb4859849ad9dd41538a9", 
        "Writing manifest to image destination", 
        "Storing signatures", 
        "stdout: 3d0f4aff1f1c3fe0b0651c7c234773a3d2b70446ffabcfbfbb1a543ae6717f5c", 
        "stderr: Trying to pull docker://docker.io/tripleostein/centos-binary-aodh-listener:current-tripleo-rdo...Getting image source signatures", 
        "Copying blob sha256:7e62dae50d0a7397420ed2e12331d90211ae1dda4aa6ba9139d58916c1a6955c", 
        "Copying blob sha256:8789a6153edeba07d18c16b1dc27999d8d6e5431c422998b12f68e8e0c5daa68", 
        "Copying config sha256:3d0f4aff1f1c3fe0b0651c7c234773a3d2b70446ffabcfbfbb1a543ae6717f5c", 
        "stdout: 03422bf2f39f06891bbc00e8028adbfed2e17d87a0720f5fcb615a721d349db5", 
        "stderr: Trying to pull docker://docker.io/tripleostein/centos-binary-aodh-notifier:current-tripleo-rdo...Getting image source signatures", 
        "Copying blob sha256:5ca10bda4d3e36a0087a467e650218f17c49799fe366f7c274f65b7a670f71a5", 
        "Copying blob sha256:d2404b69d2aa6bebb60b61a06acf36dfd6d19c7ee55116ac2e67ad2005721bf4", 
        "Copying config sha256:03422bf2f39f06891bbc00e8028adbfed2e17d87a0720f5fcb615a721d349db5", 
        "stdout: 273b232c7ca90d9145ed9670d759c44ad85a35c93ef6e2e85e1b30e48388a24b", 
        "stderr: Trying to pull docker://docker.io/tripleostein/centos-binary-nova-consoleauth:current-tripleo-rdo...Getting image source signatures", 
        "Copying blob sha256:d75ae4cf64b29c5e27cec9a45bbf01b196dc716834c117ab6017cb74882919e0", 
        "Copying blob sha256:88531674244332349666cefabdff747eacb0035c77771f43c8f4f47a52d7685f", 
        "Copying blob sha256:9869b6ce22f44304615e534ccc6c32765cd48d898b2c46ea4aa5d86c7a208c96", 
        "Copying blob sha256:f6294bc12da549b2a997050c47023556c25332e72e05c8fa2644761de96aa425", 
        "Copying blob sha256:9aef06bfe3cf0d3f0c7de9f920f09b66b2aa0caf7ba789d44f375c6e66265cbe", 
        "Copying blob sha256:fdb19949181371b67da293599368c586f6da768f760bbe93cfc4ff386ee2cb5e", 
        "Copying blob sha256:f16675560dcb58f5455427a2c4d5393209bbc6da16a22c08784ec982d83188a0", 
        "Copying config sha256:273b232c7ca90d9145ed9670d759c44ad85a35c93ef6e2e85e1b30e48388a24b", 
        "stdout: dd24b7c3c63f2c2e6ec2ca1c254a736ef30c5f13c2b4ff2e4768ac00384fe50e", 
        "stderr: Trying to pull docker://docker.io/tripleostein/centos-binary-nova-novncproxy:current-tripleo-rdo...Getting image source signatures", 
        "Copying blob sha256:6e606b51efb55eadbe2f0b7838ac2e240fb3f603194c4183eca754740eb0a9eb", 
        "Copying blob sha256:a365bfc36ed6bb0363648576454209d9906e65fea360d2692328a5b01c2005d0", 
        "Copying config sha256:dd24b7c3c63f2c2e6ec2ca1c254a736ef30c5f13c2b4ff2e4768ac00384fe50e", 
        "stdout: 9b62912976576c33badb2c1bc8e2a7422f51f1c109d9138690083f942fc7ae3b", 
        "stderr: Trying to pull docker://docker.io/tripleostein/centos-binary-nova-scheduler:current-tripleo-rdo...Getting image source signatures", 
        "Copying blob sha256:56ce51d525d196436cfcf835b60c440e77206b9e62efddb2f1a770ff58e5452d", 
        "Copying blob sha256:59cd39cdc861ed15233aae958898ed780969c92426928f1775907135a1a0beda", 
        "Copying config sha256:9b62912976576c33badb2c1bc8e2a7422f51f1c109d9138690083f942fc7ae3b", 
        "stdout: b0a58adaebe28aaab583303f3a8bff965eb2ee319d2647bc0cac96c41aad1c5a", 
        "stderr: Trying to pull docker://docker.io/tripleostein/centos-binary-ovn-nb-db-server:current-tripleo-rdo...Getting image source signatures", 
        "Copying blob sha256:b9846bbbebab5607bb743a5e4f50c07967ae16a461e65c862bd21028e59faf58", 
        "Copying blob sha256:a60799747bf1ae164a3509aefe1a60b8faf89ebeeac00f81309e984e4b351a0c", 
        "Copying blob sha256:68ff526217749f85694f4ecc42f60077a24679a69ccbe48915ca4fd575841f0b", 
        "Copying blob sha256:d7fd089bb17e5cbf93092b1825b7b49c6dac8f2341507a8a5488854b0ee5d695", 
        "Copying blob sha256:957fca782c67875fb57f10cc632f82848848485bc10effa1ea802b69f4b552b9", 
        "Copying blob sha256:ffe31f7d08a0268aa81e6e20b0e129e9ba91d4182aac483ce2a78c9bb638da22", 
        "Copying blob sha256:ccdf261da70cd6ff62e257e38a82962de2b29fc9e85c0bbe5fb35748f86052e5", 
        "Copying blob sha256:d706b333e736df19a5aabec6ed3feff849c7fb2566948f280a924cdcc5f77d7e", 
        "Copying blob sha256:6b46a88a8f3bac80cfdda0f19e4d85817397cdd9008288a28efab1163530d09c", 
        "Copying blob sha256:890d64703f16b2020259d273b45d9bf79a3ebe7c02010f3aff25164272b39362", 
        "Copying config sha256:b0a58adaebe28aaab583303f3a8bff965eb2ee319d2647bc0cac96c41aad1c5a", 
        "stdout: ddcdd3c20638dc9fd39b2a495fe601c5f869175c47608537cc437ff4c3fe2505", 
        "stderr: Trying to pull docker://docker.io/tripleostein/centos-binary-ovn-northd:current-tripleo-rdo...Getting image source signatures", 
        "Copying blob sha256:5a2a3b7bfb802bad01b32ae95ebe0d5c3aabe46fb397a7b55586eed3fa5d8b3f", 
        "Copying blob sha256:c112aa9371ebdc20b7d458a66991d13c4d4b6209552b9679b47eccb019d3a7cc", 
        "Copying config sha256:ddcdd3c20638dc9fd39b2a495fe601c5f869175c47608537cc437ff4c3fe2505", 
        "stdout: cadca49e0e23048c94debe5da30e9ae1973e78ec0f334600063807a4887e1ab8", 
        "stderr: Trying to pull docker://docker.io/tripleostein/centos-binary-ovn-sb-db-server:current-tripleo-rdo...Getting image source signatures", 
        "Copying blob sha256:6b470af2cb129a83d94a88e6adf8bc486e694f84a48677b9241ba0977565ecba", 
        "Copying blob sha256:44b7e2430de35111d1cbb683ef6c3970472686ab44607e496dc9c99e39894027", 
        "Copying blob sha256:6cb5a12bd3052d100d6e2b0798ff30297831a369584bc8a7984929ea6fc665f2", 
        "Copying blob sha256:7d80033d7c492be615491052a22fa7288eb2f1180c4f2f84f649c81b1b9760ee", 
        "Copying config sha256:cadca49e0e23048c94debe5da30e9ae1973e78ec0f334600063807a4887e1ab8", 
        "stdout: a33cb1f2c5f39822cf8fe58e80f7f1b835f027f08c35f1bedbbba75c1f180270", 
        "stderr: Trying to pull docker://docker.io/tripleostein/centos-binary-swift-container:current-tripleo-rdo...Getting image source signatures", 
        "Copying blob sha256:6a8b329e2234e1a19a3aa91ccb586e3540a4c5464ad263ee76de34bc05f78212", 
        "Copying blob sha256:be817afa7b98add2661bfaab95d450fb41ca56adb06301a2c8c33d13a3278109", 
        "Copying blob sha256:778b5f306cfd7e6af23d58d8addd34f3d50b4b441a09628c766987b2bfbf0212", 
        "Copying blob sha256:fc38390f14e8ae1bd7c72e4136f0004dc655f4df400d4bfdb6f6075484c97966", 
        "Copying blob sha256:c79f73bc1d26b481cc8d4e8d14e599dfb2fe5668b8ae974b9a90d4dfe402caeb", 
        "Copying blob sha256:7f211c86201e29de65858d380694fda728af7cf140b00d611111a1dc9e8c899e", 
        "Copying blob sha256:d672f0e6fe7bc6135bfab85bc8c6e82bcf1e86bbefd5f33429aa56388a95f2ba", 
        "Copying blob sha256:5532a630876ec8885e185570aa8c811d5ffa3e6447a9b8e629d15376d8c7a199", 
        "Copying config sha256:a33cb1f2c5f39822cf8fe58e80f7f1b835f027f08c35f1bedbbba75c1f180270", 
        "stdout: f4b2e8f94f7c256e7a54c4eee40ad5b669895a138fd3538b7d44db7ee472cf94", 
        "stderr: ", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_aodh_evaluator.service to /etc/systemd/system/tripleo_aodh_evaluator.service.", 
        "Created symlink from /etc/systemd/system/timers.target.wants/tripleo_aodh_evaluator_healthcheck.timer to /etc/systemd/system/tripleo_aodh_evaluator_healthcheck.timer.", 
        "Created symlink from /etc/systemd/system/tripleo_aodh_evaluator.service.requires/tripleo_aodh_evaluator_healthcheck.timer to /etc/systemd/system/tripleo_aodh_evaluator_healthcheck.timer.", 
        "stdout: 49f7a4e75c039ea9d06edb90df17905138eb7d9c5b45b230ed89f4df716526e7", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_nova_scheduler.service to /etc/systemd/system/tripleo_nova_scheduler.service.", 
        "Created symlink from /etc/systemd/system/timers.target.wants/tripleo_nova_scheduler_healthcheck.timer to /etc/systemd/system/tripleo_nova_scheduler_healthcheck.timer.", 
        "Created symlink from /etc/systemd/system/tripleo_nova_scheduler.service.requires/tripleo_nova_scheduler_healthcheck.timer to /etc/systemd/system/tripleo_nova_scheduler_healthcheck.timer.", 
        "stdout: 9686de9731876332eda2f40536f4a35345d40b7c5cbbf716a023258fa88d596e", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_swift_object_server.service to /etc/systemd/system/tripleo_swift_object_server.service.", 
        "Created symlink from /etc/systemd/system/timers.target.wants/tripleo_swift_object_server_healthcheck.timer to /etc/systemd/system/tripleo_swift_object_server_healthcheck.timer.", 
        "Created symlink from /etc/systemd/system/tripleo_swift_object_server.service.requires/tripleo_swift_object_server_healthcheck.timer to /etc/systemd/system/tripleo_swift_object_server_healthcheck.timer.", 
        "stdout: ", 
        "stdout: 81d42fa3e51bbdd0242a1fb425f0051c8a6399a7d93f04a2dbbae6fcac425ccd", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_ovn_south_db_server.service to /etc/systemd/system/tripleo_ovn_south_db_server.service.", 
        "stdout: 2cf23d2592392e07fe8f1e47fd48ebe9cb09cb37b9c2d8e4aa67359bf976fe6a", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_heat_api.service to /etc/systemd/system/tripleo_heat_api.service.", 
        "Created symlink from /etc/systemd/system/timers.target.wants/tripleo_heat_api_healthcheck.timer to /etc/systemd/system/tripleo_heat_api_healthcheck.timer.", 
        "Created symlink from /etc/systemd/system/tripleo_heat_api.service.requires/tripleo_heat_api_healthcheck.timer to /etc/systemd/system/tripleo_heat_api_healthcheck.timer.", 
        "stdout: 5bf92a2243d6b223bbd0f18b4119a660fe3fc539e230d34f247ec3078b4bb058", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_swift_object_auditor.service to /etc/systemd/system/tripleo_swift_object_auditor.service.", 
        "stdout: 932c5e0c023e3904acb85bcaa4f338f8b71ffdbbdb5428ba4cfa943b56ffe974", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_swift_account_replicator.service to /etc/systemd/system/tripleo_swift_account_replicator.service.", 
        "stdout: 9d07d72239d6181865384c30b65b7a6676ca791e2bdd7c25cd2a8112203d135c", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_ceilometer_agent_central.service to /etc/systemd/system/tripleo_ceilometer_agent_central.service.", 
        "Created symlink from /etc/systemd/system/timers.target.wants/tripleo_ceilometer_agent_central_healthcheck.timer to /etc/systemd/system/tripleo_ceilometer_agent_central_healthcheck.timer.", 
        "Created symlink from /etc/systemd/system/tripleo_ceilometer_agent_central.service.requires/tripleo_ceilometer_agent_central_healthcheck.timer to /etc/systemd/system/tripleo_ceilometer_agent_central_healthcheck.timer.", 
        "stdout: e45d3b502a09b01da214021f28d5d550417ee1960548dd62e3509287b908a650", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_aodh_notifier.service to /etc/systemd/system/tripleo_aodh_notifier.service.", 
        "Created symlink from /etc/systemd/system/timers.target.wants/tripleo_aodh_notifier_healthcheck.timer to /etc/systemd/system/tripleo_aodh_notifier_healthcheck.timer.", 
        "Created symlink from /etc/systemd/system/tripleo_aodh_notifier.service.requires/tripleo_aodh_notifier_healthcheck.timer to /etc/systemd/system/tripleo_aodh_notifier_healthcheck.timer.", 
        "stdout: c77159a5b95674b1eb33edb2768758faeb8abb6fc92be84f93fc9164dd576def", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_swift_container_updater.service to /etc/systemd/system/tripleo_swift_container_updater.service.", 
        "stdout: 728378bc9e095156fe67812a1d9d3915da0c4b043648ff201daf776886c56228", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_nova_api_cron.service to /etc/systemd/system/tripleo_nova_api_cron.service.", 
        "Created symlink from /etc/systemd/system/timers.target.wants/tripleo_nova_api_cron_healthcheck.timer to /etc/systemd/system/tripleo_nova_api_cron_healthcheck.timer.", 
        "Created symlink from /etc/systemd/system/tripleo_nova_api_cron.service.requires/tripleo_nova_api_cron_healthcheck.timer to /etc/systemd/system/tripleo_nova_api_cron_healthcheck.timer.", 
        "stdout: 5a0c6b3914e3b622685023dad1a1387ebc10983aabf213f0046e567838571c81", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_nova_consoleauth.service to /etc/systemd/system/tripleo_nova_consoleauth.service.", 
        "Created symlink from /etc/systemd/system/timers.target.wants/tripleo_nova_consoleauth_healthcheck.timer to /etc/systemd/system/tripleo_nova_consoleauth_healthcheck.timer.", 
        "Created symlink from /etc/systemd/system/tripleo_nova_consoleauth.service.requires/tripleo_nova_consoleauth_healthcheck.timer to /etc/systemd/system/tripleo_nova_consoleauth_healthcheck.timer.", 
        "stdout: d0a1be7029c60a73a1e4877edfe59cbc6ae9c73f232211aa46534ce35718b416", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_cinder_volume.service to /etc/systemd/system/tripleo_cinder_volume.service.", 
        "Created symlink from /etc/systemd/system/timers.target.wants/tripleo_cinder_volume_healthcheck.timer to /etc/systemd/system/tripleo_cinder_volume_healthcheck.timer.", 
        "Created symlink from /etc/systemd/system/tripleo_cinder_volume.service.requires/tripleo_cinder_volume_healthcheck.timer to /etc/systemd/system/tripleo_cinder_volume_healthcheck.timer.", 
        "stdout: 1a722af7314f11a45de0cda5ae1f9c162ba6b683fd7029da5c799dfd95932880", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_ceilometer_agent_notification.service to /etc/systemd/system/tripleo_ceilometer_agent_notification.service.", 
        "Created symlink from /etc/systemd/system/timers.target.wants/tripleo_ceilometer_agent_notification_healthcheck.timer to /etc/systemd/system/tripleo_ceilometer_agent_notification_healthcheck.timer.", 
        "Created symlink from /etc/systemd/system/tripleo_ceilometer_agent_notification.service.requires/tripleo_ceilometer_agent_notification_healthcheck.timer to /etc/systemd/system/tripleo_ceilometer_agent_notification_healthcheck.timer.", 
        "stdout: b89c8b809466bc602e89b29e398c9a90b8b138ba681aa9fb9ce62e29a3355b71", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_swift_account_reaper.service to /etc/systemd/system/tripleo_swift_account_reaper.service.", 
        "stdout: 4823700a3a2aa1e9748cf078546171648ac958f31bb34670556ad89b911aa8e5", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_swift_rsync.service to /etc/systemd/system/tripleo_swift_rsync.service.", 
        "stdout: 08e91d085b23aeac649efb41d1e61fbdb199d8b7b1595969f99fea8bdcf335f1", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_aodh_api.service to /etc/systemd/system/tripleo_aodh_api.service.", 
        "Created symlink from /etc/systemd/system/timers.target.wants/tripleo_aodh_api_healthcheck.timer to /etc/systemd/system/tripleo_aodh_api_healthcheck.timer.", 
        "Created symlink from /etc/systemd/system/tripleo_aodh_api.service.requires/tripleo_aodh_api_healthcheck.timer to /etc/systemd/system/tripleo_aodh_api_healthcheck.timer.", 
        "stdout: 61ad4f801caa8f081339e7b4710672f490a1d8d2fea0c8d39ba3a638f7ab949d", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_heat_engine.service to /etc/systemd/system/tripleo_heat_engine.service.", 
        "Created symlink from /etc/systemd/system/timers.target.wants/tripleo_heat_engine_healthcheck.timer to /etc/systemd/system/tripleo_heat_engine_healthcheck.timer.", 
        "Created symlink from /etc/systemd/system/tripleo_heat_engine.service.requires/tripleo_heat_engine_healthcheck.timer to /etc/systemd/system/tripleo_heat_engine_healthcheck.timer.", 
        "stdout: cb404b440f58e9b3472bb8feb9cc265b44c8d17a44c430b98ca2be470f2848f0", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_cinder_api.service to /etc/systemd/system/tripleo_cinder_api.service.", 
        "Created symlink from /etc/systemd/system/timers.target.wants/tripleo_cinder_api_healthcheck.timer to /etc/systemd/system/tripleo_cinder_api_healthcheck.timer.", 
        "Created symlink from /etc/systemd/system/tripleo_cinder_api.service.requires/tripleo_cinder_api_healthcheck.timer to /etc/systemd/system/tripleo_cinder_api_healthcheck.timer.", 
        "stdout: 0d08d0cfb66fa8f1ec6542de3c99f2665e59e682c26809678dbce697ba553592", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_swift_container_server.service to /etc/systemd/system/tripleo_swift_container_server.service.", 
        "Created symlink from /etc/systemd/system/timers.target.wants/tripleo_swift_container_server_healthcheck.timer to /etc/systemd/system/tripleo_swift_container_server_healthcheck.timer.", 
        "Created symlink from /etc/systemd/system/tripleo_swift_container_server.service.requires/tripleo_swift_container_server_healthcheck.timer to /etc/systemd/system/tripleo_swift_container_server_healthcheck.timer.", 
        "stdout: ec87de07193bf889d78464f8ed5adf1813e5cde569077007be11a272229d35b8", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_swift_object_replicator.service to /etc/systemd/system/tripleo_swift_object_replicator.service.", 
        "stdout: fbc66c05f00f0f5e0a5bd3f98024c5d8daf80c51a91abfdb494d7941956816be", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_cinder_scheduler.service to /etc/systemd/system/tripleo_cinder_scheduler.service.", 
        "Created symlink from /etc/systemd/system/timers.target.wants/tripleo_cinder_scheduler_healthcheck.timer to /etc/systemd/system/tripleo_cinder_scheduler_healthcheck.timer.", 
        "Created symlink from /etc/systemd/system/tripleo_cinder_scheduler.service.requires/tripleo_cinder_scheduler_healthcheck.timer to /etc/systemd/system/tripleo_cinder_scheduler_healthcheck.timer.", 
        "stdout: 975a6cffbac2d4fc7b7210dbb193a4e8baedcc1de710ba941ab3e1e86bfeffd5", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_nova_conductor.service to /etc/systemd/system/tripleo_nova_conductor.service.", 
        "Created symlink from /etc/systemd/system/timers.target.wants/tripleo_nova_conductor_healthcheck.timer to /etc/systemd/system/tripleo_nova_conductor_healthcheck.timer.", 
        "Created symlink from /etc/systemd/system/tripleo_nova_conductor.service.requires/tripleo_nova_conductor_healthcheck.timer to /etc/systemd/system/tripleo_nova_conductor_healthcheck.timer.", 
        "stdout: 8c84d9960bf3d05beb4451f68ef27269d629b237fa1d8fcfdfe40bd741765c63", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_swift_account_server.service to /etc/systemd/system/tripleo_swift_account_server.service.", 
        "Created symlink from /etc/systemd/system/timers.target.wants/tripleo_swift_account_server_healthcheck.timer to /etc/systemd/system/tripleo_swift_account_server_healthcheck.timer.", 
        "Created symlink from /etc/systemd/system/tripleo_swift_account_server.service.requires/tripleo_swift_account_server_healthcheck.timer to /etc/systemd/system/tripleo_swift_account_server_healthcheck.timer.", 
        "stdout: ca9d8728083520ab84f6394ca220035652e3d8a4d9ebf34ac0fa55b3bcb04b0b", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_logrotate_crond.service to /etc/systemd/system/tripleo_logrotate_crond.service.", 
        "Created symlink from /etc/systemd/system/timers.target.wants/tripleo_logrotate_crond_healthcheck.timer to /etc/systemd/system/tripleo_logrotate_crond_healthcheck.timer.", 
        "Created symlink from /etc/systemd/system/tripleo_logrotate_crond.service.requires/tripleo_logrotate_crond_healthcheck.timer to /etc/systemd/system/tripleo_logrotate_crond_healthcheck.timer.", 
        "stdout: 9b44be86031399a758cc7048822fbde703b840e8d2bbbd377bcaa2633ff8165e", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_cinder_api_cron.service to /etc/systemd/system/tripleo_cinder_api_cron.service.", 
        "Created symlink from /etc/systemd/system/timers.target.wants/tripleo_cinder_api_cron_healthcheck.timer to /etc/systemd/system/tripleo_cinder_api_cron_healthcheck.timer.", 
        "Created symlink from /etc/systemd/system/tripleo_cinder_api_cron.service.requires/tripleo_cinder_api_cron_healthcheck.timer to /etc/systemd/system/tripleo_cinder_api_cron_healthcheck.timer.", 
        "stdout: 0979802a01e262b87140a77715a976f7d49c34e97677a7a25863373c36a1dcd6", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_swift_account_auditor.service to /etc/systemd/system/tripleo_swift_account_auditor.service.", 
        "stdout: 5bddf7def6b0cd4b3a0b424dadbbef2685a8187317f63c095e02ca32dfd030e7", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_swift_container_replicator.service to /etc/systemd/system/tripleo_swift_container_replicator.service.", 
        "stdout: d03bd30530060c5f44f709e6ad940d375c97eaea3fd5225580372e1139c017fb", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_swift_object_updater.service to /etc/systemd/system/tripleo_swift_object_updater.service.", 
        "stdout: df86cad6f6a3dfa08615fecfdcc5c139b42f1b9263eb1dc9209f79b10660da91", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_swift_object_expirer.service to /etc/systemd/system/tripleo_swift_object_expirer.service.", 
        "stdout: 98e6fc3ec6391cf7f11b575ceeebc9847df6e05818a1ef00fd99f60f2bf4e140", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_heat_api_cron.service to /etc/systemd/system/tripleo_heat_api_cron.service.", 
        "Created symlink from /etc/systemd/system/timers.target.wants/tripleo_heat_api_cron_healthcheck.timer to /etc/systemd/system/tripleo_heat_api_cron_healthcheck.timer.", 
        "Created symlink from /etc/systemd/system/tripleo_heat_api_cron.service.requires/tripleo_heat_api_cron_healthcheck.timer to /etc/systemd/system/tripleo_heat_api_cron_healthcheck.timer.", 
        "stdout: 945e95ce536f168f14465e33d2cc183c3f10709462a500e73af8d31f7b7274aa", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_swift_container_auditor.service to /etc/systemd/system/tripleo_swift_container_auditor.service.", 
        "stdout: 7518cb6cfaf165aef849a5345f2643fbc1db09c8c870ad127ff8f2fe0da6324b", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_ovn_north_db_server.service to /etc/systemd/system/tripleo_ovn_north_db_server.service.", 
        "stdout: dcee3ed6a7ccc16a22be0146af637fb5d3f35c146455ee9d2109c282e3732e2d", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_aodh_listener.service to /etc/systemd/system/tripleo_aodh_listener.service.", 
        "Created symlink from /etc/systemd/system/timers.target.wants/tripleo_aodh_listener_healthcheck.timer to /etc/systemd/system/tripleo_aodh_listener_healthcheck.timer.", 
        "Created symlink from /etc/systemd/system/tripleo_aodh_listener.service.requires/tripleo_aodh_listener_healthcheck.timer to /etc/systemd/system/tripleo_aodh_listener_healthcheck.timer.", 
        "stdout: e41c9780ad666c16011b656078ca5e6fa8516b1a701aeb525e793372e822dc8b", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_neutron_api.service to /etc/systemd/system/tripleo_neutron_api.service.", 
        "Created symlink from /etc/systemd/system/timers.target.wants/tripleo_neutron_api_healthcheck.timer to /etc/systemd/system/tripleo_neutron_api_healthcheck.timer.", 
        "Created symlink from /etc/systemd/system/tripleo_neutron_api.service.requires/tripleo_neutron_api_healthcheck.timer to /etc/systemd/system/tripleo_neutron_api_healthcheck.timer.", 
        "stdout: c5008e760ebb4f4814b3e0e76548d5bc9e7b9dca8fbec6e4d13050a2f0c63c95", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_heat_api_cfn.service to /etc/systemd/system/tripleo_heat_api_cfn.service.", 
        "Created symlink from /etc/systemd/system/timers.target.wants/tripleo_heat_api_cfn_healthcheck.timer to /etc/systemd/system/tripleo_heat_api_cfn_healthcheck.timer.", 
        "Created symlink from /etc/systemd/system/tripleo_heat_api_cfn.service.requires/tripleo_heat_api_cfn_healthcheck.timer to /etc/systemd/system/tripleo_heat_api_cfn_healthcheck.timer.", 
        "stdout: 5aaf69225d39bd59b5bc2e53e92ee9f4570f4880e551d547bfa63beb9a090872", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_nova_vnc_proxy.service to /etc/systemd/system/tripleo_nova_vnc_proxy.service.", 
        "Created symlink from /etc/systemd/system/timers.target.wants/tripleo_nova_vnc_proxy_healthcheck.timer to /etc/systemd/system/tripleo_nova_vnc_proxy_healthcheck.timer.", 
        "Created symlink from /etc/systemd/system/tripleo_nova_vnc_proxy.service.requires/tripleo_nova_vnc_proxy_healthcheck.timer to /etc/systemd/system/tripleo_nova_vnc_proxy_healthcheck.timer.", 
        "stdout: 8e8a589b7a98b33634e1c591ab2add119a694f707747e86175be6454ffa9bd30", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_nova_placement.service to /etc/systemd/system/tripleo_nova_placement.service.", 
        "Created symlink from /etc/systemd/system/timers.target.wants/tripleo_nova_placement_healthcheck.timer to /etc/systemd/system/tripleo_nova_placement_healthcheck.timer.", 
        "Created symlink from /etc/systemd/system/tripleo_nova_placement.service.requires/tripleo_nova_placement_healthcheck.timer to /etc/systemd/system/tripleo_nova_placement_healthcheck.timer.", 
        "stderr: net_mlx5: cannot load glue library: libibverbs.so.1: cannot open shared object file: No such file or directory", 
        "net_mlx5: cannot initialize PMD due to missing run-time dependency on rdma-core libraries (libibverbs, libmlx5)", 
        "PMD: net_mlx4: cannot load glue library: libibverbs.so.1: cannot open shared object file: No such file or directory", 
        "PMD: net_mlx4: cannot initialize PMD due to missing run-time dependency on rdma-core libraries (libibverbs, libmlx4)", 
        "stdout: 19ae3df539ffa939f4c476ea0f819fb164196f3467f3b0d2773ba3aebf687eea", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_ovn_controller.service to /etc/systemd/system/tripleo_ovn_controller.service.", 
        "Created symlink from /etc/systemd/system/timers.target.wants/tripleo_ovn_controller_healthcheck.timer to /etc/systemd/system/tripleo_ovn_controller_healthcheck.timer.", 
        "Created symlink from /etc/systemd/system/tripleo_ovn_controller.service.requires/tripleo_ovn_controller_healthcheck.timer to /etc/systemd/system/tripleo_ovn_controller_healthcheck.timer.", 
        "stdout: 9984532c5000a34051ff5e5e1b24dd260232338c48e81cd4bf7d09b5727c024f", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_swift_proxy.service to /etc/systemd/system/tripleo_swift_proxy.service.", 
        "Created symlink from /etc/systemd/system/timers.target.wants/tripleo_swift_proxy_healthcheck.timer to /etc/systemd/system/tripleo_swift_proxy_healthcheck.timer.", 
        "Created symlink from /etc/systemd/system/tripleo_swift_proxy.service.requires/tripleo_swift_proxy_healthcheck.timer to /etc/systemd/system/tripleo_swift_proxy_healthcheck.timer.", 
        "stdout: efec8366c26b00c2db488bf547d4a2713baf8f2a301026b75a7e8e41c8a504a5", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_glance_api.service to /etc/systemd/system/tripleo_glance_api.service.", 
        "Created symlink from /etc/systemd/system/timers.target.wants/tripleo_glance_api_healthcheck.timer to /etc/systemd/system/tripleo_glance_api_healthcheck.timer.", 
        "Created symlink from /etc/systemd/system/tripleo_glance_api.service.requires/tripleo_glance_api_healthcheck.timer to /etc/systemd/system/tripleo_glance_api_healthcheck.timer.", 
        "stdout: 6e550c858c45cc62c936f5a7e5972e0599bfb4c654cdb4aebfb6d0e7d4adbc6f", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_nova_api.service to /etc/systemd/system/tripleo_nova_api.service.", 
        "Created symlink from /etc/systemd/system/timers.target.wants/tripleo_nova_api_healthcheck.timer to /etc/systemd/system/tripleo_nova_api_healthcheck.timer.", 
        "Created symlink from /etc/systemd/system/tripleo_nova_api.service.requires/tripleo_nova_api_healthcheck.timer to /etc/systemd/system/tripleo_nova_api_healthcheck.timer.", 
        "stdout: ec30375a291720a00bb7ea1dd82bcf305a09d61d35bcfcc8b460fa5f27d735d6", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_nova_metadata.service to /etc/systemd/system/tripleo_nova_metadata.service.", 
        "Created symlink from /etc/systemd/system/timers.target.wants/tripleo_nova_metadata_healthcheck.timer to /etc/systemd/system/tripleo_nova_metadata_healthcheck.timer.", 
        "Created symlink from /etc/systemd/system/tripleo_nova_metadata.service.requires/tripleo_nova_metadata_healthcheck.timer to /etc/systemd/system/tripleo_nova_metadata_healthcheck.timer.", 
        "stdout: 5e466fb9d6a2f22f8eb189d67aef6438560f305289bc7e9d945509846b469328", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_panko_api.service to /etc/systemd/system/tripleo_panko_api.service.", 
        "Created symlink from /etc/systemd/system/timers.target.wants/tripleo_panko_api_healthcheck.timer to /etc/systemd/system/tripleo_panko_api_healthcheck.timer.", 
        "Created symlink from /etc/systemd/system/tripleo_panko_api.service.requires/tripleo_panko_api_healthcheck.timer to /etc/systemd/system/tripleo_panko_api_healthcheck.timer.", 
        "stdout: bb2b9ff558e55e59e074cd0263db719a9bb250dc5f8df9d8afbecebcb7f605b9", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_ovn_northd.service to /etc/systemd/system/tripleo_ovn_northd.service.", 
        "Created symlink from /etc/systemd/system/timers.target.wants/tripleo_ovn_northd_healthcheck.timer to /etc/systemd/system/tripleo_ovn_northd_healthcheck.timer.", 
        "Created symlink from /etc/systemd/system/tripleo_ovn_northd.service.requires/tripleo_ovn_northd_healthcheck.timer to /etc/systemd/system/tripleo_ovn_northd_healthcheck.timer."
    ]
}
2019-06-05 14:20:27,444 p=17240 u=mistral |  ok: [lab-computehci-0] => {
    "failed_when_result": false, 
    "outputs.stdout_lines | default([]) | union(outputs.stderr_lines | default([]))": [
        "stdout: b016581646a97e0fcb1248e96aeb01123ba6353de92e155354d50903ba94b296", 
        "", 
        "stderr: Trying to pull docker://docker.io/tripleostein/centos-binary-ceilometer-compute:current-tripleo-rdo...Getting image source signatures", 
        "Copying blob sha256:a35613cff6f04cbfd2f3b845d5a923d56d6f2fb718f85784e8fdcd97ae77846e", 
        "Copying blob sha256:0f2be6d2e8e6e42cb3e633544d0b1aa8328bd7004a3a4b1dfc0c7a6ba14cd0c7", 
        "Copying blob sha256:31c8fa1ceee01b746a6b64c4718f5e42e867c08532b29f8d33626a8385327ede", 
        "Copying blob sha256:8ba884070f611d31cb2c42eddb691319dc9facf5e0ec67672fcfa135181ab3df", 
        "Copying blob sha256:5b8f702199c16fd0d5c9c4d0028550b144acb532f4a6b8200b3f53e1cbc43aba", 
        "Copying blob sha256:c0862342b9e7a81856422b95348a2d1952b46e01df6c72f74d94cac2c5815c51", 
        "Copying blob sha256:0fc1fd86055457f85a0cb3f333292570aaa2803c4b556966847f55f8f3544fa8", 
        "Copying blob sha256:46d3c6aa676de9a0ee74cfac77cced69fb7a4df7c5b9e8a7ef33922881d87c81", 
        "Copying blob sha256:fc3b29499fda939e998b0c14c6e98720e1cb7a66fd1ce884cad8d64a63669cf4", 
        "Copying blob sha256:d6dbd69ea530292192935158b778ccffc396ead2093138f75c6e1fa33b7a17fa", 
        "Copying blob sha256:6310d6ac1536a2eb8e769d217451e2c6d420eb3c39b0fb1b9ad088a73ea67211", 
        "Copying blob sha256:c80c3921174be89bdd60d2454983524a19a15b09f26f47b6822e6440d5939973", 
        "Copying blob sha256:2799d99efade4475ca55aad34887eabf4e9ec76e592bc0b0a80cbd8d01080ffc", 
        "Copying blob sha256:921488feccf56d8c8eb6086cd998b48f907fa44dbc5e7cf8525efd96f7c1f776", 
        "Copying blob sha256:2cc44a4e32219b5aad308d7d3bdc5ba18788e8830c0cf3aa9056e1d0dc647058", 
        "Copying blob sha256:d36b87fd0812d0e39ef92e729105260f496efbfb19ad7b6981218862502aa0f3", 
        "Copying blob sha256:5b89a36d5e9e14c5ac5981e8ed2304bb8ce19da7d91793f44c48ac17e7b03717", 
        "Copying blob sha256:98d5e2479617c862dcad487a2c52021bc16e516ebafe9fdab6b3eb8648b73f57", 
        "Copying blob sha256:bd6e2c36ff0e45e35121c3bc2cb54f803eb809aacb2778260d4211de2ba9fabb", 
        "Copying blob sha256:f68d231cf9d36f0c6d1381c301b6afe0d2450100d736078b83c7891c513f6da0", 
        "Copying blob sha256:e262843cdaf24781dce31bdcdee7c4f4b4be29e4ef40215d73e2179608590dfd", 
        "Copying blob sha256:7971653943cd097a7807d1f3e029791a226ea79c01560ae7168efea6e683f431", 
        "Copying blob sha256:43af3b756ca1ae55bd452e50e5a8bac8b1f4791a9ca3dfa71edf28a754ab34b7", 
        "Copying blob sha256:e916b8a446f9ff8e13f7398ccca737459243baf513a8c1e81edbac2f653c3e6b", 
        "Copying blob sha256:ccae8e3351ac86f5c7d66e9c84321057c9f05063428851fa0f1c17946090212d", 
        "Copying blob sha256:89c8d96f0d37376ba1f54c92128660aaea0a802cb9d9d396a45366b02fc589cc", 
        "Copying blob sha256:45d804df81db3a3f58373c31a92eb2484c2b9038ec59d86fed68b6ce62565939", 
        "Copying blob sha256:343f9f42dd124dbd53b97d676c7702f6308aa52ad4e28983f1aa15f733d48213", 
        "Copying blob sha256:2d01a0974751fc9cc1065451e7b098858b0da5e16027ae2e982b73e0d98e6db7", 
        "Copying blob sha256:db14d426f79b93edeabaed84076b9eb5d44a91971a58ab5919c86dea5401c3b3", 
        "Copying config sha256:b016581646a97e0fcb1248e96aeb01123ba6353de92e155354d50903ba94b296", 
        "Writing manifest to image destination", 
        "Storing signatures", 
        "stdout: b4349651cac4c16828616286150cc38674b43cda1888cb7570cdea2aa4494c68", 
        "stderr: ", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_ceilometer_agent_compute.service to /etc/systemd/system/tripleo_ceilometer_agent_compute.service.", 
        "Created symlink from /etc/systemd/system/timers.target.wants/tripleo_ceilometer_agent_compute_healthcheck.timer to /etc/systemd/system/tripleo_ceilometer_agent_compute_healthcheck.timer.", 
        "Created symlink from /etc/systemd/system/tripleo_ceilometer_agent_compute.service.requires/tripleo_ceilometer_agent_compute_healthcheck.timer to /etc/systemd/system/tripleo_ceilometer_agent_compute_healthcheck.timer.", 
        "stdout: Secret 473c3318-87c3-11e9-861d-5254009e1c0e created", 
        "Secret value set", 
        "stdout: b0773366fe5132d1c97d68647d64505e8c4255c5b9588254cd0abcc5ca619891", 
        "stderr: WARNING: The same type, major and minor should not be used for multiple devices.", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_nova_migration_target.service to /etc/systemd/system/tripleo_nova_migration_target.service.", 
        "Created symlink from /etc/systemd/system/timers.target.wants/tripleo_nova_migration_target_healthcheck.timer to /etc/systemd/system/tripleo_nova_migration_target_healthcheck.timer.", 
        "Created symlink from /etc/systemd/system/tripleo_nova_migration_target.service.requires/tripleo_nova_migration_target_healthcheck.timer to /etc/systemd/system/tripleo_nova_migration_target_healthcheck.timer.", 
        "stdout: ", 
        "stdout: Info: Loading facts", 
        "Info: Loading facts", 
        "Notice: Compiled catalog for lab-computehci-0.localdomain in environment production in 0.78 seconds", 
        "Info: Applying configuration version '1559762347'", 
        "Notice: /Stage[main]/Neutron::Agents::Ovn_metadata/Exec[Set OVS Manager]/returns: executed successfully", 
        "Info: /Stage[main]/Neutron::Agents::Ovn_metadata/Exec[Set OVS Manager]: Scheduling refresh of Service[ovn-metadata]", 
        "Info: /Stage[main]/Neutron::Agents::Ovn_metadata/Service[ovn-metadata]: Unscheduling all events on Service[ovn-metadata]", 
        "Info: Class[Neutron::Agents::Ovn_metadata]: Unscheduling all events on Class[Neutron::Agents::Ovn_metadata]", 
        "Info: Creating state file /var/lib/puppet/state/state.yaml", 
        "Notice: Applied catalog in 0.14 seconds", 
        "Changes:", 
        "            Total: 1", 
        "Events:", 
        "          Success: 1", 
        "Resources:", 
        "          Changed: 1", 
        "      Out of sync: 1", 
        "          Skipped: 143", 
        "            Total: 144", 
        "Time:", 
        "             Exec: 0.06", 
        "   Transaction evaluation: 0.14", 
        "   Catalog application: 0.14", 
        "   Config retrieval: 0.88", 
        "         Last run: 1559762348", 
        "            Total: 0.14", 
        "Version:", 
        "           Config: 1559762347", 
        "           Puppet: 5.5.10", 
        "+ STEP=4", 
        "+ TAGS=exec", 
        "+ CONFIG='include ::tripleo::profile::base::neutron::ovn_metadata'", 
        "+ EXTRA_ARGS=", 
        "+ '[' -d /tmp/puppet-etc ']'", 
        "+ cp -a /tmp/puppet-etc/auth.conf /tmp/puppet-etc/hiera.yaml /tmp/puppet-etc/hieradata /tmp/puppet-etc/modules /tmp/puppet-etc/puppet.conf /tmp/puppet-etc/ssl /etc/puppet", 
        "+ echo '{\"step\": 4}'", 
        "+ export FACTER_deployment_type=containers", 
        "+ FACTER_deployment_type=containers", 
        "+ set +e", 
        "+ puppet apply --verbose --detailed-exitcodes --summarize --color=false --modulepath /etc/puppet/modules:/opt/stack/puppet-modules:/usr/share/openstack-puppet/modules --tags exec -e 'noop_resource('\\''package'\\''); include ::tripleo::profile::base::neutron::ovn_metadata'", 
        "Warning: Support for ruby version 2.0.0 is deprecated and will be removed in a future release. See https://puppet.com/docs/puppet/latest/system_requirements.html for a list of supported ruby versions.", 
        "   (location: /usr/share/ruby/vendor_ruby/puppet.rb:130:in `<module:Puppet>')", 
        "net_mlx5: cannot load glue library: libibverbs.so.1: cannot open shared object file: No such file or directory", 
        "net_mlx5: cannot initialize PMD due to missing run-time dependency on rdma-core libraries (libibverbs, libmlx5)", 
        "PMD: net_mlx4: cannot load glue library: libibverbs.so.1: cannot open shared object file: No such file or directory", 
        "PMD: net_mlx4: cannot initialize PMD due to missing run-time dependency on rdma-core libraries (libibverbs, libmlx4)", 
        "Warning: ModuleLoader: module 'tripleo' has unresolved dependencies - it will only see those that are resolved. Use 'puppet module list --tree' to see information about modules\\n   (file & line not available)", 
        "Warning: /etc/puppet/hiera.yaml: Use of 'hiera.yaml' version 3 is deprecated. It should be converted to version 5", 
        "   (file: /etc/puppet/hiera.yaml)", 
        "Warning: Undefined variable '::deploy_config_name'; \\n   (file & line not available)", 
        "Warning: The function 'hiera' is deprecated in favor of using 'lookup'. See https://puppet.com/docs/puppet/5.5/deprecated_language.html\\n   (file & line not available)", 
        "Warning: ModuleLoader: module 'openstacklib' has unresolved dependencies - it will only see those that are resolved. Use 'puppet module list --tree' to see information about modules\\n   (file & line not available)", 
        "Warning: Unknown variable: 'dhcp_agents_per_net'. (file: /etc/puppet/modules/tripleo/manifests/profile/base/neutron.pp, line: 154, column: 37)", 
        "Warning: ModuleLoader: module 'neutron' has unresolved dependencies - it will only see those that are resolved. Use 'puppet module list --tree' to see information about modules\\n   (file & line not available)", 
        "Warning: This method is deprecated, please use match expressions with Stdlib::Compat::Array instead. They are described at https://docs.puppet.com/puppet/latest/reference/lang_data_type.html#match-expressions. at [\"/etc/puppet/modules/neutron/manifests/init.pp\", 470]:[\"/etc/puppet/modules/tripleo/manifests/profile/base/neutron/ovn_metadata.pp\", 40]", 
        "   (location: /etc/puppet/modules/stdlib/lib/puppet/functions/deprecation.rb:28:in `deprecation')", 
        "+ rc=2", 
        "+ set -e", 
        "+ set +ux", 
        "stdout: 61e45a2abf8915cddf3341eabc70ed99f48ef82835871bc70ffa3fd1e9afcebe", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_logrotate_crond.service to /etc/systemd/system/tripleo_logrotate_crond.service.", 
        "Created symlink from /etc/systemd/system/timers.target.wants/tripleo_logrotate_crond_healthcheck.timer to /etc/systemd/system/tripleo_logrotate_crond_healthcheck.timer.", 
        "Created symlink from /etc/systemd/system/tripleo_logrotate_crond.service.requires/tripleo_logrotate_crond_healthcheck.timer to /etc/systemd/system/tripleo_logrotate_crond_healthcheck.timer.", 
        "stdout: 9841fc29d47ac026bded76bd9a48dca406e076a9c69bd1646f2da2da1cc3f49f", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_ovn_metadata_agent.service to /etc/systemd/system/tripleo_ovn_metadata_agent.service.", 
        "Created symlink from /etc/systemd/system/timers.target.wants/tripleo_ovn_metadata_agent_healthcheck.timer to /etc/systemd/system/tripleo_ovn_metadata_agent_healthcheck.timer.", 
        "Created symlink from /etc/systemd/system/tripleo_ovn_metadata_agent.service.requires/tripleo_ovn_metadata_agent_healthcheck.timer to /etc/systemd/system/tripleo_ovn_metadata_agent_healthcheck.timer.", 
        "stdout: fb48b7eed543caa47af5680546a1afb2724dc5c2611afc113593fb3250d1c603", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_ovn_controller.service to /etc/systemd/system/tripleo_ovn_controller.service.", 
        "Created symlink from /etc/systemd/system/timers.target.wants/tripleo_ovn_controller_healthcheck.timer to /etc/systemd/system/tripleo_ovn_controller_healthcheck.timer.", 
        "Created symlink from /etc/systemd/system/tripleo_ovn_controller.service.requires/tripleo_ovn_controller_healthcheck.timer to /etc/systemd/system/tripleo_ovn_controller_healthcheck.timer.", 
        "stdout: INFO:nova_wait_for_placement_service:response - <Response [503]>", 
        "INFO:nova_wait_for_placement_service:Placement service not up - 503, <html><body><h1>503 Service Unavailable</h1>", 
        "No server is available to handle this request.", 
        "</body></html>", 
        "INFO:nova_wait_for_placement_service:response - <Response [503]>", 
        "INFO:nova_wait_for_placement_service:Placement service up! - {\"versions\": [{\"status\": \"CURRENT\", \"min_version\": \"1.0\", \"max_version\": \"1.30\", \"id\": \"v1.0\", \"links\": [{\"href\": \"\", \"rel\": \"self\"}]}]}", 
        "stderr: + command -v python3", 
        "+ command -v python2", 
        "+ python2 /container-config-scripts/nova_wait_for_placement_service.py", 
        "stdout: e685655544eb58c3830263e07cfae76593713de912aceb6d352cd1e9d45309fc", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_nova_compute.service to /etc/systemd/system/tripleo_nova_compute.service.", 
        "Created symlink from /etc/systemd/system/timers.target.wants/tripleo_nova_compute_healthcheck.timer to /etc/systemd/system/tripleo_nova_compute_healthcheck.timer.", 
        "Created symlink from /etc/systemd/system/tripleo_nova_compute.service.requires/tripleo_nova_compute_healthcheck.timer to /etc/systemd/system/tripleo_nova_compute_healthcheck.timer.", 
        "stdout: ERROR:nova_wait_for_compute_service:Error while waiting for nova-compute service to register", 
        "Traceback (most recent call last):", 
        "  File \"/container-config-scripts/nova_wait_for_compute_service.py\", line 102, in <module>", 
        "    service_list = nova.services.list(binary='nova-compute')", 
        "  File \"/usr/lib/python2.7/site-packages/novaclient/v2/services.py\", line 52, in list", 
        "    return self._list(url, \"services\")", 
        "  File \"/usr/lib/python2.7/site-packages/novaclient/base.py\", line 254, in _list", 
        "    resp, body = self.api.client.get(url)", 
        "  File \"/usr/lib/python2.7/site-packages/keystoneauth1/adapter.py\", line 375, in get", 
        "    return self.request(url, 'GET', **kwargs)", 
        "  File \"/usr/lib/python2.7/site-packages/novaclient/client.py\", line 78, in request", 
        "    raise exceptions.from_response(resp, body, url, method)", 
        "ClientException: Unknown Error (HTTP 503)", 
        "INFO:nova_wait_for_compute_service:Nova-compute service registered", 
        "+ python2 /container-config-scripts/nova_wait_for_compute_service.py"
    ]
}
2019-06-05 14:20:27,469 p=17240 u=mistral |  TASK [Clean container_puppet_tasks for lab-controller-0 step 4] ****************
2019-06-05 14:20:27,469 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:520
2019-06-05 14:20:27,469 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:27 -0500 (0:00:00.076)       0:17:01.238 ******** 
2019-06-05 14:20:27,601 p=17240 u=mistral |  ok: [lab-controller-0] => {"changed": false, "path": "/var/lib/container-puppet/container-puppet-tasks4.json", "state": "absent"}
2019-06-05 14:20:27,607 p=17240 u=mistral |  ok: [lab-computehci-0] => {"changed": false, "path": "/var/lib/container-puppet/container-puppet-tasks4.json", "state": "absent"}
2019-06-05 14:20:27,633 p=17240 u=mistral |  TASK [Calculate container_puppet_tasks for lab-controller-0 step 4] ************
2019-06-05 14:20:27,633 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:527
2019-06-05 14:20:27,633 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:27 -0500 (0:00:00.164)       0:17:01.402 ******** 
2019-06-05 14:20:27,673 p=17240 u=mistral |  ok: [lab-controller-0] => (item={'puppet_tags': u'cinder_config,cinder_type,file,concat,file_line', 'config_volume': u'cinder_init_tasks', 'config_image': u'docker.io/tripleostein/centos-binary-cinder-api:current-tripleo-rdo', 'volumes': [u'/var/lib/config-data/cinder/etc/cinder/:/etc/cinder/:ro'], 'service_name': u'cinder_api', 'step_config': u'include ::tripleo::profile::base::cinder::api'}) => {"ansible_facts": {"host_container_puppet_tasks": [{"config_image": "docker.io/tripleostein/centos-binary-mariadb:current-tripleo-rdo", "config_volume": "mysql_init_tasks", "puppet_tags": "mysql_database,mysql_grant,mysql_user", "service_name": "mysql", "step_config": "include ::tripleo::profile::base::database::mysql", "volumes": ["/var/lib/mysql:/var/lib/mysql/:rw", "/var/log/containers/mysql:/var/log/mariadb", "/var/lib/config-data/puppet-generated/mysql/root:/root:rw"]}, {"config_image": "docker.io/tripleostein/centos-binary-rabbitmq:current-tripleo-rdo", "config_volume": "rabbit_init_tasks", "puppet_tags": "rabbitmq_policy,rabbitmq_user", "service_name": "oslo_messaging_rpc", "step_config": "include ::tripleo::profile::base::rabbitmq", "volumes": ["/var/lib/config-data/rabbitmq/etc/rabbitmq/:/etc/rabbitmq/:ro", "/var/lib/rabbitmq:/var/lib/rabbitmq:z"]}, {"config_image": "docker.io/tripleostein/centos-binary-keystone:current-tripleo-rdo", "config_volume": "keystone_init_tasks", "puppet_tags": "keystone_config,keystone_domain_config,keystone_endpoint,keystone_identity_provider,keystone_paste_ini,keystone_role,keystone_service,keystone_tenant,keystone_user,keystone_user_role,keystone_domain", "service_name": "keystone", "step_config": "include ::tripleo::profile::base::keystone"}, {"config_image": "docker.io/tripleostein/centos-binary-cinder-api:current-tripleo-rdo", "config_volume": "cinder_init_tasks", "puppet_tags": "cinder_config,cinder_type,file,concat,file_line", "service_name": "cinder_api", "step_config": "include ::tripleo::profile::base::cinder::api", "volumes": ["/var/lib/config-data/cinder/etc/cinder/:/etc/cinder/:ro"]}]}, "changed": false, "item": {"config_image": "docker.io/tripleostein/centos-binary-cinder-api:current-tripleo-rdo", "config_volume": "cinder_init_tasks", "puppet_tags": "cinder_config,cinder_type,file,concat,file_line", "service_name": "cinder_api", "step_config": "include ::tripleo::profile::base::cinder::api", "volumes": ["/var/lib/config-data/cinder/etc/cinder/:/etc/cinder/:ro"]}}
2019-06-05 14:20:27,705 p=17240 u=mistral |  TASK [Write container-puppet-tasks json file for lab-controller-0 step 4] ******
2019-06-05 14:20:27,705 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:537
2019-06-05 14:20:27,705 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:27 -0500 (0:00:00.071)       0:17:01.474 ******** 
2019-06-05 14:20:27,745 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:27,999 p=17240 u=mistral |  changed: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:20:28,024 p=17240 u=mistral |  TASK [Run container-puppet tasks (bootstrap tasks) for step 4] *****************
2019-06-05 14:20:28,024 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:548
2019-06-05 14:20:28,024 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:28 -0500 (0:00:00.319)       0:17:01.793 ******** 
2019-06-05 14:20:28,065 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:43,430 p=17240 u=mistral |  ok: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:43,455 p=17240 u=mistral |  TASK [Debug output for task: Run container-puppet tasks (bootstrap tasks) for step 4] ***
2019-06-05 14:20:43,455 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:567
2019-06-05 14:20:43,455 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:43 -0500 (0:00:15.430)       0:17:17.224 ******** 
2019-06-05 14:20:43,486 p=17240 u=mistral |  ok: [lab-controller-0] => {
    "failed_when_result": false, 
    "outputs.stdout_lines | default([]) | union(outputs.stderr_lines | default([]))": [
        "2019-06-05 19:20:28,278 INFO: 74600 -- Running container-puppet", 
        "2019-06-05 19:20:28,278 INFO: 74600 -- Service compilation completed.", 
        "2019-06-05 19:20:28,279 INFO: 74600 -- Starting multiprocess configuration steps.  Using 4 processes.", 
        "2019-06-05 19:20:28,284 INFO: 74603 -- Starting configuration of mysql_init_tasks using image docker.io/tripleostein/centos-binary-mariadb:current-tripleo-rdo", 
        "2019-06-05 19:20:28,285 INFO: 74604 -- Starting configuration of cinder_init_tasks using image docker.io/tripleostein/centos-binary-cinder-api:current-tripleo-rdo", 
        "2019-06-05 19:20:28,287 INFO: 74605 -- Starting configuration of rabbit_init_tasks using image docker.io/tripleostein/centos-binary-rabbitmq:current-tripleo-rdo", 
        "2019-06-05 19:20:28,287 INFO: 74606 -- Starting configuration of keystone_init_tasks using image docker.io/tripleostein/centos-binary-keystone:current-tripleo-rdo", 
        "2019-06-05 19:20:28,533 INFO: 74606 -- Removing container: container-puppet-keystone_init_tasks", 
        "2019-06-05 19:20:28,606 INFO: 74604 -- Removing container: container-puppet-cinder_init_tasks", 
        "2019-06-05 19:20:28,608 INFO: 74603 -- Removing container: container-puppet-mysql_init_tasks", 
        "2019-06-05 19:20:28,819 INFO: 74605 -- Removing container: container-puppet-rabbit_init_tasks", 
        "2019-06-05 19:20:29,187 INFO: 74603 -- Image already exists: docker.io/tripleostein/centos-binary-mariadb:current-tripleo-rdo", 
        "2019-06-05 19:20:29,191 INFO: 74605 -- Image already exists: docker.io/tripleostein/centos-binary-rabbitmq:current-tripleo-rdo", 
        "2019-06-05 19:20:29,192 INFO: 74606 -- Image already exists: docker.io/tripleostein/centos-binary-keystone:current-tripleo-rdo", 
        "2019-06-05 19:20:29,203 INFO: 74604 -- Image already exists: docker.io/tripleostein/centos-binary-cinder-api:current-tripleo-rdo", 
        "2019-06-05 19:20:39,091 WARNING: 74606 -- + mkdir -p /etc/puppet", 
        "+ cp -dR /tmp/puppet-etc/auth.conf /tmp/puppet-etc/hiera.yaml /tmp/puppet-etc/hieradata /tmp/puppet-etc/modules /tmp/puppet-etc/puppet.conf /tmp/puppet-etc/ssl /etc/puppet", 
        "+ rm -Rf /etc/puppet/ssl", 
        "+ echo '{\"step\": 4}'", 
        "+ TAGS=", 
        "+ '[' -n file,file_line,concat,augeas,cron,keystone_config,keystone_domain_config,keystone_endpoint,keystone_identity_provider,keystone_paste_ini,keystone_role,keystone_service,keystone_tenant,keystone_user,keystone_user_role,keystone_domain ']'", 
        "+ TAGS='--tags file,file_line,concat,augeas,cron,keystone_config,keystone_domain_config,keystone_endpoint,keystone_identity_provider,keystone_paste_ini,keystone_role,keystone_service,keystone_tenant,keystone_user,keystone_user_role,keystone_domain'", 
        "+ CHECK_MODE=", 
        "+ '[' -d /tmp/puppet-check-mode ']'", 
        "+ origin_of_time=/var/lib/config-data/keystone_init_tasks.origin_of_time", 
        "+ touch /var/lib/config-data/keystone_init_tasks.origin_of_time", 
        "+ sync", 
        "+ export NET_HOST=true", 
        "+ NET_HOST=true", 
        "+ set +e", 
        "+ '[' true == false ']'", 
        "+ export FACTER_deployment_type=containers", 
        "+ FACTER_deployment_type=containers", 
        "++ tr '[:upper:]' '[:lower:]'", 
        "++ cat /sys/class/dmi/id/product_uuid", 
        "+ export FACTER_uuid=ad8c85d9-6f5f-4d90-97fa-e31eefd815d6", 
        "+ FACTER_uuid=ad8c85d9-6f5f-4d90-97fa-e31eefd815d6", 
        "+ /usr/bin/puppet apply --summarize --detailed-exitcodes --color=false --logdest syslog --logdest console --modulepath=/etc/puppet/modules:/usr/share/openstack-puppet/modules --tags file,file_line,concat,augeas,cron,keystone_config,keystone_domain_config,keystone_endpoint,keystone_identity_provider,keystone_paste_ini,keystone_role,keystone_service,keystone_tenant,keystone_user,keystone_user_role,keystone_domain /etc/config.pp", 
        "+ rc=2", 
        "+ set -e", 
        "+ '[' 2 -ne 2 -a 2 -ne 0 ']'", 
        "+ '[' -z true ']'", 
        "", 
        "2019-06-05 19:20:39,092 INFO: 74606 -- Removing container: container-puppet-keystone_init_tasks", 
        "2019-06-05 19:20:39,335 INFO: 74606 -- Finished processing puppet configs for keystone_init_tasks", 
        "2019-06-05 19:20:39,390 WARNING: 74603 -- + mkdir -p /etc/puppet", 
        "+ '[' -n file,file_line,concat,augeas,cron,mysql_database,mysql_grant,mysql_user ']'", 
        "+ TAGS='--tags file,file_line,concat,augeas,cron,mysql_database,mysql_grant,mysql_user'", 
        "+ origin_of_time=/var/lib/config-data/mysql_init_tasks.origin_of_time", 
        "+ touch /var/lib/config-data/mysql_init_tasks.origin_of_time", 
        "+ /usr/bin/puppet apply --summarize --detailed-exitcodes --color=false --logdest syslog --logdest console --modulepath=/etc/puppet/modules:/usr/share/openstack-puppet/modules --tags file,file_line,concat,augeas,cron,mysql_database,mysql_grant,mysql_user /etc/config.pp", 
        "2019-06-05 19:20:39,390 INFO: 74603 -- Removing container: container-puppet-mysql_init_tasks", 
        "2019-06-05 19:20:39,565 INFO: 74603 -- Finished processing puppet configs for mysql_init_tasks", 
        "2019-06-05 19:20:40,884 WARNING: 74605 -- + mkdir -p /etc/puppet", 
        "+ '[' -n file,file_line,concat,augeas,cron,rabbitmq_policy,rabbitmq_user ']'", 
        "+ TAGS='--tags file,file_line,concat,augeas,cron,rabbitmq_policy,rabbitmq_user'", 
        "+ origin_of_time=/var/lib/config-data/rabbit_init_tasks.origin_of_time", 
        "+ touch /var/lib/config-data/rabbit_init_tasks.origin_of_time", 
        "+ /usr/bin/puppet apply --summarize --detailed-exitcodes --color=false --logdest syslog --logdest console --modulepath=/etc/puppet/modules:/usr/share/openstack-puppet/modules --tags file,file_line,concat,augeas,cron,rabbitmq_policy,rabbitmq_user /etc/config.pp", 
        "2019-06-05 19:20:40,885 INFO: 74605 -- Removing container: container-puppet-rabbit_init_tasks", 
        "2019-06-05 19:20:41,017 INFO: 74605 -- Finished processing puppet configs for rabbit_init_tasks", 
        "2019-06-05 19:20:43,169 WARNING: 74604 -- + mkdir -p /etc/puppet", 
        "+ '[' -n file,file_line,concat,augeas,cron,cinder_config,cinder_type,file,concat,file_line ']'", 
        "+ TAGS='--tags file,file_line,concat,augeas,cron,cinder_config,cinder_type,file,concat,file_line'", 
        "+ origin_of_time=/var/lib/config-data/cinder_init_tasks.origin_of_time", 
        "+ touch /var/lib/config-data/cinder_init_tasks.origin_of_time", 
        "+ /usr/bin/puppet apply --summarize --detailed-exitcodes --color=false --logdest syslog --logdest console --modulepath=/etc/puppet/modules:/usr/share/openstack-puppet/modules --tags file,file_line,concat,augeas,cron,cinder_config,cinder_type,file,concat,file_line /etc/config.pp", 
        "2019-06-05 19:20:43,169 INFO: 74604 -- Removing container: container-puppet-cinder_init_tasks", 
        "2019-06-05 19:20:43,318 INFO: 74604 -- Finished processing puppet configs for cinder_init_tasks"
    ]
}
2019-06-05 14:20:43,497 p=17240 u=mistral |  skipping: [lab-computehci-0] => {}
2019-06-05 14:20:43,498 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:20:43,498 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:20:43,502 p=17240 u=mistral |  PLAY [External deployment step 5] **********************************************
2019-06-05 14:20:43,508 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:20:43,521 p=17240 u=mistral |  TASK [set blacklisted_hostnames] ***********************************************
2019-06-05 14:20:43,521 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:2
2019-06-05 14:20:43,522 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:43 -0500 (0:00:00.066)       0:17:17.291 ******** 
2019-06-05 14:20:43,533 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:43,547 p=17240 u=mistral |  TASK [create ceph-ansible temp dirs] *******************************************
2019-06-05 14:20:43,548 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:5
2019-06-05 14:20:43,548 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:43 -0500 (0:00:00.026)       0:17:17.317 ******** 
2019-06-05 14:20:43,565 p=17240 u=mistral |  skipping: [undercloud] => (item=/var/lib/mistral/lab/ceph-ansible)  => {"changed": false, "item": "/var/lib/mistral/lab/ceph-ansible", "skip_reason": "Conditional result was False"}
2019-06-05 14:20:43,569 p=17240 u=mistral |  skipping: [undercloud] => (item=/var/lib/mistral/lab/ceph-ansible/group_vars)  => {"changed": false, "item": "/var/lib/mistral/lab/ceph-ansible/group_vars", "skip_reason": "Conditional result was False"}
2019-06-05 14:20:43,572 p=17240 u=mistral |  skipping: [undercloud] => (item=/var/lib/mistral/lab/ceph-ansible/host_vars)  => {"changed": false, "item": "/var/lib/mistral/lab/ceph-ansible/host_vars", "skip_reason": "Conditional result was False"}
2019-06-05 14:20:43,575 p=17240 u=mistral |  skipping: [undercloud] => (item=/var/lib/mistral/lab/ceph-ansible/fetch_dir)  => {"changed": false, "item": "/var/lib/mistral/lab/ceph-ansible/fetch_dir", "skip_reason": "Conditional result was False"}
2019-06-05 14:20:43,590 p=17240 u=mistral |  TASK [generate inventory] ******************************************************
2019-06-05 14:20:43,590 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:16
2019-06-05 14:20:43,590 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:43 -0500 (0:00:00.042)       0:17:17.360 ******** 
2019-06-05 14:20:43,602 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:43,616 p=17240 u=mistral |  TASK [set ceph-ansible group vars all] *****************************************
2019-06-05 14:20:43,616 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:30
2019-06-05 14:20:43,617 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:43 -0500 (0:00:00.026)       0:17:17.386 ******** 
2019-06-05 14:20:43,629 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:43,643 p=17240 u=mistral |  TASK [generate ceph-ansible group vars all] ************************************
2019-06-05 14:20:43,643 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:139
2019-06-05 14:20:43,644 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:43 -0500 (0:00:00.027)       0:17:17.413 ******** 
2019-06-05 14:20:43,655 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:43,670 p=17240 u=mistral |  TASK [set ceph-ansible extra vars] *********************************************
2019-06-05 14:20:43,670 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:143
2019-06-05 14:20:43,670 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:43 -0500 (0:00:00.026)       0:17:17.439 ******** 
2019-06-05 14:20:43,682 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:43,696 p=17240 u=mistral |  TASK [generate ceph-ansible extra vars] ****************************************
2019-06-05 14:20:43,697 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:150
2019-06-05 14:20:43,697 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:43 -0500 (0:00:00.026)       0:17:17.466 ******** 
2019-06-05 14:20:43,709 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:43,723 p=17240 u=mistral |  TASK [generate nodes-uuid data file] *******************************************
2019-06-05 14:20:43,723 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:154
2019-06-05 14:20:43,724 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:43 -0500 (0:00:00.026)       0:17:17.493 ******** 
2019-06-05 14:20:43,735 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:43,749 p=17240 u=mistral |  TASK [generate nodes-uuid playbook] ********************************************
2019-06-05 14:20:43,749 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:158
2019-06-05 14:20:43,749 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:43 -0500 (0:00:00.025)       0:17:17.519 ******** 
2019-06-05 14:20:43,762 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:43,776 p=17240 u=mistral |  TASK [detect private key file] *************************************************
2019-06-05 14:20:43,776 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:179
2019-06-05 14:20:43,776 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:43 -0500 (0:00:00.026)       0:17:17.545 ******** 
2019-06-05 14:20:43,787 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:43,802 p=17240 u=mistral |  TASK [set private key file] ****************************************************
2019-06-05 14:20:43,802 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:183
2019-06-05 14:20:43,803 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:43 -0500 (0:00:00.026)       0:17:17.572 ******** 
2019-06-05 14:20:43,814 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:43,828 p=17240 u=mistral |  TASK [run nodes-uuid] **********************************************************
2019-06-05 14:20:43,829 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:187
2019-06-05 14:20:43,829 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:43 -0500 (0:00:00.026)       0:17:17.598 ******** 
2019-06-05 14:20:43,841 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:43,855 p=17240 u=mistral |  TASK [set ceph-ansible params from Heat] ***************************************
2019-06-05 14:20:43,855 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:195
2019-06-05 14:20:43,855 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:43 -0500 (0:00:00.026)       0:17:17.624 ******** 
2019-06-05 14:20:43,869 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:43,885 p=17240 u=mistral |  TASK [set ceph-ansible playbooks] **********************************************
2019-06-05 14:20:43,886 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:200
2019-06-05 14:20:43,886 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:43 -0500 (0:00:00.030)       0:17:17.655 ******** 
2019-06-05 14:20:43,897 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:43,913 p=17240 u=mistral |  TASK [was path for local ceph-ansible fetch directory backups set?] ************
2019-06-05 14:20:43,913 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:205
2019-06-05 14:20:43,913 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:43 -0500 (0:00:00.027)       0:17:17.683 ******** 
2019-06-05 14:20:43,925 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:43,939 p=17240 u=mistral |  TASK [look for requested ceph-ansible fetch directory for local backup] ********
2019-06-05 14:20:43,940 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:210
2019-06-05 14:20:43,940 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:43 -0500 (0:00:00.026)       0:17:17.709 ******** 
2019-06-05 14:20:43,951 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:43,966 p=17240 u=mistral |  TASK [autocreate new directory for ceph-ansible fetch directory backup] ********
2019-06-05 14:20:43,966 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:214
2019-06-05 14:20:43,966 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:43 -0500 (0:00:00.026)       0:17:17.736 ******** 
2019-06-05 14:20:43,978 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:43,993 p=17240 u=mistral |  TASK [look for tarball of ceph-ansible fetch directory in local backup] ********
2019-06-05 14:20:43,993 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:222
2019-06-05 14:20:43,993 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:43 -0500 (0:00:00.026)       0:17:17.762 ******** 
2019-06-05 14:20:44,005 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:44,019 p=17240 u=mistral |  TASK [untar local backup of ceph-ansible fetch directory] **********************
2019-06-05 14:20:44,019 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:226
2019-06-05 14:20:44,019 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:44 -0500 (0:00:00.026)       0:17:17.789 ******** 
2019-06-05 14:20:44,031 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:44,046 p=17240 u=mistral |  TASK [set facts for swift back up of ceph-ansible fetch directory] *************
2019-06-05 14:20:44,046 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:232
2019-06-05 14:20:44,046 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:44 -0500 (0:00:00.027)       0:17:17.816 ******** 
2019-06-05 14:20:44,058 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:44,073 p=17240 u=mistral |  TASK [attempt download of fetch directory tarball from swift backup] ***********
2019-06-05 14:20:44,073 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:238
2019-06-05 14:20:44,073 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:44 -0500 (0:00:00.026)       0:17:17.842 ******** 
2019-06-05 14:20:44,085 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:44,099 p=17240 u=mistral |  TASK [ensure we create a new fetch_directory or use the old fetch_directory] ***
2019-06-05 14:20:44,099 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:243
2019-06-05 14:20:44,100 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:44 -0500 (0:00:00.026)       0:17:17.869 ******** 
2019-06-05 14:20:44,112 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:44,126 p=17240 u=mistral |  TASK [unpack downloaded ceph-ansible fetch tarball to fetch directory] *********
2019-06-05 14:20:44,126 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:251
2019-06-05 14:20:44,126 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:44 -0500 (0:00:00.026)       0:17:17.895 ******** 
2019-06-05 14:20:44,137 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:44,152 p=17240 u=mistral |  TASK [remove downloaded ceph-ansible fetch directory tarball from filesystem] ***
2019-06-05 14:20:44,152 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:257
2019-06-05 14:20:44,152 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:44 -0500 (0:00:00.026)       0:17:17.922 ******** 
2019-06-05 14:20:44,164 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:44,178 p=17240 u=mistral |  TASK [set ceph-ansible command] ************************************************
2019-06-05 14:20:44,179 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:265
2019-06-05 14:20:44,179 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:44 -0500 (0:00:00.026)       0:17:17.948 ******** 
2019-06-05 14:20:44,189 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:44,205 p=17240 u=mistral |  TASK [run ceph-ansible (immediate log at /var/lib/mistral/lab/ceph-ansible/ceph_ansible_command.log)] ***
2019-06-05 14:20:44,205 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:277
2019-06-05 14:20:44,205 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:44 -0500 (0:00:00.026)       0:17:17.974 ******** 
2019-06-05 14:20:44,216 p=17240 u=mistral |  skipping: [undercloud] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:44,230 p=17240 u=mistral |  TASK [print ceph-ansible output in case of failure] ****************************
2019-06-05 14:20:44,231 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:293
2019-06-05 14:20:44,231 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:44 -0500 (0:00:00.025)       0:17:18.000 ******** 
2019-06-05 14:20:44,242 p=17240 u=mistral |  skipping: [undercloud] => {}
2019-06-05 14:20:44,257 p=17240 u=mistral |  TASK [register contents of fetch_directory after ceph-ansible run] *************
2019-06-05 14:20:44,257 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:300
2019-06-05 14:20:44,257 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:44 -0500 (0:00:00.026)       0:17:18.026 ******** 
2019-06-05 14:20:44,268 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:44,282 p=17240 u=mistral |  TASK [create ceph-ansible fetch directory tarball in local backup] *************
2019-06-05 14:20:44,282 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:305
2019-06-05 14:20:44,283 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:44 -0500 (0:00:00.025)       0:17:18.052 ******** 
2019-06-05 14:20:44,297 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:44,311 p=17240 u=mistral |  TASK [create temporary ceph-ansible fetch directory tarball for swift backup] ***
2019-06-05 14:20:44,311 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:315
2019-06-05 14:20:44,311 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:44 -0500 (0:00:00.028)       0:17:18.081 ******** 
2019-06-05 14:20:44,326 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:44,343 p=17240 u=mistral |  TASK [backup temporary ceph-ansible fetch directory tarball in swift] **********
2019-06-05 14:20:44,343 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:321
2019-06-05 14:20:44,344 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:44 -0500 (0:00:00.032)       0:17:18.113 ******** 
2019-06-05 14:20:44,355 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:44,371 p=17240 u=mistral |  TASK [ensure we were able to backup temporary fetch directory to swift] ********
2019-06-05 14:20:44,371 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:325
2019-06-05 14:20:44,371 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:44 -0500 (0:00:00.027)       0:17:18.140 ******** 
2019-06-05 14:20:44,384 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:44,399 p=17240 u=mistral |  TASK [clean temporary fetch directory after swift backup] **********************
2019-06-05 14:20:44,399 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:333
2019-06-05 14:20:44,399 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:44 -0500 (0:00:00.028)       0:17:18.169 ******** 
2019-06-05 14:20:44,413 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:44,429 p=17240 u=mistral |  TASK [Remove ceph-ansible fetch directory] *************************************
2019-06-05 14:20:44,429 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:342
2019-06-05 14:20:44,429 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:44 -0500 (0:00:00.029)       0:17:18.198 ******** 
2019-06-05 14:20:44,442 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:44,462 p=17240 u=mistral |  TASK [set ceph-ansible group vars mgrs] ****************************************
2019-06-05 14:20:44,462 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:351
2019-06-05 14:20:44,462 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:44 -0500 (0:00:00.033)       0:17:18.232 ******** 
2019-06-05 14:20:44,481 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:44,499 p=17240 u=mistral |  TASK [generate ceph-ansible group vars mgrs] ***********************************
2019-06-05 14:20:44,499 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:355
2019-06-05 14:20:44,500 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:44 -0500 (0:00:00.037)       0:17:18.269 ******** 
2019-06-05 14:20:44,515 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:44,530 p=17240 u=mistral |  TASK [set ceph-ansible group vars mons] ****************************************
2019-06-05 14:20:44,530 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:363
2019-06-05 14:20:44,530 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:44 -0500 (0:00:00.030)       0:17:18.299 ******** 
2019-06-05 14:20:44,543 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:44,559 p=17240 u=mistral |  TASK [generate ceph-ansible group vars mons] ***********************************
2019-06-05 14:20:44,559 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:368
2019-06-05 14:20:44,559 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:44 -0500 (0:00:00.029)       0:17:18.328 ******** 
2019-06-05 14:20:44,570 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:44,585 p=17240 u=mistral |  TASK [set_fact] ****************************************************************
2019-06-05 14:20:44,585 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:376
2019-06-05 14:20:44,585 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:44 -0500 (0:00:00.026)       0:17:18.355 ******** 
2019-06-05 14:20:44,598 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:44,612 p=17240 u=mistral |  TASK [Create temp file for prepare parameter] **********************************
2019-06-05 14:20:44,612 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:379
2019-06-05 14:20:44,612 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:44 -0500 (0:00:00.026)       0:17:18.381 ******** 
2019-06-05 14:20:44,625 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:44,640 p=17240 u=mistral |  TASK [Create temp file for role data] ******************************************
2019-06-05 14:20:44,640 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:385
2019-06-05 14:20:44,640 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:44 -0500 (0:00:00.027)       0:17:18.409 ******** 
2019-06-05 14:20:44,651 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:44,666 p=17240 u=mistral |  TASK [Write ContainerImagePrepare parameter file] ******************************
2019-06-05 14:20:44,666 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:391
2019-06-05 14:20:44,666 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:44 -0500 (0:00:00.026)       0:17:18.436 ******** 
2019-06-05 14:20:44,680 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:44,694 p=17240 u=mistral |  TASK [Write role data file] ****************************************************
2019-06-05 14:20:44,694 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:659
2019-06-05 14:20:44,694 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:44 -0500 (0:00:00.027)       0:17:18.463 ******** 
2019-06-05 14:20:44,709 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:44,725 p=17240 u=mistral |  TASK [Run tripleo-container-image-prepare logged to /var/log/tripleo-container-image-prepare.log] ***
2019-06-05 14:20:44,725 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:905
2019-06-05 14:20:44,725 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:44 -0500 (0:00:00.030)       0:17:18.494 ******** 
2019-06-05 14:20:44,739 p=17240 u=mistral |  skipping: [undercloud] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:44,754 p=17240 u=mistral |  TASK [Delete param file] *******************************************************
2019-06-05 14:20:44,754 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:911
2019-06-05 14:20:44,755 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:44 -0500 (0:00:00.029)       0:17:18.524 ******** 
2019-06-05 14:20:44,769 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:44,785 p=17240 u=mistral |  TASK [Delete role file] ********************************************************
2019-06-05 14:20:44,785 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:916
2019-06-05 14:20:44,785 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:44 -0500 (0:00:00.030)       0:17:18.555 ******** 
2019-06-05 14:20:44,801 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:44,818 p=17240 u=mistral |  TASK [set ceph-ansible group vars clients] *************************************
2019-06-05 14:20:44,819 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:925
2019-06-05 14:20:44,819 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:44 -0500 (0:00:00.033)       0:17:18.588 ******** 
2019-06-05 14:20:44,830 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:44,847 p=17240 u=mistral |  TASK [generate ceph-ansible group vars clients] ********************************
2019-06-05 14:20:44,847 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:928
2019-06-05 14:20:44,847 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:44 -0500 (0:00:00.028)       0:17:18.616 ******** 
2019-06-05 14:20:44,859 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:44,875 p=17240 u=mistral |  TASK [set ceph-ansible group vars osds] ****************************************
2019-06-05 14:20:44,875 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:936
2019-06-05 14:20:44,875 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:44 -0500 (0:00:00.028)       0:17:18.644 ******** 
2019-06-05 14:20:44,886 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:44,902 p=17240 u=mistral |  TASK [generate ceph-ansible group vars osds] ***********************************
2019-06-05 14:20:44,902 p=17240 u=mistral |  task path: /var/lib/mistral/lab/external_deploy_steps_tasks.yaml:943
2019-06-05 14:20:44,902 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:44 -0500 (0:00:00.026)       0:17:18.671 ******** 
2019-06-05 14:20:44,913 p=17240 u=mistral |  skipping: [undercloud] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:44,913 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:20:44,914 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:20:44,918 p=17240 u=mistral |  PLAY [Overcloud deploy step tasks for 5] ***************************************
2019-06-05 14:20:44,920 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:20:44,943 p=17240 u=mistral |  TASK [Write the config_step hieradata for the deploy step 5 tasks] *************
2019-06-05 14:20:44,943 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deploy_steps_playbook.yaml:506
2019-06-05 14:20:44,943 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:44 -0500 (0:00:00.041)       0:17:18.712 ******** 
2019-06-05 14:20:45,276 p=17240 u=mistral |  changed: [lab-controller-0] => {"changed": true, "checksum": "039e0b234f00fbd1242930f0d5dc67e8b4c067fe", "dest": "/etc/puppet/hieradata/config_step.json", "gid": 0, "group": "root", "md5sum": "868a394a237b10c579b0c7ac25057be6", "mode": "0600", "owner": "root", "secontext": "system_u:object_r:puppet_etc_t:s0", "size": 11, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559762444.95-131937136439312/source", "state": "file", "uid": 0}
2019-06-05 14:20:45,280 p=17240 u=mistral |  changed: [lab-computehci-0] => {"changed": true, "checksum": "039e0b234f00fbd1242930f0d5dc67e8b4c067fe", "dest": "/etc/puppet/hieradata/config_step.json", "gid": 0, "group": "root", "md5sum": "868a394a237b10c579b0c7ac25057be6", "mode": "0600", "owner": "root", "secontext": "system_u:object_r:puppet_etc_t:s0", "size": 11, "src": "/home/tripleo-admin/.ansible/tmp/ansible-tmp-1559762444.98-37413541511860/source", "state": "file", "uid": 0}
2019-06-05 14:20:45,304 p=17240 u=mistral |  TASK [Run puppet on the host to apply IPtables rules] **************************
2019-06-05 14:20:45,304 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/deploy_steps_tasks.yaml:2
2019-06-05 14:20:45,304 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:45 -0500 (0:00:00.361)       0:17:19.073 ******** 
2019-06-05 14:20:45,333 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:45,341 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:45,365 p=17240 u=mistral |  TASK [configure tmpwatch on the host] ******************************************
2019-06-05 14:20:45,365 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/deploy_steps_tasks.yaml:13
2019-06-05 14:20:45,365 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:45 -0500 (0:00:00.061)       0:17:19.135 ******** 
2019-06-05 14:20:45,393 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:45,405 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:45,431 p=17240 u=mistral |  TASK [create iptables service] *************************************************
2019-06-05 14:20:45,432 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/deploy_steps_tasks.yaml:27
2019-06-05 14:20:45,432 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:45 -0500 (0:00:00.066)       0:17:19.201 ******** 
2019-06-05 14:20:45,460 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:45,467 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:45,491 p=17240 u=mistral |  TASK [enable tripleo-iptables service] *****************************************
2019-06-05 14:20:45,491 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/deploy_steps_tasks.yaml:58
2019-06-05 14:20:45,491 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:45 -0500 (0:00:00.059)       0:17:19.261 ******** 
2019-06-05 14:20:45,520 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:45,528 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:45,551 p=17240 u=mistral |  TASK [create ip6tables service] ************************************************
2019-06-05 14:20:45,551 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/deploy_steps_tasks.yaml:62
2019-06-05 14:20:45,552 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:45 -0500 (0:00:00.060)       0:17:19.321 ******** 
2019-06-05 14:20:45,579 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:45,587 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:45,611 p=17240 u=mistral |  TASK [enable tripleo-ip6tables service] ****************************************
2019-06-05 14:20:45,611 p=17240 u=mistral |  task path: /var/lib/mistral/lab/Controller/deploy_steps_tasks.yaml:93
2019-06-05 14:20:45,611 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:45 -0500 (0:00:00.059)       0:17:19.380 ******** 
2019-06-05 14:20:45,639 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:45,646 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:45,669 p=17240 u=mistral |  TASK [configure tmpwatch on the host] ******************************************
2019-06-05 14:20:45,670 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/deploy_steps_tasks.yaml:2
2019-06-05 14:20:45,670 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:45 -0500 (0:00:00.058)       0:17:19.439 ******** 
2019-06-05 14:20:45,697 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:45,707 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:45,730 p=17240 u=mistral |  TASK [create iptables service] *************************************************
2019-06-05 14:20:45,730 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/deploy_steps_tasks.yaml:16
2019-06-05 14:20:45,730 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:45 -0500 (0:00:00.060)       0:17:19.499 ******** 
2019-06-05 14:20:45,757 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:45,771 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:45,798 p=17240 u=mistral |  TASK [enable tripleo-iptables service] *****************************************
2019-06-05 14:20:45,798 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/deploy_steps_tasks.yaml:47
2019-06-05 14:20:45,798 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:45 -0500 (0:00:00.067)       0:17:19.567 ******** 
2019-06-05 14:20:45,860 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:45,870 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:45,893 p=17240 u=mistral |  TASK [create ip6tables service] ************************************************
2019-06-05 14:20:45,893 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/deploy_steps_tasks.yaml:51
2019-06-05 14:20:45,894 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:45 -0500 (0:00:00.095)       0:17:19.663 ******** 
2019-06-05 14:20:45,922 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:45,931 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:45,955 p=17240 u=mistral |  TASK [enable tripleo-ip6tables service] ****************************************
2019-06-05 14:20:45,955 p=17240 u=mistral |  task path: /var/lib/mistral/lab/ComputeHCI/deploy_steps_tasks.yaml:82
2019-06-05 14:20:45,955 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:45 -0500 (0:00:00.061)       0:17:19.724 ******** 
2019-06-05 14:20:45,983 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:45,992 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:45,993 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:20:45,993 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:20:45,997 p=17240 u=mistral |  PLAY [Overcloud common deploy step tasks 5] ************************************
2019-06-05 14:20:46,002 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:20:46,024 p=17240 u=mistral |  TASK [Check if /var/lib/tripleo-config/container-startup-config-1.json already exists] ***
2019-06-05 14:20:46,024 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deploy_steps_playbook.yaml:538
2019-06-05 14:20:46,024 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:46 -0500 (0:00:00.068)       0:17:19.793 ******** 
2019-06-05 14:20:46,123 p=17240 u=mistral |  ok: [lab-controller-0] => {"changed": false, "stat": {"exists": false}}
2019-06-05 14:20:46,145 p=17240 u=mistral |  ok: [lab-computehci-0] => {"changed": false, "stat": {"exists": false}}
2019-06-05 14:20:46,168 p=17240 u=mistral |  TASK [gather facts needed by role] *********************************************
2019-06-05 14:20:46,169 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:6
2019-06-05 14:20:46,169 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:46 -0500 (0:00:00.144)       0:17:19.938 ******** 
2019-06-05 14:20:46,197 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:46,207 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:46,232 p=17240 u=mistral |  TASK [set python_cmd] **********************************************************
2019-06-05 14:20:46,232 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:13
2019-06-05 14:20:46,232 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:46 -0500 (0:00:00.063)       0:17:20.001 ******** 
2019-06-05 14:20:46,262 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:46,273 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:46,297 p=17240 u=mistral |  TASK [print python facts] ******************************************************
2019-06-05 14:20:46,297 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:22
2019-06-05 14:20:46,297 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:46 -0500 (0:00:00.065)       0:17:20.066 ******** 
2019-06-05 14:20:46,325 p=17240 u=mistral |  ok: [lab-controller-0] => {
    "msg": "python_cmd: python2"
}
2019-06-05 14:20:46,337 p=17240 u=mistral |  ok: [lab-computehci-0] => {
    "msg": "python_cmd: python2"
}
2019-06-05 14:20:46,362 p=17240 u=mistral |  TASK [Create and ensure setype for /var/log/containers directory] **************
2019-06-05 14:20:46,362 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:31
2019-06-05 14:20:46,362 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:46 -0500 (0:00:00.064)       0:17:20.131 ******** 
2019-06-05 14:20:46,390 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:46,401 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:46,424 p=17240 u=mistral |  TASK [Create ContainerLogStdoutPath directory] *********************************
2019-06-05 14:20:46,424 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:39
2019-06-05 14:20:46,424 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:46 -0500 (0:00:00.062)       0:17:20.194 ******** 
2019-06-05 14:20:46,452 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:46,463 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:46,487 p=17240 u=mistral |  TASK [Create /var/lib/tripleo-config directory] ********************************
2019-06-05 14:20:46,487 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:46
2019-06-05 14:20:46,487 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:46 -0500 (0:00:00.062)       0:17:20.256 ******** 
2019-06-05 14:20:46,516 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:46,527 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:46,550 p=17240 u=mistral |  TASK [Delete existing /var/lib/tripleo-config/check-mode directory for check mode] ***
2019-06-05 14:20:46,550 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:60
2019-06-05 14:20:46,551 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:46 -0500 (0:00:00.063)       0:17:20.320 ******** 
2019-06-05 14:20:46,579 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:46,590 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:46,613 p=17240 u=mistral |  TASK [Create /var/lib/tripleo-config/check-mode directory for check mode] ******
2019-06-05 14:20:46,614 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:75
2019-06-05 14:20:46,614 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:46 -0500 (0:00:00.063)       0:17:20.383 ******** 
2019-06-05 14:20:46,645 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:46,656 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:46,680 p=17240 u=mistral |  TASK [Write the puppet step_config manifest] ***********************************
2019-06-05 14:20:46,680 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:93
2019-06-05 14:20:46,680 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:46 -0500 (0:00:00.066)       0:17:20.449 ******** 
2019-06-05 14:20:46,708 p=17240 u=mistral |  skipping: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:46,719 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:46,743 p=17240 u=mistral |  TASK [Diff puppet step_config manifest changes for check mode] *****************
2019-06-05 14:20:46,743 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:105
2019-06-05 14:20:46,743 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:46 -0500 (0:00:00.063)       0:17:20.512 ******** 
2019-06-05 14:20:46,770 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:46,780 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:46,804 p=17240 u=mistral |  TASK [Diff puppet step_config manifest changes for check mode] *****************
2019-06-05 14:20:46,804 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:118
2019-06-05 14:20:46,804 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:46 -0500 (0:00:00.060)       0:17:20.573 ******** 
2019-06-05 14:20:46,832 p=17240 u=mistral |  skipping: [lab-controller-0] => {}
2019-06-05 14:20:46,842 p=17240 u=mistral |  skipping: [lab-computehci-0] => {}
2019-06-05 14:20:46,866 p=17240 u=mistral |  TASK [Create /var/lib/container-puppet] ****************************************
2019-06-05 14:20:46,866 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:129
2019-06-05 14:20:46,866 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:46 -0500 (0:00:00.062)       0:17:20.635 ******** 
2019-06-05 14:20:46,894 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:46,905 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:46,929 p=17240 u=mistral |  TASK [Create /var/lib/docker-puppet for backward compatibility] ****************
2019-06-05 14:20:46,930 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:141
2019-06-05 14:20:46,930 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:46 -0500 (0:00:00.063)       0:17:20.699 ******** 
2019-06-05 14:20:46,958 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:46,970 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:46,994 p=17240 u=mistral |  TASK [Deprecation file about /var/lib/docker-puppet] ***************************
2019-06-05 14:20:46,994 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:149
2019-06-05 14:20:46,994 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:46 -0500 (0:00:00.064)       0:17:20.764 ******** 
2019-06-05 14:20:47,025 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:47,036 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:47,060 p=17240 u=mistral |  TASK [Delete existing /var/lib/container-puppet/container-puppet.sh] ***********
2019-06-05 14:20:47,060 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:157
2019-06-05 14:20:47,060 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:47 -0500 (0:00:00.065)       0:17:20.829 ******** 
2019-06-05 14:20:47,089 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:47,099 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:47,123 p=17240 u=mistral |  TASK [Delete existing /var/lib/container-puppet/check-mode for check mode] *****
2019-06-05 14:20:47,123 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:166
2019-06-05 14:20:47,123 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:47 -0500 (0:00:00.062)       0:17:20.892 ******** 
2019-06-05 14:20:47,151 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:47,162 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:47,186 p=17240 u=mistral |  TASK [Create /var/lib/container-puppet/check-mode for check mode] **************
2019-06-05 14:20:47,186 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:177
2019-06-05 14:20:47,186 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:47 -0500 (0:00:00.062)       0:17:20.955 ******** 
2019-06-05 14:20:47,213 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:47,224 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:47,248 p=17240 u=mistral |  TASK [Write container-puppet.json file] ****************************************
2019-06-05 14:20:47,248 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:189
2019-06-05 14:20:47,248 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:47 -0500 (0:00:00.061)       0:17:21.017 ******** 
2019-06-05 14:20:47,275 p=17240 u=mistral |  skipping: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:47,286 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:47,309 p=17240 u=mistral |  TASK [Diff container-puppet.json changes for check mode] ***********************
2019-06-05 14:20:47,309 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:201
2019-06-05 14:20:47,309 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:47 -0500 (0:00:00.061)       0:17:21.078 ******** 
2019-06-05 14:20:47,336 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:47,347 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:47,371 p=17240 u=mistral |  TASK [Diff container-puppet.json changes for check mode] ***********************
2019-06-05 14:20:47,371 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:214
2019-06-05 14:20:47,371 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:47 -0500 (0:00:00.062)       0:17:21.141 ******** 
2019-06-05 14:20:47,402 p=17240 u=mistral |  skipping: [lab-controller-0] => {}
2019-06-05 14:20:47,413 p=17240 u=mistral |  skipping: [lab-computehci-0] => {}
2019-06-05 14:20:47,437 p=17240 u=mistral |  TASK [Create /var/lib/container-config-scripts] ********************************
2019-06-05 14:20:47,438 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:224
2019-06-05 14:20:47,438 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:47 -0500 (0:00:00.066)       0:17:21.207 ******** 
2019-06-05 14:20:47,467 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:47,478 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:47,502 p=17240 u=mistral |  TASK [Clean old /var/lib/container-startup-configs.json file] ******************
2019-06-05 14:20:47,502 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:235
2019-06-05 14:20:47,502 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:47 -0500 (0:00:00.064)       0:17:21.271 ******** 
2019-06-05 14:20:47,530 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:47,541 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:47,564 p=17240 u=mistral |  TASK [Clean old /var/lib/docker-container-startup-configs.json file] ***********
2019-06-05 14:20:47,564 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:243
2019-06-05 14:20:47,565 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:47 -0500 (0:00:00.062)       0:17:21.334 ******** 
2019-06-05 14:20:47,593 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:47,602 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:47,626 p=17240 u=mistral |  TASK [Write container config scripts] ******************************************
2019-06-05 14:20:47,626 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:251
2019-06-05 14:20:47,626 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:47 -0500 (0:00:00.061)       0:17:21.395 ******** 
2019-06-05 14:20:47,656 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:47,661 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:47,665 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:47,671 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:47,676 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:47,678 p=17240 u=mistral |  skipping: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:47,697 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:47,702 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:47,709 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:47,714 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:47,722 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:47,728 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:47,729 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:47,753 p=17240 u=mistral |  TASK [Set container_config_default fact] ***************************************
2019-06-05 14:20:47,753 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:270
2019-06-05 14:20:47,753 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:47 -0500 (0:00:00.127)       0:17:21.523 ******** 
2019-06-05 14:20:47,782 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:47,782 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:47,786 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:47,791 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:47,802 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:47,802 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:47,806 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:47,806 p=17240 u=mistral |  skipping: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:47,808 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:47,813 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:47,820 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:47,824 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:47,833 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:47,833 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:47,856 p=17240 u=mistral |  TASK [Set container_startup_configs_with_default fact] *************************
2019-06-05 14:20:47,856 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:278
2019-06-05 14:20:47,856 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:47 -0500 (0:00:00.102)       0:17:21.625 ******** 
2019-06-05 14:20:47,884 p=17240 u=mistral |  skipping: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:47,895 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:47,919 p=17240 u=mistral |  TASK [Write per-step container startup configs] ********************************
2019-06-05 14:20:47,919 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:287
2019-06-05 14:20:47,919 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:47 -0500 (0:00:00.062)       0:17:21.688 ******** 
2019-06-05 14:20:47,957 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:47,963 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:47,964 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:47,970 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:47,971 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:47,978 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:47,978 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:47,983 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:47,984 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:47,990 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:47,990 p=17240 u=mistral |  skipping: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:47,990 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:47,995 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:47,996 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,019 p=17240 u=mistral |  TASK [Create /var/lib/kolla/config_files directory] ****************************
2019-06-05 14:20:48,019 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:300
2019-06-05 14:20:48,019 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:48 -0500 (0:00:00.100)       0:17:21.788 ******** 
2019-06-05 14:20:48,047 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:48,058 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:48,081 p=17240 u=mistral |  TASK [Create /var/lib/config-data directory] ***********************************
2019-06-05 14:20:48,081 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:310
2019-06-05 14:20:48,082 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:48 -0500 (0:00:00.062)       0:17:21.851 ******** 
2019-06-05 14:20:48,110 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:48,120 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:48,143 p=17240 u=mistral |  TASK [Write kolla config json files] *******************************************
2019-06-05 14:20:48,143 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:317
2019-06-05 14:20:48,144 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:48 -0500 (0:00:00.062)       0:17:21.913 ******** 
2019-06-05 14:20:48,204 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,209 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,215 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,220 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,226 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,233 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,238 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,244 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,253 p=17240 u=mistral |  skipping: [lab-computehci-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,254 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,255 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,261 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,266 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,272 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,277 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,283 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,289 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,295 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,299 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,305 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,311 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,316 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,322 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,327 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,332 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,338 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,343 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,349 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,354 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,360 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,366 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,372 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,376 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,382 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,387 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,393 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,399 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,404 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,409 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,414 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,420 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,425 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,431 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,436 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,442 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,447 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,453 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,459 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,464 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,468 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,474 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,480 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,484 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,491 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,496 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,501 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,507 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,512 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,518 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,523 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,528 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,534 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,541 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,545 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,551 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,555 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,561 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,567 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,572 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,578 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,582 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,588 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,593 p=17240 u=mistral |  skipping: [lab-controller-0] => (item=None)  => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,595 p=17240 u=mistral |  skipping: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:48,617 p=17240 u=mistral |  TASK [Set host puppet debugging fact string] ***********************************
2019-06-05 14:20:48,618 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:335
2019-06-05 14:20:48,618 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:48 -0500 (0:00:00.474)       0:17:22.387 ******** 
2019-06-05 14:20:48,647 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:48,658 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:48,682 p=17240 u=mistral |  TASK [Check for /etc/puppet/check-mode directory for check mode] ***************
2019-06-05 14:20:48,682 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:344
2019-06-05 14:20:48,682 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:48 -0500 (0:00:00.064)       0:17:22.452 ******** 
2019-06-05 14:20:48,710 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:48,721 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:48,745 p=17240 u=mistral |  TASK [Create /etc/puppet/check-mode/hieradata directory for check mode] ********
2019-06-05 14:20:48,745 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:353
2019-06-05 14:20:48,745 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:48 -0500 (0:00:00.062)       0:17:22.514 ******** 
2019-06-05 14:20:48,773 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:48,786 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:48,811 p=17240 u=mistral |  TASK [Write the config_step hieradata] *****************************************
2019-06-05 14:20:48,811 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:368
2019-06-05 14:20:48,811 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:48 -0500 (0:00:00.065)       0:17:22.580 ******** 
2019-06-05 14:20:49,083 p=17240 u=mistral |  ok: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:49,096 p=17240 u=mistral |  ok: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:20:49,121 p=17240 u=mistral |  TASK [Create puppet check-mode files if they don't exist for check mode] *******
2019-06-05 14:20:49,121 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:379
2019-06-05 14:20:49,121 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:49 -0500 (0:00:00.310)       0:17:22.890 ******** 
2019-06-05 14:20:49,150 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:49,161 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:20:49,187 p=17240 u=mistral |  TASK [Run puppet host configuration for step 5] ********************************
2019-06-05 14:20:49,187 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:392
2019-06-05 14:20:49,187 p=17240 u=mistral |  Wednesday 05 June 2019  14:20:49 -0500 (0:00:00.065)       0:17:22.956 ******** 
2019-06-05 14:20:55,857 p=17240 u=mistral |  changed: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:21:03,430 p=17240 u=mistral |  changed: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:21:03,455 p=17240 u=mistral |  TASK [Debug output for task: Run puppet host configuration for step 5] *********
2019-06-05 14:21:03,455 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:411
2019-06-05 14:21:03,455 p=17240 u=mistral |  Wednesday 05 June 2019  14:21:03 -0500 (0:00:14.268)       0:17:37.224 ******** 
2019-06-05 14:21:03,484 p=17240 u=mistral |  ok: [lab-controller-0] => {
    "failed_when_result": false, 
    "outputs.stdout_lines | default([]) | union(outputs.stderr_lines | default([]))": [
        "Changes:", 
        "            Total: 3", 
        "Events:", 
        "          Success: 3", 
        "Resources:", 
        "          Changed: 3", 
        "      Out of sync: 3", 
        "            Total: 195", 
        "Time:", 
        "      Concat file: 0.00", 
        "           Anchor: 0.00", 
        "         Schedule: 0.00", 
        "   Package manifest: 0.00", 
        "   Sysctl runtime: 0.00", 
        "           Sysctl: 0.00", 
        "           Augeas: 0.01", 
        "          Service: 0.09", 
        "             Exec: 0.13", 
        "          Package: 0.14", 
        "         Firewall: 0.25", 
        "         Last run: 1559762463", 
        "             File: 2.06", 
        "   Config retrieval: 2.57", 
        "   Transaction evaluation: 3.30", 
        "   Catalog application: 3.34", 
        "   Concat fragment: 0.00", 
        "       Filebucket: 0.00", 
        "            Total: 3.34", 
        "Version:", 
        "           Config: 1559762457", 
        "           Puppet: 5.5.10"
    ]
}
2019-06-05 14:21:03,503 p=17240 u=mistral |  ok: [lab-computehci-0] => {
    "failed_when_result": false, 
    "outputs.stdout_lines | default([]) | union(outputs.stderr_lines | default([]))": [
        "Changes:", 
        "            Total: 5", 
        "Events:", 
        "          Success: 5", 
        "Resources:", 
        "        Restarted: 1", 
        "          Changed: 5", 
        "      Out of sync: 5", 
        "            Total: 173", 
        "Time:", 
        "      Concat file: 0.00", 
        "         Schedule: 0.00", 
        "   Package manifest: 0.00", 
        "        File line: 0.00", 
        "           Anchor: 0.00", 
        "   Sysctl runtime: 0.00", 
        "           Sysctl: 0.00", 
        "           Augeas: 0.01", 
        "          Service: 0.09", 
        "         Firewall: 0.12", 
        "             Exec: 0.13", 
        "             File: 0.16", 
        "          Package: 0.25", 
        "   Transaction evaluation: 1.13", 
        "   Catalog application: 1.18", 
        "   Config retrieval: 1.53", 
        "         Last run: 1559762455", 
        "       Filebucket: 0.00", 
        "   Concat fragment: 0.00", 
        "            Total: 1.18", 
        "Version:", 
        "           Config: 1559762452", 
        "           Puppet: 5.5.10"
    ]
}
2019-06-05 14:21:03,528 p=17240 u=mistral |  TASK [Run container-puppet tasks (generate config) during step 5] **************
2019-06-05 14:21:03,528 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:426
2019-06-05 14:21:03,529 p=17240 u=mistral |  Wednesday 05 June 2019  14:21:03 -0500 (0:00:00.073)       0:17:37.298 ******** 
2019-06-05 14:21:03,556 p=17240 u=mistral |  skipping: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:21:03,567 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:21:03,594 p=17240 u=mistral |  TASK [Debug output for task: Run container-puppet tasks (generate config) during step 5] ***
2019-06-05 14:21:03,594 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:449
2019-06-05 14:21:03,594 p=17240 u=mistral |  Wednesday 05 June 2019  14:21:03 -0500 (0:00:00.065)       0:17:37.363 ******** 
2019-06-05 14:21:03,622 p=17240 u=mistral |  skipping: [lab-controller-0] => {}
2019-06-05 14:21:03,633 p=17240 u=mistral |  skipping: [lab-computehci-0] => {}
2019-06-05 14:21:03,656 p=17240 u=mistral |  TASK [Diff container-puppet.py puppet-generated changes for check mode] ********
2019-06-05 14:21:03,657 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:458
2019-06-05 14:21:03,657 p=17240 u=mistral |  Wednesday 05 June 2019  14:21:03 -0500 (0:00:00.062)       0:17:37.426 ******** 
2019-06-05 14:21:03,684 p=17240 u=mistral |  skipping: [lab-controller-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:21:03,695 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"changed": false, "skip_reason": "Conditional result was False"}
2019-06-05 14:21:03,718 p=17240 u=mistral |  TASK [Diff container-puppet.py puppet-generated changes for check mode] ********
2019-06-05 14:21:03,719 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:473
2019-06-05 14:21:03,719 p=17240 u=mistral |  Wednesday 05 June 2019  14:21:03 -0500 (0:00:00.062)       0:17:37.488 ******** 
2019-06-05 14:21:03,748 p=17240 u=mistral |  skipping: [lab-controller-0] => {}
2019-06-05 14:21:03,757 p=17240 u=mistral |  skipping: [lab-computehci-0] => {}
2019-06-05 14:21:03,782 p=17240 u=mistral |  TASK [Start containers for step 5] *********************************************
2019-06-05 14:21:03,782 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:491
2019-06-05 14:21:03,782 p=17240 u=mistral |  Wednesday 05 June 2019  14:21:03 -0500 (0:00:00.063)       0:17:37.551 ******** 
2019-06-05 14:21:07,129 p=17240 u=mistral |  ok: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:21:51,471 p=17240 u=mistral |  ok: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:21:51,496 p=17240 u=mistral |  TASK [Debug output for task: Start containers for step 5] **********************
2019-06-05 14:21:51,496 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:508
2019-06-05 14:21:51,496 p=17240 u=mistral |  Wednesday 05 June 2019  14:21:51 -0500 (0:00:47.714)       0:18:25.266 ******** 
2019-06-05 14:21:51,531 p=17240 u=mistral |  ok: [lab-controller-0] => {
    "failed_when_result": false, 
    "outputs.stdout_lines | default([]) | union(outputs.stderr_lines | default([]))": [
        "stdout: 8539881ea4ac01a177e73a5196b37d61d949f957eac9f7b5f6e46a618be83a74", 
        "", 
        "stderr: Trying to pull docker://docker.io/tripleostein/centos-binary-gnocchi-metricd:current-tripleo-rdo...Getting image source signatures", 
        "Copying blob sha256:a35613cff6f04cbfd2f3b845d5a923d56d6f2fb718f85784e8fdcd97ae77846e", 
        "Copying blob sha256:31c8fa1ceee01b746a6b64c4718f5e42e867c08532b29f8d33626a8385327ede", 
        "Copying blob sha256:5b8f702199c16fd0d5c9c4d0028550b144acb532f4a6b8200b3f53e1cbc43aba", 
        "Copying blob sha256:0f2be6d2e8e6e42cb3e633544d0b1aa8328bd7004a3a4b1dfc0c7a6ba14cd0c7", 
        "Copying blob sha256:c0862342b9e7a81856422b95348a2d1952b46e01df6c72f74d94cac2c5815c51", 
        "Copying blob sha256:8ba884070f611d31cb2c42eddb691319dc9facf5e0ec67672fcfa135181ab3df", 
        "Copying blob sha256:6310d6ac1536a2eb8e769d217451e2c6d420eb3c39b0fb1b9ad088a73ea67211", 
        "Copying blob sha256:c80c3921174be89bdd60d2454983524a19a15b09f26f47b6822e6440d5939973", 
        "Copying blob sha256:fc3b29499fda939e998b0c14c6e98720e1cb7a66fd1ce884cad8d64a63669cf4", 
        "Copying blob sha256:d6dbd69ea530292192935158b778ccffc396ead2093138f75c6e1fa33b7a17fa", 
        "Copying blob sha256:5b89a36d5e9e14c5ac5981e8ed2304bb8ce19da7d91793f44c48ac17e7b03717", 
        "Copying blob sha256:98d5e2479617c862dcad487a2c52021bc16e516ebafe9fdab6b3eb8648b73f57", 
        "Copying blob sha256:bd6e2c36ff0e45e35121c3bc2cb54f803eb809aacb2778260d4211de2ba9fabb", 
        "Copying blob sha256:921488feccf56d8c8eb6086cd998b48f907fa44dbc5e7cf8525efd96f7c1f776", 
        "Copying blob sha256:2799d99efade4475ca55aad34887eabf4e9ec76e592bc0b0a80cbd8d01080ffc", 
        "Copying blob sha256:d36b87fd0812d0e39ef92e729105260f496efbfb19ad7b6981218862502aa0f3", 
        "Copying blob sha256:0fc1fd86055457f85a0cb3f333292570aaa2803c4b556966847f55f8f3544fa8", 
        "Copying blob sha256:46d3c6aa676de9a0ee74cfac77cced69fb7a4df7c5b9e8a7ef33922881d87c81", 
        "Copying blob sha256:2cc44a4e32219b5aad308d7d3bdc5ba18788e8830c0cf3aa9056e1d0dc647058", 
        "Copying blob sha256:df1f845a3ee11f8ded85f3140421ff4adee3211f3d5015d3a87cb2949c99c48f", 
        "Copying blob sha256:ccae8e3351ac86f5c7d66e9c84321057c9f05063428851fa0f1c17946090212d", 
        "Copying blob sha256:89c8d96f0d37376ba1f54c92128660aaea0a802cb9d9d396a45366b02fc589cc", 
        "Copying blob sha256:45d804df81db3a3f58373c31a92eb2484c2b9038ec59d86fed68b6ce62565939", 
        "Copying blob sha256:343f9f42dd124dbd53b97d676c7702f6308aa52ad4e28983f1aa15f733d48213", 
        "Copying blob sha256:f2ca7905ab10403f2b2bd5f5981663ef10cde9c2e3e68d5f54d8f7d7ac8ebc1b", 
        "Copying blob sha256:8ecf402902124ba09cc0178e20adb960cd2a535b7a537ed5fb3ef382f78a0cec", 
        "Copying blob sha256:c6e32e433d481031eb96af6a897382a0fd4e18beaa529c56f7d0d5e6eb2a2c13", 
        "Copying blob sha256:15214f1feb624320103283175976537b2f08efc9557012f1a7eaa661f808530c", 
        "Copying blob sha256:8c0e55d40bd010c62f7c2e6784b41bf81be2d5cb67082cb145a412195034fe5a", 
        "Copying blob sha256:2b2380d57bacb7b34e36547d934c80c3b83eefcaa4f19931877d932865d793c9", 
        "Copying blob sha256:e49d714928a818ae63b3028fc87177e80ef611a6385d377d098de18339860c37", 
        "Copying config sha256:8539881ea4ac01a177e73a5196b37d61d949f957eac9f7b5f6e46a618be83a74", 
        "Writing manifest to image destination", 
        "Storing signatures", 
        "stdout: 5a9a95b601303d8d7c6ec59acb63a9e1ab8199c99b46c80993d58f6e04f2b550", 
        "stderr: Trying to pull docker://docker.io/tripleostein/centos-binary-gnocchi-statsd:current-tripleo-rdo...Getting image source signatures", 
        "Copying blob sha256:6f0ab2d6247f4636093468bdd4a973919e0cce5d62d8538f0ddaa854f15484aa", 
        "Copying blob sha256:fafdadd670f3cb9ee57665ee5278f3467ee9a54f99c09249e5631639bc0627dd", 
        "Copying config sha256:5a9a95b601303d8d7c6ec59acb63a9e1ab8199c99b46c80993d58f6e04f2b550", 
        "stdout: Running command: '/usr/bin/bootstrap_host_exec gnocchi_api /usr/bin/gnocchi-upgrade --sacks-number=128'", 
        "stderr: + sudo -E kolla_set_configs", 
        "INFO:__main__:Loading config file at /var/lib/kolla/config_files/config.json", 
        "INFO:__main__:Validating config file", 
        "INFO:__main__:Kolla config strategy set to: COPY_ALWAYS", 
        "INFO:__main__:Copying service configuration files", 
        "INFO:__main__:Deleting /etc/httpd/conf.d", 
        "INFO:__main__:Creating directory /etc/httpd/conf.d", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.d/10-gnocchi_wsgi.conf to /etc/httpd/conf.d/10-gnocchi_wsgi.conf", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.d/ssl.conf to /etc/httpd/conf.d/ssl.conf", 
        "INFO:__main__:Deleting /etc/gnocchi/gnocchi.conf", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/gnocchi/gnocchi.conf to /etc/gnocchi/gnocchi.conf", 
        "INFO:__main__:Deleting /etc/httpd/conf.d/10-gnocchi_wsgi.conf", 
        "INFO:__main__:Deleting /etc/httpd/conf.d/ssl.conf", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/access_compat.load to /etc/httpd/conf.modules.d/access_compat.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/actions.load to /etc/httpd/conf.modules.d/actions.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/alias.conf to /etc/httpd/conf.modules.d/alias.conf", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/alias.load to /etc/httpd/conf.modules.d/alias.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/auth_basic.load to /etc/httpd/conf.modules.d/auth_basic.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/auth_digest.load to /etc/httpd/conf.modules.d/auth_digest.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/authn_anon.load to /etc/httpd/conf.modules.d/authn_anon.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/authn_core.load to /etc/httpd/conf.modules.d/authn_core.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/authn_dbm.load to /etc/httpd/conf.modules.d/authn_dbm.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/authn_file.load to /etc/httpd/conf.modules.d/authn_file.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/authz_core.load to /etc/httpd/conf.modules.d/authz_core.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/authz_dbm.load to /etc/httpd/conf.modules.d/authz_dbm.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/authz_groupfile.load to /etc/httpd/conf.modules.d/authz_groupfile.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/authz_host.load to /etc/httpd/conf.modules.d/authz_host.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/authz_owner.load to /etc/httpd/conf.modules.d/authz_owner.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/authz_user.load to /etc/httpd/conf.modules.d/authz_user.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/autoindex.conf to /etc/httpd/conf.modules.d/autoindex.conf", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/autoindex.load to /etc/httpd/conf.modules.d/autoindex.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/cache.load to /etc/httpd/conf.modules.d/cache.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/cgi.load to /etc/httpd/conf.modules.d/cgi.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/dav.load to /etc/httpd/conf.modules.d/dav.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/dav_fs.conf to /etc/httpd/conf.modules.d/dav_fs.conf", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/dav_fs.load to /etc/httpd/conf.modules.d/dav_fs.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/deflate.conf to /etc/httpd/conf.modules.d/deflate.conf", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/deflate.load to /etc/httpd/conf.modules.d/deflate.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/dir.conf to /etc/httpd/conf.modules.d/dir.conf", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/dir.load to /etc/httpd/conf.modules.d/dir.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/env.load to /etc/httpd/conf.modules.d/env.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/expires.load to /etc/httpd/conf.modules.d/expires.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/ext_filter.load to /etc/httpd/conf.modules.d/ext_filter.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/filter.load to /etc/httpd/conf.modules.d/filter.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/include.load to /etc/httpd/conf.modules.d/include.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/log_config.load to /etc/httpd/conf.modules.d/log_config.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/logio.load to /etc/httpd/conf.modules.d/logio.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/mime.conf to /etc/httpd/conf.modules.d/mime.conf", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/mime.load to /etc/httpd/conf.modules.d/mime.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/mime_magic.conf to /etc/httpd/conf.modules.d/mime_magic.conf", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/mime_magic.load to /etc/httpd/conf.modules.d/mime_magic.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/negotiation.conf to /etc/httpd/conf.modules.d/negotiation.conf", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/negotiation.load to /etc/httpd/conf.modules.d/negotiation.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/prefork.conf to /etc/httpd/conf.modules.d/prefork.conf", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/prefork.load to /etc/httpd/conf.modules.d/prefork.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/rewrite.load to /etc/httpd/conf.modules.d/rewrite.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/setenvif.conf to /etc/httpd/conf.modules.d/setenvif.conf", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/setenvif.load to /etc/httpd/conf.modules.d/setenvif.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/socache_shmcb.load to /etc/httpd/conf.modules.d/socache_shmcb.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/speling.load to /etc/httpd/conf.modules.d/speling.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/ssl.load to /etc/httpd/conf.modules.d/ssl.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/status.conf to /etc/httpd/conf.modules.d/status.conf", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/status.load to /etc/httpd/conf.modules.d/status.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/substitute.load to /etc/httpd/conf.modules.d/substitute.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/suexec.load to /etc/httpd/conf.modules.d/suexec.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/systemd.load to /etc/httpd/conf.modules.d/systemd.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/unixd.load to /etc/httpd/conf.modules.d/unixd.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/usertrack.load to /etc/httpd/conf.modules.d/usertrack.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/version.load to /etc/httpd/conf.modules.d/version.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/vhost_alias.load to /etc/httpd/conf.modules.d/vhost_alias.load", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/wsgi.conf to /etc/httpd/conf.modules.d/wsgi.conf", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf.modules.d/wsgi.load to /etc/httpd/conf.modules.d/wsgi.load", 
        "INFO:__main__:Deleting /etc/httpd/conf/httpd.conf", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf/httpd.conf to /etc/httpd/conf/httpd.conf", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/httpd/conf/ports.conf to /etc/httpd/conf/ports.conf", 
        "INFO:__main__:Creating directory /etc/my.cnf.d", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/etc/my.cnf.d/tripleo.cnf to /etc/my.cnf.d/tripleo.cnf", 
        "INFO:__main__:Creating directory /var/www/cgi-bin/gnocchi", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src/var/www/cgi-bin/gnocchi/app to /var/www/cgi-bin/gnocchi/app", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src-ceph/ceph.conf to /etc/ceph/ceph.conf", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src-ceph/ceph.mon.keyring to /etc/ceph/ceph.mon.keyring", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src-ceph/ceph.client.admin.keyring to /etc/ceph/ceph.client.admin.keyring", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src-ceph/ceph.mgr.lab-controller-0.keyring to /etc/ceph/ceph.mgr.lab-controller-0.keyring", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src-ceph/ceph.client.openstack.keyring to /etc/ceph/ceph.client.openstack.keyring", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src-ceph/ceph.client.manila.keyring to /etc/ceph/ceph.client.manila.keyring", 
        "INFO:__main__:Copying /var/lib/kolla/config_files/src-ceph/ceph.client.radosgw.keyring to /etc/ceph/ceph.client.radosgw.keyring", 
        "INFO:__main__:Writing out command to execute", 
        "INFO:__main__:Setting permission for /var/log/gnocchi", 
        "INFO:__main__:Setting permission for /etc/ceph/ceph.client.openstack.keyring", 
        "++ cat /run_command", 
        "+ CMD='/usr/bin/bootstrap_host_exec gnocchi_api /usr/bin/gnocchi-upgrade --sacks-number=128'", 
        "+ ARGS=", 
        "+ [[ ! -n '' ]]", 
        "+ . kolla_extend_start", 
        "++ GNOCCHI_LOG_DIR=/var/log/kolla/gnocchi", 
        "++ [[ ! -d /var/log/kolla/gnocchi ]]", 
        "++ mkdir -p /var/log/kolla/gnocchi", 
        "+++ stat -c %U:%G /var/log/kolla/gnocchi", 
        "++ [[ root:kolla != \\g\\n\\o\\c\\c\\h\\i\\:\\k\\o\\l\\l\\a ]]", 
        "++ chown gnocchi:kolla /var/log/kolla/gnocchi", 
        "+++ stat -c %a /var/log/kolla/gnocchi", 
        "++ [[ 2755 != \\7\\5\\5 ]]", 
        "++ chmod 755 /var/log/kolla/gnocchi", 
        "++ . /usr/local/bin/kolla_gnocchi_extend_start", 
        "+++ [[ centos =~ debian|ubuntu ]]", 
        "+++ rm -rf /var/run/httpd/htcacheclean /run/httpd/htcacheclean '/tmp/httpd*'", 
        "+++ [[ -n '' ]]", 
        "+ echo 'Running command: '\\''/usr/bin/bootstrap_host_exec gnocchi_api /usr/bin/gnocchi-upgrade --sacks-number=128'\\'''", 
        "+ exec /usr/bin/bootstrap_host_exec gnocchi_api /usr/bin/gnocchi-upgrade --sacks-number=128", 
        "2019-06-05 19:21:10,732 [22] WARNING  oslo_config.cfg: Deprecated: Option \"coordination_url\" from group \"storage\" is deprecated. Use option \"coordination_url\" from group \"DEFAULT\".", 
        "2019-06-05 19:21:10,732 [22] INFO     gnocchi.service: Gnocchi version 4.3.3.dev4", 
        "2019-06-05 19:21:10,924 [22] INFO     gnocchi.cli.manage: Upgrading indexer SQLAlchemyIndexer: mysql+pymysql://***:***@172.16.2.110/gnocchi?read_default_group=tripleo&read_default_file=/etc/my.cnf.d/tripleo.cnf", 
        "2019-06-05 19:21:11,080 [22] INFO     gnocchi.common.ceph: Ceph storage backend use 'cradox' python library", 
        "2019-06-05 19:21:11,119 [22] INFO     gnocchi.cli.manage: Upgrading storage CephStorage: 473c3318-87c3-11e9-861d-5254009e1c0e", 
        "2019-06-05 19:21:11,120 [22] INFO     gnocchi.cli.manage: Upgrading incoming storage RedisStorage: Redis<ConnectionPool<Connection<host=172.16.2.186,port=6379,db=0>>>", 
        "stdout: 7b88501a84cc5c0fe3cba173b643141342193c3ebbd2ab2e18e90fee50eee646", 
        "stderr: ", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_gnocchi_statsd.service to /etc/systemd/system/tripleo_gnocchi_statsd.service.", 
        "Created symlink from /etc/systemd/system/timers.target.wants/tripleo_gnocchi_statsd_healthcheck.timer to /etc/systemd/system/tripleo_gnocchi_statsd_healthcheck.timer.", 
        "Created symlink from /etc/systemd/system/tripleo_gnocchi_statsd.service.requires/tripleo_gnocchi_statsd_healthcheck.timer to /etc/systemd/system/tripleo_gnocchi_statsd_healthcheck.timer.", 
        "stdout: 646e18132cf23f30e393626bd2037491e2ad17f397e5ca33f96ec8a9000dd5c9", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_gnocchi_metricd.service to /etc/systemd/system/tripleo_gnocchi_metricd.service.", 
        "Created symlink from /etc/systemd/system/timers.target.wants/tripleo_gnocchi_metricd_healthcheck.timer to /etc/systemd/system/tripleo_gnocchi_metricd_healthcheck.timer.", 
        "Created symlink from /etc/systemd/system/tripleo_gnocchi_metricd.service.requires/tripleo_gnocchi_metricd_healthcheck.timer to /etc/systemd/system/tripleo_gnocchi_metricd_healthcheck.timer.", 
        "stdout: 4a00cb698256e471bd3457e656a3c2f795717bb5de4695a51c3dba745bd6c5e7", 
        "Created symlink from /etc/systemd/system/multi-user.target.wants/tripleo_gnocchi_api.service to /etc/systemd/system/tripleo_gnocchi_api.service.", 
        "Created symlink from /etc/systemd/system/timers.target.wants/tripleo_gnocchi_api_healthcheck.timer to /etc/systemd/system/tripleo_gnocchi_api_healthcheck.timer.", 
        "Created symlink from /etc/systemd/system/tripleo_gnocchi_api.service.requires/tripleo_gnocchi_api_healthcheck.timer to /etc/systemd/system/tripleo_gnocchi_api_healthcheck.timer.", 
        "stdout: "
    ]
}
2019-06-05 14:21:51,547 p=17240 u=mistral |  ok: [lab-computehci-0] => {
    "failed_when_result": false, 
    "outputs.stdout_lines | default([]) | union(outputs.stderr_lines | default([]))": [
        "stdout: Found 2 cell mappings.", 
        "Skipping cell0 since it does not contain hosts.", 
        "Getting computes from cell 'default': 3ce3c85b-c9f1-41f3-91ed-1b86be063631", 
        "Creating host mapping for service lab-computehci-0.localdomain", 
        "Found 1 unmapped computes in cell: 3ce3c85b-c9f1-41f3-91ed-1b86be063631", 
        "", 
        "stderr: + command -v python3", 
        "+ command -v python2", 
        "+ python2 /container-config-scripts/nova_cell_v2_discover_hosts.py"
    ]
}
2019-06-05 14:21:51,572 p=17240 u=mistral |  TASK [Clean container_puppet_tasks for lab-controller-0 step 5] ****************
2019-06-05 14:21:51,572 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:520
2019-06-05 14:21:51,572 p=17240 u=mistral |  Wednesday 05 June 2019  14:21:51 -0500 (0:00:00.076)       0:18:25.342 ******** 
2019-06-05 14:21:51,691 p=17240 u=mistral |  ok: [lab-controller-0] => {"changed": false, "path": "/var/lib/container-puppet/container-puppet-tasks5.json", "state": "absent"}
2019-06-05 14:21:51,718 p=17240 u=mistral |  ok: [lab-computehci-0] => {"changed": false, "path": "/var/lib/container-puppet/container-puppet-tasks5.json", "state": "absent"}
2019-06-05 14:21:51,743 p=17240 u=mistral |  TASK [Calculate container_puppet_tasks for lab-controller-0 step 5] ************
2019-06-05 14:21:51,744 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:527
2019-06-05 14:21:51,744 p=17240 u=mistral |  Wednesday 05 June 2019  14:21:51 -0500 (0:00:00.171)       0:18:25.513 ******** 
2019-06-05 14:21:51,818 p=17240 u=mistral |  TASK [Write container-puppet-tasks json file for lab-controller-0 step 5] ******
2019-06-05 14:21:51,818 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:537
2019-06-05 14:21:51,818 p=17240 u=mistral |  Wednesday 05 June 2019  14:21:51 -0500 (0:00:00.074)       0:18:25.588 ******** 
2019-06-05 14:21:51,859 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:21:52,119 p=17240 u=mistral |  changed: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": true}
2019-06-05 14:21:52,144 p=17240 u=mistral |  TASK [Run container-puppet tasks (bootstrap tasks) for step 5] *****************
2019-06-05 14:21:52,144 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:548
2019-06-05 14:21:52,144 p=17240 u=mistral |  Wednesday 05 June 2019  14:21:52 -0500 (0:00:00.325)       0:18:25.913 ******** 
2019-06-05 14:21:52,184 p=17240 u=mistral |  skipping: [lab-computehci-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:22:03,846 p=17240 u=mistral |  ok: [lab-controller-0] => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false}
2019-06-05 14:22:03,871 p=17240 u=mistral |  TASK [Debug output for task: Run container-puppet tasks (bootstrap tasks) for step 5] ***
2019-06-05 14:22:03,871 p=17240 u=mistral |  task path: /var/lib/mistral/lab/common_deploy_steps_tasks.yaml:567
2019-06-05 14:22:03,871 p=17240 u=mistral |  Wednesday 05 June 2019  14:22:03 -0500 (0:00:11.726)       0:18:37.640 ******** 
2019-06-05 14:22:03,901 p=17240 u=mistral |  ok: [lab-controller-0] => {
    "failed_when_result": false, 
    "outputs.stdout_lines | default([]) | union(outputs.stderr_lines | default([]))": [
        "2019-06-05 19:21:52,407 INFO: 80443 -- Running container-puppet", 
        "2019-06-05 19:21:52,408 INFO: 80443 -- Service compilation completed.", 
        "2019-06-05 19:21:52,408 INFO: 80443 -- Starting multiprocess configuration steps.  Using 4 processes.", 
        "2019-06-05 19:21:52,413 INFO: 80472 -- Starting configuration of mysql_init_tasks using image docker.io/tripleostein/centos-binary-mariadb:current-tripleo-rdo", 
        "2019-06-05 19:21:52,413 INFO: 80473 -- Starting configuration of cinder_init_tasks using image docker.io/tripleostein/centos-binary-cinder-api:current-tripleo-rdo", 
        "2019-06-05 19:21:52,413 INFO: 80474 -- Starting configuration of rabbit_init_tasks using image docker.io/tripleostein/centos-binary-rabbitmq:current-tripleo-rdo", 
        "2019-06-05 19:21:52,415 INFO: 80475 -- Starting configuration of keystone_init_tasks using image docker.io/tripleostein/centos-binary-keystone:current-tripleo-rdo", 
        "2019-06-05 19:21:52,596 INFO: 80473 -- Removing container: container-puppet-cinder_init_tasks", 
        "2019-06-05 19:21:52,812 INFO: 80475 -- Removing container: container-puppet-keystone_init_tasks", 
        "2019-06-05 19:21:52,816 INFO: 80474 -- Removing container: container-puppet-rabbit_init_tasks", 
        "2019-06-05 19:21:52,819 INFO: 80472 -- Removing container: container-puppet-mysql_init_tasks", 
        "2019-06-05 19:21:53,146 INFO: 80473 -- Image already exists: docker.io/tripleostein/centos-binary-cinder-api:current-tripleo-rdo", 
        "2019-06-05 19:21:53,438 INFO: 80472 -- Image already exists: docker.io/tripleostein/centos-binary-mariadb:current-tripleo-rdo", 
        "2019-06-05 19:21:53,441 INFO: 80475 -- Image already exists: docker.io/tripleostein/centos-binary-keystone:current-tripleo-rdo", 
        "2019-06-05 19:21:53,446 INFO: 80474 -- Image already exists: docker.io/tripleostein/centos-binary-rabbitmq:current-tripleo-rdo", 
        "2019-06-05 19:22:02,601 WARNING: 80472 -- + mkdir -p /etc/puppet", 
        "+ cp -dR /tmp/puppet-etc/auth.conf /tmp/puppet-etc/hiera.yaml /tmp/puppet-etc/hieradata /tmp/puppet-etc/modules /tmp/puppet-etc/puppet.conf /tmp/puppet-etc/ssl /etc/puppet", 
        "+ rm -Rf /etc/puppet/ssl", 
        "+ echo '{\"step\": 5}'", 
        "+ TAGS=", 
        "+ '[' -n file,file_line,concat,augeas,cron,mysql_database,mysql_grant,mysql_user ']'", 
        "+ TAGS='--tags file,file_line,concat,augeas,cron,mysql_database,mysql_grant,mysql_user'", 
        "+ CHECK_MODE=", 
        "+ '[' -d /tmp/puppet-check-mode ']'", 
        "+ origin_of_time=/var/lib/config-data/mysql_init_tasks.origin_of_time", 
        "+ touch /var/lib/config-data/mysql_init_tasks.origin_of_time", 
        "+ sync", 
        "+ export NET_HOST=true", 
        "+ NET_HOST=true", 
        "+ set +e", 
        "+ '[' true == false ']'", 
        "+ export FACTER_deployment_type=containers", 
        "+ FACTER_deployment_type=containers", 
        "++ cat /sys/class/dmi/id/product_uuid", 
        "++ tr '[:upper:]' '[:lower:]'", 
        "+ export FACTER_uuid=ad8c85d9-6f5f-4d90-97fa-e31eefd815d6", 
        "+ FACTER_uuid=ad8c85d9-6f5f-4d90-97fa-e31eefd815d6", 
        "+ /usr/bin/puppet apply --summarize --detailed-exitcodes --color=false --logdest syslog --logdest console --modulepath=/etc/puppet/modules:/usr/share/openstack-puppet/modules --tags file,file_line,concat,augeas,cron,mysql_database,mysql_grant,mysql_user /etc/config.pp", 
        "+ rc=2", 
        "+ set -e", 
        "+ '[' 2 -ne 2 -a 2 -ne 0 ']'", 
        "+ '[' -z true ']'", 
        "", 
        "2019-06-05 19:22:02,602 INFO: 80472 -- Removing container: container-puppet-mysql_init_tasks", 
        "2019-06-05 19:22:02,605 WARNING: 80475 -- + mkdir -p /etc/puppet", 
        "+ '[' -n file,file_line,concat,augeas,cron,keystone_config,keystone_domain_config,keystone_endpoint,keystone_identity_provider,keystone_paste_ini,keystone_role,keystone_service,keystone_tenant,keystone_user,keystone_user_role,keystone_domain ']'", 
        "+ TAGS='--tags file,file_line,concat,augeas,cron,keystone_config,keystone_domain_config,keystone_endpoint,keystone_identity_provider,keystone_paste_ini,keystone_role,keystone_service,keystone_tenant,keystone_user,keystone_user_role,keystone_domain'", 
        "+ origin_of_time=/var/lib/config-data/keystone_init_tasks.origin_of_time", 
        "+ touch /var/lib/config-data/keystone_init_tasks.origin_of_time", 
        "+ /usr/bin/puppet apply --summarize --detailed-exitcodes --color=false --logdest syslog --logdest console --modulepath=/etc/puppet/modules:/usr/share/openstack-puppet/modules --tags file,file_line,concat,augeas,cron,keystone_config,keystone_domain_config,keystone_endpoint,keystone_identity_provider,keystone_paste_ini,keystone_role,keystone_service,keystone_tenant,keystone_user,keystone_user_role,keystone_domain /etc/config.pp", 
        "2019-06-05 19:22:02,605 INFO: 80475 -- Removing container: container-puppet-keystone_init_tasks", 
        "2019-06-05 19:22:02,877 INFO: 80472 -- Finished processing puppet configs for mysql_init_tasks", 
        "2019-06-05 19:22:02,914 INFO: 80475 -- Finished processing puppet configs for keystone_init_tasks", 
        "2019-06-05 19:22:03,491 WARNING: 80474 -- + mkdir -p /etc/puppet", 
        "+ '[' -n file,file_line,concat,augeas,cron,rabbitmq_policy,rabbitmq_user ']'", 
        "+ TAGS='--tags file,file_line,concat,augeas,cron,rabbitmq_policy,rabbitmq_user'", 
        "+ origin_of_time=/var/lib/config-data/rabbit_init_tasks.origin_of_time", 
        "+ touch /var/lib/config-data/rabbit_init_tasks.origin_of_time", 
        "+ /usr/bin/puppet apply --summarize --detailed-exitcodes --color=false --logdest syslog --logdest console --modulepath=/etc/puppet/modules:/usr/share/openstack-puppet/modules --tags file,file_line,concat,augeas,cron,rabbitmq_policy,rabbitmq_user /etc/config.pp", 
        "2019-06-05 19:22:03,492 INFO: 80474 -- Removing container: container-puppet-rabbit_init_tasks", 
        "2019-06-05 19:22:03,610 WARNING: 80473 -- + mkdir -p /etc/puppet", 
        "+ '[' -n file,file_line,concat,augeas,cron,cinder_config,cinder_type,file,concat,file_line ']'", 
        "+ TAGS='--tags file,file_line,concat,augeas,cron,cinder_config,cinder_type,file,concat,file_line'", 
        "+ origin_of_time=/var/lib/config-data/cinder_init_tasks.origin_of_time", 
        "+ touch /var/lib/config-data/cinder_init_tasks.origin_of_time", 
        "+ /usr/bin/puppet apply --summarize --detailed-exitcodes --color=false --logdest syslog --logdest console --modulepath=/etc/puppet/modules:/usr/share/openstack-puppet/modules --tags file,file_line,concat,augeas,cron,cinder_config,cinder_type,file,concat,file_line /etc/config.pp", 
        "2019-06-05 19:22:03,610 INFO: 80473 -- Removing container: container-puppet-cinder_init_tasks", 
        "2019-06-05 19:22:03,723 INFO: 80474 -- Finished processing puppet configs for rabbit_init_tasks", 
        "2019-06-05 19:22:03,761 INFO: 80473 -- Finished processing puppet configs for cinder_init_tasks"
    ]
}
2019-06-05 14:22:03,910 p=17240 u=mistral |  skipping: [lab-computehci-0] => {}
2019-06-05 14:22:03,911 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:22:03,911 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:22:03,915 p=17240 u=mistral |  PLAY [Server Post Deployments] *************************************************
2019-06-05 14:22:03,917 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:22:03,939 p=17240 u=mistral |  TASK [include_tasks] ***********************************************************
2019-06-05 14:22:03,940 p=17240 u=mistral |  task path: /var/lib/mistral/lab/deploy_steps_playbook.yaml:554
2019-06-05 14:22:03,940 p=17240 u=mistral |  Wednesday 05 June 2019  14:22:03 -0500 (0:00:00.068)       0:18:37.709 ******** 
2019-06-05 14:22:03,977 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:22:03,977 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:22:03,981 p=17240 u=mistral |  PLAY [External deployment Post Deploy tasks] ***********************************
2019-06-05 14:22:03,982 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:22:03,982 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:22:03,983 p=17240 u=mistral |  META: ran handlers
2019-06-05 14:22:03,983 p=17240 u=mistral |  PLAY RECAP *********************************************************************
2019-06-05 14:22:03,983 p=17240 u=mistral |  lab-computehci-0           : ok=193  changed=90   unreachable=0    failed=0   
2019-06-05 14:22:03,983 p=17240 u=mistral |  lab-controller-0           : ok=258  changed=142  unreachable=0    failed=0   
2019-06-05 14:22:03,983 p=17240 u=mistral |  undercloud                 : ok=45   changed=19   unreachable=0    failed=0   
2019-06-05 14:22:03,984 p=17240 u=mistral |  Wednesday 05 June 2019  14:22:03 -0500 (0:00:00.043)       0:18:37.753 ******** 
2019-06-05 14:22:03,984 p=17240 u=mistral |  =============================================================================== 
